{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ea1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86576f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a0de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yelp = pd.read_csv(\"yelp_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a40b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yelp=df_yelp.set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904116b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yelp=df_yelp.rename(columns={\"Consumer_complaint_narrative\":\"review\",\"category_id\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3818ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_yelp.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf8b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c8821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers=list(df['label'].unique())\n",
    "# list_zeros = [0]*5\n",
    "# count_dictionary = dict(zip(numbers, list_zeros))\n",
    "\n",
    "# values_array_train=[]\n",
    "# values_array_test=[]\n",
    "# values_array_unlabelled=[]\n",
    "# for index, row in df.iterrows():\n",
    "#     if count_dictionary[row['label']]<20:\n",
    "#         count_dictionary[row['label']]=count_dictionary[row['label']]+1\n",
    "#         values_array_train.append((row['review'],row['label']))\n",
    "#     elif count_dictionary[row['label']]<60:\n",
    "#         count_dictionary[row['label']]=count_dictionary[row['label']]+1\n",
    "#         values_array_test.append((row['review'],row['label']))\n",
    "#     elif count_dictionary[row['label']]<600:\n",
    "#         count_dictionary[row['label']]=count_dictionary[row['label']]+1\n",
    "#         values_array_unlabelled.append((row['review'],'UNK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c542416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_l=pd.read_csv(\"assigned/train_l.csv\", index_col=\"Unnamed: 0\")\n",
    "df_test_l=pd.read_csv(\"assigned/test_l.csv\", index_col=\"Unnamed: 0\")\n",
    "df_u=pd.read_csv(\"assigned/u.csv\", index_col=\"Unnamed: 0\")\n",
    "df_train_u=pd.read_csv(\"assigned/train_u.csv\", index_col=\"Unnamed: 0\")\n",
    "df_test_u=pd.read_csv(\"assigned/test_u.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8852454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huge gender imbalance and rude staff.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Didn't come here to eat just drink but can't r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nova's is great  if you get their fresh bread....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got coconut shaved ice with condensed milk a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very nice octogenarian who was wholly unable t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0              Huge gender imbalance and rude staff.  1\n",
       "1  Didn't come here to eat just drink but can't r...  3\n",
       "2  Nova's is great  if you get their fresh bread....  4\n",
       "3  I got coconut shaved ice with condensed milk a...  5\n",
       "4  Very nice octogenarian who was wholly unable t...  2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_l.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db7938f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_array_train=list(df_train_l.to_records(index=False))\n",
    "values_array_test=list(df_test_l.to_records(index=False))\n",
    "values_array_unlabelled=df_u.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804df80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a0c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f64668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_unlabelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67737956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I love Starbucks coffee.  My new favorite is the blonde roast.  This location gets pretty crowded, especially on Friday mornings.  The baristas here are really friendly.', 5), ('This place is so good I have never had bad food or service. The owner Kevin makes sure you leave happy. The pizza and wings are the best any were.', 5), ('i came in as a tourist in the early afternoon with friends. The local folks were having a great time. We got the full tourist tour by the bartender, she was patient and made some great drinks. Love Tiki and this bar was fun!!', 5), ('Roasted chicken with apricot glaze was perfect! Perfectly moist with delicious flavor.', 5), ('Great Pizza & service. Will go back', 4), ('My favorite! I love that they use plastic protectors for the pedicure tubs. I love the massage chairs. The staff is always friendly & welcoming. My pedicure lasts & lasts. Mona is the best!', 5), ('Had a flat and went to a Big O Tires to get it fix. Front desk manager Pat was great and replace my tire and had me out the door in under 15 minutes. Great job and great crew.', 5), ('Beautiful restaurant like if a freakin greek temple was a dance club.  Love Pelmini (dumplings in lemon sauce), stuffed grape leaves with meat gravy, crab roll-a-snacks, even juicy chicken wings.  Ton of tasty Greek tapas', 4), ('We were in town for the Arizona State v. Wisconsin game and, of course, had to stop at State Street Brats.  Great atmosphere and good food.  One of the best places I have ever been to watch college football.', 4), ('Great food and great staff!  Service was fast and constant.  Prices are reasonable for the portions.  Love this place and will be going back!', 5), ('The best sandwiches that I have ever had, hands down.  This shop is actually a big reason that we book our rooms at Planet Hollywood.  Breakfast sandwiches are amazing.  We actually go to restaurants for drinks and then to Earl of Sandwich for dinner.  :)', 5), ('Very professional cleaning, and very nice people. My wife and I have used their services for years, and I highly recommend to all.', 5), (\"Perfect atmosphere. Best BLT, fried pickles and pasta salad(with Stevie's dressing.) One of my favorites in Charlotte.\", 5), (\"Order the Black Cod Miso! Hands down the best fish that I've ever tasted.\", 5), ('Always a favorite', 3), ('Grade: C-\\\\n\\\\nI really hope that was chicken in my Chicken Lo-Mein. What happened to this place? What a dump. Good service but I kept wondering how old the huge mold stain on the ceiling was.', 3), ('Just have the cake.', 3), ('Great food.', 5), ('Too pricey and not kid friendly', 3), ('love this place! the entire staff from the hostess, servers to sushi chefs are very nice and friendly. Our favorite sushi, and a MUST TRY in our opinion is THE MONICA --- yummmm-oh! :)', 5), ('This place is beautiful! I thoroughly enjoyed my walk through and time spent here. They have nice shops, a place for getting tattooed, nice restaurants, and fun attractions like Cirque du Soleil and CSI Experience!  I will be back next time.', 4), ('Food was good when it finally came.  Portions were small.  They had no staff working.  Waited 20 minutes to place drink order.  Probably will not go back.', 1), ('Food was great and the employees were great.  No free beverage refills though.  I was hoping id get a little more pork also.', 3), (\"I love this people, they are super nice and fab at what they do! I'm so happy I found them!\", 5), ('Nice quality tuna excellent use of sesame seed on the sushi roll positive experience tried the jalapeno bomber hotttt!', 4), (\"It's subway, it's consistent, its cheap...\", 3), (\"Food was unreal.  Was in town on a business trip and this was a home run for a quick lunch.  I usually dip my fry's in ranch, and this was the best ranch I have ever had. Beef was pure and cooked perfectly.\", 5), (\"Don't get the godfather you will be on the toilet. Been on the toilet for an hour already. Tony your restaurant is going downhill.\", 1), ('Not the best or least expensive option in town, but the avocado enchiladas are a light modern twist on a classic dish. Mi Gusta', 3), ('Good music and dancers on Thursday Salsa & Club Night.', 3), ('Love, love, love this LV store ! The people were very friendly and helpful, not snotty like you might find in other LV stores. The sales associate went out of her way to help me find the perfect wallet . Sssooo pleased with my purchase !', 5), ('Really, really cute but way overpriced. Love the clothes though.', 4), ('Nothing at this location.  I would rather go elsewhere in Queen Creek.  It is not worth coming here.', 2), (\"My favorite grocery in the area. Staff is friendly; and they always have great deals. You can get sandwiches made to order too, which a lot of people don't realize!\", 5), (\"The food is good and teppan is always fun.  I like the pink rice they make on the flat top, too.  Even though their tricks are the usuals, they're still very entertaining.\", 3), ('I rated it lower because its in the middle of a dirty hotel that smells. but the pastries are yummy and staff are nice. Still overpriced like the other local ones in the area.', 3), ('Nice employees, nice location, Awful sushi.  Should have known something was amiss when it was empty at 6:30 on a Friday night.  Surely there are better places in town.', 2), (\"Love this place!! I love that the pizza design your own at the same price. No up charging. S'mores pizza for dessert is a must!!! Fast, hot, and fresh!!\", 5), ('Good food at a reasonable price in a very comfortable setting overlooking the strip.', 5), (\"No oysters in their AYCE Sushi dinner menu! Try the spicy seafood salad.. you can get a half order, you'll like it!\", 4), (\"Yelpers are correct! This place is something special. The food is delicious and they have great customer service. The fusion tacos, fusion flautas, bulgogi plate and fried rice were sooo good! Will definitely come back the next time we're in Vegas.\", 5), ('Terrible service. Our waiter was offensive and bad at serving the drinks the customer ordered', 1), ('best. burger. in. the. world.', 5), (\"I thought my salad was disgusting.  I had chicken on my salad and I thought I was chewing on a chicken foot....Yuck! There was almost no lettuce mostly black bean juice and gristle.  I will not go back again and I suggest you don't either.\", 1), (\"Yuk. not very tasty at all. only good point was that the counter guy caught that they had missed the bacon (if you can call it that) on hubby's burger.\", 1), (\"This place has EXCELLENT food, with generous helpings!\\\\nMaybe that's why in the AM it usually has a bit of a line.\\\\nI've never been disappointed, and the prices are very reasonable.\", 4), ('Tasty, well-priced Malaysian cuisine unfussily presented and served in next to no time.', 3), (\"I've never had a tough time checking into Sky Harbor.  I do have trouble picking people up because I don't read the signs correctly :)  If my flights delayed I know that I can chill at one of the great bars they have in the Terminal 4.\", 3), ('By far one of the best buffets in las Vegas!', 4), ('Tried the Fajita Chicken and Beef mixed, is one of the best I tried. Other foods though are OK. Servings are huge!!', 3), ('Love this place, great beer selection, appetizers are as big as full meals and staff are friendly and attentive. Great place to stop after work. Happy hour could be a bit more generous but oh well.', 5), ('Great place to go to especially on the weekends, Thursdays, Fridays, and Saturdays.  Line can be long, but if you know people, you can pretty much just get in before other people.', 4), ('no microwave or fridge; kind of weak A/C; no ice machine on second floor; ghetto part of town.', 2), ('Overrated. By serving everything tapas-style, Wicked Spoon has essentially increased the surface area of all dishes, allowing for maximum heat lamp dry-age. Yay.', 2), ('Outstanding customer service,friendly and knowledgeable staff,best prices around.\\\\nIf you shop elsewhere,you are a bad person,and should feel bad.', 5), (\"Had lunch here today. The service was extremely slow. It took several minutes, I'd guess about 15, for someone to take my order, and then another 15 or 20 minutes for the order to get to my table.  The food was very good but don't be in a hurry.\", 2), ('Best bakery, very awesome atmosphere.', 5), ('We ordered the Chicken panin and Tuna. What a waste of money. Awful! Will never return.  Paradise is 1000 times better.', 1), ('Good food. Great location. Good service.', 3), (\"Will never go back, Have been here twice, what a mistake. Expect to send your food back when it comes out. Burgers were burnt , Soup was cold. Everything is loaded with salt. Awful food. Cosmopolitan staff doesn't care if you complain about it\", 1), (\"If you have patience, this place isn't too bad. Ramen is good. Be sure to order the honey toast for dessert. However, it took another 20 min to come out.\", 3), (\"My family has been using this dental office for over 10 years now!  The staff really cares about their patients. I love this place. Not a fan of getting dental work done but I surely wouldn't do it anywhere else\", 5), ('Pizza is very good!  Patio is nice and well shaded.  They will allow pets on the patio if well behaved!', 3), ('The folks running this place remain enthusiastic and friendly, but the food has become a bit too sweet, even the savory dishes are much too sweet. It is too bad as I really liked the food the first few times we went.', 2), (\"The view is absolutely amazing, as is the staff! We went to see the High Roller about a week ago and we were not disappointed! Go at night. It's worth the extra money and the lights are spectacular.\", 5), ('Horrible breakfast. Leathery eggs, razor-thin soggy bacon, COLD breakfast potatoes and only one slice of barely-singed toast. Staff was lackluster and kept forgetting items. Maybe their pizza is OK, but best avoided for breakfast.', 1), ('OMG....  By far the best food I have ever had.', 5), ('Good food, great prices, good service.', 5), (\"Don't waste your time.  They don't listen to your order and then give you attitude when you question them on accuracy and quality.  Chick with tats and piercings is rude and arrogant.\", 1), ('I was not a fan of the psychedelic \\\\ng strings, the neon electric pants , the store doesnt \\\\nhave nothing nice  unless you want to wear a tutu and some crazy ass pants', 1), (\"This is a hidden gem in Mesa.  It was one of the best Thai restaurants I've ever eat at in my life.  Not only was the food excellent, but the service was superb.  We were able to get the flat noodles and also a rice dish.  I cannot wait to go back.\", 5), (\"If you're a cupcake fanatic like me, you'll like this place!! Tried their red velvet cupcake (which is as big as a muffin, but very moist & awesome frosting. Gotta try this place!\", 3), ('Oyster shooters in a plastic cup. Looked a little dirty. Shooters just tasted like ketchup.', 1), ('Helpful staff....thanks, Manuel. Quiet haven, inexpensive meal. But, dammit, a marguerite pizza is NOT supposed to have sauce on it. Hence the three stars.', 3), (\"Service is hit or miss. Pretty typical of a small nail salon. Shirley is fantastic..I'm not sure what to say about some of the other nail technicians..they've always done a consistent job with my manicures and pedicures but bad attitudes can definitely ruin the experience.\", 3), (\"Service is terrible. Server literally came up to the table and said you ready? We didn't have water or anything. He didn't bring water for another 10 min. I'm forced to put 1star but I would be 0 stars if I could. Service first!\", 1), (\"The bathroom is disgusting, it should be check on regularly, especially when there are 3 of you working an no one actually doing anything and you're not busy.\\\\n\\\\nAs far as service and product, it's Starbucks.\", 1), ('Compared to other options in the area, Brewskes is just a dated, overpriced dive bar.  The Menu has improved, but everything else (including the atmosphere) makes you wonder how they can justify chrginng the prices they do. There are much nicer places.', 1), ('All our food was bland and burnt. 2 nights in a row. Probably cuz we stumbled in past 3am. But still. Come on.', 2), (\"No matter how any times they tell me that this is the friendliest airport over the PA system, it still doesn't make it true..\\\\n\\\\nThe good thing is that the security lines are short the majority of the time.\", 2), (\"Only good for girls. They treat guys like shit until they buy a table. This club is not a hot club so unless you roll with a bunch of girls don't even bother.\", 1), ('The rooms are nice and good. The staff was friendly.  It is a nice place to stay. It can be pricey but one of my top hotels on the strip in Las Vegas.', 5), (\"Be careful if they walk around with a pan of cupcakes offering them.\\\\n\\\\nyou may think it's a nice gesture from the restaurant, but if you take one, its $2\\\\n\\\\nTotally uncool.\", 2), (\"Just opened and their service is dialed in. Great, fun atmosphere. Food was really good. Portions were big. It's obvious the employees love working there. Keep up the good work!\", 5), (\"We stayed Downtown Phoenix and took the light rail to the Sun Devil Stadium, with a quick stop for the bars on Mill. Couldn't have been easier!  No parking or traffic worries. Also didn't have to worry about having a drink. Easy, fast and trouble-free.\", 5), ('Awesome breakfast! Great service! I had the chili cheese omelet. Best omelets around. This is my new favorite place for breakfast!', 5), ('Food is great and so was service. Wings plump and juicy', 5), (\"One of the best Chinese places in Arizona by far. Independent from the other Chen's, this one seems to focus on the eating experience. Decor and customer service is a A+ in my book!\\\\n\\\\nWill be back!\", 5), (\"Dirty location and very high prices but they do have great daily specials.  The employees were nice but I won't be back to this location.\", 2), (\"Fantastic!! Love the Ramen! There's definitely a wait but worth it. Get the Gyoza and Miso Ramen. I get the Spicy Miso Ramen with extra bamboo shoots. Yummmmy!!\", 5), (\"Waited an hour and a half for my 10 year son to get pain meds with a broken arm!!! Not acceptable! ! They won't even see you unless you check in at a kiosk\", 1), ('Food is terrible and the owner is rude. Very unpleasant experience.', 1), (\"They have good chicken and bomb biscuits when fresh. I just hate the service and paying for sauce. I mean I just bought a 12 pc bucket can I have atleast one sauce? I understand if I didn't buy chicken but whatever lol end rant.\", 3), ('Delicious, Unique experience, great for groups or intimate dinners.', 5), ('My favorite park! I love hiking up the hill and enjoying the view. The park is always clean and well maintained. My daughter really enjoys the water feature and playground here also.', 5), ('Bad food and even worse service. Do not waste your time or money. I ordered the Cuban sandwich and it tasted like it just came from the microwave.', 1), ('Amazing happy hour and lunch menu! Good for date nights, groups, or families. Sushi is always fresh and tastes great! Drink deals are a plus with delicious green tea ice cream to end the visit. I highly recommend Yen Sushi!', 5), (\"Dirty, dirty bathrooms.  If this is what your bathrooms look like I'd hate to see what the deli area looks like, or wherever else you store food products.  Posting pics of the bathroom and the hilarious sign regarding the cleanliness of bathrooms.\", 1), ('Great meals,drinks and service in the bar. Happy hour until 7pm is a plus. We experienced none of the problems recently experienced by others, other than they were out of Corona beer. Nice change of pace from usual Westside restaurants and menus. Will return soon.', 4), ('I have been here a couple times to eat inside their family restaurant.  They run a great business. Their food is great I love the yellow coconut curry at a level 10! I get their food to go all of the time. They are quick and easy to communicate with.', 5), (\"This establishment has outgrown it's community, patients hidden in every nook & cranny.  Staff are knowledgable and friendly. The building it's self is extremely old and in need if repairs.\", 2), ('Place has great food! Service was slow due to how busy it was but well worth the wait.\\\\n\\\\nHighly recommended place for breakfast!', 4), (\"Great venue for music. The bartenders perform as if they've been beaten in the head with a club before work. I recommend bringing your own booze since it was approximately a 20 minute wait per drink on a Saturday night with no live music playing.\", 3), ('Rebuilt after being bought from Joe Miller 2 years ago. Great stickie buns and good live music - piano bar, and fantastic views of Camelback Mountain, Mummy Mountain and the Praying Monk!\\\\nFresh Fish and great Steaks!', 4), ('The ambiance at the restaurant was great.  \\\\n\\\\nI was a little disappointed with the mushroom purse, but that was probably because I was expecting something totally different.\\\\n\\\\nMy favorite was the kung pao shrimp.  Perfectly battered and well seasoned!', 3), (\"Okay so as I was eating it I was loving it. So tasty...but then about an hour later I was sick. I won't give you the gory details, but I definitely won't be going there again.\", 1), ('Yeah, this place has true Edinburgh grit. Stopped off for a quickie on way to hotel and stayed for dinner and the friendly company. If you are wandering down Rose Street, give this place a shot.', 4), (\"Tried a green smoothie, the apple and greens. My smoothie was way to icy, i had to ask them to blend it again. Next time, I'll just order my goto here, the mango-a-gogo.\", 2), ('One of the better values in vegas, this hip bastardized mexican place is pretty freakin good.  I got the baby back ribs marinated in some watermellon reduction.  Flan for desert was great.  1+ extra point for ironic  sexual innuendo in the name.', 4), (\"I went to Mimi's for breakfast/brunch and was diappointed.  The food was ok and the prices were a bit on the high side.  Service was decent but my expectations for this place were high and I was disappointed.\", 2), ('We came because of the great reviews.  Our server got almost every order wrong.  I give the one star for the chips and salsa.  I love good Mexican food.  This was not good at all.  I could not eat mine.  I will not try again.  The atmosphere was nice though!', 1), ('Stopped here to get a propane refill and the girl at the counter said no one was working who could refill it for me. \\\\n\\\\nHeads up folks, if you offer a service, you should train someone to do that service, even if it is the weekend!', 1), ('GREAT service! Such friendly staff. Tried Malaysian food for the first time, it was yummy!', 4), ('Just like any other sushi place with a high pricing for the average quality', 1), ('Closed (good riddance) and replaced by the Great Dane (much better)', 1), (\"This place is GARBAGE. Food tasted like a frozen microwave food platter. Service was slow. I wouldn't recommend this place at all. Your better off going to Roberto's.\", 1), ('This place is gross.  The tables are not clean and the staff is rude.  I watched them wipe thier nose and then touch my foood.  When I questioned this the manager said that the germs will \\\\\"cook off\\\\\".  I left with trying thier food.', 1), ('The Roasted Beef Steak tomato and the Spicy Tuna were amazing.  Heather and Cisco are great at the bar.', 4), (\"The staff here is extremely polite and courteous. I haven't been to a Einstein bagels in years I completely forgot how delightful the food is here. I ordered two bagels which only took about 3 minutes to make. If your looking for some fast service I definitely would recommend this place.\", 4), ('This is the only gas station I have every been to in my entire life to charge you to use your debit card and pump said they did not take credit. LAME. Poor beer selection. This convenient store is not very convenient.', 2), (\"This hotel is a good value if you are just looking for a place to sleep. It's an older hotel in need of some repairs. However, the room was clean, the bed was comfortable, and the water pressure was great.\", 2), ('Price is right, but you get what you pay for.', 2), ('Super yummy sandwiches and soups. They make all of their own bread, and have many original choices. The roast beef gorgonzola is awesome!', 4), (\"Due to BPA concerns, I won't be getting hot sandwiches at Jason's anymore. All hot protein on sandwiches are heated in plastic bags. The club sandwiches are still awesome.\", 3), (\"Ate here for breakfast since we were comped coupons.  It was a pretty standard buffet, but for 3 of us to eat with the coupon it was like $10 so can't complain about the price.\", 3), ('Cinnamon toast egg samich is good, but not sure about the sprinkled cinnamon and sugar on egg and American cheese. Coffee is great, I love this place they always get you in and out with out any problems', 2), (\"This place was gross. Spent way too much money for low quality food. My husband barely are his and they didn't even care.\", 1), (\"Nothing gourmet here, greasy fried food. Barely any crab legs.I didn't eat much and I kept throwing good away cause it was nasty. Save your money and go elsewhere.\\\\n\\\\nNot going there again\", 1), ('Decent place, stopped by for dinner for a friends birthday.  \\\\n\\\\nFood was good, but the real winner here is the service!', 4), ('not too bad. pretty big and open and theyve got good picnic table and grill areas. only downside is the screaming sound of airplanes from the airport. but my niece thought it was cool.', 4), ('The array of selection is wonderful. Fresh, clean and tasty.', 3), (\"The service was terrible. The counter help couldn't be bothered. I am from back east and a bit of a sub snob but this place doesn't even come close to good for az standards.\", 1), ('Not bad but definitely not great for the price and wait. The waitresses are nice but very inattentive. The dragon roll at happy hour had burnt eel and the sea bass took over 25 minutes to come out. Not worth my time nor my money.', 2), (\"Bad service. Bad food. Bad lunch for my 12/25. This was last year's 12/25 by the way.\", 2), ('I like this place.  Good service.  Food is pretty standard.', 3), ('Great show. But we never had the sandstorm day replaced.  Bad Pasquale Rotella billionaire.', 2), (\"Everything is great but the staff! I've been there three times and every time I go the same girl is always working! Her nails are always very dirty... it is really gross.\", 3), (\"I want to hate you because you're a chain, but I have to adore you because of your tried and true familiarity. Bless you for having Southwestern Egg Rolls when I truly needed a snack to quell my wicked hangover before I took my 6 hour flight.\", 3), (\"Delicious food....fresh....fresh...   Resonably priced.  Don't forget your punch card\", 4), ('TOTAL RIP OFF! We paid $14 for an 8oz margarita full of ice - wont ever go back - food was flavorless - this place has gone down hill fast - What a total waste of $$$', 1), (\"It was a fun experience, I'm not sure if I'd go back because seafood isn't really my thing. Service was alright but had to keep waiting for a water!\", 3), ('So far. So good. I had a 12 appoint mention and they took me in right away. I just went to get a estimate of the damage and to see if I can get a check right away.', 4), ('Woah! $45 for a mani pedi, hold the phone. Wish they were worth every penny, but unfortunately they were not. Quite the minimal manicure and not so much effort in the pedicure. Definitely not worth the price.', 2), ('This is my favorite shredded beef taco in my area.  The rest of the food is just satisfactory, nothing special.  But, when I am in the mood for tacos, this is a great choice!', 3), (\"stopped here cause we had a gift card.  Next time, I'm giving the gift card away.  SLOWEST service ever!  Drive 5 more minutes & go to Grouchy Johns!!\", 2), ('I was struggling between a 3 & 4 star. It was ok. Nothing happened to make it bad or great. I guess I would go again if I happened to be in the area.', 3), ('Had a firehouse hero sandwich and it was quite delicious.  It was a very flavorful sandwich, the prices were reasonable, and the people there are friendly.', 4), (\"I have been to this location twice in the past month and each time they mess up our order. Either they put two pieces of nuts I. A whole large ice cream or completely don't put in any item at all! I won't be coming to this location anymore.\", 1), ('But they are improving and the rodeo burger is back. Even with that though it is still the worst fast food around.', 2), ('Friday night seafood................  all you can eat crab.  Yummy.  The selection was wonderful.  It was all really good.', 4), ('This company is very unethical.. If you are looking to be treated like an idiot and not get your phone calls returned I would  highly recommend wardley. Thank god for Yelp AND THANKS FOR NOTHING WARDLEY!', 1), ('Nice decor, great service, very very mediocre sushi. Sashimi was OK but all of the rolls, from basic to specialty, were very muddled. Many other sushi options in CLT for WAY less $$$.', 2), ('Have since tried almost all the subs on the menu... This is still my go-to place for a toasted sub!  Size of the sub is great and they make sure you will not be left hungry.', 4), (\"Gosh, this place sucks.   Service was crappy.  Takes forever to eat.  Also, the chips were really thick and the salsa tasted like spaghetti sauce.  Far far far from the best mexican food I've ever had.  Felt like a rip off.\", 2), (\"Contrived, overpriced, soulless clothes, and a name, which in a desperate attempt to sound edgy, makes a schoolboy-level pun on based on the substance better known as gentlemens' relish.\\\\n\\\\nWaste of time.\", 2), (\"I don't really like cold eggs. We waited a really long time for brunch and everyone's food was cold. \\\\n\\\\nTheir bread and raspberry beignets were delicious though.\", 2), (\"Yum, yum, yum!  And I didn't have to don my formals, either!\\\\n\\\\nNo items are bad here, and cheap too.\", 4), (\"Good chinese delivery. Quick, hot, lots of flavor. I'd recommend they use a bit less salt, as some of the dishes had a lot of it. Aside from that, good stuff.\", 4), ('This is seriously the nicest and cleanest gym I have ever been to, not to mention with all the new machines and the juice bar which is a added bonus. The vibe here is great compared to other gyms here in Vegas.', 4), ('Simple food and healthy.  Good stop for an easy good for you meal.', 4), ('Rooms are nice, but food and bar service is very very slow and takes forever! Will not order or eat here again.', 2), ('When you installed my windshield you broke my chromatic mirror. My receipt shows you as Ultimate Glassworks Novus with same address. I have spoken with you (owner is nasty) and will pursue with all measures at my disposal. The date of the install was 5/17/2011.', 1), ('Carne Asada was great. Drinks are weak. Chile Rellenos are the worst. Ever. Very bland restaurant.', 2), ('The Frozen Hot Chocolate was bomb!\\\\n\\\\nespecially.. you know.. summer in vegas..', 4), ('Not good Chinese food.', 2), (\"OK, out of all the places I've been too, this is the most fun. So many fun and unruly nights here. And yes, afterwards was a buffets somewhere. So bad, yet so good.\", 4), (\"This place for some reason... Always gets my order wrong. If it's not size it's the way my drink is made. Sigh.. Idk. I haven't been back in a while. Probably won't be either.\", 2), (\"Don't come here for the food. The beer is ok, standard Wisconsin bar alcohol selection. The servers are not too attentive.\", 2), (\"I can say that this sushi place is one of the best place i've been to here in vegas! Great service , Great food! Def coming back.\", 4), ('Great location. Fine, not excellent, food. The oysters were phenomenal, but the special entree was disappointing...expensive and disappointing. Excellent drinks.', 3), ('They finally followed up on this issue and my insurance company and myself were satisfied with the results.', 4), ('The grossest grilled chicken salad EVER! Slimy chicken that is NOT hot and yellow lettuce!!! At least I have the croutons to eat.  I should have known better :(', 1), ('An excellent place to go for a ice cream....   Great burger too....', 4), ('Dirty and no service. Got tired of waiting and left.  I do not understand the great reviews.  Who knows maybe I went on a had day. But there were only two other tables and one had finished eating alread.', 1), ('Easily the worst post office I have ever been to period.  Long lines and employees that are not friendly at all.  They need another post office in the centennial area of town to accommodate the citizens that live here.  One is clearly not enough.', 1), ('I just have one word to say... \\\\\"Expensive!\\\\\" Food isn\\'t that great, service is good and their Saturday night band is pretty good also.', 3), (\"I was going to mark this as a place to try until I read the rude responses by this owner to negative reviews!  I'll pass on this place. Sounds like food is primarily bland & don't complain about it! they throw you out?\", 1), ('good food and lots of it but its a bit expensive\\\\n\\\\n\\\\n gift shop is good though', 3), (\"I love the atmosphere and the food was great, you get to sing and dance there if you aren't shy.\", 4), (\"They are ok.  Tried to step out of the box.  Got the Banana/Peanut Butter. No good. Cake wasn't fresh.  Only ate half of it.  Will make sure I ask which ones are the freshest. ??  Hope that the other flavors are ok.\", 2), ('I came out from California and was looking  for good Mexican food. What I found was a diamond in the rough. The tacos were great. The staff was on point and did a great job. Will be coming back.', 4), (\"Pool was cloudy and murky. You have to pay $500 to sit on one of the big blue seats by the pool. Everything here costs too much money. The pool isnt even that great. I'd rather even be at the excalibur than here!\", 1), (\"The food is damn good. I've been coming to this restaurant for years. I love thAt Kung pao chicken.\", 4), (\"I always go to Tutti Giorni when I want some cheap pasta....fast. Not exactly a gourmet's delight. But they deliver what you expect, cheap and delicious pasta....it sure beats eating at subway.\", 3), ('One of the better matinee values in vegas! White tigers...good magic...pretty girls...what more do you want in this town!??! Its the typical boxes and vanishes but he has a great act! enjoy!', 3), ('After reading so many fabulous review I was let down by the food and experience. Not worth the 600 + that we spent. I also never received out golden tickets', 2), (\"Walgreen's has the best nuts. However, they recently changed their prices and only give a cheaper, 2-for on the halves and pieces. And they upped the price (again) on the whole cashews.  I will be shopping elsewhere.\", 2), (\"Food are very salty! I prefer Bamboo Club in Scottsdale. Very bad experience, poor customer service. Staffs are not professional. I wouldn't recommended it.\", 1), ('Too much food and not  tasty!,', 2), ('pros: Great place! Good organic food!   Enthusiastic stuff!\\\\n\\\\ncons:  High turnover rate, often new stuff is clueless and service could vary from good to bad', 4), ('Great place to hang out. One of my fav bars in downtown phoenix. great decor, great music and great drinks!', 4), ('We ate at Koji when we were in Vegas last week.   The food was ok, sushi was fine but not extraordinary.\\\\n\\\\nThe rice was piping hot.  \\\\n\\\\nThe service was chilly served with a side of indifference.', 3), (\"$8 for a tiny sandwich with one egg, two greasy strips of bacon, and a stale muffin. They say it's pricy because they get it local? It has to have substance to be considered anything. So whack.\", 1), ('As my husband so accurately put it while we shared a drink on the crappy patio, \\\\\"I\\'ve seen better ambience in a Chuck E. Cheese.\\\\\"', 2), ('A smaller buffet off-strip. Good place to come for cheap, typical american food. Not great, not bad. The restaurant is clean and the service is very good. Nothing spectacular to report.', 3), ('Ambiance was nice. Steak (pecan sirloin) was tasty. Waitresses were friendly. However was not overly impressed with restaurant. It was indistinguishable from other steakhouses.', 3), ('Perfect for people watching, not crowded. Fondue tree is beautiful, but somewhat disappointing as we were expecting a traditional fondue service - the fondue is served as a trio of chocolate dipping sauces. Convenient location right next to the front desk.', 3), (\"Good food. \\\\n\\\\nAwful service stick to delivery if you have to actually deal with anyone in the store you'd probably want to punch them.\", 2), (\"This is not the best pho in the Valley. I hate to write a poor review of a business but don't get your hopes up if you're a pho enthusiast.\", 2), (\"I use to have my boots repaired at Jova's but they increased their prices so much I stopped.  Does pretty good work but have out priced himself!\\\\n\\\\nThere are other Boot Repair places in Las Vegas that do just as good work at much lower prices.\", 2)]\n"
     ]
    }
   ],
   "source": [
    "print(values_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37916145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.3.2\n",
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install sentencepiece\n",
    "\n",
    "##Set random values\n",
    "#seed_val = 42\n",
    "seed_val = 4\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d415d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88a04fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 64\n",
    "batch_size = 92\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-6\n",
    "#learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 400\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "\n",
    "#model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "#model_name=\"google/electra-large-discriminator\"\n",
    "#model_name=\"google/electra-small-discriminator\"\n",
    "#model_name=\"microsoft/deberta-v2-xxlarge\"\n",
    "#model_name=\"microsoft/deberta-v3-base\"\n",
    "model_name = \"google/electra-base-discriminator\"\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the TREC QC Dataset\n",
    "#--------------------------------\n",
    "#! git clone https://github.com/crux82/ganbert\n",
    "\n",
    "#  NOTE: in this setting 50 classes are involved\n",
    "# labeled_file = \"./ganbert/data/labeled.tsv\"\n",
    "# unlabeled_file = \"./ganbert/data/unlabeled.tsv\"\n",
    "# test_filename = \"./ganbert/data/test.tsv\"\n",
    "\n",
    "label_list = ['UNK',1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c908c079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/electra-base-discriminator/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/electra-base-discriminator/resolve/main/pytorch_model.bin from cache at /home/harry/.cache/huggingface/transformers/aed576b8aec823c870feda40d60bd803ac8e40056ecb7d7f43dd0b2bfd82e373.db390a2059e53ead2bb00e1a2f8cd50b0a47e1969d180cd70339ec3f6f29dce1\n",
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ElectraModel were initialized from the model checkpoint at google/electra-base-discriminator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/google/electra-base-discriminator/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/vocab.txt from cache at /home/harry/.cache/huggingface/transformers/fe616facc71d8e3afc69de3edac76bf1e4a0a741e80d9a99a2cc6a9a8f5f74b5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/tokenizer.json from cache at /home/harry/.cache/huggingface/transformers/81840ac426bf0d690bfb69a4ec7d706e8853d8ab309e7decb6b72ab939d6682e.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/tokenizer_config.json from cache at /home/harry/.cache/huggingface/transformers/6f8b3f5095b6f44f5c75cee3c56b971b3208b08132ba2f9fb775a4a7b7140942.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9\n",
      "loading configuration file https://huggingface.co/google/electra-base-discriminator/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6383a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the examples\n",
    "labeled_examples = values_array_train\n",
    "#unlabeled_examples = values_array_unlabelled\n",
    "test_examples = values_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d4fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  examples = []\n",
    "\n",
    "  # Count the percentage of labeled examples  \n",
    "  num_labeled_examples = 0\n",
    "  for label_mask in label_masks:\n",
    "    if label_mask: \n",
    "      num_labeled_examples += 1\n",
    "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "  # if required it applies the balance\n",
    "  for index, ex in enumerate(input_examples): \n",
    "    if label_mask_rate == 1 or not balance_label_examples:\n",
    "      examples.append((ex, label_masks[index]))\n",
    "    else:\n",
    "      # IT SIMULATE A LABELED EXAMPLE\n",
    "      if label_masks[index]:\n",
    "        balance = int(1/label_mask_rate)\n",
    "        balance = int(math.log(balance,2))\n",
    "        if balance < 1:\n",
    "          balance = 1\n",
    "        for b in range(0, int(balance)):\n",
    "          examples.append((ex, label_masks[index]))\n",
    "      else:\n",
    "        examples.append((ex, label_masks[index]))\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for (text, label_mask) in examples:\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[text[1]])\n",
    "    label_mask_array.append(label_mask)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "  label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56feab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "# if unlabeled_examples:\n",
    "#   train_examples = train_examples + unlabeled_examples\n",
    "#   #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "#   tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
    "#   train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cce6ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Generator as in \n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
    "#         super(Generator, self).__init__()\n",
    "#         layers = []\n",
    "#         hidden_sizes = [noise_size] + hidden_sizes\n",
    "#         for i in range(len(hidden_sizes)-1):\n",
    "#             layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "#         layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
    "#         self.layers = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, noise):\n",
    "#         output_rep = self.layers(noise)\n",
    "#         return output_rep\n",
    "\n",
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f27045c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/electra-base-discriminator/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "#hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "#generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  #generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dcbc408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.013\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.105\n",
      "  Test Loss: 1.796\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.988\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.145\n",
      "  Test Loss: 1.790\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.924\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.190\n",
      "  Test Loss: 1.785\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.935\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.220\n",
      "  Test Loss: 1.779\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 5 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.930\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.225\n",
      "  Test Loss: 1.774\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 6 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.911\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.230\n",
      "  Test Loss: 1.770\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 7 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.905\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.230\n",
      "  Test Loss: 1.765\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 8 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.925\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.230\n",
      "  Test Loss: 1.760\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 9 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.937\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.240\n",
      "  Test Loss: 1.756\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 10 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.875\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.240\n",
      "  Test Loss: 1.751\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 11 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.911\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.250\n",
      "  Test Loss: 1.746\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 12 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.866\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.250\n",
      "  Test Loss: 1.742\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 13 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.881\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.255\n",
      "  Test Loss: 1.738\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 14 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.862\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.265\n",
      "  Test Loss: 1.734\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 15 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.818\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.280\n",
      "  Test Loss: 1.730\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 16 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.860\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.285\n",
      "  Test Loss: 1.725\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 17 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.819\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.280\n",
      "  Test Loss: 1.721\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 18 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.837\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.275\n",
      "  Test Loss: 1.717\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 19 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.806\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.275\n",
      "  Test Loss: 1.714\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 20 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.811\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.280\n",
      "  Test Loss: 1.710\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 21 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.783\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.280\n",
      "  Test Loss: 1.707\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 22 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.800\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.290\n",
      "  Test Loss: 1.704\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 23 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.795\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.295\n",
      "  Test Loss: 1.701\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 24 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.763\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.295\n",
      "  Test Loss: 1.698\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 25 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.817\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.300\n",
      "  Test Loss: 1.694\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 26 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.786\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.295\n",
      "  Test Loss: 1.691\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 27 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.784\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.305\n",
      "  Test Loss: 1.688\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 28 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.784\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.300\n",
      "  Test Loss: 1.686\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 29 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.733\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.275\n",
      "  Test Loss: 1.683\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 30 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.764\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.270\n",
      "  Test Loss: 1.680\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 31 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.760\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.270\n",
      "  Test Loss: 1.677\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 32 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.729\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.290\n",
      "  Test Loss: 1.675\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 33 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.716\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.280\n",
      "  Test Loss: 1.672\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 34 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.741\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.290\n",
      "  Test Loss: 1.669\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 35 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.737\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.295\n",
      "  Test Loss: 1.667\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 36 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.697\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.290\n",
      "  Test Loss: 1.664\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 37 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.725\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.285\n",
      "  Test Loss: 1.661\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 38 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.727\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.290\n",
      "  Test Loss: 1.657\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 39 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.719\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.285\n",
      "  Test Loss: 1.654\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 40 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.709\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.290\n",
      "  Test Loss: 1.651\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 41 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.678\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.300\n",
      "  Test Loss: 1.648\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 42 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.667\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.305\n",
      "  Test Loss: 1.644\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 43 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.665\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.310\n",
      "  Test Loss: 1.641\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 44 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.650\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.305\n",
      "  Test Loss: 1.639\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 45 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.669\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.320\n",
      "  Test Loss: 1.636\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 46 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.643\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.310\n",
      "  Test Loss: 1.634\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 47 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.643\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.300\n",
      "  Test Loss: 1.632\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 48 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.634\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.325\n",
      "  Test Loss: 1.629\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 49 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.688\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.315\n",
      "  Test Loss: 1.627\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 50 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.615\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.315\n",
      "  Test Loss: 1.626\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 51 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.629\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.315\n",
      "  Test Loss: 1.625\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 52 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.623\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.325\n",
      "  Test Loss: 1.624\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 53 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.586\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.340\n",
      "  Test Loss: 1.622\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 54 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.597\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.325\n",
      "  Test Loss: 1.620\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 55 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.640\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.320\n",
      "  Test Loss: 1.618\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 56 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.636\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.320\n",
      "  Test Loss: 1.615\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 57 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.609\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.330\n",
      "  Test Loss: 1.612\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 58 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.560\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.345\n",
      "  Test Loss: 1.607\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 59 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.569\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.355\n",
      "  Test Loss: 1.603\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 60 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.574\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.360\n",
      "  Test Loss: 1.599\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 61 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.566\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.365\n",
      "  Test Loss: 1.596\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 62 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.558\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.365\n",
      "  Test Loss: 1.592\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 63 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.559\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.375\n",
      "  Test Loss: 1.589\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 64 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.555\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 1.586\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 65 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.541\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 1.584\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 66 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.477\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.582\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 67 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.534\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.580\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 68 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.539\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.380\n",
      "  Test Loss: 1.576\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 69 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.477\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.365\n",
      "  Test Loss: 1.572\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 70 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.512\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.350\n",
      "  Test Loss: 1.568\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 71 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.498\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 1.564\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 72 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.479\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.559\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 73 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.491\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.555\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 74 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.481\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.430\n",
      "  Test Loss: 1.550\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 75 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.441\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 1.546\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 76 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.468\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 1.542\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 77 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.404\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 1.540\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 78 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.388\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.425\n",
      "  Test Loss: 1.538\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 79 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.402\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 1.534\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 80 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.391\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.530\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 81 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.381\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 1.524\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 82 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.350\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.435\n",
      "  Test Loss: 1.516\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 83 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.357\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 1.509\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 84 / 400 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss discriminator: 1.328\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 1.501\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 85 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.329\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.497\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 86 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.362\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 1.495\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 87 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.298\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 1.492\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 88 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.276\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.425\n",
      "  Test Loss: 1.486\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 89 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.282\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.435\n",
      "  Test Loss: 1.478\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 90 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.272\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.455\n",
      "  Test Loss: 1.470\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 91 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.234\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.455\n",
      "  Test Loss: 1.464\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 92 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.286\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.435\n",
      "  Test Loss: 1.458\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 93 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.195\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 1.455\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 94 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.232\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.450\n",
      "  Test Loss: 1.453\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 95 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.200\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 1.449\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 96 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.185\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.435\n",
      "  Test Loss: 1.445\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 97 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.165\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.430\n",
      "  Test Loss: 1.438\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 98 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.166\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.450\n",
      "  Test Loss: 1.429\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 99 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.173\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 1.421\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 100 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.123\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 1.414\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 101 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.109\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.450\n",
      "  Test Loss: 1.408\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 102 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.088\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.455\n",
      "  Test Loss: 1.403\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 103 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.087\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.460\n",
      "  Test Loss: 1.398\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 104 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.037\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.390\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 105 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.056\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.381\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 106 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.078\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.470\n",
      "  Test Loss: 1.379\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 107 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.062\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.376\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 108 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.052\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.366\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 109 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.035\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.470\n",
      "  Test Loss: 1.355\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 110 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.970\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.470\n",
      "  Test Loss: 1.345\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 111 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.979\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.470\n",
      "  Test Loss: 1.339\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 112 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.004\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.334\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 113 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.950\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.335\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 114 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.972\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.340\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 115 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.933\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.341\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 116 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.912\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.341\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 117 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.909\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.339\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 118 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.835\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.332\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 119 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.863\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.320\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 120 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.877\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.307\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 121 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.821\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.460\n",
      "  Test Loss: 1.296\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 122 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.837\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.465\n",
      "  Test Loss: 1.289\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 123 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.842\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.285\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 124 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.755\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.470\n",
      "  Test Loss: 1.285\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 125 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.722\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.289\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 126 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.775\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.289\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 127 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.828\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.284\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 128 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.799\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.273\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 129 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.714\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.263\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 130 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.257\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 131 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.660\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.254\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 132 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.666\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.252\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 133 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.681\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.252\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 134 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.720\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.250\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 135 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.243\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 136 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.660\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.238\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 137 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.630\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.233\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 138 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.640\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.228\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 139 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.651\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.224\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 140 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.624\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.220\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 141 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.649\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.207\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 142 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.600\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.198\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 143 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.581\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.198\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 144 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.568\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.205\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 145 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.583\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.219\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 146 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.571\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.232\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 147 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.527\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.233\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 148 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.547\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.225\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 149 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.491\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.216\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 150 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.484\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.207\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 151 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.476\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.200\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 152 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.472\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.198\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 153 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.483\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.198\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 154 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.472\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.200\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 155 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.475\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.202\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 156 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.444\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.199\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 157 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.438\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.197\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 158 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.466\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.200\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 159 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.420\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.207\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 160 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.419\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.214\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 161 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.418\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.217\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 162 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.408\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.216\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 163 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.429\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.211\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 164 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.405\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.211\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 165 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.373\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.211\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 166 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.386\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.470\n",
      "  Test Loss: 1.205\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 167 / 400 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss discriminator: 0.384\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.199\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 168 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.348\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.195\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 169 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.359\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.193\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 170 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.346\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.189\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 171 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.390\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.188\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 172 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.332\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.192\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 173 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.339\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.201\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 174 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.317\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.207\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 175 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.330\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.208\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 176 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.322\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.206\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 177 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.319\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.204\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 178 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.353\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.203\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 179 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.352\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.204\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 180 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.307\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.206\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 181 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.303\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.207\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 182 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.324\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.206\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 183 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.299\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.205\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 184 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.291\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.203\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 185 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.275\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.198\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 186 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.279\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.194\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 187 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.281\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.196\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 188 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.279\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.201\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 189 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.261\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.210\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 190 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.292\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.221\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 191 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.265\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.226\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 192 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.285\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.224\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 193 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.270\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.520\n",
      "  Test Loss: 1.218\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 194 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.254\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.212\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 195 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.243\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.210\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 196 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.276\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.210\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 197 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.243\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.215\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 198 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.262\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.223\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 199 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.240\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.229\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 200 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.226\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.233\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 201 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.236\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.236\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 202 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.224\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.237\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 203 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.255\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.244\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 204 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.212\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.255\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 205 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.247\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.251\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 206 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.216\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.239\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 207 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.238\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.231\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 208 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.220\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.231\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 209 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.208\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.235\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 210 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.206\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.237\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 211 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.227\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.235\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 212 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.209\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.235\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 213 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.198\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.237\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 214 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.203\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.515\n",
      "  Test Loss: 1.238\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 215 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.199\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.515\n",
      "  Test Loss: 1.237\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 216 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.209\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.235\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 217 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.195\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.235\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 218 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.194\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.237\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 219 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.194\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.241\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 220 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.202\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.249\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 221 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.175\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.258\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 222 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.178\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.485\n",
      "  Test Loss: 1.267\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 223 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.187\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.270\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 224 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.186\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.480\n",
      "  Test Loss: 1.268\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 225 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.188\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.265\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 226 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.176\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.263\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 227 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.191\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.262\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 228 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.167\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.262\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 229 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.173\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.264\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 230 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.179\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.268\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 231 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.169\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.273\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 232 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.167\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.279\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 233 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.168\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.285\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 234 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.161\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.291\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 235 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.164\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.294\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 236 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.151\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.295\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 237 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.160\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.515\n",
      "  Test Loss: 1.292\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 238 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.167\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.286\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 239 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.146\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.285\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 240 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.149\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.289\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 241 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.163\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.294\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 242 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.154\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.298\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 243 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.154\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "\n",
      "  Average training loss discriminator: 0.087\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.414\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 311 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.092\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.420\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 312 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.084\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.424\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 313 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.100\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.428\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 314 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.083\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.432\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 315 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.087\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.432\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 316 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.084\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.430\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 317 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.088\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.427\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 318 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.092\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.423\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 319 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.086\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.419\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 320 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.088\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.418\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 321 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.080\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.515\n",
      "  Test Loss: 1.417\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 322 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.096\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.418\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 323 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.075\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.423\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 324 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.084\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.428\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 325 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.077\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.433\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 326 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.077\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.438\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 327 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.078\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.447\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 328 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.075\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.456\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 329 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.076\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.459\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 330 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.076\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.457\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 331 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.079\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.451\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 332 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.078\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.448\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 333 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.070\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.446\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 334 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.082\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.449\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 335 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.071\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.455\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 336 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.077\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.462\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 337 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.069\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.467\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 338 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.074\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.467\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 339 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.078\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.465\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 340 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.074\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.464\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 341 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.074\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.464\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 342 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.071\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.515\n",
      "  Test Loss: 1.463\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 343 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.071\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.462\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 344 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.074\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.462\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 345 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.075\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.464\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 346 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.072\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.467\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 347 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.073\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.469\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 348 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.067\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.470\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 349 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.066\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.470\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 350 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.073\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.471\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 351 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.067\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.472\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 352 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.069\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.471\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 353 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.068\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.472\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 354 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.063\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.473\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 355 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.066\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.477\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 356 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.067\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.483\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 357 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.063\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.489\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 358 / 400 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss discriminator: 0.061\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.495\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 359 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.072\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.500\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 360 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.072\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.503\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 361 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.059\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.503\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 362 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.070\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.501\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 363 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.067\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.500\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 364 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.061\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.500\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 365 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.067\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.502\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 366 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.064\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.502\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 367 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.060\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.501\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 368 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.064\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.500\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 369 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.066\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.503\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 370 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.065\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.509\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 371 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.062\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.515\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 372 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.068\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.523\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 373 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.060\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.534\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 374 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.057\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.541\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 375 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.065\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.547\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 376 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.059\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.551\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 377 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.061\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.551\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 378 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.059\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.547\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 379 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.057\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.544\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 380 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.058\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.540\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 381 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.055\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.537\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 382 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.056\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.534\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 383 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.056\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.532\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 384 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.059\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.532\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 385 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.061\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.534\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 386 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.054\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.538\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 387 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.052\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.515\n",
      "  Test Loss: 1.542\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 388 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.055\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.510\n",
      "  Test Loss: 1.544\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 389 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.054\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.546\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 390 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.053\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.545\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 391 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.057\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.543\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 392 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.056\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.541\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 393 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.056\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.539\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 394 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.058\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.490\n",
      "  Test Loss: 1.539\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 395 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.054\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.541\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 396 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.052\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 1.543\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 397 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.052\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.547\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 398 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.058\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.495\n",
      "  Test Loss: 1.553\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 399 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.057\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.561\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 400 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.053\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.505\n",
      "  Test Loss: 1.569\n",
      "  Test took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "accuracy_array=[]\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "#g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
    "#gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "#   scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "#                                            num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "    #generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_label_mask = batch[3].to(device)\n",
    "\n",
    "        real_batch_size = b_input_ids.shape[0]\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "        #hidden_states = model_outputs[-1]\n",
    "        #print(hidden_states[0].size())\n",
    "        \n",
    "        # Generate fake data that should have the same distribution of the ones\n",
    "        # encoded by the transformer. \n",
    "        # First noisy input are used in input to the Generator\n",
    "        #noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "        # Gnerate Fake data\n",
    "        #gen_rep = generator(noise)\n",
    "        #print(\"Length of generator output {}\".format(len(gen_rep)))\n",
    "        #print(\"Length of single generator output {}\".format(len(gen_rep[0])))\n",
    "\n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        #disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(hidden_states)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        features_list = torch.split(features, real_batch_size)\n",
    "        D_real_features = features_list[0]\n",
    "        #D_fake_features = features_list[1]\n",
    "      \n",
    "        logits_list = torch.split(logits, real_batch_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "        #D_fake_logits = logits_list[1]\n",
    "        \n",
    "        probs_list = torch.split(probs, real_batch_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        #D_fake_probs = probs_list[1]\n",
    "\n",
    "        #---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        #---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "#         g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "#         g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "#         g_loss = g_loss_d + g_feat_reg\n",
    "  \n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:,0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples, \n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "          D_L_Supervised = 0\n",
    "        else:\n",
    "          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "                 \n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        #D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U #+ D_L_unsupervised2U\n",
    "\n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        #gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        #g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward() \n",
    "        \n",
    "        # Apply modifications\n",
    "        #gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        #tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "        \n",
    "        _, preds = torch.max(logits[:,0:-1], 1)\n",
    "        #print(preds)\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "          scheduler_d.step()\n",
    "          #scheduler_g.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    #avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    #print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "    discriminator.eval()\n",
    "    #generator.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            #hidden_states = model_outputs[-1]\n",
    "            hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "        #print(preds)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            #'Training Loss generator': avg_train_loss_g,\n",
    "            'Training Loss discriminator': avg_train_loss_d,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    accuracy_array.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fa12c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9b68eaba58>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df6d31d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.525"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9771217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_array[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16686415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
