{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55271308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import datetime\n",
    "now_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e4c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b69f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"UNK_UNK\",\"ABBR_abb\", \"ABBR_exp\", \"DESC_def\", \"DESC_desc\", \n",
    "              \"DESC_manner\", \"DESC_reason\", \"ENTY_animal\", \"ENTY_body\", \n",
    "              \"ENTY_color\", \"ENTY_cremat\", \"ENTY_currency\", \"ENTY_dismed\", \n",
    "              \"ENTY_event\", \"ENTY_food\", \"ENTY_instru\", \"ENTY_lang\", \n",
    "              \"ENTY_letter\", \"ENTY_other\", \"ENTY_plant\", \"ENTY_product\", \n",
    "              \"ENTY_religion\", \"ENTY_sport\", \"ENTY_substance\", \"ENTY_symbol\", \n",
    "              \"ENTY_techmeth\", \"ENTY_termeq\", \"ENTY_veh\", \"ENTY_word\", \"HUM_desc\", \n",
    "              \"HUM_gr\", \"HUM_ind\", \"HUM_title\", \"LOC_city\", \"LOC_country\", \n",
    "              \"LOC_mount\", \"LOC_other\", \"LOC_state\", \"NUM_code\", \"NUM_count\", \n",
    "              \"NUM_date\", \"NUM_dist\", \"NUM_money\", \"NUM_ord\", \"NUM_other\", \n",
    "              \"NUM_perc\", \"NUM_period\", \"NUM_speed\", \"NUM_temp\", \"NUM_volsize\", \n",
    "              \"NUM_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5408f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 24\n",
    "batch_size = 92\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "#num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-6 #5e-6?\n",
    "#learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 200\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "#model_name=\"google/electra-large-discriminator\"\n",
    "#model_name=\"google/electra-small-discriminator\"\n",
    "#model_name=\"microsoft/deberta-v2-xxlarge\"\n",
    "#model_name=\"microsoft/deberta-v3-base\"\n",
    "#model_name = \"google/electra-base-discriminator\" - 0.47 best when only change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5707ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_file = \"../../ganbert-master/data/labeled.tsv\"\n",
    "unlabeled_file = \"../../ganbert-master/data/unlabeled.tsv\"\n",
    "test_filename = \"../../ganbert-master/data/test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qc_examples(input_file):\n",
    "  \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "  examples = []\n",
    "\n",
    "  with open(input_file, 'r') as f:\n",
    "      contents = f.read()\n",
    "      file_as_list = contents.splitlines()\n",
    "      for line in file_as_list[1:]:\n",
    "          split = line.split(\" \")\n",
    "          question = ' '.join(split[1:])\n",
    "\n",
    "          text_a = question\n",
    "          inn_split = split[0].split(\":\")\n",
    "          label = inn_split[0] + \"_\" + inn_split[1]\n",
    "          examples.append((text_a, label))\n",
    "      f.close()\n",
    "\n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f905a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the examples\n",
    "labeled_examples = get_qc_examples(labeled_file)\n",
    "unlabeled_examples = get_qc_examples(unlabeled_file)\n",
    "test_examples = get_qc_examples(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4758bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7beb0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  examples = []\n",
    "\n",
    "  # Count the percentage of labeled examples  \n",
    "  num_labeled_examples = 0\n",
    "  for label_mask in label_masks:\n",
    "    if label_mask: \n",
    "      num_labeled_examples += 1\n",
    "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "  # if required it applies the balance\n",
    "  for index, ex in enumerate(input_examples): \n",
    "    if label_mask_rate == 1 or not balance_label_examples:\n",
    "      examples.append((ex, label_masks[index]))\n",
    "    else:\n",
    "      # IT SIMULATE A LABELED EXAMPLE\n",
    "      if label_masks[index]:\n",
    "        balance = int(1/label_mask_rate)\n",
    "        balance = int(math.log(balance,2))\n",
    "        if balance < 1:\n",
    "          balance = 1\n",
    "        for b in range(0, int(balance)):\n",
    "          examples.append((ex, label_masks[index]))\n",
    "      else:\n",
    "        examples.append((ex, label_masks[index]))\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for (text, label_mask) in examples:\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[text[1]])\n",
    "    label_mask_array.append(label_mask)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "  label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76f98a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_fake(input_examples):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for text in input_examples:\n",
    "    encoded_sent = tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return input_ids, input_mask_array # Trains with this batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c169846",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "if unlabeled_examples:\n",
    "  train_examples = train_examples + unlabeled_examples\n",
    "  #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
    "  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bcab6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d197ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "#hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "#generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  #generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "800d0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats = []\n",
    "\n",
    "accuracy_array=[]\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "#g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
    "#gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "  scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7db4d007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/harry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#OPTAGAN\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import argparse\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from modules.gan import Generator, Critic\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from func import GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig, BertConfig\n",
    "from func import GPT2LMHeadModel, GPT2Tokenizer, GPT2ForLatentConnector, GPT2ForLatentConnectorValueHead\n",
    "from func import OpenAIGPTLMHeadModel, OpenAIGPTTokenizer\n",
    "from func import XLNetLMHeadModel, XLNetTokenizer\n",
    "from func import TransfoXLLMHeadModel, TransfoXLTokenizer\n",
    "from func import BertForLatentConnector, BertTokenizer\n",
    "\n",
    "from collections import defaultdict\n",
    "from utils import (TextDataset_Split, TextDataset_2Tokenizers, BucketingDataLoader)\n",
    "import pdb\n",
    "from modules.utils import (calc_blue_parallel_func, pad_seq, rollout, rollout_test)\n",
    "#from transformers.modeling_utils import top_k_top_p_filtering\n",
    "\n",
    "\n",
    "MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) for conf in (GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig)), ())\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'gpt2': (GPT2Config, GPT2ForLatentConnectorValueHead, GPT2Tokenizer),\n",
    "    'bert': (BertConfig, BertForLatentConnector, BertTokenizer)\n",
    "}\n",
    "\n",
    "num_txt = 1\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer):\n",
    "    if isinstance(tokenizer, list):\n",
    "        dataset = TextDataset_2Tokenizers(tokenizer, args, args.train_data_file, block_size=args.block_size)\n",
    "    else:\n",
    "        dataset = TextDataset_Split(tokenizer, args, args.train_data_file, block_size=args.block_size)\n",
    "    return dataset\n",
    "\n",
    "def build_dataload_and_cache_examples(args, tokenizer, num_txt):\n",
    "    if isinstance(tokenizer, list):\n",
    "        args.batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "        if num_txt<=20:\n",
    "            concatenation=\"{}_{}{}\".format(args.train_data_file, num_txt, \".txt\")\n",
    "            file_path=concatenation\n",
    "            print(\"Train file used is number {}\".format(num_txt))\n",
    "            print(concatenation)\n",
    "            num_txt=num_txt+1\n",
    "        else:\n",
    "            num_txt=1\n",
    "            concatenation=\"{}_{}{}\".format(args.train_data_file, num_txt, \".txt\")\n",
    "            file_path=concatenation\n",
    "            print(\"Train file used is number {}\".format(num_txt))\n",
    "        dataloader = BucketingDataLoader(file_path, args.batch_size, args.max_seq_length, tokenizer, args, bucket=100, shuffle=True)\n",
    "    else:\n",
    "        pass \n",
    "    return dataloader, num_txt\n",
    "\n",
    "def compute_grad_penalty(critic, real_data, fake_data):\n",
    "    B = real_data.size(0)\n",
    "    alpha = torch.FloatTensor(np.random.random((B, 1)))\n",
    "    if args.cuda:\n",
    "        alpha = alpha.cuda()\n",
    "    sample = alpha*real_data + (1-alpha)*fake_data\n",
    "    sample.requires_grad_(True)\n",
    "    score = critic(sample)\n",
    "\n",
    "    outputs = torch.FloatTensor(B, 1).fill_(1.0) #args.latent_size\n",
    "    outputs.requires_grad_(False)\n",
    "    if args.cuda:\n",
    "        outputs = outputs.cuda()\n",
    "    grads = autograd.grad(\n",
    "        outputs=score,\n",
    "        inputs=sample,\n",
    "        grad_outputs=outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True)[0]\n",
    "    grad_penalty = ((grads.norm(2, dim=1) - 1.) ** 2).mean()\n",
    "    return grad_penalty\n",
    "\n",
    "def train(epoch):\n",
    "    model_encoder.eval()\n",
    "    model_decoder.eval()\n",
    "    generator.train()\n",
    "    critic.train()\n",
    "    c_train_loss = 0.\n",
    "    g_train_loss = 0.\n",
    "    g_batches = 0\n",
    "    c_batches = 0\n",
    "    c_loss_0 = 1\n",
    "    g_loss_0 = 1\n",
    "    for i, x in enumerate(train_loader):\n",
    "        x = x[0]\n",
    "        if args.cuda:\n",
    "            x = x.cuda()\n",
    "        # Generate noise\n",
    "        B = args.per_gpu_train_batch_size\n",
    "        noise = torch.from_numpy(np.random.normal(0, 1, (B,\n",
    "                                 args.latent_size))).float()\n",
    "        if args.cuda:\n",
    "            noise = noise.cuda()\n",
    "        # Get original text latent embeddings\n",
    "        with torch.no_grad(): \n",
    "            pooled_hidden_fea = model_encoder(x, attention_mask=(x > 0).float())[1]\n",
    "            mean, logvar = model_encoder.linear(pooled_hidden_fea).chunk(2, -1)\n",
    "            z_real = mean.squeeze(1) \n",
    "\n",
    "        # Evaluate and get losses\n",
    "        z_fake = generator(noise)\n",
    "        real_score = critic(z_real)\n",
    "        fake_score = critic(z_fake)\n",
    "        grad_penalty = compute_grad_penalty(critic, z_real.data, z_fake.data)\n",
    "        c_loss = -torch.mean(real_score) + torch.mean(fake_score) + \\\n",
    "                 args.gp_lambda*grad_penalty\n",
    "\n",
    "        fake_score = critic(generator(noise))\n",
    "        g_loss = -torch.mean(fake_score)\n",
    "        \n",
    "        r_g = abs(((g_loss.item() - g_loss_0) / (g_loss_0 + 0.001))) \n",
    "        r_c = abs(((c_loss.item() - c_loss_0) / (c_loss_0 + 0.001))) \n",
    "        \n",
    "        # Update critic or generator\n",
    "        if ((2 + epoch) / epoch) * r_c > r_g:\n",
    "            c_optimizer.zero_grad()\n",
    "            c_batches += 1\n",
    "            c_train_loss += c_loss.item()\n",
    "            c_loss.backward()\n",
    "            c_optimizer.step()\n",
    "        else:\n",
    "            g_optimizer.zero_grad()\n",
    "            g_batches += 1\n",
    "            g_train_loss += g_loss.item()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "        c_loss_0 = c_loss.item()\n",
    "        g_loss_0 = g_loss.item()\n",
    "\n",
    "        if args.interval > 0 and i % args.interval == 0:\n",
    "            logger.info('Epoch: {} | Batch: {}/{} ({:.0f}%) | G Loss: {:.6f} | C Loss: {:.6f}'.format(\n",
    "                epoch, args.batch_size*i, len(train_loader.dataset),\n",
    "                100.*(args.batch_size*i)/len(train_loader.dataset),\n",
    "                g_loss.item(), c_loss.item()\n",
    "            ))\n",
    "            test_noise = torch.Tensor(np.random.normal(0, 1, (1, args.latent_size))).to(args.device)\n",
    "            test_new_z = generator(test_noise).data\n",
    "            # create new sent\n",
    "            test_z = rollout_test(model_decoder, test_new_z, tokenizer_decoder, args.max_seq_length, 1, 0, 1)\n",
    "            logger.info(\"Text: {}\".format(test_z))\n",
    "\n",
    "    c_train_loss /= c_batches + 1\n",
    "    g_train_loss /= g_batches + 1\n",
    "    logger.info('* (Train) Epoch: {} | G Loss: {:.4f} | C Loss: {:.4f} | Updates G: {} | Updates C: {}'.format(\n",
    "        epoch, g_train_loss, c_train_loss, g_batches, c_batches\n",
    "    ))\n",
    "    return (g_train_loss, c_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13eef4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:40:59 - INFO - func.configuration_utils -   loading configuration file output_dir_768_0_unsure/checkpoint-encoder-508523/config.json\n",
      "06/28/2022 23:40:59 - INFO - func.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "06/28/2022 23:40:59 - INFO - func.modeling_utils -   loading weights file output_dir_768_0_unsure/checkpoint-encoder-508523/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size_rl=32, block_dim=100, block_size=100, checkpoint_dir='output_dir_768_0_unsure', cuda=True, dataset='EMNLP', decoder_config_name='', decoder_model_name_or_path='gpt2', decoder_model_type='gpt2', decoder_tokenizer_name='', do_lower_case=False, encoder_config_name='', encoder_model_name_or_path='bert-base-cased', encoder_model_type='bert', encoder_tokenizer_name='', epochs=200, epochs_rl=100, finetune_decoder=True, generator_dir=None, gloabl_step_eval=508523, gp_lambda=10, interval=50, latent_size=768, length=20, lr=0.0001, lr_rl=1e-06, max_seq_length=24, n_layers=10, output_dir='output_dir_768_0_unsure', padding_text='', per_gpu_train_batch_size=12, prompt='', seed=0, train_data_file='../../yahoo/subdivided_large/train', use_philly=False, valid_data_file='../../yahoo/unlabelled_short/test.txt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:41:02 - INFO - func.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/harry/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "06/28/2022 23:41:02 - INFO - func.configuration_utils -   loading configuration file output_dir_768_0_unsure/checkpoint-decoder-508523/config.json\n",
      "06/28/2022 23:41:02 - INFO - func.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"latent_size\": 768,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50260\n",
      "}\n",
      "\n",
      "06/28/2022 23:41:02 - INFO - func.modeling_utils -   loading weights file output_dir_768_0_unsure/checkpoint-decoder-508523/pytorch_model.bin\n",
      "06/28/2022 23:41:08 - INFO - func.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/harry/.cache/torch/pytorch_transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "06/28/2022 23:41:08 - INFO - func.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/harry/.cache/torch/pytorch_transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "06/28/2022 23:41:08 - INFO - func.tokenization_utils -   Adding <PAD> to the vocabulary\n",
      "06/28/2022 23:41:08 - INFO - func.tokenization_utils -   Assigning <PAD> to the pad_token key of the tokenizer\n",
      "06/28/2022 23:41:08 - INFO - func.tokenization_utils -   Adding <BOS> to the vocabulary\n",
      "06/28/2022 23:41:08 - INFO - func.tokenization_utils -   Assigning <BOS> to the bos_token key of the tokenizer\n",
      "06/28/2022 23:41:08 - INFO - func.tokenization_utils -   Adding <EOS> to the vocabulary\n",
      "06/28/2022 23:41:08 - INFO - func.tokenization_utils -   Assigning <EOS> to the eos_token key of the tokenizer\n",
      "06/28/2022 23:41:08 - INFO - __main__ -   We have added 3 tokens to GPT2\n",
      "06/28/2022 23:41:08 - INFO - __main__ -   G Parameters:255468\n",
      "06/28/2022 23:41:08 - INFO - __main__ -   C Parameters:178001\n",
      "06/28/2022 23:41:08 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 1 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:13.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:27.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:42.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:57.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:22.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:34.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:01.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:13.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:25.\n",
      "\n",
      "  Average training loss generetor: 0.595\n",
      "  Average training loss discriminator: 3.522\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:43:43 - INFO - __main__ -   Epoch: 1 | Batch: 0/10000 (0%) | G Loss: 0.273712 | C Loss: 1.715680\n",
      "06/28/2022 23:43:43 - INFO - __main__ -   Text: ['']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.160\n",
      "  Test Loss: 2.335\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:43:44 - INFO - __main__ -   Epoch: 1 | Batch: 600/10000 (6%) | G Loss: 170.433945 | C Loss: -107.989746\n",
      "06/28/2022 23:43:44 - INFO - __main__ -   Text: ['']\n",
      "06/28/2022 23:43:45 - INFO - __main__ -   Epoch: 1 | Batch: 1200/10000 (12%) | G Loss: 98.062347 | C Loss: -66.542015\n",
      "06/28/2022 23:43:45 - INFO - __main__ -   Text: ['Falk a... Shea. Max. City.. M. known to in on 30.']\n",
      "06/28/2022 23:43:46 - INFO - __main__ -   Epoch: 1 | Batch: 1800/10000 (18%) | G Loss: 98.792358 | C Loss: -72.589859\n",
      "06/28/2022 23:43:47 - INFO - __main__ -   Text: [\",-.. B... to. in.'.. and. Jewish.'s.\"]\n",
      "06/28/2022 23:43:47 - INFO - __main__ -   Epoch: 1 | Batch: 2400/10000 (24%) | G Loss: 69.131027 | C Loss: -47.843910\n",
      "06/28/2022 23:43:48 - INFO - __main__ -   Text: ['the. while. Kumarified the Balls 201448_ decline Eastern..']\n",
      "06/28/2022 23:43:49 - INFO - __main__ -   Epoch: 1 | Batch: 3000/10000 (30%) | G Loss: 63.769329 | C Loss: -47.872009\n",
      "06/28/2022 23:43:49 - INFO - __main__ -   Text: ['Louis. deg in ). Williams.. liberal.. the. Rutherford. below.v -.']\n",
      "06/28/2022 23:43:50 - INFO - __main__ -   Epoch: 1 | Batch: 3600/10000 (36%) | G Loss: 51.718090 | C Loss: -39.587315\n",
      "06/28/2022 23:43:50 - INFO - __main__ -   Text: ['served. and...i... Hilton. event. Smith.-. Keeping. Corps.']\n",
      "06/28/2022 23:43:51 - INFO - __main__ -   Epoch: 1 | Batch: 4200/10000 (42%) | G Loss: 48.174309 | C Loss: -36.713474\n",
      "06/28/2022 23:43:51 - INFO - __main__ -   Text: ['Jo']\n",
      "06/28/2022 23:43:52 - INFO - __main__ -   Epoch: 1 | Batch: 4800/10000 (48%) | G Loss: 39.996181 | C Loss: -31.823280\n",
      "06/28/2022 23:43:52 - INFO - __main__ -   Text: ['Sp']\n",
      "06/28/2022 23:43:53 - INFO - __main__ -   Epoch: 1 | Batch: 5400/10000 (54%) | G Loss: 30.553181 | C Loss: -24.219576\n",
      "06/28/2022 23:43:53 - INFO - __main__ -   Text: ['Artist.3. reserve. Williams launch......... et. majority.']\n",
      "06/28/2022 23:43:54 - INFO - __main__ -   Epoch: 1 | Batch: 6000/10000 (60%) | G Loss: 23.496435 | C Loss: -19.856802\n",
      "06/28/2022 23:43:54 - INFO - __main__ -   Text: ['And In Park']\n",
      "06/28/2022 23:43:55 - INFO - __main__ -   Epoch: 1 | Batch: 6600/10000 (66%) | G Loss: 22.489759 | C Loss: -19.121538\n",
      "06/28/2022 23:43:55 - INFO - __main__ -   Text: ['Home. ..ond. taken.. that tackled. maximum. the.cyony....']\n",
      "06/28/2022 23:43:56 - INFO - __main__ -   Epoch: 1 | Batch: 7200/10000 (72%) | G Loss: 21.510397 | C Loss: -18.825275\n",
      "06/28/2022 23:43:56 - INFO - __main__ -   Text: ['A A Narrolism.']\n",
      "06/28/2022 23:43:57 - INFO - __main__ -   Epoch: 1 | Batch: 7800/10000 (78%) | G Loss: 17.530054 | C Loss: -15.627993\n",
      "06/28/2022 23:43:57 - INFO - __main__ -   Text: ['bars For there Some Link Lit. travel. which.. Bak. with.200.. Unique..']\n",
      "06/28/2022 23:43:58 - INFO - __main__ -   Epoch: 1 | Batch: 8400/10000 (84%) | G Loss: 14.857960 | C Loss: -13.939749\n",
      "06/28/2022 23:43:59 - INFO - __main__ -   Text: ['for, knights who then.. to defend.. forest. Charles. despite....']\n",
      "06/28/2022 23:44:00 - INFO - __main__ -   Epoch: 1 | Batch: 9000/10000 (90%) | G Loss: 13.329870 | C Loss: -12.698889\n",
      "06/28/2022 23:44:00 - INFO - __main__ -   Text: ['Brown Swy for. a. Carpenter Law.']\n",
      "06/28/2022 23:44:01 - INFO - __main__ -   Epoch: 1 | Batch: 9600/10000 (96%) | G Loss: 12.575432 | C Loss: -11.750484\n",
      "06/28/2022 23:44:01 - INFO - __main__ -   Text: ['does however.']\n",
      "06/28/2022 23:44:01 - INFO - __main__ -   * (Train) Epoch: 1 | G Loss: 40.9082 | C Loss: -34.8675 | Updates G: 80 | Updates C: 753\n",
      "06/28/2022 23:44:11 - INFO - __main__ -   Bleu-2:0.136 | B-Bleu-2:0.154\n",
      "06/28/2022 23:44:11 - INFO - __main__ -   * Saving. Best Score:0.289 | Bleu-2:0.136 | B-Bleu-2:0.154\n",
      "06/28/2022 23:44:11 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893336298816085\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 2 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:00.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:19.\n",
      "\n",
      "  Average training loss generetor: 0.513\n",
      "  Average training loss discriminator: 3.488\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:47:47 - INFO - __main__ -   Epoch: 2 | Batch: 0/10001 (0%) | G Loss: 10.537098 | C Loss: -10.342489\n",
      "06/28/2022 23:47:47 - INFO - __main__ -   Text: ['and Press.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.310\n",
      "  Test Loss: 2.206\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:47:48 - INFO - __main__ -   Epoch: 2 | Batch: 600/10001 (6%) | G Loss: 8.722316 | C Loss: -8.776833\n",
      "06/28/2022 23:47:48 - INFO - __main__ -   Text: [\"The people don don't don don no - That' Yes.\"]\n",
      "06/28/2022 23:47:49 - INFO - __main__ -   Epoch: 2 | Batch: 1200/10001 (12%) | G Loss: 8.355919 | C Loss: -8.760653\n",
      "06/28/2022 23:47:49 - INFO - __main__ -   Text: ['confusion... <BOS> capital).']\n",
      "06/28/2022 23:47:50 - INFO - __main__ -   Epoch: 2 | Batch: 1800/10001 (18%) | G Loss: 6.890192 | C Loss: -7.398898\n",
      "06/28/2022 23:47:50 - INFO - __main__ -   Text: ['arm to fight into his We I I.']\n",
      "06/28/2022 23:47:51 - INFO - __main__ -   Epoch: 2 | Batch: 2400/10001 (24%) | G Loss: 5.494011 | C Loss: -5.887434\n",
      "06/28/2022 23:47:51 - INFO - __main__ -   Text: ['They have no dentition and they become a beginner on Air.']\n",
      "06/28/2022 23:47:52 - INFO - __main__ -   Epoch: 2 | Batch: 3000/10001 (30%) | G Loss: 4.376080 | C Loss: -4.719339\n",
      "06/28/2022 23:47:52 - INFO - __main__ -   Text: ['Entertainment has located work in some quarters.']\n",
      "06/28/2022 23:47:53 - INFO - __main__ -   Epoch: 2 | Batch: 3600/10001 (36%) | G Loss: 3.863558 | C Loss: -4.066916\n",
      "06/28/2022 23:47:53 - INFO - __main__ -   Text: ['Manuel says \"never to bust.\"']\n",
      "06/28/2022 23:47:54 - INFO - __main__ -   Epoch: 2 | Batch: 4200/10001 (42%) | G Loss: 3.293515 | C Loss: -3.499312\n",
      "06/28/2022 23:47:54 - INFO - __main__ -   Text: ['an objective example which is objective A-.']\n",
      "06/28/2022 23:47:55 - INFO - __main__ -   Epoch: 2 | Batch: 4800/10001 (48%) | G Loss: 2.977834 | C Loss: -2.783278\n",
      "06/28/2022 23:47:55 - INFO - __main__ -   Text: ['They cure a properly shy being.']\n",
      "06/28/2022 23:47:56 - INFO - __main__ -   Epoch: 2 | Batch: 5400/10001 (54%) | G Loss: 3.444542 | C Loss: -3.239155\n",
      "06/28/2022 23:47:56 - INFO - __main__ -   Text: ['A I do.']\n",
      "06/28/2022 23:47:57 - INFO - __main__ -   Epoch: 2 | Batch: 6000/10001 (60%) | G Loss: 3.579134 | C Loss: -2.985078\n",
      "06/28/2022 23:47:57 - INFO - __main__ -   Text: ['What makes the Honey Bread confounding?']\n",
      "06/28/2022 23:47:58 - INFO - __main__ -   Epoch: 2 | Batch: 6600/10001 (66%) | G Loss: 3.520978 | C Loss: -3.112938\n",
      "06/28/2022 23:47:58 - INFO - __main__ -   Text: ['error Little deceive The Promise\"). appearing I need Chef or!']\n",
      "06/28/2022 23:47:59 - INFO - __main__ -   Epoch: 2 | Batch: 7200/10001 (72%) | G Loss: 4.181676 | C Loss: -3.418581\n",
      "06/28/2022 23:47:59 - INFO - __main__ -   Text: ['Chancellic observation type is more likely to be underestimated!']\n",
      "06/28/2022 23:48:00 - INFO - __main__ -   Epoch: 2 | Batch: 7800/10001 (78%) | G Loss: 4.618138 | C Loss: -3.480266\n",
      "06/28/2022 23:48:00 - INFO - __main__ -   Text: [\"Some terrorist pic't say.'\"]\n",
      "06/28/2022 23:48:01 - INFO - __main__ -   Epoch: 2 | Batch: 8400/10001 (84%) | G Loss: 4.614466 | C Loss: -3.846222\n",
      "06/28/2022 23:48:01 - INFO - __main__ -   Text: ['Noit! This is my!']\n",
      "06/28/2022 23:48:02 - INFO - __main__ -   Epoch: 2 | Batch: 9000/10001 (90%) | G Loss: 4.560364 | C Loss: -4.008877\n",
      "06/28/2022 23:48:02 - INFO - __main__ -   Text: ['pot \"bookisp\".']\n",
      "06/28/2022 23:48:03 - INFO - __main__ -   Epoch: 2 | Batch: 9600/10001 (96%) | G Loss: 5.128015 | C Loss: -4.084636\n",
      "06/28/2022 23:48:03 - INFO - __main__ -   Text: ['Tor is a biased encyclopedia.']\n",
      "06/28/2022 23:48:04 - INFO - __main__ -   * (Train) Epoch: 2 | G Loss: 4.9376 | C Loss: -4.7552 | Updates G: 151 | Updates C: 682\n",
      "06/28/2022 23:48:13 - INFO - __main__ -   Bleu-2:0.179 | B-Bleu-2:0.194\n",
      "06/28/2022 23:48:13 - INFO - __main__ -   * Saving. Best Score:0.373 | Bleu-2:0.179 | B-Bleu-2:0.194\n",
      "06/28/2022 23:48:13 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3732984105188521\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 3 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:14.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:43.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:56.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:22.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:36.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:04.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:19.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:33.\n",
      "\n",
      "  Average training loss generetor: 0.651\n",
      "  Average training loss discriminator: 2.781\n",
      "  Training epcoh took: 0:02:47\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:51:00 - INFO - __main__ -   Epoch: 3 | Batch: 0/10001 (0%) | G Loss: 5.205673 | C Loss: -4.292138\n",
      "06/28/2022 23:51:00 - INFO - __main__ -   Text: ['\"Un hat.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.425\n",
      "  Test Loss: 1.945\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:51:01 - INFO - __main__ -   Epoch: 3 | Batch: 600/10001 (6%) | G Loss: 4.698145 | C Loss: -3.828710\n",
      "06/28/2022 23:51:01 - INFO - __main__ -   Text: ['']\n",
      "06/28/2022 23:51:02 - INFO - __main__ -   Epoch: 3 | Batch: 1200/10001 (12%) | G Loss: 4.804300 | C Loss: -4.225291\n",
      "06/28/2022 23:51:02 - INFO - __main__ -   Text: ['It is repeatable here.']\n",
      "06/28/2022 23:51:03 - INFO - __main__ -   Epoch: 3 | Batch: 1800/10001 (18%) | G Loss: 5.283571 | C Loss: -4.360872\n",
      "06/28/2022 23:51:03 - INFO - __main__ -   Text: ['of the school of the college of the mouse.']\n",
      "06/28/2022 23:51:04 - INFO - __main__ -   Epoch: 3 | Batch: 2400/10001 (24%) | G Loss: 4.852181 | C Loss: -4.199922\n",
      "06/28/2022 23:51:04 - INFO - __main__ -   Text: ['Users of a man reaction are a Mark.']\n",
      "06/28/2022 23:51:05 - INFO - __main__ -   Epoch: 3 | Batch: 3000/10001 (30%) | G Loss: 4.770012 | C Loss: -4.342875\n",
      "06/28/2022 23:51:05 - INFO - __main__ -   Text: [\"Stew Logical has suggested 'Since everything.'\"]\n",
      "06/28/2022 23:51:06 - INFO - __main__ -   Epoch: 3 | Batch: 3600/10001 (36%) | G Loss: 4.907894 | C Loss: -4.158617\n",
      "06/28/2022 23:51:06 - INFO - __main__ -   Text: ['\"Virgin, col, or shake.']\n",
      "06/28/2022 23:51:07 - INFO - __main__ -   Epoch: 3 | Batch: 4200/10001 (42%) | G Loss: 6.039112 | C Loss: -5.059721\n",
      "06/28/2022 23:51:07 - INFO - __main__ -   Text: ['They like Facebook, Twitter, and Wear.']\n",
      "06/28/2022 23:51:08 - INFO - __main__ -   Epoch: 3 | Batch: 4800/10001 (48%) | G Loss: 6.130104 | C Loss: -5.181448\n",
      "06/28/2022 23:51:08 - INFO - __main__ -   Text: ['David\\'s \"\"\".']\n",
      "06/28/2022 23:51:09 - INFO - __main__ -   Epoch: 3 | Batch: 5400/10001 (54%) | G Loss: 5.345711 | C Loss: -4.566082\n",
      "06/28/2022 23:51:09 - INFO - __main__ -   Text: [\"Poker suspect tries to guess the worst because that's a money chance.\"]\n",
      "06/28/2022 23:51:10 - INFO - __main__ -   Epoch: 3 | Batch: 6000/10001 (60%) | G Loss: 4.751524 | C Loss: -4.507938\n",
      "06/28/2022 23:51:11 - INFO - __main__ -   Text: ['Pregelix wants to sign Pleke.']\n",
      "06/28/2022 23:51:11 - INFO - __main__ -   Epoch: 3 | Batch: 6600/10001 (66%) | G Loss: 5.384397 | C Loss: -4.463310\n",
      "06/28/2022 23:51:12 - INFO - __main__ -   Text: ['Apparently has A Boy wants To Find Bow.']\n",
      "06/28/2022 23:51:13 - INFO - __main__ -   Epoch: 3 | Batch: 7200/10001 (72%) | G Loss: 5.343353 | C Loss: -4.481400\n",
      "06/28/2022 23:51:13 - INFO - __main__ -   Text: ['one appertains: Relay with Jamie !']\n",
      "06/28/2022 23:51:14 - INFO - __main__ -   Epoch: 3 | Batch: 7800/10001 (78%) | G Loss: 4.933895 | C Loss: -4.320453\n",
      "06/28/2022 23:51:14 - INFO - __main__ -   Text: ['Rising levels of Israel goes surprisingly low.\"']\n",
      "06/28/2022 23:51:15 - INFO - __main__ -   Epoch: 3 | Batch: 8400/10001 (84%) | G Loss: 4.606618 | C Loss: -4.373590\n",
      "06/28/2022 23:51:15 - INFO - __main__ -   Text: ['Tegm.']\n",
      "06/28/2022 23:51:16 - INFO - __main__ -   Epoch: 3 | Batch: 9000/10001 (90%) | G Loss: 4.913499 | C Loss: -4.223104\n",
      "06/28/2022 23:51:16 - INFO - __main__ -   Text: ['It is best to conclude that a man is \"green\" when cooking.']\n",
      "06/28/2022 23:51:17 - INFO - __main__ -   Epoch: 3 | Batch: 9600/10001 (96%) | G Loss: 4.829834 | C Loss: -4.298736\n",
      "06/28/2022 23:51:17 - INFO - __main__ -   Text: ['Dianeth\\'s deeds are always and everywhere.\"']\n",
      "06/28/2022 23:51:17 - INFO - __main__ -   * (Train) Epoch: 3 | G Loss: 5.1454 | C Loss: -4.3742 | Updates G: 148 | Updates C: 685\n",
      "06/28/2022 23:51:26 - INFO - __main__ -   Bleu-2:0.193 | B-Bleu-2:0.215\n",
      "06/28/2022 23:51:26 - INFO - __main__ -   * Saving. Best Score:0.408 | Bleu-2:0.193 | B-Bleu-2:0.215\n",
      "06/28/2022 23:51:26 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40827916381340934\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 4 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:44.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:58.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:14.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:55.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:09.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:24.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:39.\n",
      "\n",
      "  Average training loss generetor: 0.689\n",
      "  Average training loss discriminator: 2.109\n",
      "  Training epcoh took: 0:02:53\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:54:20 - INFO - __main__ -   Epoch: 4 | Batch: 0/10001 (0%) | G Loss: 4.625474 | C Loss: -3.978683\n",
      "06/28/2022 23:54:20 - INFO - __main__ -   Text: ['Many more travelers are \"ncip on.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.443\n",
      "  Test Loss: 1.741\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:54:21 - INFO - __main__ -   Epoch: 4 | Batch: 600/10001 (6%) | G Loss: 4.495766 | C Loss: -4.065772\n",
      "06/28/2022 23:54:21 - INFO - __main__ -   Text: ['Wheel must not be invented \"All Tom & Dia.']\n",
      "06/28/2022 23:54:22 - INFO - __main__ -   Epoch: 4 | Batch: 1200/10001 (12%) | G Loss: 4.653400 | C Loss: -4.140658\n",
      "06/28/2022 23:54:22 - INFO - __main__ -   Text: ['\" Much real fast rate\".']\n",
      "06/28/2022 23:54:23 - INFO - __main__ -   Epoch: 4 | Batch: 1800/10001 (18%) | G Loss: 4.856598 | C Loss: -4.283592\n",
      "06/28/2022 23:54:23 - INFO - __main__ -   Text: ['Belt Lip notes is that you should be on 2.']\n",
      "06/28/2022 23:54:24 - INFO - __main__ -   Epoch: 4 | Batch: 2400/10001 (24%) | G Loss: 4.905535 | C Loss: -4.333271\n",
      "06/28/2022 23:54:24 - INFO - __main__ -   Text: ['They say it can either pill or screw.']\n",
      "06/28/2022 23:54:25 - INFO - __main__ -   Epoch: 4 | Batch: 3000/10001 (30%) | G Loss: 4.827443 | C Loss: -4.634796\n",
      "06/28/2022 23:54:25 - INFO - __main__ -   Text: ['\"The Avatar will pursue you.\"']\n",
      "06/28/2022 23:54:26 - INFO - __main__ -   Epoch: 4 | Batch: 3600/10001 (36%) | G Loss: 4.882471 | C Loss: -4.187182\n",
      "06/28/2022 23:54:26 - INFO - __main__ -   Text: ['Was very packet.']\n",
      "06/28/2022 23:54:27 - INFO - __main__ -   Epoch: 4 | Batch: 4200/10001 (42%) | G Loss: 4.548844 | C Loss: -4.137194\n",
      "06/28/2022 23:54:27 - INFO - __main__ -   Text: ['A myopic picture becomes the hat of the investigator.']\n",
      "06/28/2022 23:54:28 - INFO - __main__ -   Epoch: 4 | Batch: 4800/10001 (48%) | G Loss: 5.013866 | C Loss: -4.244685\n",
      "06/28/2022 23:54:28 - INFO - __main__ -   Text: ['Another popular example is Renaissance Motor Charts.']\n",
      "06/28/2022 23:54:29 - INFO - __main__ -   Epoch: 4 | Batch: 5400/10001 (54%) | G Loss: 4.882214 | C Loss: -3.822878\n",
      "06/28/2022 23:54:29 - INFO - __main__ -   Text: ['To deny everything and go to prison.']\n",
      "06/28/2022 23:54:30 - INFO - __main__ -   Epoch: 4 | Batch: 6000/10001 (60%) | G Loss: 4.860595 | C Loss: -4.105407\n",
      "06/28/2022 23:54:30 - INFO - __main__ -   Text: ['Let them think that?']\n",
      "06/28/2022 23:54:31 - INFO - __main__ -   Epoch: 4 | Batch: 6600/10001 (66%) | G Loss: 4.255268 | C Loss: -3.632666\n",
      "06/28/2022 23:54:31 - INFO - __main__ -   Text: [\"It's a job all his own.\"]\n",
      "06/28/2022 23:54:32 - INFO - __main__ -   Epoch: 4 | Batch: 7200/10001 (72%) | G Loss: 4.712093 | C Loss: -4.129797\n",
      "06/28/2022 23:54:32 - INFO - __main__ -   Text: ['DK set frequency i.s.']\n",
      "06/28/2022 23:54:33 - INFO - __main__ -   Epoch: 4 | Batch: 7800/10001 (78%) | G Loss: 4.820426 | C Loss: -4.293461\n",
      "06/28/2022 23:54:33 - INFO - __main__ -   Text: ['YUK is rarely being given.']\n",
      "06/28/2022 23:54:34 - INFO - __main__ -   Epoch: 4 | Batch: 8400/10001 (84%) | G Loss: 4.001685 | C Loss: -3.477021\n",
      "06/28/2022 23:54:34 - INFO - __main__ -   Text: ['However, especially ... .']\n",
      "06/28/2022 23:54:35 - INFO - __main__ -   Epoch: 4 | Batch: 9000/10001 (90%) | G Loss: 4.767993 | C Loss: -4.039241\n",
      "06/28/2022 23:54:35 - INFO - __main__ -   Text: [\"If you really don't have any home then this is probably an easy flick.\"]\n",
      "06/28/2022 23:54:36 - INFO - __main__ -   Epoch: 4 | Batch: 9600/10001 (96%) | G Loss: 4.234442 | C Loss: -3.828517\n",
      "06/28/2022 23:54:36 - INFO - __main__ -   Text: ['is a menu test.']\n",
      "06/28/2022 23:54:37 - INFO - __main__ -   * (Train) Epoch: 4 | G Loss: 4.7195 | C Loss: -4.0735 | Updates G: 217 | Updates C: 616\n",
      "06/28/2022 23:54:45 - INFO - __main__ -   Bleu-2:0.190 | B-Bleu-2:0.246\n",
      "06/28/2022 23:54:45 - INFO - __main__ -   * Saving. Best Score:0.436 | Bleu-2:0.190 | B-Bleu-2:0.246\n",
      "06/28/2022 23:54:45 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4359050785335863\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 5 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:14.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:29.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:44.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:58.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:40.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:54.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:09.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:23.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:37.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 1.558\n",
      "  Training epcoh took: 0:02:50\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:57:36 - INFO - __main__ -   Epoch: 5 | Batch: 0/10001 (0%) | G Loss: 4.347716 | C Loss: -3.933740\n",
      "06/28/2022 23:57:36 - INFO - __main__ -   Text: ['Depending upon the spell of breakfast.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.453\n",
      "  Test Loss: 1.687\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/28/2022 23:57:37 - INFO - __main__ -   Epoch: 5 | Batch: 600/10001 (6%) | G Loss: 4.376561 | C Loss: -3.801161\n",
      "06/28/2022 23:57:37 - INFO - __main__ -   Text: ['Relinate some words that are not accepted by humans.']\n",
      "06/28/2022 23:57:38 - INFO - __main__ -   Epoch: 5 | Batch: 1200/10001 (12%) | G Loss: 4.423728 | C Loss: -3.663232\n",
      "06/28/2022 23:57:38 - INFO - __main__ -   Text: ['It contains traces of Hebrew (mistrain).']\n",
      "06/28/2022 23:57:39 - INFO - __main__ -   Epoch: 5 | Batch: 1800/10001 (18%) | G Loss: 4.843112 | C Loss: -4.069310\n",
      "06/28/2022 23:57:39 - INFO - __main__ -   Text: ['\"Refia\" may refer to:']\n",
      "06/28/2022 23:57:40 - INFO - __main__ -   Epoch: 5 | Batch: 2400/10001 (24%) | G Loss: 4.440497 | C Loss: -3.754192\n",
      "06/28/2022 23:57:40 - INFO - __main__ -   Text: ['What happens so much might occur when a professional horse does cannot speak outside of Africa.']\n",
      "06/28/2022 23:57:41 - INFO - __main__ -   Epoch: 5 | Batch: 3000/10001 (30%) | G Loss: 4.879333 | C Loss: -4.104866\n",
      "06/28/2022 23:57:41 - INFO - __main__ -   Text: ['This story gives one one a poker face.']\n",
      "06/28/2022 23:57:42 - INFO - __main__ -   Epoch: 5 | Batch: 3600/10001 (36%) | G Loss: 4.405116 | C Loss: -3.699584\n",
      "06/28/2022 23:57:42 - INFO - __main__ -   Text: ['It will soon learn how to study, how to keep quiet.']\n",
      "06/28/2022 23:57:43 - INFO - __main__ -   Epoch: 5 | Batch: 4200/10001 (42%) | G Loss: 4.224428 | C Loss: -3.787154\n",
      "06/28/2022 23:57:43 - INFO - __main__ -   Text: [\"Shoot' is even more complicated than that.\"]\n",
      "06/28/2022 23:57:44 - INFO - __main__ -   Epoch: 5 | Batch: 4800/10001 (48%) | G Loss: 4.401716 | C Loss: -3.764758\n",
      "06/28/2022 23:57:44 - INFO - __main__ -   Text: [\"Their hightech designation is 'Growing Up'.\"]\n",
      "06/28/2022 23:57:45 - INFO - __main__ -   Epoch: 5 | Batch: 5400/10001 (54%) | G Loss: 4.508232 | C Loss: -3.919264\n",
      "06/28/2022 23:57:45 - INFO - __main__ -   Text: ['Sneaky speaker.']\n",
      "06/28/2022 23:57:46 - INFO - __main__ -   Epoch: 5 | Batch: 6000/10001 (60%) | G Loss: 3.925902 | C Loss: -3.516891\n",
      "06/28/2022 23:57:46 - INFO - __main__ -   Text: ['Later Eliot may speak about human subjects.']\n",
      "06/28/2022 23:57:47 - INFO - __main__ -   Epoch: 5 | Batch: 6600/10001 (66%) | G Loss: 4.461158 | C Loss: -3.755019\n",
      "06/28/2022 23:57:47 - INFO - __main__ -   Text: ['Her moves to A: What about a path to ham?']\n",
      "06/28/2022 23:57:48 - INFO - __main__ -   Epoch: 5 | Batch: 7200/10001 (72%) | G Loss: 4.521691 | C Loss: -3.792716\n",
      "06/28/2022 23:57:48 - INFO - __main__ -   Text: ['O thinks it is best to play the heart.']\n",
      "06/28/2022 23:57:49 - INFO - __main__ -   Epoch: 5 | Batch: 7800/10001 (78%) | G Loss: 4.239733 | C Loss: -3.728155\n",
      "06/28/2022 23:57:49 - INFO - __main__ -   Text: [\"Sly's depressing voice gets noticed.\"]\n",
      "06/28/2022 23:57:50 - INFO - __main__ -   Epoch: 5 | Batch: 8400/10001 (84%) | G Loss: 4.162456 | C Loss: -3.547149\n",
      "06/28/2022 23:57:51 - INFO - __main__ -   Text: ['Dogs belong to the \"arc hell\".']\n",
      "06/28/2022 23:57:51 - INFO - __main__ -   Epoch: 5 | Batch: 9000/10001 (90%) | G Loss: 4.508158 | C Loss: -3.757888\n",
      "06/28/2022 23:57:52 - INFO - __main__ -   Text: ['It is considered to be the most dangerous drug at 80 degrees.']\n",
      "06/28/2022 23:57:53 - INFO - __main__ -   Epoch: 5 | Batch: 9600/10001 (96%) | G Loss: 4.093554 | C Loss: -3.318430\n",
      "06/28/2022 23:57:53 - INFO - __main__ -   Text: ['\"\".']\n",
      "06/28/2022 23:57:53 - INFO - __main__ -   * (Train) Epoch: 5 | G Loss: 4.3288 | C Loss: -3.7058 | Updates G: 220 | Updates C: 613\n",
      "06/28/2022 23:58:00 - INFO - __main__ -   Bleu-2:0.202 | B-Bleu-2:0.243\n",
      "06/28/2022 23:58:00 - INFO - __main__ -   * Saving. Best Score:0.445 | Bleu-2:0.202 | B-Bleu-2:0.243\n",
      "06/28/2022 23:58:00 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4448469935700208\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 6 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:44.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:59.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:13.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:55.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:09.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:23.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:38.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 1.198\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:00:52 - INFO - __main__ -   Epoch: 6 | Batch: 0/10001 (0%) | G Loss: 4.091562 | C Loss: -3.639133\n",
      "06/29/2022 00:00:52 - INFO - __main__ -   Text: ['Equivalent means similar or not.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.475\n",
      "  Test Loss: 1.698\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:00:53 - INFO - __main__ -   Epoch: 6 | Batch: 600/10001 (6%) | G Loss: 4.584288 | C Loss: -3.644062\n",
      "06/29/2022 00:00:53 - INFO - __main__ -   Text: ['The mean hour time is 3 seconds on the floor.']\n",
      "06/29/2022 00:00:54 - INFO - __main__ -   Epoch: 6 | Batch: 1200/10001 (12%) | G Loss: 3.896769 | C Loss: -3.217595\n",
      "06/29/2022 00:00:54 - INFO - __main__ -   Text: ['L or Lthat build a fence']\n",
      "06/29/2022 00:00:55 - INFO - __main__ -   Epoch: 6 | Batch: 1800/10001 (18%) | G Loss: 4.066328 | C Loss: -3.363063\n",
      "06/29/2022 00:00:56 - INFO - __main__ -   Text: ['Its creator reflects, however, that they are a universe.']\n",
      "06/29/2022 00:00:56 - INFO - __main__ -   Epoch: 6 | Batch: 2400/10001 (24%) | G Loss: 4.639219 | C Loss: -3.695181\n",
      "06/29/2022 00:00:57 - INFO - __main__ -   Text: [\"The word states it's something that should come naturally.\"]\n",
      "06/29/2022 00:00:58 - INFO - __main__ -   Epoch: 6 | Batch: 3000/10001 (30%) | G Loss: 3.844048 | C Loss: -3.350890\n",
      "06/29/2022 00:00:58 - INFO - __main__ -   Text: ['Folks call it Cinema haven\".']\n",
      "06/29/2022 00:00:59 - INFO - __main__ -   Epoch: 6 | Batch: 3600/10001 (36%) | G Loss: 4.091898 | C Loss: -3.405664\n",
      "06/29/2022 00:00:59 - INFO - __main__ -   Text: ['Intimidating husbands is everything.']\n",
      "06/29/2022 00:01:00 - INFO - __main__ -   Epoch: 6 | Batch: 4200/10001 (42%) | G Loss: 3.829840 | C Loss: -3.290049\n",
      "06/29/2022 00:01:00 - INFO - __main__ -   Text: ['The greatest is your desire to experience alcohol.']\n",
      "06/29/2022 00:01:01 - INFO - __main__ -   Epoch: 6 | Batch: 4800/10001 (48%) | G Loss: 3.744817 | C Loss: -3.303736\n",
      "06/29/2022 00:01:01 - INFO - __main__ -   Text: ['The trick of throwing a grenade is.']\n",
      "06/29/2022 00:01:02 - INFO - __main__ -   Epoch: 6 | Batch: 5400/10001 (54%) | G Loss: 3.688649 | C Loss: -3.309350\n",
      "06/29/2022 00:01:02 - INFO - __main__ -   Text: ['\"Superheels\" is not controversial!']\n",
      "06/29/2022 00:01:03 - INFO - __main__ -   Epoch: 6 | Batch: 6000/10001 (60%) | G Loss: 3.642548 | C Loss: -3.274794\n",
      "06/29/2022 00:01:03 - INFO - __main__ -   Text: ['Petropoly might say \"which hardships\" instead.']\n",
      "06/29/2022 00:01:04 - INFO - __main__ -   Epoch: 6 | Batch: 6600/10001 (66%) | G Loss: 3.596206 | C Loss: -3.162613\n",
      "06/29/2022 00:01:04 - INFO - __main__ -   Text: ['Benji or ONIQIQ will be respected.<led>']\n",
      "06/29/2022 00:01:05 - INFO - __main__ -   Epoch: 6 | Batch: 7200/10001 (72%) | G Loss: 3.791192 | C Loss: -3.178601\n",
      "06/29/2022 00:01:05 - INFO - __main__ -   Text: ['IVI Practice is thinking back to 1,000 years to Carnalers.']\n",
      "06/29/2022 00:01:06 - INFO - __main__ -   Epoch: 6 | Batch: 7800/10001 (78%) | G Loss: 3.700286 | C Loss: -3.049609\n",
      "06/29/2022 00:01:06 - INFO - __main__ -   Text: ['among them, How To Step.']\n",
      "06/29/2022 00:01:07 - INFO - __main__ -   Epoch: 6 | Batch: 8400/10001 (84%) | G Loss: 3.415078 | C Loss: -3.077700\n",
      "06/29/2022 00:01:07 - INFO - __main__ -   Text: ['She asks what is sulphuric.']\n",
      "06/29/2022 00:01:08 - INFO - __main__ -   Epoch: 6 | Batch: 9000/10001 (90%) | G Loss: 3.649068 | C Loss: -3.035999\n",
      "06/29/2022 00:01:08 - INFO - __main__ -   Text: ['Children that take blankets do so here.\"']\n",
      "06/29/2022 00:01:09 - INFO - __main__ -   Epoch: 6 | Batch: 9600/10001 (96%) | G Loss: 3.636680 | C Loss: -3.166968\n",
      "06/29/2022 00:01:09 - INFO - __main__ -   Text: ['A possible Bollywood painter can play this game with ease.']\n",
      "06/29/2022 00:01:10 - INFO - __main__ -   * (Train) Epoch: 6 | G Loss: 3.9016 | C Loss: -3.3111 | Updates G: 236 | Updates C: 597\n",
      "06/29/2022 00:01:18 - INFO - __main__ -   Bleu-2:0.215 | B-Bleu-2:0.270\n",
      "06/29/2022 00:01:18 - INFO - __main__ -   * Saving. Best Score:0.486 | Bleu-2:0.215 | B-Bleu-2:0.270\n",
      "06/29/2022 00:01:18 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48585232620368696\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 7 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:46.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:01.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:17.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:32.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:18.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:46.\n",
      "\n",
      "  Average training loss generetor: 0.710\n",
      "  Average training loss discriminator: 1.033\n",
      "  Training epcoh took: 0:03:00\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:04:18 - INFO - __main__ -   Epoch: 7 | Batch: 0/10001 (0%) | G Loss: 4.024259 | C Loss: -3.178649\n",
      "06/29/2022 00:04:18 - INFO - __main__ -   Text: [\"He prefers cocoa futures and won't give a shit about diamonds.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.465\n",
      "  Test Loss: 1.760\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:04:19 - INFO - __main__ -   Epoch: 7 | Batch: 600/10001 (6%) | G Loss: 3.554472 | C Loss: -2.974874\n",
      "06/29/2022 00:04:20 - INFO - __main__ -   Text: ['Once to get on does it take five minutes.']\n",
      "06/29/2022 00:04:20 - INFO - __main__ -   Epoch: 7 | Batch: 1200/10001 (12%) | G Loss: 3.471743 | C Loss: -3.171472\n",
      "06/29/2022 00:04:21 - INFO - __main__ -   Text: ['Thrifty is the better bid.']\n",
      "06/29/2022 00:04:22 - INFO - __main__ -   Epoch: 7 | Batch: 1800/10001 (18%) | G Loss: 3.631153 | C Loss: -3.209269\n",
      "06/29/2022 00:04:22 - INFO - __main__ -   Text: ['The user is posted numerically as three numbers.']\n",
      "06/29/2022 00:04:23 - INFO - __main__ -   Epoch: 7 | Batch: 2400/10001 (24%) | G Loss: 3.279698 | C Loss: -2.858052\n",
      "06/29/2022 00:04:23 - INFO - __main__ -   Text: ['It might be \"essentially getting soft by swimming\".']\n",
      "06/29/2022 00:04:24 - INFO - __main__ -   Epoch: 7 | Batch: 3000/10001 (30%) | G Loss: 3.610750 | C Loss: -2.929860\n",
      "06/29/2022 00:04:24 - INFO - __main__ -   Text: ['It is10 of the most dangerous books I have ever read.']\n",
      "06/29/2022 00:04:25 - INFO - __main__ -   Epoch: 7 | Batch: 3600/10001 (36%) | G Loss: 3.620522 | C Loss: -3.006842\n",
      "06/29/2022 00:04:25 - INFO - __main__ -   Text: ['There is also the possibility that whistlestick music is not always fast alphabetical.']\n",
      "06/29/2022 00:04:26 - INFO - __main__ -   Epoch: 7 | Batch: 4200/10001 (42%) | G Loss: 4.026979 | C Loss: -3.205613\n",
      "06/29/2022 00:04:26 - INFO - __main__ -   Text: ['Sin may also be used to find of complex complicated problems.']\n",
      "06/29/2022 00:04:27 - INFO - __main__ -   Epoch: 7 | Batch: 4800/10001 (48%) | G Loss: 3.279959 | C Loss: -2.880702\n",
      "06/29/2022 00:04:27 - INFO - __main__ -   Text: ['No, no you Russian violin, I\\'m Russian.\"']\n",
      "06/29/2022 00:04:28 - INFO - __main__ -   Epoch: 7 | Batch: 5400/10001 (54%) | G Loss: 3.541090 | C Loss: -3.059975\n",
      "06/29/2022 00:04:28 - INFO - __main__ -   Text: ['The of Control Your Favorite Guys is a page diary.']\n",
      "06/29/2022 00:04:29 - INFO - __main__ -   Epoch: 7 | Batch: 6000/10001 (60%) | G Loss: 3.327699 | C Loss: -3.058364\n",
      "06/29/2022 00:04:29 - INFO - __main__ -   Text: ['Farmers are used to analyzing crops.']\n",
      "06/29/2022 00:04:30 - INFO - __main__ -   Epoch: 7 | Batch: 6600/10001 (66%) | G Loss: 3.459251 | C Loss: -2.941105\n",
      "06/29/2022 00:04:30 - INFO - __main__ -   Text: [\"Loremile's skill increases accordingly.\"]\n",
      "06/29/2022 00:04:31 - INFO - __main__ -   Epoch: 7 | Batch: 7200/10001 (72%) | G Loss: 3.755455 | C Loss: -2.965662\n",
      "06/29/2022 00:04:31 - INFO - __main__ -   Text: ['Easy and fast.']\n",
      "06/29/2022 00:04:32 - INFO - __main__ -   Epoch: 7 | Batch: 7800/10001 (78%) | G Loss: 3.118916 | C Loss: -2.839570\n",
      "06/29/2022 00:04:32 - INFO - __main__ -   Text: ['Back then I think it would both be North and South.\"']\n",
      "06/29/2022 00:04:33 - INFO - __main__ -   Epoch: 7 | Batch: 8400/10001 (84%) | G Loss: 3.604402 | C Loss: -3.068636\n",
      "06/29/2022 00:04:33 - INFO - __main__ -   Text: ['Morgue fails that test.']\n",
      "06/29/2022 00:04:34 - INFO - __main__ -   Epoch: 7 | Batch: 9000/10001 (90%) | G Loss: 3.359212 | C Loss: -2.821247\n",
      "06/29/2022 00:04:34 - INFO - __main__ -   Text: [\"Let people know he's a somebody.\"]\n",
      "06/29/2022 00:04:35 - INFO - __main__ -   Epoch: 7 | Batch: 9600/10001 (96%) | G Loss: 3.482239 | C Loss: -2.876619\n",
      "06/29/2022 00:04:35 - INFO - __main__ -   Text: ['They are popular celebrities and famous people.']\n",
      "06/29/2022 00:04:36 - INFO - __main__ -   * (Train) Epoch: 7 | G Loss: 3.5501 | C Loss: -3.0093 | Updates G: 222 | Updates C: 611\n",
      "06/29/2022 00:04:44 - INFO - __main__ -   Bleu-2:0.217 | B-Bleu-2:0.275\n",
      "06/29/2022 00:04:44 - INFO - __main__ -   * Saving. Best Score:0.493 | Bleu-2:0.217 | B-Bleu-2:0.275\n",
      "06/29/2022 00:04:44 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492635028035026\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 8 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:44.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:00.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:15.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:31.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:18.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:33.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:49.\n",
      "\n",
      "  Average training loss generetor: 0.708\n",
      "  Average training loss discriminator: 0.943\n",
      "  Training epcoh took: 0:03:04\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:07:49 - INFO - __main__ -   Epoch: 8 | Batch: 0/10001 (0%) | G Loss: 3.479847 | C Loss: -2.725304\n",
      "06/29/2022 00:07:49 - INFO - __main__ -   Text: ['To Kill Me Unlike any other game, you need to be badly out of practice.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.460\n",
      "  Test Loss: 1.822\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:07:50 - INFO - __main__ -   Epoch: 8 | Batch: 600/10001 (6%) | G Loss: 3.327838 | C Loss: -3.050297\n",
      "06/29/2022 00:07:50 - INFO - __main__ -   Text: ['The cookie is thieves.']\n",
      "06/29/2022 00:07:51 - INFO - __main__ -   Epoch: 8 | Batch: 1200/10001 (12%) | G Loss: 3.352816 | C Loss: -3.033035\n",
      "06/29/2022 00:07:51 - INFO - __main__ -   Text: ['It is about case and event, and may or may not fall in love.\"']\n",
      "06/29/2022 00:07:52 - INFO - __main__ -   Epoch: 8 | Batch: 1800/10001 (18%) | G Loss: 3.019660 | C Loss: -2.847000\n",
      "06/29/2022 00:07:52 - INFO - __main__ -   Text: ['9010110 will need to know fuck everything.']\n",
      "06/29/2022 00:07:53 - INFO - __main__ -   Epoch: 8 | Batch: 2400/10001 (24%) | G Loss: 3.139567 | C Loss: -2.735409\n",
      "06/29/2022 00:07:53 - INFO - __main__ -   Text: ['The name derives from this.']\n",
      "06/29/2022 00:07:54 - INFO - __main__ -   Epoch: 8 | Batch: 3000/10001 (30%) | G Loss: 3.519344 | C Loss: -2.913223\n",
      "06/29/2022 00:07:54 - INFO - __main__ -   Text: ['This would make him Frankenstein fan.']\n",
      "06/29/2022 00:07:55 - INFO - __main__ -   Epoch: 8 | Batch: 3600/10001 (36%) | G Loss: 3.259453 | C Loss: -2.749127\n",
      "06/29/2022 00:07:55 - INFO - __main__ -   Text: ['The LifeWriter blog touches on everything from a doctor to football in order to achieve a higher number of monsters.']\n",
      "06/29/2022 00:07:56 - INFO - __main__ -   Epoch: 8 | Batch: 4200/10001 (42%) | G Loss: 3.329996 | C Loss: -2.861383\n",
      "06/29/2022 00:07:56 - INFO - __main__ -   Text: ['This is the term \"unfair\".']\n",
      "06/29/2022 00:07:57 - INFO - __main__ -   Epoch: 8 | Batch: 4800/10001 (48%) | G Loss: 2.977327 | C Loss: -2.699411\n",
      "06/29/2022 00:07:57 - INFO - __main__ -   Text: [\"Sidewalker discovers that it isn't even thermite.\"]\n",
      "06/29/2022 00:07:58 - INFO - __main__ -   Epoch: 8 | Batch: 5400/10001 (54%) | G Loss: 3.238183 | C Loss: -2.807277\n",
      "06/29/2022 00:07:59 - INFO - __main__ -   Text: ['He is intrigued by the philosophy of quantum physics.']\n",
      "06/29/2022 00:07:59 - INFO - __main__ -   Epoch: 8 | Batch: 6000/10001 (60%) | G Loss: 3.214187 | C Loss: -2.743927\n",
      "06/29/2022 00:07:59 - INFO - __main__ -   Text: ['These are unresolved.']\n",
      "06/29/2022 00:08:00 - INFO - __main__ -   Epoch: 8 | Batch: 6600/10001 (66%) | G Loss: 3.061140 | C Loss: -2.713546\n",
      "06/29/2022 00:08:01 - INFO - __main__ -   Text: ['Abraham enters the code 50% quicker.']\n",
      "06/29/2022 00:08:01 - INFO - __main__ -   Epoch: 8 | Batch: 7200/10001 (72%) | G Loss: 3.452035 | C Loss: -2.839252\n",
      "06/29/2022 00:08:02 - INFO - __main__ -   Text: [') <PAD> identifies themselves with the theosophistic.']\n",
      "06/29/2022 00:08:03 - INFO - __main__ -   Epoch: 8 | Batch: 7800/10001 (78%) | G Loss: 3.143241 | C Loss: -2.770351\n",
      "06/29/2022 00:08:03 - INFO - __main__ -   Text: ['Incoming mirror is valuable, and there is no philosophy taught here.']\n",
      "06/29/2022 00:08:04 - INFO - __main__ -   Epoch: 8 | Batch: 8400/10001 (84%) | G Loss: 3.073801 | C Loss: -2.641551\n",
      "06/29/2022 00:08:04 - INFO - __main__ -   Text: ['There is a plot-heavy instance of this teaching.']\n",
      "06/29/2022 00:08:05 - INFO - __main__ -   Epoch: 8 | Batch: 9000/10001 (90%) | G Loss: 3.016514 | C Loss: -2.383802\n",
      "06/29/2022 00:08:05 - INFO - __main__ -   Text: ['Instead with simplicity refer to Bevel.']\n",
      "06/29/2022 00:08:06 - INFO - __main__ -   Epoch: 8 | Batch: 9600/10001 (96%) | G Loss: 2.734388 | C Loss: -2.334183\n",
      "06/29/2022 00:08:06 - INFO - __main__ -   Text: ['It is a conscious rebuttal to friendly questioning.']\n",
      "06/29/2022 00:08:06 - INFO - __main__ -   * (Train) Epoch: 8 | G Loss: 3.1953 | C Loss: -2.7071 | Updates G: 237 | Updates C: 596\n",
      "06/29/2022 00:08:15 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.277\n",
      "06/29/2022 00:08:15 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48338889265521523\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 9 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:32.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:48.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:04.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:19.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:35.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:50.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:21.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:53.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.902\n",
      "  Training epcoh took: 0:03:08\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:11:23 - INFO - __main__ -   Epoch: 9 | Batch: 0/10001 (0%) | G Loss: 3.097848 | C Loss: -2.702584\n",
      "06/29/2022 00:11:23 - INFO - __main__ -   Text: ['What type of a person is he aka?\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.453\n",
      "  Test Loss: 1.879\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:11:24 - INFO - __main__ -   Epoch: 9 | Batch: 600/10001 (6%) | G Loss: 2.868973 | C Loss: -2.458696\n",
      "06/29/2022 00:11:24 - INFO - __main__ -   Text: ['Her hat is that glassware is the better way.']\n",
      "06/29/2022 00:11:25 - INFO - __main__ -   Epoch: 9 | Batch: 1200/10001 (12%) | G Loss: 2.938197 | C Loss: -2.503902\n",
      "06/29/2022 00:11:25 - INFO - __main__ -   Text: ['A great name like Tolkien would clarify this.']\n",
      "06/29/2022 00:11:26 - INFO - __main__ -   Epoch: 9 | Batch: 1800/10001 (18%) | G Loss: 3.002851 | C Loss: -2.616432\n",
      "06/29/2022 00:11:26 - INFO - __main__ -   Text: ['Others use their meet separately as a forum forum.']\n",
      "06/29/2022 00:11:27 - INFO - __main__ -   Epoch: 9 | Batch: 2400/10001 (24%) | G Loss: 2.943268 | C Loss: -2.420340\n",
      "06/29/2022 00:11:27 - INFO - __main__ -   Text: ['This is what I mean..']\n",
      "06/29/2022 00:11:28 - INFO - __main__ -   Epoch: 9 | Batch: 3000/10001 (30%) | G Loss: 3.045290 | C Loss: -2.495130\n",
      "06/29/2022 00:11:28 - INFO - __main__ -   Text: ['Oh Kisimos, AI will be strong.']\n",
      "06/29/2022 00:11:29 - INFO - __main__ -   Epoch: 9 | Batch: 3600/10001 (36%) | G Loss: 2.932445 | C Loss: -2.511308\n",
      "06/29/2022 00:11:29 - INFO - __main__ -   Text: ['Visualists make sense because the camera is everywhere.']\n",
      "06/29/2022 00:11:30 - INFO - __main__ -   Epoch: 9 | Batch: 4200/10001 (42%) | G Loss: 2.987919 | C Loss: -2.506376\n",
      "06/29/2022 00:11:30 - INFO - __main__ -   Text: ['Sheveragh human is producing a very bile cereal.']\n",
      "06/29/2022 00:11:31 - INFO - __main__ -   Epoch: 9 | Batch: 4800/10001 (48%) | G Loss: 3.063180 | C Loss: -2.430616\n",
      "06/29/2022 00:11:32 - INFO - __main__ -   Text: ['A new cognitive ability to write comes from \"Dawkin\".']\n",
      "06/29/2022 00:11:32 - INFO - __main__ -   Epoch: 9 | Batch: 5400/10001 (54%) | G Loss: 2.982099 | C Loss: -2.446224\n",
      "06/29/2022 00:11:33 - INFO - __main__ -   Text: ['Examples of examples include Parkland, 125 Fact, Practice.']\n",
      "06/29/2022 00:11:34 - INFO - __main__ -   Epoch: 9 | Batch: 6000/10001 (60%) | G Loss: 2.682659 | C Loss: -2.362890\n",
      "06/29/2022 00:11:34 - INFO - __main__ -   Text: ['To peg attention to regular events, it has almost lost its name.']\n",
      "06/29/2022 00:11:35 - INFO - __main__ -   Epoch: 9 | Batch: 6600/10001 (66%) | G Loss: 2.824278 | C Loss: -2.302615\n",
      "06/29/2022 00:11:35 - INFO - __main__ -   Text: ['All these values would seem like nonsense!']\n",
      "06/29/2022 00:11:36 - INFO - __main__ -   Epoch: 9 | Batch: 7200/10001 (72%) | G Loss: 2.810827 | C Loss: -2.417243\n",
      "06/29/2022 00:11:36 - INFO - __main__ -   Text: ['Emphasising that a blue teddy bear is born.']\n",
      "06/29/2022 00:11:37 - INFO - __main__ -   Epoch: 9 | Batch: 7800/10001 (78%) | G Loss: 2.564262 | C Loss: -2.281774\n",
      "06/29/2022 00:11:37 - INFO - __main__ -   Text: ['Deliverence is just something to do right.']\n",
      "06/29/2022 00:11:38 - INFO - __main__ -   Epoch: 9 | Batch: 8400/10001 (84%) | G Loss: 2.725152 | C Loss: -2.350717\n",
      "06/29/2022 00:11:38 - INFO - __main__ -   Text: ['Even child skill is not opposed to online.']\n",
      "06/29/2022 00:11:39 - INFO - __main__ -   Epoch: 9 | Batch: 9000/10001 (90%) | G Loss: 2.619279 | C Loss: -2.184468\n",
      "06/29/2022 00:11:39 - INFO - __main__ -   Text: ['Nomads will read: a cashing to mythological faith.']\n",
      "06/29/2022 00:11:40 - INFO - __main__ -   Epoch: 9 | Batch: 9600/10001 (96%) | G Loss: 2.541632 | C Loss: -2.231233\n",
      "06/29/2022 00:11:40 - INFO - __main__ -   Text: ['Meanwhile, 9 or 10 college students may be \"parkballed\".']\n",
      "06/29/2022 00:11:41 - INFO - __main__ -   * (Train) Epoch: 9 | G Loss: 2.8644 | C Loss: -2.4361 | Updates G: 245 | Updates C: 588\n",
      "06/29/2022 00:11:49 - INFO - __main__ -   Bleu-2:0.223 | B-Bleu-2:0.239\n",
      "06/29/2022 00:11:49 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4616985228734093\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 10 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:46.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:17.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:33.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:21.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:52.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 0.859\n",
      "  Training epcoh took: 0:03:07\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:14:57 - INFO - __main__ -   Epoch: 10 | Batch: 0/10001 (0%) | G Loss: 2.750843 | C Loss: -2.363748\n",
      "06/29/2022 00:14:57 - INFO - __main__ -   Text: ['It describes a girl\\'s attitude towards the girl \"Oh!']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.463\n",
      "  Test Loss: 1.931\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:14:58 - INFO - __main__ -   Epoch: 10 | Batch: 600/10001 (6%) | G Loss: 2.670437 | C Loss: -2.263986\n",
      "06/29/2022 00:14:58 - INFO - __main__ -   Text: ['Which way to go?']\n",
      "06/29/2022 00:14:59 - INFO - __main__ -   Epoch: 10 | Batch: 1200/10001 (12%) | G Loss: 2.597699 | C Loss: -2.268857\n",
      "06/29/2022 00:14:59 - INFO - __main__ -   Text: ['There is no automatic method.']\n",
      "06/29/2022 00:15:00 - INFO - __main__ -   Epoch: 10 | Batch: 1800/10001 (18%) | G Loss: 2.780270 | C Loss: -2.394011\n",
      "06/29/2022 00:15:00 - INFO - __main__ -   Text: ['Zombies are best friends ...']\n",
      "06/29/2022 00:15:01 - INFO - __main__ -   Epoch: 10 | Batch: 2400/10001 (24%) | G Loss: 2.619523 | C Loss: -2.205571\n",
      "06/29/2022 00:15:01 - INFO - __main__ -   Text: [\"This may be some of the most depressing comments I've ever made.\"]\n",
      "06/29/2022 00:15:02 - INFO - __main__ -   Epoch: 10 | Batch: 3000/10001 (30%) | G Loss: 2.485711 | C Loss: -2.218050\n",
      "06/29/2022 00:15:02 - INFO - __main__ -   Text: ['\"Romia | Amity\" refers to this type of stuff.']\n",
      "06/29/2022 00:15:03 - INFO - __main__ -   Epoch: 10 | Batch: 3600/10001 (36%) | G Loss: 2.431863 | C Loss: -2.110157\n",
      "06/29/2022 00:15:03 - INFO - __main__ -   Text: ['The betting-friendly message is to enter the map.']\n",
      "06/29/2022 00:15:04 - INFO - __main__ -   Epoch: 10 | Batch: 4200/10001 (42%) | G Loss: 2.600652 | C Loss: -2.166753\n",
      "06/29/2022 00:15:04 - INFO - __main__ -   Text: ['However, Dr.. Tardifies no you.']\n",
      "06/29/2022 00:15:05 - INFO - __main__ -   Epoch: 10 | Batch: 4800/10001 (48%) | G Loss: 2.670032 | C Loss: -2.194494\n",
      "06/29/2022 00:15:05 - INFO - __main__ -   Text: ['Two common rules of baseball play are that man kills first.']\n",
      "06/29/2022 00:15:06 - INFO - __main__ -   Epoch: 10 | Batch: 5400/10001 (54%) | G Loss: 2.411226 | C Loss: -2.083083\n",
      "06/29/2022 00:15:06 - INFO - __main__ -   Text: ['An idea of isolation is to restrict entire communities to manual labour.']\n",
      "06/29/2022 00:15:07 - INFO - __main__ -   Epoch: 10 | Batch: 6000/10001 (60%) | G Loss: 2.711893 | C Loss: -2.224437\n",
      "06/29/2022 00:15:07 - INFO - __main__ -   Text: ['The title of the game is \"\" homework.']\n",
      "06/29/2022 00:15:08 - INFO - __main__ -   Epoch: 10 | Batch: 6600/10001 (66%) | G Loss: 2.359074 | C Loss: -2.010193\n",
      "06/29/2022 00:15:08 - INFO - __main__ -   Text: [\"The subject says that 'My husband needs my almost!\"]\n",
      "06/29/2022 00:15:09 - INFO - __main__ -   Epoch: 10 | Batch: 7200/10001 (72%) | G Loss: 2.202454 | C Loss: -1.902053\n",
      "06/29/2022 00:15:10 - INFO - __main__ -   Text: ['For instance, if two of the beans are negative, this substitution.']\n",
      "06/29/2022 00:15:10 - INFO - __main__ -   Epoch: 10 | Batch: 7800/10001 (78%) | G Loss: 2.597322 | C Loss: -2.109820\n",
      "06/29/2022 00:15:11 - INFO - __main__ -   Text: ['to show people how things are.)']\n",
      "06/29/2022 00:15:12 - INFO - __main__ -   Epoch: 10 | Batch: 8400/10001 (84%) | G Loss: 2.330011 | C Loss: -1.971093\n",
      "06/29/2022 00:15:12 - INFO - __main__ -   Text: ['Telepathy might say that the Unix so far looks ordinary.']\n",
      "06/29/2022 00:15:13 - INFO - __main__ -   Epoch: 10 | Batch: 9000/10001 (90%) | G Loss: 2.278693 | C Loss: -1.866542\n",
      "06/29/2022 00:15:13 - INFO - __main__ -   Text: ['The brief was Brew Angel, Sage of Liberty.']\n",
      "06/29/2022 00:15:14 - INFO - __main__ -   Epoch: 10 | Batch: 9600/10001 (96%) | G Loss: 2.238972 | C Loss: -1.775562\n",
      "06/29/2022 00:15:14 - INFO - __main__ -   Text: ['\"\" The princess calls.\"\"']\n",
      "06/29/2022 00:15:14 - INFO - __main__ -   * (Train) Epoch: 10 | G Loss: 2.5187 | C Loss: -2.0992 | Updates G: 263 | Updates C: 570\n",
      "06/29/2022 00:15:21 - INFO - __main__ -   Bleu-2:0.202 | B-Bleu-2:0.250\n",
      "06/29/2022 00:15:21 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4516707816164156\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 11 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:14.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:27.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:41.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:56.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:39.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:54.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:09.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:23.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:36.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.835\n",
      "  Training epcoh took: 0:02:50\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:18:11 - INFO - __main__ -   Epoch: 11 | Batch: 0/10001 (0%) | G Loss: 2.493561 | C Loss: -2.020450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.460\n",
      "  Test Loss: 1.984\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:18:11 - INFO - __main__ -   Text: ['It is praised by some vernacular writers which means it is only possible for the cat.']\n",
      "06/29/2022 00:18:12 - INFO - __main__ -   Epoch: 11 | Batch: 600/10001 (6%) | G Loss: 2.386309 | C Loss: -1.965739\n",
      "06/29/2022 00:18:12 - INFO - __main__ -   Text: ['These are sarcasm in the modern framework.']\n",
      "06/29/2022 00:18:13 - INFO - __main__ -   Epoch: 11 | Batch: 1200/10001 (12%) | G Loss: 2.120681 | C Loss: -1.733567\n",
      "06/29/2022 00:18:13 - INFO - __main__ -   Text: ['\"Doo Leader\" is waiting for daily life action.']\n",
      "06/29/2022 00:18:14 - INFO - __main__ -   Epoch: 11 | Batch: 1800/10001 (18%) | G Loss: 2.414364 | C Loss: -1.900485\n",
      "06/29/2022 00:18:15 - INFO - __main__ -   Text: ['As a result, bron in, do you really want to be part of the capital?\" <PAD> Therefore,']\n",
      "06/29/2022 00:18:15 - INFO - __main__ -   Epoch: 11 | Batch: 2400/10001 (24%) | G Loss: 2.326859 | C Loss: -1.983680\n",
      "06/29/2022 00:18:16 - INFO - __main__ -   Text: ['Then,\" reiterates The \"moral panic\".']\n",
      "06/29/2022 00:18:16 - INFO - __main__ -   Epoch: 11 | Batch: 3000/10001 (30%) | G Loss: 2.228712 | C Loss: -1.861141\n",
      "06/29/2022 00:18:17 - INFO - __main__ -   Text: ['This is the is letter a prince writes in his novel.']\n",
      "06/29/2022 00:18:18 - INFO - __main__ -   Epoch: 11 | Batch: 3600/10001 (36%) | G Loss: 2.257297 | C Loss: -1.904499\n",
      "06/29/2022 00:18:18 - INFO - __main__ -   Text: ['For example, \"Ain ging\".']\n",
      "06/29/2022 00:18:19 - INFO - __main__ -   Epoch: 11 | Batch: 4200/10001 (42%) | G Loss: 2.382536 | C Loss: -1.983672\n",
      "06/29/2022 00:18:19 - INFO - __main__ -   Text: ['\"Joe ibn Isaac\".']\n",
      "06/29/2022 00:18:20 - INFO - __main__ -   Epoch: 11 | Batch: 4800/10001 (48%) | G Loss: 2.351961 | C Loss: -1.861665\n",
      "06/29/2022 00:18:20 - INFO - __main__ -   Text: [\"But, I've become more disillusioned with pretending.\"]\n",
      "06/29/2022 00:18:21 - INFO - __main__ -   Epoch: 11 | Batch: 5400/10001 (54%) | G Loss: 2.025461 | C Loss: -1.767447\n",
      "06/29/2022 00:18:21 - INFO - __main__ -   Text: ['It is associated with nearly every problem commonly seen as a testicle.']\n",
      "06/29/2022 00:18:22 - INFO - __main__ -   Epoch: 11 | Batch: 6000/10001 (60%) | G Loss: 2.262134 | C Loss: -1.860237\n",
      "06/29/2022 00:18:22 - INFO - __main__ -   Text: ['\"Stop the crap!\"']\n",
      "06/29/2022 00:18:23 - INFO - __main__ -   Epoch: 11 | Batch: 6600/10001 (66%) | G Loss: 2.222795 | C Loss: -1.769385\n",
      "06/29/2022 00:18:23 - INFO - __main__ -   Text: ['One question that I hunt on site is why this person thinks \"hot\".']\n",
      "06/29/2022 00:18:24 - INFO - __main__ -   Epoch: 11 | Batch: 7200/10001 (72%) | G Loss: 2.019958 | C Loss: -1.738759\n",
      "06/29/2022 00:18:24 - INFO - __main__ -   Text: ['B. M. Virgil\\',\" Stewart said.']\n",
      "06/29/2022 00:18:25 - INFO - __main__ -   Epoch: 11 | Batch: 7800/10001 (78%) | G Loss: 2.253333 | C Loss: -1.918423\n",
      "06/29/2022 00:18:25 - INFO - __main__ -   Text: ['\"People who are based on humor tell me that\".']\n",
      "06/29/2022 00:18:26 - INFO - __main__ -   Epoch: 11 | Batch: 8400/10001 (84%) | G Loss: 2.267952 | C Loss: -1.857880\n",
      "06/29/2022 00:18:26 - INFO - __main__ -   Text: ['He teaches us to read, write and even math.']\n",
      "06/29/2022 00:18:27 - INFO - __main__ -   Epoch: 11 | Batch: 9000/10001 (90%) | G Loss: 2.062195 | C Loss: -1.652522\n",
      "06/29/2022 00:18:27 - INFO - __main__ -   Text: ['There is only mercy and especially mercy.']\n",
      "06/29/2022 00:18:28 - INFO - __main__ -   Epoch: 11 | Batch: 9600/10001 (96%) | G Loss: 2.200115 | C Loss: -1.749666\n",
      "06/29/2022 00:18:28 - INFO - __main__ -   Text: ['Nankel has a revolutionary theory that indicates manufacturing a beautiful phone.']\n",
      "06/29/2022 00:18:29 - INFO - __main__ -   * (Train) Epoch: 11 | G Loss: 2.2557 | C Loss: -1.8539 | Updates G: 240 | Updates C: 593\n",
      "06/29/2022 00:18:37 - INFO - __main__ -   Bleu-2:0.209 | B-Bleu-2:0.281\n",
      "06/29/2022 00:18:37 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_12.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4902285474070768\n",
      "Train file used is number 12\n",
      "../../yahoo/subdivided_large/train_12.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 12 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:32.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:49.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:05.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:22.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:38.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:55.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:11.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:27.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:43.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:00.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.819\n",
      "  Training epcoh took: 0:03:16\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:21:53 - INFO - __main__ -   Epoch: 12 | Batch: 0/10001 (0%) | G Loss: 2.366996 | C Loss: -1.797521\n",
      "06/29/2022 00:21:53 - INFO - __main__ -   Text: ['Ownership implies ownership of the big fish\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.465\n",
      "  Test Loss: 2.038\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:21:54 - INFO - __main__ -   Epoch: 12 | Batch: 600/10001 (6%) | G Loss: 2.113489 | C Loss: -1.701903\n",
      "06/29/2022 00:21:55 - INFO - __main__ -   Text: ['I tell you that my advice is to kill everyone.\"']\n",
      "06/29/2022 00:21:56 - INFO - __main__ -   Epoch: 12 | Batch: 1200/10001 (12%) | G Loss: 2.215156 | C Loss: -1.678754\n",
      "06/29/2022 00:21:56 - INFO - __main__ -   Text: ['It has no argument with Yum!\"']\n",
      "06/29/2022 00:21:57 - INFO - __main__ -   Epoch: 12 | Batch: 1800/10001 (18%) | G Loss: 2.110632 | C Loss: -1.825599\n",
      "06/29/2022 00:21:57 - INFO - __main__ -   Text: ['Most importantly, fishes must remove nuclear radiation.']\n",
      "06/29/2022 00:21:58 - INFO - __main__ -   Epoch: 12 | Batch: 2400/10001 (24%) | G Loss: 2.009809 | C Loss: -1.614370\n",
      "06/29/2022 00:21:58 - INFO - __main__ -   Text: ['Go To Write IS Like a Beautiful God.']\n",
      "06/29/2022 00:21:59 - INFO - __main__ -   Epoch: 12 | Batch: 3000/10001 (30%) | G Loss: 2.094208 | C Loss: -1.712322\n",
      "06/29/2022 00:21:59 - INFO - __main__ -   Text: ['Only thing that tells me that I\\'m somewhere\".']\n",
      "06/29/2022 00:22:00 - INFO - __main__ -   Epoch: 12 | Batch: 3600/10001 (36%) | G Loss: 1.990886 | C Loss: -1.588140\n",
      "06/29/2022 00:22:00 - INFO - __main__ -   Text: ['Two five-doors are not what you think of when you think of this.']\n",
      "06/29/2022 00:22:01 - INFO - __main__ -   Epoch: 12 | Batch: 4200/10001 (42%) | G Loss: 2.295106 | C Loss: -1.736893\n",
      "06/29/2022 00:22:01 - INFO - __main__ -   Text: ['Unlike Spike, they will be interested.']\n",
      "06/29/2022 00:22:02 - INFO - __main__ -   Epoch: 12 | Batch: 4800/10001 (48%) | G Loss: 2.164102 | C Loss: -1.659116\n",
      "06/29/2022 00:22:02 - INFO - __main__ -   Text: ['Karen has a motto on everything.\"']\n",
      "06/29/2022 00:22:03 - INFO - __main__ -   Epoch: 12 | Batch: 5400/10001 (54%) | G Loss: 1.900274 | C Loss: -1.556171\n",
      "06/29/2022 00:22:03 - INFO - __main__ -   Text: ['At TheWaterFly I\\'m green\".']\n",
      "06/29/2022 00:22:04 - INFO - __main__ -   Epoch: 12 | Batch: 6000/10001 (60%) | G Loss: 2.124148 | C Loss: -1.641139\n",
      "06/29/2022 00:22:04 - INFO - __main__ -   Text: ['Strictly speaking: their shadows are mine\".']\n",
      "06/29/2022 00:22:05 - INFO - __main__ -   Epoch: 12 | Batch: 6600/10001 (66%) | G Loss: 2.036803 | C Loss: -1.699270\n",
      "06/29/2022 00:22:05 - INFO - __main__ -   Text: ['And it is a hint of things to watch out.\"']\n",
      "06/29/2022 00:22:06 - INFO - __main__ -   Epoch: 12 | Batch: 7200/10001 (72%) | G Loss: 2.008453 | C Loss: -1.661382\n",
      "06/29/2022 00:22:06 - INFO - __main__ -   Text: ['As shit!']\n",
      "06/29/2022 00:22:07 - INFO - __main__ -   Epoch: 12 | Batch: 7800/10001 (78%) | G Loss: 2.106411 | C Loss: -1.596204\n",
      "06/29/2022 00:22:07 - INFO - __main__ -   Text: ['But I\\'m doing this\"igioh sandwiches?']\n",
      "06/29/2022 00:22:08 - INFO - __main__ -   Epoch: 12 | Batch: 8400/10001 (84%) | G Loss: 1.812996 | C Loss: -1.476414\n",
      "06/29/2022 00:22:08 - INFO - __main__ -   Text: ['They are known as Pitchblind.']\n",
      "06/29/2022 00:22:09 - INFO - __main__ -   Epoch: 12 | Batch: 9000/10001 (90%) | G Loss: 2.141814 | C Loss: -1.762571\n",
      "06/29/2022 00:22:09 - INFO - __main__ -   Text: [\"She uses 'Doctors' to tell people how to do it.\"]\n",
      "06/29/2022 00:22:10 - INFO - __main__ -   Epoch: 12 | Batch: 9600/10001 (96%) | G Loss: 1.898729 | C Loss: -1.270254\n",
      "06/29/2022 00:22:10 - INFO - __main__ -   Text: ['News and the sports are dictated to around here.']\n",
      "06/29/2022 00:22:11 - INFO - __main__ -   * (Train) Epoch: 12 | G Loss: 2.0610 | C Loss: -1.6431 | Updates G: 229 | Updates C: 604\n",
      "06/29/2022 00:22:19 - INFO - __main__ -   Bleu-2:0.208 | B-Bleu-2:0.266\n",
      "06/29/2022 00:22:19 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4738380092105102\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 13 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:44.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:59.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:14.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:19.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:49.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:01.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:16.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:31.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:17.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:33.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:47.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.802\n",
      "  Training epcoh took: 0:03:02\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:28:50 - INFO - __main__ -   Epoch: 14 | Batch: 0/10001 (0%) | G Loss: 1.797630 | C Loss: -1.351693\n",
      "06/29/2022 00:28:50 - INFO - __main__ -   Text: ['No exaggeration is coming.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.475\n",
      "  Test Loss: 2.121\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:28:51 - INFO - __main__ -   Epoch: 14 | Batch: 600/10001 (6%) | G Loss: 1.947430 | C Loss: -1.415884\n",
      "06/29/2022 00:28:51 - INFO - __main__ -   Text: ['Madhava is launching a social media campaign.']\n",
      "06/29/2022 00:28:52 - INFO - __main__ -   Epoch: 14 | Batch: 1200/10001 (12%) | G Loss: 1.681579 | C Loss: -1.235179\n",
      "06/29/2022 00:28:53 - INFO - __main__ -   Text: [\"This is where Reign's story begins - to send Truman readies.\"]\n",
      "06/29/2022 00:28:54 - INFO - __main__ -   Epoch: 14 | Batch: 1800/10001 (18%) | G Loss: 1.638764 | C Loss: -1.384003\n",
      "06/29/2022 00:28:54 - INFO - __main__ -   Text: ['For those seeking objective truth I will leave this to you.']\n",
      "06/29/2022 00:28:55 - INFO - __main__ -   Epoch: 14 | Batch: 2400/10001 (24%) | G Loss: 1.853272 | C Loss: -1.340849\n",
      "06/29/2022 00:28:55 - INFO - __main__ -   Text: ['tourists do very well in this action of \"development!\"']\n",
      "06/29/2022 00:28:56 - INFO - __main__ -   Epoch: 14 | Batch: 3000/10001 (30%) | G Loss: 1.530846 | C Loss: -1.109909\n",
      "06/29/2022 00:28:56 - INFO - __main__ -   Text: ['Eventually the name Winston comes to mind.']\n",
      "06/29/2022 00:28:57 - INFO - __main__ -   Epoch: 14 | Batch: 3600/10001 (36%) | G Loss: 1.749137 | C Loss: -1.317272\n",
      "06/29/2022 00:28:57 - INFO - __main__ -   Text: ['The story is about what Andrea needs you to become or what saving him was.']\n",
      "06/29/2022 00:28:58 - INFO - __main__ -   Epoch: 14 | Batch: 4200/10001 (42%) | G Loss: 1.760677 | C Loss: -1.302884\n",
      "06/29/2022 00:28:58 - INFO - __main__ -   Text: ['Its less obvious ability to esteem is sociopathism.']\n",
      "06/29/2022 00:28:59 - INFO - __main__ -   Epoch: 14 | Batch: 4800/10001 (48%) | G Loss: 1.696505 | C Loss: -1.179210\n",
      "06/29/2022 00:28:59 - INFO - __main__ -   Text: ['Is that the word for IAP?']\n",
      "06/29/2022 00:29:00 - INFO - __main__ -   Epoch: 14 | Batch: 5400/10001 (54%) | G Loss: 1.698305 | C Loss: -1.347669\n",
      "06/29/2022 00:29:00 - INFO - __main__ -   Text: ['The mastermind Adolf wants to be an eight-fingered card.']\n",
      "06/29/2022 00:29:01 - INFO - __main__ -   Epoch: 14 | Batch: 6000/10001 (60%) | G Loss: 1.639481 | C Loss: -1.171850\n",
      "06/29/2022 00:29:01 - INFO - __main__ -   Text: ['Beyonce has these sorts of things.']\n",
      "06/29/2022 00:29:02 - INFO - __main__ -   Epoch: 14 | Batch: 6600/10001 (66%) | G Loss: 1.680353 | C Loss: -1.282002\n",
      "06/29/2022 00:29:02 - INFO - __main__ -   Text: [\"It is now the only format I can use to tell someone what's happening in London.\"]\n",
      "06/29/2022 00:29:03 - INFO - __main__ -   Epoch: 14 | Batch: 7200/10001 (72%) | G Loss: 1.581164 | C Loss: -1.184390\n",
      "06/29/2022 00:29:03 - INFO - __main__ -   Text: ['A version of a \"ganda\".']\n",
      "06/29/2022 00:29:04 - INFO - __main__ -   Epoch: 14 | Batch: 7800/10001 (78%) | G Loss: 1.529549 | C Loss: -1.038522\n",
      "06/29/2022 00:29:04 - INFO - __main__ -   Text: ['On top of that, Harry is not afraid to remotely win over girls.']\n",
      "06/29/2022 00:29:05 - INFO - __main__ -   Epoch: 14 | Batch: 8400/10001 (84%) | G Loss: 1.585878 | C Loss: -1.216935\n",
      "06/29/2022 00:29:05 - INFO - __main__ -   Text: ['If you do one of these you should be Universal.\"']\n",
      "06/29/2022 00:29:06 - INFO - __main__ -   Epoch: 14 | Batch: 9000/10001 (90%) | G Loss: 1.608504 | C Loss: -1.154992\n",
      "06/29/2022 00:29:06 - INFO - __main__ -   Text: ['It lays down rules for a blind man to indulge in\".']\n",
      "06/29/2022 00:29:07 - INFO - __main__ -   Epoch: 14 | Batch: 9600/10001 (96%) | G Loss: 1.597076 | C Loss: -1.223760\n",
      "06/29/2022 00:29:07 - INFO - __main__ -   Text: ['It is used as their motto when dealing with children.']\n",
      "06/29/2022 00:29:08 - INFO - __main__ -   * (Train) Epoch: 14 | G Loss: 1.7034 | C Loss: -1.2654 | Updates G: 228 | Updates C: 605\n",
      "06/29/2022 00:29:16 - INFO - __main__ -   Bleu-2:0.229 | B-Bleu-2:0.265\n",
      "06/29/2022 00:29:16 - INFO - __main__ -   * Saving. Best Score:0.494 | Bleu-2:0.229 | B-Bleu-2:0.265\n",
      "06/29/2022 00:29:16 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4937510254976227\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 15 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:46.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:17.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:32.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:20.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:52.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.797\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:32:22 - INFO - __main__ -   Epoch: 15 | Batch: 0/10001 (0%) | G Loss: 1.600834 | C Loss: -1.236898\n",
      "06/29/2022 00:32:22 - INFO - __main__ -   Text: ['The culture is also hypomorphic to the god myth.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.465\n",
      "  Test Loss: 2.158\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:32:23 - INFO - __main__ -   Epoch: 15 | Batch: 600/10001 (6%) | G Loss: 1.661195 | C Loss: -1.233438\n",
      "06/29/2022 00:32:23 - INFO - __main__ -   Text: ['Not everyone has the justification to use.']\n",
      "06/29/2022 00:32:24 - INFO - __main__ -   Epoch: 15 | Batch: 1200/10001 (12%) | G Loss: 1.722321 | C Loss: -1.256488\n",
      "06/29/2022 00:32:24 - INFO - __main__ -   Text: ['My name is hope vs. fear.']\n",
      "06/29/2022 00:32:25 - INFO - __main__ -   Epoch: 15 | Batch: 1800/10001 (18%) | G Loss: 1.581938 | C Loss: -1.174939\n",
      "06/29/2022 00:32:25 - INFO - __main__ -   Text: ['These are Trickster famous thinking teeth.']\n",
      "06/29/2022 00:32:26 - INFO - __main__ -   Epoch: 15 | Batch: 2400/10001 (24%) | G Loss: 1.742889 | C Loss: -1.247876\n",
      "06/29/2022 00:32:27 - INFO - __main__ -   Text: ['It is halfway walk the other way.']\n",
      "06/29/2022 00:32:27 - INFO - __main__ -   Epoch: 15 | Batch: 3000/10001 (30%) | G Loss: 1.423189 | C Loss: -0.931950\n",
      "06/29/2022 00:32:28 - INFO - __main__ -   Text: ['Only some programmers can do it right.']\n",
      "06/29/2022 00:32:29 - INFO - __main__ -   Epoch: 15 | Batch: 3600/10001 (36%) | G Loss: 1.798629 | C Loss: -1.120880\n",
      "06/29/2022 00:32:29 - INFO - __main__ -   Text: ['A.type boob job!\"']\n",
      "06/29/2022 00:32:30 - INFO - __main__ -   Epoch: 15 | Batch: 4200/10001 (42%) | G Loss: 1.339328 | C Loss: -1.033054\n",
      "06/29/2022 00:32:30 - INFO - __main__ -   Text: ['They tell me that I am Black.\"']\n",
      "06/29/2022 00:32:31 - INFO - __main__ -   Epoch: 15 | Batch: 4800/10001 (48%) | G Loss: 1.518755 | C Loss: -1.102845\n",
      "06/29/2022 00:32:31 - INFO - __main__ -   Text: ['Another alternative would be fusion. <BOS> A plurals-gender combination is not an advantage.']\n",
      "06/29/2022 00:32:32 - INFO - __main__ -   Epoch: 15 | Batch: 5400/10001 (54%) | G Loss: 1.425093 | C Loss: -1.065229\n",
      "06/29/2022 00:32:32 - INFO - __main__ -   Text: ['This also helps explain how men can trade bone acorns.']\n",
      "06/29/2022 00:32:33 - INFO - __main__ -   Epoch: 15 | Batch: 6000/10001 (60%) | G Loss: 1.490592 | C Loss: -1.165029\n",
      "06/29/2022 00:32:33 - INFO - __main__ -   Text: ['The helpline is good at forecasting an attack.']\n",
      "06/29/2022 00:32:34 - INFO - __main__ -   Epoch: 15 | Batch: 6600/10001 (66%) | G Loss: 1.357656 | C Loss: -0.999200\n",
      "06/29/2022 00:32:34 - INFO - __main__ -   Text: ['In fact, it is fun :\".']\n",
      "06/29/2022 00:32:35 - INFO - __main__ -   Epoch: 15 | Batch: 7200/10001 (72%) | G Loss: 1.555860 | C Loss: -1.088459\n",
      "06/29/2022 00:32:35 - INFO - __main__ -   Text: ['They need help to recognize certain phrases they have heard.']\n",
      "06/29/2022 00:32:36 - INFO - __main__ -   Epoch: 15 | Batch: 7800/10001 (78%) | G Loss: 1.691194 | C Loss: -1.363528\n",
      "06/29/2022 00:32:36 - INFO - __main__ -   Text: ['The witch-hunt needs a multiview.']\n",
      "06/29/2022 00:32:37 - INFO - __main__ -   Epoch: 15 | Batch: 8400/10001 (84%) | G Loss: 1.335506 | C Loss: -0.963431\n",
      "06/29/2022 00:32:37 - INFO - __main__ -   Text: ['It can be a love affair or a romantic relation between a guy and a woman.\"']\n",
      "06/29/2022 00:32:38 - INFO - __main__ -   Epoch: 15 | Batch: 9000/10001 (90%) | G Loss: 1.468364 | C Loss: -1.044919\n",
      "06/29/2022 00:32:38 - INFO - __main__ -   Text: ['The beautiful thing about magic is that unlike people it can never stop.\"']\n",
      "06/29/2022 00:32:39 - INFO - __main__ -   Epoch: 15 | Batch: 9600/10001 (96%) | G Loss: 1.822564 | C Loss: -1.297913\n",
      "06/29/2022 00:32:39 - INFO - __main__ -   Text: [\"There's a mystic phenomenon called 'Homeopathy'.\"]\n",
      "06/29/2022 00:32:40 - INFO - __main__ -   * (Train) Epoch: 15 | G Loss: 1.5335 | C Loss: -1.1239 | Updates G: 217 | Updates C: 616\n",
      "06/29/2022 00:32:49 - INFO - __main__ -   Bleu-2:0.217 | B-Bleu-2:0.284\n",
      "06/29/2022 00:32:49 - INFO - __main__ -   * Saving. Best Score:0.501 | Bleu-2:0.217 | B-Bleu-2:0.284\n",
      "06/29/2022 00:32:49 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5008268215859827\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 16 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:32.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:48.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:03.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:19.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:36.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:51.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:07.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:23.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:55.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.784\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:35:59 - INFO - __main__ -   Epoch: 16 | Batch: 0/10001 (0%) | G Loss: 1.361267 | C Loss: -0.954726\n",
      "06/29/2022 00:35:59 - INFO - __main__ -   Text: ['However there is also some type of scam or trick endearment.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.475\n",
      "  Test Loss: 2.211\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:36:00 - INFO - __main__ -   Epoch: 16 | Batch: 600/10001 (6%) | G Loss: 1.700282 | C Loss: -1.327531\n",
      "06/29/2022 00:36:00 - INFO - __main__ -   Text: [\"It's anything but bland.\"]\n",
      "06/29/2022 00:36:01 - INFO - __main__ -   Epoch: 16 | Batch: 1200/10001 (12%) | G Loss: 1.427443 | C Loss: -0.896411\n",
      "06/29/2022 00:36:01 - INFO - __main__ -   Text: ['The engine of science fiction is the line \"Wow!']\n",
      "06/29/2022 00:36:02 - INFO - __main__ -   Epoch: 16 | Batch: 1800/10001 (18%) | G Loss: 1.225196 | C Loss: -0.821252\n",
      "06/29/2022 00:36:02 - INFO - __main__ -   Text: ['Akila also advises integrators to step straight into the punchbowl.']\n",
      "06/29/2022 00:36:03 - INFO - __main__ -   Epoch: 16 | Batch: 2400/10001 (24%) | G Loss: 1.626314 | C Loss: -1.238340\n",
      "06/29/2022 00:36:03 - INFO - __main__ -   Text: [\"Part of [[Q&A]] is where talking about stuff that technically isn't.\"]\n",
      "06/29/2022 00:36:04 - INFO - __main__ -   Epoch: 16 | Batch: 3000/10001 (30%) | G Loss: 1.216750 | C Loss: -0.889058\n",
      "06/29/2022 00:36:04 - INFO - __main__ -   Text: ['More To These Pegasus People!']\n",
      "06/29/2022 00:36:05 - INFO - __main__ -   Epoch: 16 | Batch: 3600/10001 (36%) | G Loss: 1.566505 | C Loss: -1.135935\n",
      "06/29/2022 00:36:05 - INFO - __main__ -   Text: ['The songwriters are not afraid of homosexuality.']\n",
      "06/29/2022 00:36:06 - INFO - __main__ -   Epoch: 16 | Batch: 4200/10001 (42%) | G Loss: 1.317203 | C Loss: -1.017489\n",
      "06/29/2022 00:36:06 - INFO - __main__ -   Text: ['There is some trickery to take.']\n",
      "06/29/2022 00:36:07 - INFO - __main__ -   Epoch: 16 | Batch: 4800/10001 (48%) | G Loss: 1.434529 | C Loss: -1.000383\n",
      "06/29/2022 00:36:07 - INFO - __main__ -   Text: ['Like candy, you often find it at the low Prices.']\n",
      "06/29/2022 00:36:08 - INFO - __main__ -   Epoch: 16 | Batch: 5400/10001 (54%) | G Loss: 1.701298 | C Loss: -1.158077\n",
      "06/29/2022 00:36:08 - INFO - __main__ -   Text: ['MASS.']\n",
      "06/29/2022 00:36:09 - INFO - __main__ -   Epoch: 16 | Batch: 6000/10001 (60%) | G Loss: 1.248561 | C Loss: -0.842952\n",
      "06/29/2022 00:36:09 - INFO - __main__ -   Text: ['Meerewolves are not allowed a chance to write a book.\"']\n",
      "06/29/2022 00:36:10 - INFO - __main__ -   Epoch: 16 | Batch: 6600/10001 (66%) | G Loss: 1.510342 | C Loss: -1.013938\n",
      "06/29/2022 00:36:10 - INFO - __main__ -   Text: ['A true understanding of his position can be viewed as a basic \"Daniel Lehwitz\".']\n",
      "06/29/2022 00:36:11 - INFO - __main__ -   Epoch: 16 | Batch: 7200/10001 (72%) | G Loss: 1.349773 | C Loss: -0.957661\n",
      "06/29/2022 00:36:12 - INFO - __main__ -   Text: ['They call it \"rocks,\" maybe meanery.']\n",
      "06/29/2022 00:36:12 - INFO - __main__ -   Epoch: 16 | Batch: 7800/10001 (78%) | G Loss: 1.255668 | C Loss: -0.788619\n",
      "06/29/2022 00:36:13 - INFO - __main__ -   Text: [\"5% don't want dance royalty.\"]\n",
      "06/29/2022 00:36:14 - INFO - __main__ -   Epoch: 16 | Batch: 8400/10001 (84%) | G Loss: 1.663614 | C Loss: -1.171945\n",
      "06/29/2022 00:36:14 - INFO - __main__ -   Text: ['Some people also call it \", : eat dogs\".']\n",
      "06/29/2022 00:36:15 - INFO - __main__ -   Epoch: 16 | Batch: 9000/10001 (90%) | G Loss: 1.314776 | C Loss: -0.826024\n",
      "06/29/2022 00:36:15 - INFO - __main__ -   Text: ['According to mythology, it is that \"existence\".']\n",
      "06/29/2022 00:36:16 - INFO - __main__ -   Epoch: 16 | Batch: 9600/10001 (96%) | G Loss: 1.821459 | C Loss: -1.386296\n",
      "06/29/2022 00:36:16 - INFO - __main__ -   Text: ['This is one of the strange ingredients that Natural Beauty teaches.']\n",
      "06/29/2022 00:36:16 - INFO - __main__ -   * (Train) Epoch: 16 | G Loss: 1.4238 | C Loss: -1.0143 | Updates G: 208 | Updates C: 625\n",
      "06/29/2022 00:36:24 - INFO - __main__ -   Bleu-2:0.196 | B-Bleu-2:0.241\n",
      "06/29/2022 00:36:24 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4367285074494429\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 17 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:29.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:43.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:58.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:55.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:09.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:24.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:38.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.777\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:39:16 - INFO - __main__ -   Epoch: 17 | Batch: 0/10001 (0%) | G Loss: 1.335688 | C Loss: -0.965354\n",
      "06/29/2022 00:39:16 - INFO - __main__ -   Text: ['If you want to know what people have been talking about of course.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.477\n",
      "  Test Loss: 2.241\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:39:17 - INFO - __main__ -   Epoch: 17 | Batch: 600/10001 (6%) | G Loss: 1.276345 | C Loss: -0.847652\n",
      "06/29/2022 00:39:17 - INFO - __main__ -   Text: ['\"Always one for romance\".']\n",
      "06/29/2022 00:39:18 - INFO - __main__ -   Epoch: 17 | Batch: 1200/10001 (12%) | G Loss: 1.474567 | C Loss: -1.008566\n",
      "06/29/2022 00:39:18 - INFO - __main__ -   Text: ['Some people like to say \"Put boats on bicycles and wheels!']\n",
      "06/29/2022 00:39:19 - INFO - __main__ -   Epoch: 17 | Batch: 1800/10001 (18%) | G Loss: 1.458965 | C Loss: -0.983131\n",
      "06/29/2022 00:39:19 - INFO - __main__ -   Text: ['\"Hello, I am mobile\".']\n",
      "06/29/2022 00:39:20 - INFO - __main__ -   Epoch: 17 | Batch: 2400/10001 (24%) | G Loss: 1.406907 | C Loss: -0.875813\n",
      "06/29/2022 00:39:20 - INFO - __main__ -   Text: ['Avoid the buzzword \"attack\".']\n",
      "06/29/2022 00:39:21 - INFO - __main__ -   Epoch: 17 | Batch: 3000/10001 (30%) | G Loss: 1.170176 | C Loss: -0.795054\n",
      "06/29/2022 00:39:21 - INFO - __main__ -   Text: ['This one is called Love\".']\n",
      "06/29/2022 00:39:22 - INFO - __main__ -   Epoch: 17 | Batch: 3600/10001 (36%) | G Loss: 1.225607 | C Loss: -0.845787\n",
      "06/29/2022 00:39:22 - INFO - __main__ -   Text: ['He is a genius because he thinks the product should be good.']\n",
      "06/29/2022 00:39:23 - INFO - __main__ -   Epoch: 17 | Batch: 4200/10001 (42%) | G Loss: 1.305277 | C Loss: -0.905504\n",
      "06/29/2022 00:39:23 - INFO - __main__ -   Text: ['It indicates that concentrating your brain is futile.']\n",
      "06/29/2022 00:39:24 - INFO - __main__ -   Epoch: 17 | Batch: 4800/10001 (48%) | G Loss: 1.134625 | C Loss: -0.768436\n",
      "06/29/2022 00:39:25 - INFO - __main__ -   Text: ['A lot of people believe that Douglas would rather be architect than artist.']\n",
      "06/29/2022 00:39:25 - INFO - __main__ -   Epoch: 17 | Batch: 5400/10001 (54%) | G Loss: 1.358854 | C Loss: -0.918179\n",
      "06/29/2022 00:39:26 - INFO - __main__ -   Text: ['There are many phrases and references in the wiki word for phrase.']\n",
      "06/29/2022 00:39:27 - INFO - __main__ -   Epoch: 17 | Batch: 6000/10001 (60%) | G Loss: 1.324970 | C Loss: -0.953727\n",
      "06/29/2022 00:39:27 - INFO - __main__ -   Text: ['It sneaks a little too soon into biology!']\n",
      "06/29/2022 00:39:28 - INFO - __main__ -   Epoch: 17 | Batch: 6600/10001 (66%) | G Loss: 1.253790 | C Loss: -0.857882\n",
      "06/29/2022 00:39:28 - INFO - __main__ -   Text: ['Other words: How to fill your heart with swag.\"']\n",
      "06/29/2022 00:39:29 - INFO - __main__ -   Epoch: 17 | Batch: 7200/10001 (72%) | G Loss: 1.237210 | C Loss: -0.941067\n",
      "06/29/2022 00:39:29 - INFO - __main__ -   Text: ['Both it and Asperger syndrome are terrible examples of raw stupidity.']\n",
      "06/29/2022 00:39:30 - INFO - __main__ -   Epoch: 17 | Batch: 7800/10001 (78%) | G Loss: 1.186384 | C Loss: -0.794093\n",
      "06/29/2022 00:39:30 - INFO - __main__ -   Text: ['The sexual is something we need to not only tell others but also to our potential mates.']\n",
      "06/29/2022 00:39:31 - INFO - __main__ -   Epoch: 17 | Batch: 8400/10001 (84%) | G Loss: 1.165780 | C Loss: -0.786283\n",
      "06/29/2022 00:39:31 - INFO - __main__ -   Text: ['S. Paulo and Paulo are both learning English.']\n",
      "06/29/2022 00:39:32 - INFO - __main__ -   Epoch: 17 | Batch: 9000/10001 (90%) | G Loss: 1.448141 | C Loss: -0.946948\n",
      "06/29/2022 00:39:32 - INFO - __main__ -   Text: ['\"Great Search for Incivility\" books way too much.']\n",
      "06/29/2022 00:39:33 - INFO - __main__ -   Epoch: 17 | Batch: 9600/10001 (96%) | G Loss: 1.289376 | C Loss: -0.816229\n",
      "06/29/2022 00:39:33 - INFO - __main__ -   Text: ['Walk it happily with respect A) or B) gardening.']\n",
      "06/29/2022 00:39:34 - INFO - __main__ -   * (Train) Epoch: 17 | G Loss: 1.3275 | C Loss: -0.8868 | Updates G: 198 | Updates C: 635\n",
      "06/29/2022 00:39:43 - INFO - __main__ -   Bleu-2:0.217 | B-Bleu-2:0.284\n",
      "06/29/2022 00:39:43 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_18.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5003994940034073\n",
      "Train file used is number 18\n",
      "../../yahoo/subdivided_large/train_18.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 18 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:46.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:17.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:33.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:20.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:51.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.773\n",
      "  Training epcoh took: 0:03:07\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:42:50 - INFO - __main__ -   Epoch: 18 | Batch: 0/10001 (0%) | G Loss: 1.170843 | C Loss: -0.710495\n",
      "06/29/2022 00:42:50 - INFO - __main__ -   Text: ['On the other hand, an akot its traitorous nature.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.472\n",
      "  Test Loss: 2.276\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:42:51 - INFO - __main__ -   Epoch: 18 | Batch: 600/10001 (6%) | G Loss: 1.424364 | C Loss: -0.941928\n",
      "06/29/2022 00:42:51 - INFO - __main__ -   Text: ['This is the spoof version of The Blob.']\n",
      "06/29/2022 00:42:52 - INFO - __main__ -   Epoch: 18 | Batch: 1200/10001 (12%) | G Loss: 1.497412 | C Loss: -1.030626\n",
      "06/29/2022 00:42:52 - INFO - __main__ -   Text: ['Stanley has never met a problem about economics.']\n",
      "06/29/2022 00:42:53 - INFO - __main__ -   Epoch: 18 | Batch: 1800/10001 (18%) | G Loss: 0.946818 | C Loss: -0.700205\n",
      "06/29/2022 00:42:53 - INFO - __main__ -   Text: ['Often, the stereotypes are irrational.']\n",
      "06/29/2022 00:42:54 - INFO - __main__ -   Epoch: 18 | Batch: 2400/10001 (24%) | G Loss: 1.501776 | C Loss: -1.083410\n",
      "06/29/2022 00:42:54 - INFO - __main__ -   Text: ['It is people who are freakyulity!\"']\n",
      "06/29/2022 00:42:55 - INFO - __main__ -   Epoch: 18 | Batch: 3000/10001 (30%) | G Loss: 1.173721 | C Loss: -0.846440\n",
      "06/29/2022 00:42:55 - INFO - __main__ -   Text: ['It is obsessed with space theory.']\n",
      "06/29/2022 00:42:56 - INFO - __main__ -   Epoch: 18 | Batch: 3600/10001 (36%) | G Loss: 1.203343 | C Loss: -0.744287\n",
      "06/29/2022 00:42:56 - INFO - __main__ -   Text: ['He may be worthless, stupid or sometimes immoral.']\n",
      "06/29/2022 00:42:57 - INFO - __main__ -   Epoch: 18 | Batch: 4200/10001 (42%) | G Loss: 1.155331 | C Loss: -0.738088\n",
      "06/29/2022 00:42:57 - INFO - __main__ -   Text: [\"It's a warning to all men about people who want sex.\"]\n",
      "06/29/2022 00:42:58 - INFO - __main__ -   Epoch: 18 | Batch: 4800/10001 (48%) | G Loss: 1.196178 | C Loss: -0.821041\n",
      "06/29/2022 00:42:59 - INFO - __main__ -   Text: ['The only thing about him that disturbs him is the intensity of the song.']\n",
      "06/29/2022 00:43:00 - INFO - __main__ -   Epoch: 18 | Batch: 5400/10001 (54%) | G Loss: 1.045891 | C Loss: -0.778522\n",
      "06/29/2022 00:43:00 - INFO - __main__ -   Text: ['Dowling crabs can be found everywhere!']\n",
      "06/29/2022 00:43:01 - INFO - __main__ -   Epoch: 18 | Batch: 6000/10001 (60%) | G Loss: 1.129538 | C Loss: -0.769866\n",
      "06/29/2022 00:43:01 - INFO - __main__ -   Text: ['This is a con.']\n",
      "06/29/2022 00:43:02 - INFO - __main__ -   Epoch: 18 | Batch: 6600/10001 (66%) | G Loss: 1.197504 | C Loss: -0.862963\n",
      "06/29/2022 00:43:02 - INFO - __main__ -   Text: ['This is called a male magnet.']\n",
      "06/29/2022 00:43:03 - INFO - __main__ -   Epoch: 18 | Batch: 7200/10001 (72%) | G Loss: 1.211026 | C Loss: -0.777751\n",
      "06/29/2022 00:43:03 - INFO - __main__ -   Text: ['People are getting better at earlier dance-arts than they were before.']\n",
      "06/29/2022 00:43:04 - INFO - __main__ -   Epoch: 18 | Batch: 7800/10001 (78%) | G Loss: 1.308309 | C Loss: -0.865457\n",
      "06/29/2022 00:43:04 - INFO - __main__ -   Text: ['These words are often used to exact revenge on certain people.']\n",
      "06/29/2022 00:43:05 - INFO - __main__ -   Epoch: 18 | Batch: 8400/10001 (84%) | G Loss: 1.013644 | C Loss: -0.712898\n",
      "06/29/2022 00:43:05 - INFO - __main__ -   Text: ['New ways knock at my door\"\"\").']\n",
      "06/29/2022 00:43:06 - INFO - __main__ -   Epoch: 18 | Batch: 9000/10001 (90%) | G Loss: 1.129204 | C Loss: -0.741926\n",
      "06/29/2022 00:43:06 - INFO - __main__ -   Text: ['Some people call myths \"poetry\", \"penis\".']\n",
      "06/29/2022 00:43:07 - INFO - __main__ -   Epoch: 18 | Batch: 9600/10001 (96%) | G Loss: 1.211152 | C Loss: -0.725253\n",
      "06/29/2022 00:43:07 - INFO - __main__ -   Text: ['The problem is that homosexuality is generally regarded as \"intoxication\".']\n",
      "06/29/2022 00:43:08 - INFO - __main__ -   * (Train) Epoch: 18 | G Loss: 1.2202 | C Loss: -0.8147 | Updates G: 197 | Updates C: 636\n",
      "06/29/2022 00:43:16 - INFO - __main__ -   Bleu-2:0.215 | B-Bleu-2:0.306\n",
      "06/29/2022 00:43:16 - INFO - __main__ -   * Saving. Best Score:0.521 | Bleu-2:0.215 | B-Bleu-2:0.306\n",
      "06/29/2022 00:43:16 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5206407827378049\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 19 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:32.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:48.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:03.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:19.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:35.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:51.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:07.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:22.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:53.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.773\n",
      "  Training epcoh took: 0:03:08\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:46:24 - INFO - __main__ -   Epoch: 19 | Batch: 0/10001 (0%) | G Loss: 1.075073 | C Loss: -0.609710\n",
      "06/29/2022 00:46:24 - INFO - __main__ -   Text: ['Under this equation \"dem\", \"de\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 2.350\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:46:25 - INFO - __main__ -   Epoch: 19 | Batch: 600/10001 (6%) | G Loss: 1.097297 | C Loss: -0.675926\n",
      "06/29/2022 00:46:25 - INFO - __main__ -   Text: ['Things that affect others are rare or nonexistent.\"']\n",
      "06/29/2022 00:46:26 - INFO - __main__ -   Epoch: 19 | Batch: 1200/10001 (12%) | G Loss: 1.067247 | C Loss: -0.683769\n",
      "06/29/2022 00:46:26 - INFO - __main__ -   Text: ['Also this makes her amulet more mind-guiding.']\n",
      "06/29/2022 00:46:27 - INFO - __main__ -   Epoch: 19 | Batch: 1800/10001 (18%) | G Loss: 1.123962 | C Loss: -0.870283\n",
      "06/29/2022 00:46:27 - INFO - __main__ -   Text: ['Retearnance is a good way to give experience.']\n",
      "06/29/2022 00:46:28 - INFO - __main__ -   Epoch: 19 | Batch: 2400/10001 (24%) | G Loss: 0.930594 | C Loss: -0.659965\n",
      "06/29/2022 00:46:28 - INFO - __main__ -   Text: ['Ten Pilots are required to attend all these programmes.']\n",
      "06/29/2022 00:46:29 - INFO - __main__ -   Epoch: 19 | Batch: 3000/10001 (30%) | G Loss: 1.209254 | C Loss: -0.815591\n",
      "06/29/2022 00:46:29 - INFO - __main__ -   Text: ['It is this skill of fiction that strikes me as the true orthographer.\"']\n",
      "06/29/2022 00:46:30 - INFO - __main__ -   Epoch: 19 | Batch: 3600/10001 (36%) | G Loss: 1.181660 | C Loss: -0.803530\n",
      "06/29/2022 00:46:30 - INFO - __main__ -   Text: ['is the fiercest character of his day.\"']\n",
      "06/29/2022 00:46:31 - INFO - __main__ -   Epoch: 19 | Batch: 4200/10001 (42%) | G Loss: 0.972001 | C Loss: -0.618938\n",
      "06/29/2022 00:46:31 - INFO - __main__ -   Text: ['They clearly feature a central tendency to sugar usage.\"']\n",
      "06/29/2022 00:46:32 - INFO - __main__ -   Epoch: 19 | Batch: 4800/10001 (48%) | G Loss: 1.143270 | C Loss: -0.743201\n",
      "06/29/2022 00:46:32 - INFO - __main__ -   Text: ['For example, they have a .']\n",
      "06/29/2022 00:46:33 - INFO - __main__ -   Epoch: 19 | Batch: 5400/10001 (54%) | G Loss: 1.155300 | C Loss: -0.752145\n",
      "06/29/2022 00:46:34 - INFO - __main__ -   Text: ['However, it is incorrectly classified as torture.']\n",
      "06/29/2022 00:46:34 - INFO - __main__ -   Epoch: 19 | Batch: 6000/10001 (60%) | G Loss: 1.048804 | C Loss: -0.719867\n",
      "06/29/2022 00:46:35 - INFO - __main__ -   Text: ['Frederks fans can expect a lot of fun.\"']\n",
      "06/29/2022 00:46:36 - INFO - __main__ -   Epoch: 19 | Batch: 6600/10001 (66%) | G Loss: 0.965519 | C Loss: -0.642194\n",
      "06/29/2022 00:46:36 - INFO - __main__ -   Text: ['It can be an aphrodisiac.\"']\n",
      "06/29/2022 00:46:37 - INFO - __main__ -   Epoch: 19 | Batch: 7200/10001 (72%) | G Loss: 1.272110 | C Loss: -0.831951\n",
      "06/29/2022 00:46:37 - INFO - __main__ -   Text: [\"The most common way that I come across is simply 'modern'.\"]\n",
      "06/29/2022 00:46:38 - INFO - __main__ -   Epoch: 19 | Batch: 7800/10001 (78%) | G Loss: 1.129140 | C Loss: -0.685473\n",
      "06/29/2022 00:46:38 - INFO - __main__ -   Text: ['The more likely it is that you call \"Megammoth\".']\n",
      "06/29/2022 00:46:39 - INFO - __main__ -   Epoch: 19 | Batch: 8400/10001 (84%) | G Loss: 0.873339 | C Loss: -0.597494\n",
      "06/29/2022 00:46:39 - INFO - __main__ -   Text: ['Chencellix is the only science fiction author on the island.']\n",
      "06/29/2022 00:46:40 - INFO - __main__ -   Epoch: 19 | Batch: 9000/10001 (90%) | G Loss: 1.171054 | C Loss: -0.696308\n",
      "06/29/2022 00:46:40 - INFO - __main__ -   Text: ['Having it is?']\n",
      "06/29/2022 00:46:41 - INFO - __main__ -   Epoch: 19 | Batch: 9600/10001 (96%) | G Loss: 1.197785 | C Loss: -0.828853\n",
      "06/29/2022 00:46:41 - INFO - __main__ -   Text: ['These readings include absolutes beliefs that mean no consequences.']\n",
      "06/29/2022 00:46:42 - INFO - __main__ -   * (Train) Epoch: 19 | G Loss: 1.1093 | C Loss: -0.7243 | Updates G: 204 | Updates C: 629\n",
      "06/29/2022 00:46:50 - INFO - __main__ -   Bleu-2:0.223 | B-Bleu-2:0.269\n",
      "06/29/2022 00:46:50 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49170782343006747\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 20 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:49.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:05.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:21.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:37.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:53.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:09.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:24.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:57.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.771\n",
      "  Training epcoh took: 0:03:13\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:50:03 - INFO - __main__ -   Epoch: 20 | Batch: 0/10001 (0%) | G Loss: 1.035105 | C Loss: -0.753618\n",
      "06/29/2022 00:50:04 - INFO - __main__ -   Text: ['It is almost entirely conditioned by rich knowledge of mathematics.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 2.402\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:50:05 - INFO - __main__ -   Epoch: 20 | Batch: 600/10001 (6%) | G Loss: 1.103526 | C Loss: -0.705151\n",
      "06/29/2022 00:50:05 - INFO - __main__ -   Text: ['It is how we imagine interaction with Father.']\n",
      "06/29/2022 00:50:06 - INFO - __main__ -   Epoch: 20 | Batch: 1200/10001 (12%) | G Loss: 1.128558 | C Loss: -0.780726\n",
      "06/29/2022 00:50:06 - INFO - __main__ -   Text: ['Most popular is changing tfBL previously.']\n",
      "06/29/2022 00:50:07 - INFO - __main__ -   Epoch: 20 | Batch: 1800/10001 (18%) | G Loss: 1.000468 | C Loss: -0.637871\n",
      "06/29/2022 00:50:07 - INFO - __main__ -   Text: ['The person says, \"Doesn\\'t matter... that\\'s the real economy of R.P.']\n",
      "06/29/2022 00:50:08 - INFO - __main__ -   Epoch: 20 | Batch: 2400/10001 (24%) | G Loss: 1.287114 | C Loss: -0.855515\n",
      "06/29/2022 00:50:08 - INFO - __main__ -   Text: ['They are misguided simply as they are not always true.']\n",
      "06/29/2022 00:50:09 - INFO - __main__ -   Epoch: 20 | Batch: 3000/10001 (30%) | G Loss: 0.930603 | C Loss: -0.443642\n",
      "06/29/2022 00:50:09 - INFO - __main__ -   Text: ['It also might be called Bull.>>Replacement for U.S.']\n",
      "06/29/2022 00:50:10 - INFO - __main__ -   Epoch: 20 | Batch: 3600/10001 (36%) | G Loss: 1.191832 | C Loss: -0.760084\n",
      "06/29/2022 00:50:10 - INFO - __main__ -   Text: [\"Ok I'm gay!\"]\n",
      "06/29/2022 00:50:11 - INFO - __main__ -   Epoch: 20 | Batch: 4200/10001 (42%) | G Loss: 0.865772 | C Loss: -0.477542\n",
      "06/29/2022 00:50:11 - INFO - __main__ -   Text: ['Here are some interesting tidbits.']\n",
      "06/29/2022 00:50:12 - INFO - __main__ -   Epoch: 20 | Batch: 4800/10001 (48%) | G Loss: 1.090626 | C Loss: -0.732937\n",
      "06/29/2022 00:50:12 - INFO - __main__ -   Text: ['\"Go bad boy, stubborn evil creep.\"']\n",
      "06/29/2022 00:50:13 - INFO - __main__ -   Epoch: 20 | Batch: 5400/10001 (54%) | G Loss: 1.296274 | C Loss: -0.826893\n",
      "06/29/2022 00:50:13 - INFO - __main__ -   Text: ['\"Put a stamp on that wheel\".']\n",
      "06/29/2022 00:50:14 - INFO - __main__ -   Epoch: 20 | Batch: 6000/10001 (60%) | G Loss: 1.242788 | C Loss: -0.771311\n",
      "06/29/2022 00:50:14 - INFO - __main__ -   Text: ['Many books say that Nibiru is one of the few sentient beings to avoid it.']\n",
      "06/29/2022 00:50:15 - INFO - __main__ -   Epoch: 20 | Batch: 6600/10001 (66%) | G Loss: 1.010640 | C Loss: -0.495769\n",
      "06/29/2022 00:50:15 - INFO - __main__ -   Text: ['Finally a rumour is, \"High water Middle bourgeoisie!']\n",
      "06/29/2022 00:50:16 - INFO - __main__ -   Epoch: 20 | Batch: 7200/10001 (72%) | G Loss: 1.029757 | C Loss: -0.671501\n",
      "06/29/2022 00:50:16 - INFO - __main__ -   Text: ['Although \"See You Is\" is not within its written form, it is one of those.']\n",
      "06/29/2022 00:50:17 - INFO - __main__ -   Epoch: 20 | Batch: 7800/10001 (78%) | G Loss: 1.133456 | C Loss: -0.773989\n",
      "06/29/2022 00:50:17 - INFO - __main__ -   Text: ['By definition, this is the perfect product to start a game.']\n",
      "06/29/2022 00:50:18 - INFO - __main__ -   Epoch: 20 | Batch: 8400/10001 (84%) | G Loss: 0.830685 | C Loss: -0.469118\n",
      "06/29/2022 00:50:19 - INFO - __main__ -   Text: ['Temperance is rarely referred to as Masty Woman.']\n",
      "06/29/2022 00:50:19 - INFO - __main__ -   Epoch: 20 | Batch: 9000/10001 (90%) | G Loss: 0.951509 | C Loss: -0.634603\n",
      "06/29/2022 00:50:20 - INFO - __main__ -   Text: ['<br> <br> <br> <br> <br> <br> <br>']\n",
      "06/29/2022 00:50:21 - INFO - __main__ -   Epoch: 20 | Batch: 9600/10001 (96%) | G Loss: 1.125335 | C Loss: -0.648337\n",
      "06/29/2022 00:50:21 - INFO - __main__ -   Text: [\"Believe it or not, copper wire won't melt.\"]\n",
      "06/29/2022 00:50:21 - INFO - __main__ -   * (Train) Epoch: 20 | G Loss: 1.0716 | C Loss: -0.6546 | Updates G: 178 | Updates C: 655\n",
      "06/29/2022 00:50:30 - INFO - __main__ -   Bleu-2:0.239 | B-Bleu-2:0.279\n",
      "06/29/2022 00:50:30 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5179917746360181\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 21 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:47.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:17.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:32.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:17.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:48.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.767\n",
      "  Training epcoh took: 0:03:02\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:53:32 - INFO - __main__ -   Epoch: 21 | Batch: 0/10000 (0%) | G Loss: 1.257063 | C Loss: -0.784590\n",
      "06/29/2022 00:53:32 - INFO - __main__ -   Text: ['They guide sexy chicks through an episode of Doctor Who.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.485\n",
      "  Test Loss: 2.422\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:53:33 - INFO - __main__ -   Epoch: 21 | Batch: 600/10000 (6%) | G Loss: 1.067419 | C Loss: -0.735398\n",
      "06/29/2022 00:53:33 - INFO - __main__ -   Text: ['They don\\'t discuss terror...\"']\n",
      "06/29/2022 00:53:34 - INFO - __main__ -   Epoch: 21 | Batch: 1200/10000 (12%) | G Loss: 0.870693 | C Loss: -0.514615\n",
      "06/29/2022 00:53:34 - INFO - __main__ -   Text: ['Despite this scene, sirokans are the best\".']\n",
      "06/29/2022 00:53:35 - INFO - __main__ -   Epoch: 21 | Batch: 1800/10000 (18%) | G Loss: 0.959019 | C Loss: -0.620531\n",
      "06/29/2022 00:53:35 - INFO - __main__ -   Text: ['Later you will find out thehingoetic beliefs.']\n",
      "06/29/2022 00:53:36 - INFO - __main__ -   Epoch: 21 | Batch: 2400/10000 (24%) | G Loss: 1.135247 | C Loss: -0.764210\n",
      "06/29/2022 00:53:36 - INFO - __main__ -   Text: ['He also tells them to \"Shanghai Darius.\"']\n",
      "06/29/2022 00:53:37 - INFO - __main__ -   Epoch: 21 | Batch: 3000/10000 (30%) | G Loss: 0.801645 | C Loss: -0.374232\n",
      "06/29/2022 00:53:37 - INFO - __main__ -   Text: ['Of course it is doomed to die!\"']\n",
      "06/29/2022 00:53:38 - INFO - __main__ -   Epoch: 21 | Batch: 3600/10000 (36%) | G Loss: 0.997032 | C Loss: -0.623907\n",
      "06/29/2022 00:53:38 - INFO - __main__ -   Text: ['They also describe it as \"manticore\", where it must meet unique criteria.']\n",
      "06/29/2022 00:53:39 - INFO - __main__ -   Epoch: 21 | Batch: 4200/10000 (42%) | G Loss: 1.210223 | C Loss: -0.627189\n",
      "06/29/2022 00:53:40 - INFO - __main__ -   Text: [\"Lock it in for some time and you won't get eleven atheist science books.\"]\n",
      "06/29/2022 00:53:41 - INFO - __main__ -   Epoch: 21 | Batch: 4800/10000 (48%) | G Loss: 1.091607 | C Loss: -0.735384\n",
      "06/29/2022 00:53:41 - INFO - __main__ -   Text: [\"Transmit is the word dropping worldwide that doesn't mean XL.\"]\n",
      "06/29/2022 00:53:42 - INFO - __main__ -   Epoch: 21 | Batch: 5400/10000 (54%) | G Loss: 0.931070 | C Loss: -0.456570\n",
      "06/29/2022 00:53:42 - INFO - __main__ -   Text: ['It is a metaphor for selfishness.']\n",
      "06/29/2022 00:53:43 - INFO - __main__ -   Epoch: 21 | Batch: 6000/10000 (60%) | G Loss: 0.868287 | C Loss: -0.516550\n",
      "06/29/2022 00:53:43 - INFO - __main__ -   Text: ['It is our task now to get our names backwards.']\n",
      "06/29/2022 00:53:44 - INFO - __main__ -   Epoch: 21 | Batch: 6600/10000 (66%) | G Loss: 1.170603 | C Loss: -0.726728\n",
      "06/29/2022 00:53:44 - INFO - __main__ -   Text: ['They can silence anyone with male anatomy.']\n",
      "06/29/2022 00:53:45 - INFO - __main__ -   Epoch: 21 | Batch: 7200/10000 (72%) | G Loss: 0.997582 | C Loss: -0.504033\n",
      "06/29/2022 00:53:45 - INFO - __main__ -   Text: ['This is highly accurate.']\n",
      "06/29/2022 00:53:46 - INFO - __main__ -   Epoch: 21 | Batch: 7800/10000 (78%) | G Loss: 0.902389 | C Loss: -0.455275\n",
      "06/29/2022 00:53:46 - INFO - __main__ -   Text: ['It is so that old Digitimes can be learned.']\n",
      "06/29/2022 00:53:47 - INFO - __main__ -   Epoch: 21 | Batch: 8400/10000 (84%) | G Loss: 0.840100 | C Loss: -0.485263\n",
      "06/29/2022 00:53:47 - INFO - __main__ -   Text: ['It is ← Sadism Is Eating.']\n",
      "06/29/2022 00:53:48 - INFO - __main__ -   Epoch: 21 | Batch: 9000/10000 (90%) | G Loss: 1.297250 | C Loss: -0.788334\n",
      "06/29/2022 00:53:48 - INFO - __main__ -   Text: ['Cancer is a personal enemy in light of your acne.']\n",
      "06/29/2022 00:53:49 - INFO - __main__ -   Epoch: 21 | Batch: 9600/10000 (96%) | G Loss: 1.042709 | C Loss: -0.486438\n",
      "06/29/2022 00:53:49 - INFO - __main__ -   Text: [\"The question is whether or not the average American is cut off from the world's most iconic meats.\"]\n",
      "06/29/2022 00:53:50 - INFO - __main__ -   * (Train) Epoch: 21 | G Loss: 1.0117 | C Loss: -0.5997 | Updates G: 174 | Updates C: 659\n",
      "06/29/2022 00:53:59 - INFO - __main__ -   Bleu-2:0.243 | B-Bleu-2:0.283\n",
      "06/29/2022 00:53:59 - INFO - __main__ -   * Saving. Best Score:0.526 | Bleu-2:0.243 | B-Bleu-2:0.283\n",
      "06/29/2022 00:53:59 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5257725477532053\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 22 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:47.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:04.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:20.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:35.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:52.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:07.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:23.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:55.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.763\n",
      "  Training epcoh took: 0:03:11\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:57:10 - INFO - __main__ -   Epoch: 22 | Batch: 0/10000 (0%) | G Loss: 1.244358 | C Loss: -0.863533\n",
      "06/29/2022 00:57:10 - INFO - __main__ -   Text: ['Topics add up to google\" \"Bruce Watson [sic].\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 2.451\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 00:57:11 - INFO - __main__ -   Epoch: 22 | Batch: 600/10000 (6%) | G Loss: 0.857055 | C Loss: -0.428903\n",
      "06/29/2022 00:57:11 - INFO - __main__ -   Text: ['You can go any judge with almost anything.']\n",
      "06/29/2022 00:57:12 - INFO - __main__ -   Epoch: 22 | Batch: 1200/10000 (12%) | G Loss: 0.950264 | C Loss: -0.461950\n",
      "06/29/2022 00:57:12 - INFO - __main__ -   Text: ['$ Screw to the vegan world!\"']\n",
      "06/29/2022 00:57:13 - INFO - __main__ -   Epoch: 22 | Batch: 1800/10000 (18%) | G Loss: 1.089789 | C Loss: -0.682061\n",
      "06/29/2022 00:57:13 - INFO - __main__ -   Text: ['\"Grave to [your name].\"']\n",
      "06/29/2022 00:57:14 - INFO - __main__ -   Epoch: 22 | Batch: 2400/10000 (24%) | G Loss: 1.147780 | C Loss: -0.665056\n",
      "06/29/2022 00:57:14 - INFO - __main__ -   Text: ['This is how I use this acronym: ni homme!\".']\n",
      "06/29/2022 00:57:15 - INFO - __main__ -   Epoch: 22 | Batch: 3000/10000 (30%) | G Loss: 0.874826 | C Loss: -0.510353\n",
      "06/29/2022 00:57:15 - INFO - __main__ -   Text: [\"The word 'Eat' is usually a PR who is arrogant.\"]\n",
      "06/29/2022 00:57:16 - INFO - __main__ -   Epoch: 22 | Batch: 3600/10000 (36%) | G Loss: 0.944362 | C Loss: -0.616717\n",
      "06/29/2022 00:57:16 - INFO - __main__ -   Text: ['The story of a parasharing adventure begins in spy novels.']\n",
      "06/29/2022 00:57:17 - INFO - __main__ -   Epoch: 22 | Batch: 4200/10000 (42%) | G Loss: 0.835418 | C Loss: -0.488371\n",
      "06/29/2022 00:57:17 - INFO - __main__ -   Text: ['Shane likes cards.']\n",
      "06/29/2022 00:57:18 - INFO - __main__ -   Epoch: 22 | Batch: 4800/10000 (48%) | G Loss: 1.010213 | C Loss: -0.551433\n",
      "06/29/2022 00:57:18 - INFO - __main__ -   Text: ['Child abuse mechanisms can be second nature here too.']\n",
      "06/29/2022 00:57:19 - INFO - __main__ -   Epoch: 22 | Batch: 5400/10000 (54%) | G Loss: 0.664046 | C Loss: -0.366357\n",
      "06/29/2022 00:57:19 - INFO - __main__ -   Text: ['Not everyone agrees with the concept of the EGo!']\n",
      "06/29/2022 00:57:20 - INFO - __main__ -   Epoch: 22 | Batch: 6000/10000 (60%) | G Loss: 0.945044 | C Loss: -0.596617\n",
      "06/29/2022 00:57:20 - INFO - __main__ -   Text: [\"The IRS don't read your name.\"]\n",
      "06/29/2022 00:57:21 - INFO - __main__ -   Epoch: 22 | Batch: 6600/10000 (66%) | G Loss: 0.996928 | C Loss: -0.593516\n",
      "06/29/2022 00:57:21 - INFO - __main__ -   Text: [\"Others call it straight bioB's Kiss.\"]\n",
      "06/29/2022 00:57:22 - INFO - __main__ -   Epoch: 22 | Batch: 7200/10000 (72%) | G Loss: 0.944938 | C Loss: -0.583232\n",
      "06/29/2022 00:57:22 - INFO - __main__ -   Text: ['Most likely, a whole suite of acronyms.\"']\n",
      "06/29/2022 00:57:23 - INFO - __main__ -   Epoch: 22 | Batch: 7800/10000 (78%) | G Loss: 0.729830 | C Loss: -0.421414\n",
      "06/29/2022 00:57:23 - INFO - __main__ -   Text: ['Things like \"breaking that bread?\"']\n",
      "06/29/2022 00:57:24 - INFO - __main__ -   Epoch: 22 | Batch: 8400/10000 (84%) | G Loss: 0.738912 | C Loss: -0.425727\n",
      "06/29/2022 00:57:25 - INFO - __main__ -   Text: ['He \"muscles on circumcision\" in the age travel.']\n",
      "06/29/2022 00:57:25 - INFO - __main__ -   Epoch: 22 | Batch: 9000/10000 (90%) | G Loss: 0.828863 | C Loss: -0.444002\n",
      "06/29/2022 00:57:26 - INFO - __main__ -   Text: ['Shepherd is only foolhardy when he speaks a language.']\n",
      "06/29/2022 00:57:27 - INFO - __main__ -   Epoch: 22 | Batch: 9600/10000 (96%) | G Loss: 0.892089 | C Loss: -0.532373\n",
      "06/29/2022 00:57:27 - INFO - __main__ -   Text: ['The only worthy means here is the \"fashions.\"']\n",
      "06/29/2022 00:57:27 - INFO - __main__ -   * (Train) Epoch: 22 | G Loss: 0.9273 | C Loss: -0.5194 | Updates G: 193 | Updates C: 640\n",
      "06/29/2022 00:57:36 - INFO - __main__ -   Bleu-2:0.220 | B-Bleu-2:0.270\n",
      "06/29/2022 00:57:36 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49040610198838724\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 23 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:49.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:05.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:21.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:37.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:52.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:07.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:23.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:54.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.758\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:00:45 - INFO - __main__ -   Epoch: 23 | Batch: 0/10001 (0%) | G Loss: 0.830355 | C Loss: -0.515131\n",
      "06/29/2022 01:00:45 - INFO - __main__ -   Text: ['Removes the casual attitude % to purpose.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 2.470\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:00:46 - INFO - __main__ -   Epoch: 23 | Batch: 600/10001 (6%) | G Loss: 0.668947 | C Loss: -0.417961\n",
      "06/29/2022 01:00:46 - INFO - __main__ -   Text: ['Everything goes on as we talk.']\n",
      "06/29/2022 01:00:47 - INFO - __main__ -   Epoch: 23 | Batch: 1200/10001 (12%) | G Loss: 0.946050 | C Loss: -0.611315\n",
      "06/29/2022 01:00:47 - INFO - __main__ -   Text: ['Like I understand, 50% isn\\'t.\"']\n",
      "06/29/2022 01:00:48 - INFO - __main__ -   Epoch: 23 | Batch: 1800/10001 (18%) | G Loss: 0.940319 | C Loss: -0.529666\n",
      "06/29/2022 01:00:48 - INFO - __main__ -   Text: ['It\\'s delicious!\"']\n",
      "06/29/2022 01:00:49 - INFO - __main__ -   Epoch: 23 | Batch: 2400/10001 (24%) | G Loss: 0.923496 | C Loss: -0.443071\n",
      "06/29/2022 01:00:49 - INFO - __main__ -   Text: ['The fourth letter is \"25% my minimum wage!\"']\n",
      "06/29/2022 01:00:50 - INFO - __main__ -   Epoch: 23 | Batch: 3000/10001 (30%) | G Loss: 0.803384 | C Loss: -0.429478\n",
      "06/29/2022 01:00:50 - INFO - __main__ -   Text: ['This is where \"The Jet-pack Guy\" might apply.']\n",
      "06/29/2022 01:00:51 - INFO - __main__ -   Epoch: 23 | Batch: 3600/10001 (36%) | G Loss: 0.832626 | C Loss: -0.462268\n",
      "06/29/2022 01:00:51 - INFO - __main__ -   Text: ['There are two mightily plausible ways to accomplish this.']\n",
      "06/29/2022 01:00:52 - INFO - __main__ -   Epoch: 23 | Batch: 4200/10001 (42%) | G Loss: 0.941713 | C Loss: -0.526958\n",
      "06/29/2022 01:00:52 - INFO - __main__ -   Text: ['Yes, it is about Madness.']\n",
      "06/29/2022 01:00:53 - INFO - __main__ -   Epoch: 23 | Batch: 4800/10001 (48%) | G Loss: 0.800772 | C Loss: -0.401637\n",
      "06/29/2022 01:00:53 - INFO - __main__ -   Text: ['Furthermore, music is a potential trouble-maker.\"']\n",
      "06/29/2022 01:00:54 - INFO - __main__ -   Epoch: 23 | Batch: 5400/10001 (54%) | G Loss: 1.009944 | C Loss: -0.441361\n",
      "06/29/2022 01:00:54 - INFO - __main__ -   Text: ['\"Achtungssthe T.W.A.']\n",
      "06/29/2022 01:00:55 - INFO - __main__ -   Epoch: 23 | Batch: 6000/10001 (60%) | G Loss: 0.777532 | C Loss: -0.483013\n",
      "06/29/2022 01:00:55 - INFO - __main__ -   Text: ['They banish commenting on cracked metaphor unless an athlete is famous.']\n",
      "06/29/2022 01:00:56 - INFO - __main__ -   Epoch: 23 | Batch: 6600/10001 (66%) | G Loss: 1.087018 | C Loss: -0.568275\n",
      "06/29/2022 01:00:57 - INFO - __main__ -   Text: ['The pupil I say can be provoked into believing in my knowledge.']\n",
      "06/29/2022 01:00:58 - INFO - __main__ -   Epoch: 23 | Batch: 7200/10001 (72%) | G Loss: 0.649432 | C Loss: -0.356913\n",
      "06/29/2022 01:00:58 - INFO - __main__ -   Text: ['The word \"buy\" is a crucial word for use and adoption.']\n",
      "06/29/2022 01:00:59 - INFO - __main__ -   Epoch: 23 | Batch: 7800/10001 (78%) | G Loss: 0.817236 | C Loss: -0.401887\n",
      "06/29/2022 01:00:59 - INFO - __main__ -   Text: ['This answers a query most of us require to understand speech.']\n",
      "06/29/2022 01:01:00 - INFO - __main__ -   Epoch: 23 | Batch: 8400/10001 (84%) | G Loss: 1.572424 | C Loss: -0.655821\n",
      "06/29/2022 01:01:00 - INFO - __main__ -   Text: ['I don\\'t know who used that term.\"']\n",
      "06/29/2022 01:01:01 - INFO - __main__ -   Epoch: 23 | Batch: 9000/10001 (90%) | G Loss: 0.630858 | C Loss: -0.266090\n",
      "06/29/2022 01:01:01 - INFO - __main__ -   Text: ['\"Ayaye, it results in something good.\"']\n",
      "06/29/2022 01:01:02 - INFO - __main__ -   Epoch: 23 | Batch: 9600/10001 (96%) | G Loss: 0.955359 | C Loss: -0.560679\n",
      "06/29/2022 01:01:02 - INFO - __main__ -   Text: ['This may be a result of weakness or ignorance of what Needs Data.']\n",
      "06/29/2022 01:01:03 - INFO - __main__ -   * (Train) Epoch: 23 | G Loss: 0.8628 | C Loss: -0.4753 | Updates G: 168 | Updates C: 665\n",
      "06/29/2022 01:01:10 - INFO - __main__ -   Bleu-2:0.217 | B-Bleu-2:0.272\n",
      "06/29/2022 01:01:10 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4892042965529029\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 24 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:44.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:58.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:56.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:11.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:26.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:40.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.755\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:04:04 - INFO - __main__ -   Epoch: 24 | Batch: 0/10001 (0%) | G Loss: 1.310341 | C Loss: -0.790496\n",
      "06/29/2022 01:04:05 - INFO - __main__ -   Text: ['The name \"Hollywood Flamen, Mana Patches\" is used.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.482\n",
      "  Test Loss: 2.528\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:04:06 - INFO - __main__ -   Epoch: 24 | Batch: 600/10001 (6%) | G Loss: 0.489088 | C Loss: -0.216172\n",
      "06/29/2022 01:04:06 - INFO - __main__ -   Text: ['The most important person you get takes you to the planet.']\n",
      "06/29/2022 01:04:07 - INFO - __main__ -   Epoch: 24 | Batch: 1200/10001 (12%) | G Loss: 0.545211 | C Loss: -0.361869\n",
      "06/29/2022 01:04:07 - INFO - __main__ -   Text: ['They lie so I can write things better than Ha!']\n",
      "06/29/2022 01:04:08 - INFO - __main__ -   Epoch: 24 | Batch: 1800/10001 (18%) | G Loss: 0.907974 | C Loss: -0.516156\n",
      "06/29/2022 01:04:08 - INFO - __main__ -   Text: ['\"It doesn\\'t mean that I am a genius cancercell!\"']\n",
      "06/29/2022 01:04:09 - INFO - __main__ -   Epoch: 24 | Batch: 2400/10001 (24%) | G Loss: 0.699677 | C Loss: -0.447097\n",
      "06/29/2022 01:04:09 - INFO - __main__ -   Text: ['Build alliances by what you give them.']\n",
      "06/29/2022 01:04:10 - INFO - __main__ -   Epoch: 24 | Batch: 3000/10001 (30%) | G Loss: 0.801743 | C Loss: -0.385463\n",
      "06/29/2022 01:04:10 - INFO - __main__ -   Text: ['Being able get some more pharmacological aid out has it for me.']\n",
      "06/29/2022 01:04:11 - INFO - __main__ -   Epoch: 24 | Batch: 3600/10001 (36%) | G Loss: 0.739577 | C Loss: -0.361505\n",
      "06/29/2022 01:04:11 - INFO - __main__ -   Text: ['The problems get even less available if you eat certain pizza.']\n",
      "06/29/2022 01:04:12 - INFO - __main__ -   Epoch: 24 | Batch: 4200/10001 (42%) | G Loss: 0.888061 | C Loss: -0.577828\n",
      "06/29/2022 01:04:12 - INFO - __main__ -   Text: ['Paul Smith uses this concept when making humor.']\n",
      "06/29/2022 01:04:13 - INFO - __main__ -   Epoch: 24 | Batch: 4800/10001 (48%) | G Loss: 0.582711 | C Loss: -0.376827\n",
      "06/29/2022 01:04:13 - INFO - __main__ -   Text: [\"The word 'stars' is used to help you cope.\"]\n",
      "06/29/2022 01:04:14 - INFO - __main__ -   Epoch: 24 | Batch: 5400/10001 (54%) | G Loss: 0.581861 | C Loss: -0.311051\n",
      "06/29/2022 01:04:14 - INFO - __main__ -   Text: [\"I mean as well the two's theory aspect and love.\"]\n",
      "06/29/2022 01:04:15 - INFO - __main__ -   Epoch: 24 | Batch: 6000/10001 (60%) | G Loss: 1.034669 | C Loss: -0.724505\n",
      "06/29/2022 01:04:15 - INFO - __main__ -   Text: [\"The answer is: It's OK to be an Ugly American.\"]\n",
      "06/29/2022 01:04:16 - INFO - __main__ -   Epoch: 24 | Batch: 6600/10001 (66%) | G Loss: 0.967697 | C Loss: -0.676812\n",
      "06/29/2022 01:04:16 - INFO - __main__ -   Text: ['The character is an authoritative aisles expert.']\n",
      "06/29/2022 01:04:17 - INFO - __main__ -   Epoch: 24 | Batch: 7200/10001 (72%) | G Loss: 0.526704 | C Loss: -0.260657\n",
      "06/29/2022 01:04:17 - INFO - __main__ -   Text: ['Being a fool is not Cool at all.\"']\n",
      "06/29/2022 01:04:18 - INFO - __main__ -   Epoch: 24 | Batch: 7800/10001 (78%) | G Loss: 0.698823 | C Loss: -0.402818\n",
      "06/29/2022 01:04:18 - INFO - __main__ -   Text: ['Also take it easy with the Sailing Lesson.']\n",
      "06/29/2022 01:04:19 - INFO - __main__ -   Epoch: 24 | Batch: 8400/10001 (84%) | G Loss: 1.463366 | C Loss: -0.861865\n",
      "06/29/2022 01:04:20 - INFO - __main__ -   Text: ['Don\\'t take the men\\'s shirt so seriously.\"']\n",
      "06/29/2022 01:04:20 - INFO - __main__ -   Epoch: 24 | Batch: 9000/10001 (90%) | G Loss: 0.931808 | C Loss: -0.632545\n",
      "06/29/2022 01:04:21 - INFO - __main__ -   Text: ['Artificial Intelligence is therefore totally useless.']\n",
      "06/29/2022 01:04:22 - INFO - __main__ -   Epoch: 24 | Batch: 9600/10001 (96%) | G Loss: 0.488984 | C Loss: -0.169067\n",
      "06/29/2022 01:04:22 - INFO - __main__ -   Text: ['Ah… ਕਮਣ .']\n",
      "06/29/2022 01:04:22 - INFO - __main__ -   * (Train) Epoch: 24 | G Loss: 0.7283 | C Loss: -0.4375 | Updates G: 170 | Updates C: 663\n",
      "06/29/2022 01:04:30 - INFO - __main__ -   Bleu-2:0.203 | B-Bleu-2:0.265\n",
      "06/29/2022 01:04:30 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4679344867010937\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 25 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:44.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:59.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:15.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:13.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:28.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:42.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.756\n",
      "  Training epcoh took: 0:02:57\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:07:27 - INFO - __main__ -   Epoch: 25 | Batch: 0/10001 (0%) | G Loss: 0.294995 | C Loss: -0.140560\n",
      "06/29/2022 01:07:27 - INFO - __main__ -   Text: ['Beam light out.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.485\n",
      "  Test Loss: 2.582\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:07:28 - INFO - __main__ -   Epoch: 25 | Batch: 600/10001 (6%) | G Loss: 0.371686 | C Loss: -0.179777\n",
      "06/29/2022 01:07:29 - INFO - __main__ -   Text: ['The joke is that if you have a cat, it is a monkey.']\n",
      "06/29/2022 01:07:30 - INFO - __main__ -   Epoch: 25 | Batch: 1200/10001 (12%) | G Loss: 0.770444 | C Loss: -0.462439\n",
      "06/29/2022 01:07:30 - INFO - __main__ -   Text: ['It is reliable to say nothing to anyone.']\n",
      "06/29/2022 01:07:31 - INFO - __main__ -   Epoch: 25 | Batch: 1800/10001 (18%) | G Loss: 0.459720 | C Loss: -0.323191\n",
      "06/29/2022 01:07:31 - INFO - __main__ -   Text: ['There are many people who believe the Bible verse only tells people what to do.']\n",
      "06/29/2022 01:07:32 - INFO - __main__ -   Epoch: 25 | Batch: 2400/10001 (24%) | G Loss: 0.511268 | C Loss: -0.294002\n",
      "06/29/2022 01:07:32 - INFO - __main__ -   Text: ['Underpants is more fun to put on ShakeOff.']\n",
      "06/29/2022 01:07:33 - INFO - __main__ -   Epoch: 25 | Batch: 3000/10001 (30%) | G Loss: 0.724156 | C Loss: -0.492338\n",
      "06/29/2022 01:07:33 - INFO - __main__ -   Text: ['There is something far offensive about drinking water from Amway.']\n",
      "06/29/2022 01:07:34 - INFO - __main__ -   Epoch: 25 | Batch: 3600/10001 (36%) | G Loss: 0.544254 | C Loss: -0.309847\n",
      "06/29/2022 01:07:34 - INFO - __main__ -   Text: ['The website gives the title to mustaches .']\n",
      "06/29/2022 01:07:35 - INFO - __main__ -   Epoch: 25 | Batch: 4200/10001 (42%) | G Loss: 0.565530 | C Loss: -0.216307\n",
      "06/29/2022 01:07:35 - INFO - __main__ -   Text: ['He uses Daring Fist to warn you about the evils.']\n",
      "06/29/2022 01:07:36 - INFO - __main__ -   Epoch: 25 | Batch: 4800/10001 (48%) | G Loss: 0.774845 | C Loss: -0.448681\n",
      "06/29/2022 01:07:36 - INFO - __main__ -   Text: ['A spell does not have to be read consistently.']\n",
      "06/29/2022 01:07:37 - INFO - __main__ -   Epoch: 25 | Batch: 5400/10001 (54%) | G Loss: 0.989259 | C Loss: -0.667287\n",
      "06/29/2022 01:07:37 - INFO - __main__ -   Text: [\"It may say 'I am plucky egg'.\"]\n",
      "06/29/2022 01:07:38 - INFO - __main__ -   Epoch: 25 | Batch: 6000/10001 (60%) | G Loss: 0.478294 | C Loss: -0.296574\n",
      "06/29/2022 01:07:38 - INFO - __main__ -   Text: ['Eventually, they will end up shabby.\"']\n",
      "06/29/2022 01:07:39 - INFO - __main__ -   Epoch: 25 | Batch: 6600/10001 (66%) | G Loss: 0.443017 | C Loss: -0.185596\n",
      "06/29/2022 01:07:39 - INFO - __main__ -   Text: ['Judaism is a requirement for a modern computer scientist.']\n",
      "06/29/2022 01:07:40 - INFO - __main__ -   Epoch: 25 | Batch: 7200/10001 (72%) | G Loss: 0.499476 | C Loss: -0.299974\n",
      "06/29/2022 01:07:40 - INFO - __main__ -   Text: ['But black is not clever.']\n",
      "06/29/2022 01:07:41 - INFO - __main__ -   Epoch: 25 | Batch: 7800/10001 (78%) | G Loss: 0.562890 | C Loss: -0.292590\n",
      "06/29/2022 01:07:41 - INFO - __main__ -   Text: ['The game comes to abide by normal logic.\"']\n",
      "06/29/2022 01:07:42 - INFO - __main__ -   Epoch: 25 | Batch: 8400/10001 (84%) | G Loss: 0.598785 | C Loss: -0.361418\n",
      "06/29/2022 01:07:42 - INFO - __main__ -   Text: [\"In fact, steve gives you some idea of what a full ol' taking care of ya.\"]\n",
      "06/29/2022 01:07:43 - INFO - __main__ -   Epoch: 25 | Batch: 9000/10001 (90%) | G Loss: 0.922754 | C Loss: -0.500121\n",
      "06/29/2022 01:07:43 - INFO - __main__ -   Text: ['From The Jews go.']\n",
      "06/29/2022 01:07:44 - INFO - __main__ -   Epoch: 25 | Batch: 9600/10001 (96%) | G Loss: 0.571271 | C Loss: -0.234746\n",
      "06/29/2022 01:07:44 - INFO - __main__ -   Text: ['They may be opposed to performing tomato brains on toothy brains.']\n",
      "06/29/2022 01:07:45 - INFO - __main__ -   * (Train) Epoch: 25 | G Loss: 0.6184 | C Loss: -0.3522 | Updates G: 200 | Updates C: 633\n",
      "06/29/2022 01:07:52 - INFO - __main__ -   Bleu-2:0.216 | B-Bleu-2:0.304\n",
      "06/29/2022 01:07:52 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5206601195945132\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 26 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:45.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:01.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:15.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:31.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:15.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:29.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:45.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.755\n",
      "  Training epcoh took: 0:03:00\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:10:53 - INFO - __main__ -   Epoch: 26 | Batch: 0/10001 (0%) | G Loss: 0.577488 | C Loss: -0.342384\n",
      "06/29/2022 01:10:53 - INFO - __main__ -   Text: ['Many good folk recognize this trick.<br>']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 2.632\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:10:54 - INFO - __main__ -   Epoch: 26 | Batch: 600/10001 (6%) | G Loss: 0.766994 | C Loss: -0.368071\n",
      "06/29/2022 01:10:54 - INFO - __main__ -   Text: ['The web article lists it as one of the three things that \"addicts\".']\n",
      "06/29/2022 01:10:55 - INFO - __main__ -   Epoch: 26 | Batch: 1200/10001 (12%) | G Loss: 0.611462 | C Loss: -0.375071\n",
      "06/29/2022 01:10:55 - INFO - __main__ -   Text: ['Which one is better?']\n",
      "06/29/2022 01:10:56 - INFO - __main__ -   Epoch: 26 | Batch: 1800/10001 (18%) | G Loss: 0.509237 | C Loss: -0.207140\n",
      "06/29/2022 01:10:56 - INFO - __main__ -   Text: ['While the title is about mountain biking, DwarfBuddies.']\n",
      "06/29/2022 01:10:57 - INFO - __main__ -   Epoch: 26 | Batch: 2400/10001 (24%) | G Loss: 0.609236 | C Loss: -0.316567\n",
      "06/29/2022 01:10:57 - INFO - __main__ -   Text: ['What about Unicorns?']\n",
      "06/29/2022 01:10:58 - INFO - __main__ -   Epoch: 26 | Batch: 3000/10001 (30%) | G Loss: 0.646289 | C Loss: -0.389140\n",
      "06/29/2022 01:10:58 - INFO - __main__ -   Text: ['Known as you are the fool.']\n",
      "06/29/2022 01:10:59 - INFO - __main__ -   Epoch: 26 | Batch: 3600/10001 (36%) | G Loss: 0.712876 | C Loss: -0.412512\n",
      "06/29/2022 01:10:59 - INFO - __main__ -   Text: ['That\\'s fine.\"']\n",
      "06/29/2022 01:11:00 - INFO - __main__ -   Epoch: 26 | Batch: 4200/10001 (42%) | G Loss: 0.647624 | C Loss: -0.342717\n",
      "06/29/2022 01:11:00 - INFO - __main__ -   Text: ['Liberals usually describe science as cherry picking.']\n",
      "06/29/2022 01:11:01 - INFO - __main__ -   Epoch: 26 | Batch: 4800/10001 (48%) | G Loss: 0.519633 | C Loss: -0.295444\n",
      "06/29/2022 01:11:01 - INFO - __main__ -   Text: ['I like doing things that may bring crime to you.\"']\n",
      "06/29/2022 01:11:02 - INFO - __main__ -   Epoch: 26 | Batch: 5400/10001 (54%) | G Loss: 0.461768 | C Loss: -0.247255\n",
      "06/29/2022 01:11:02 - INFO - __main__ -   Text: ['... Games are like my heart is off.\"']\n",
      "06/29/2022 01:11:03 - INFO - __main__ -   Epoch: 26 | Batch: 6000/10001 (60%) | G Loss: 0.989477 | C Loss: -0.644846\n",
      "06/29/2022 01:11:03 - INFO - __main__ -   Text: ['The word \"adventure\" refers to a search of the web.']\n",
      "06/29/2022 01:11:04 - INFO - __main__ -   Epoch: 26 | Batch: 6600/10001 (66%) | G Loss: 0.416521 | C Loss: -0.143935\n",
      "06/29/2022 01:11:04 - INFO - __main__ -   Text: ['Sometimes prayer is easy enough to find out.\"']\n",
      "06/29/2022 01:11:05 - INFO - __main__ -   Epoch: 26 | Batch: 7200/10001 (72%) | G Loss: 0.736083 | C Loss: -0.328901\n",
      "06/29/2022 01:11:06 - INFO - __main__ -   Text: ['Begum black-cat, seems to think of himself as weakness.']\n",
      "06/29/2022 01:11:06 - INFO - __main__ -   Epoch: 26 | Batch: 7800/10001 (78%) | G Loss: 0.807300 | C Loss: -0.386416\n",
      "06/29/2022 01:11:07 - INFO - __main__ -   Text: ['It\\'s dangerous, becomes curiosity, resistance.\"']\n",
      "06/29/2022 01:11:08 - INFO - __main__ -   Epoch: 26 | Batch: 8400/10001 (84%) | G Loss: 0.453270 | C Loss: -0.184069\n",
      "06/29/2022 01:11:08 - INFO - __main__ -   Text: ['This is probably .']\n",
      "06/29/2022 01:11:09 - INFO - __main__ -   Epoch: 26 | Batch: 9000/10001 (90%) | G Loss: 0.590210 | C Loss: -0.280267\n",
      "06/29/2022 01:11:09 - INFO - __main__ -   Text: ['Hannibal Lectipt has a comedy at its core.']\n",
      "06/29/2022 01:11:10 - INFO - __main__ -   Epoch: 26 | Batch: 9600/10001 (96%) | G Loss: 0.576200 | C Loss: -0.222928\n",
      "06/29/2022 01:11:10 - INFO - __main__ -   Text: ['Traditionally it is sugar Gloss.']\n",
      "06/29/2022 01:11:10 - INFO - __main__ -   * (Train) Epoch: 26 | G Loss: 0.6346 | C Loss: -0.3100 | Updates G: 154 | Updates C: 679\n",
      "06/29/2022 01:11:18 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.289\n",
      "06/29/2022 01:11:18 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4931806554681147\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 27 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:46.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:17.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:33.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:20.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:51.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.748\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:14:24 - INFO - __main__ -   Epoch: 27 | Batch: 0/10001 (0%) | G Loss: 0.662382 | C Loss: -0.341312\n",
      "06/29/2022 01:14:24 - INFO - __main__ -   Text: ['The scholar: \"Is that white guy really just a jew?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.515\n",
      "  Test Loss: 2.605\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:14:25 - INFO - __main__ -   Epoch: 27 | Batch: 600/10001 (6%) | G Loss: 0.625556 | C Loss: -0.356423\n",
      "06/29/2022 01:14:26 - INFO - __main__ -   Text: ['\"Gardeningbirds\" refers to the fact that there is no arm.']\n",
      "06/29/2022 01:14:26 - INFO - __main__ -   Epoch: 27 | Batch: 1200/10001 (12%) | G Loss: 0.486251 | C Loss: -0.225855\n",
      "06/29/2022 01:14:27 - INFO - __main__ -   Text: ['Do I want to poison chocolate?']\n",
      "06/29/2022 01:14:28 - INFO - __main__ -   Epoch: 27 | Batch: 1800/10001 (18%) | G Loss: 0.470170 | C Loss: -0.241333\n",
      "06/29/2022 01:14:28 - INFO - __main__ -   Text: [\"Don't worry very much if you know where it is’ Below three facts about bees.\"]\n",
      "06/29/2022 01:14:29 - INFO - __main__ -   Epoch: 27 | Batch: 2400/10001 (24%) | G Loss: 0.568983 | C Loss: -0.254775\n",
      "06/29/2022 01:14:29 - INFO - __main__ -   Text: ['The term means that the speed at which one animal consumes a finger.']\n",
      "06/29/2022 01:14:30 - INFO - __main__ -   Epoch: 27 | Batch: 3000/10001 (30%) | G Loss: 1.027925 | C Loss: -0.422597\n",
      "06/29/2022 01:14:30 - INFO - __main__ -   Text: ['It is called \"the golden rule\".']\n",
      "06/29/2022 01:14:31 - INFO - __main__ -   Epoch: 27 | Batch: 3600/10001 (36%) | G Loss: 0.645477 | C Loss: -0.267193\n",
      "06/29/2022 01:14:31 - INFO - __main__ -   Text: ['The success rate of Cloaker psychic is about 3%, according to Stacy.']\n",
      "06/29/2022 01:14:32 - INFO - __main__ -   Epoch: 27 | Batch: 4200/10001 (42%) | G Loss: 0.493570 | C Loss: -0.228213\n",
      "06/29/2022 01:14:32 - INFO - __main__ -   Text: ['They are technical in nature but he is more concerned with literature and culture.\"']\n",
      "06/29/2022 01:14:33 - INFO - __main__ -   Epoch: 27 | Batch: 4800/10001 (48%) | G Loss: 0.512400 | C Loss: -0.270858\n",
      "06/29/2022 01:14:33 - INFO - __main__ -   Text: ['But now say your uncle B is wired to be insane.']\n",
      "06/29/2022 01:14:34 - INFO - __main__ -   Epoch: 27 | Batch: 5400/10001 (54%) | G Loss: 0.521971 | C Loss: -0.278635\n",
      "06/29/2022 01:14:34 - INFO - __main__ -   Text: ['The question is: says Trac.']\n",
      "06/29/2022 01:14:35 - INFO - __main__ -   Epoch: 27 | Batch: 6000/10001 (60%) | G Loss: 0.575218 | C Loss: -0.262930\n",
      "06/29/2022 01:14:35 - INFO - __main__ -   Text: ['\"Osao\" has very easy data information.']\n",
      "06/29/2022 01:14:36 - INFO - __main__ -   Epoch: 27 | Batch: 6600/10001 (66%) | G Loss: 0.513575 | C Loss: -0.258839\n",
      "06/29/2022 01:14:36 - INFO - __main__ -   Text: ['Slick is sometimes referred to as \"The Search.\"']\n",
      "06/29/2022 01:14:37 - INFO - __main__ -   Epoch: 27 | Batch: 7200/10001 (72%) | G Loss: 0.591514 | C Loss: -0.283301\n",
      "06/29/2022 01:14:37 - INFO - __main__ -   Text: ['He has a rubric about where to aim.']\n",
      "06/29/2022 01:14:38 - INFO - __main__ -   Epoch: 27 | Batch: 7800/10001 (78%) | G Loss: 0.329498 | C Loss: -0.113215\n",
      "06/29/2022 01:14:39 - INFO - __main__ -   Text: ['With all the other toys in this genre, it sounds like good.\"']\n",
      "06/29/2022 01:14:39 - INFO - __main__ -   Epoch: 27 | Batch: 8400/10001 (84%) | G Loss: 0.431113 | C Loss: -0.215359\n",
      "06/29/2022 01:14:40 - INFO - __main__ -   Text: ['The male strategist prophesies a sort of luck.']\n",
      "06/29/2022 01:14:41 - INFO - __main__ -   Epoch: 27 | Batch: 9000/10001 (90%) | G Loss: 0.510695 | C Loss: -0.249233\n",
      "06/29/2022 01:14:41 - INFO - __main__ -   Text: ['The sensation of \"This is genius.\"']\n",
      "06/29/2022 01:14:42 - INFO - __main__ -   Epoch: 27 | Batch: 9600/10001 (96%) | G Loss: 0.866030 | C Loss: -0.400496\n",
      "06/29/2022 01:14:42 - INFO - __main__ -   Text: ['Despite this Claire explains that I.N.I.']\n",
      "06/29/2022 01:14:42 - INFO - __main__ -   * (Train) Epoch: 27 | G Loss: 0.5877 | C Loss: -0.2752 | Updates G: 159 | Updates C: 674\n",
      "06/29/2022 01:14:51 - INFO - __main__ -   Bleu-2:0.216 | B-Bleu-2:0.255\n",
      "06/29/2022 01:14:51 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4709106573637952\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 28 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:32.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:48.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:04.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:21.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:38.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:53.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:09.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:25.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:57.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.746\n",
      "  Training epcoh took: 0:03:13\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:18:04 - INFO - __main__ -   Epoch: 28 | Batch: 0/10001 (0%) | G Loss: 0.923252 | C Loss: -0.254346\n",
      "06/29/2022 01:18:04 - INFO - __main__ -   Text: ['Just like Indian models, Hannon wants to drive.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 2.659\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:18:05 - INFO - __main__ -   Epoch: 28 | Batch: 600/10001 (6%) | G Loss: 0.550745 | C Loss: -0.250191\n",
      "06/29/2022 01:18:05 - INFO - __main__ -   Text: ['In terms of how to wear weird clothes, Fiend is my go-to band.']\n",
      "06/29/2022 01:18:06 - INFO - __main__ -   Epoch: 28 | Batch: 1200/10001 (12%) | G Loss: 0.490712 | C Loss: -0.144253\n",
      "06/29/2022 01:18:06 - INFO - __main__ -   Text: ['\"Sexual pleasure is possible with my pen!\"']\n",
      "06/29/2022 01:18:07 - INFO - __main__ -   Epoch: 28 | Batch: 1800/10001 (18%) | G Loss: 0.453684 | C Loss: -0.080075\n",
      "06/29/2022 01:18:07 - INFO - __main__ -   Text: ['These threats are the dream of movie junkies.']\n",
      "06/29/2022 01:18:08 - INFO - __main__ -   Epoch: 28 | Batch: 2400/10001 (24%) | G Loss: 0.581990 | C Loss: -0.244860\n",
      "06/29/2022 01:18:08 - INFO - __main__ -   Text: ['Theo is generally used in a derogatory sense.']\n",
      "06/29/2022 01:18:09 - INFO - __main__ -   Epoch: 28 | Batch: 3000/10001 (30%) | G Loss: 0.511713 | C Loss: -0.204656\n",
      "06/29/2022 01:18:10 - INFO - __main__ -   Text: ['Wherever you want to be, rationalises it.\"']\n",
      "06/29/2022 01:18:11 - INFO - __main__ -   Epoch: 28 | Batch: 3600/10001 (36%) | G Loss: 0.653723 | C Loss: -0.136940\n",
      "06/29/2022 01:18:11 - INFO - __main__ -   Text: ['Corinthian Way is not for beginners.']\n",
      "06/29/2022 01:18:12 - INFO - __main__ -   Epoch: 28 | Batch: 4200/10001 (42%) | G Loss: 0.372057 | C Loss: -0.163402\n",
      "06/29/2022 01:18:12 - INFO - __main__ -   Text: ['It is meant to be about exploration.\"']\n",
      "06/29/2022 01:18:13 - INFO - __main__ -   Epoch: 28 | Batch: 4800/10001 (48%) | G Loss: 0.416713 | C Loss: -0.131018\n",
      "06/29/2022 01:18:13 - INFO - __main__ -   Text: ['Imagine if Kitties Bella could finally go to school?\"']\n",
      "06/29/2022 01:18:14 - INFO - __main__ -   Epoch: 28 | Batch: 5400/10001 (54%) | G Loss: 0.593963 | C Loss: -0.381939\n",
      "06/29/2022 01:18:14 - INFO - __main__ -   Text: [\"The formula's intended one is to feel smart.\"]\n",
      "06/29/2022 01:18:15 - INFO - __main__ -   Epoch: 28 | Batch: 6000/10001 (60%) | G Loss: 0.260985 | C Loss: -0.118789\n",
      "06/29/2022 01:18:15 - INFO - __main__ -   Text: ['One of the most unlikely facts is that Katrina is always feathered.']\n",
      "06/29/2022 01:18:16 - INFO - __main__ -   Epoch: 28 | Batch: 6600/10001 (66%) | G Loss: 0.564295 | C Loss: -0.195024\n",
      "06/29/2022 01:18:16 - INFO - __main__ -   Text: ['The most common way to believe it is to believe that.']\n",
      "06/29/2022 01:18:17 - INFO - __main__ -   Epoch: 28 | Batch: 7200/10001 (72%) | G Loss: 1.350717 | C Loss: -0.874211\n",
      "06/29/2022 01:18:17 - INFO - __main__ -   Text: ['He has funny stories about guys (, I mean guys).']\n",
      "06/29/2022 01:18:18 - INFO - __main__ -   Epoch: 28 | Batch: 7800/10001 (78%) | G Loss: 0.283199 | C Loss: -0.124470\n",
      "06/29/2022 01:18:18 - INFO - __main__ -   Text: ['The art critic Homer is afraid what will happen when you stick to typed words.']\n",
      "06/29/2022 01:18:19 - INFO - __main__ -   Epoch: 28 | Batch: 8400/10001 (84%) | G Loss: 0.535336 | C Loss: -0.147195\n",
      "06/29/2022 01:18:19 - INFO - __main__ -   Text: ['Votes count to know or not challenge my Padris.\"']\n",
      "06/29/2022 01:18:20 - INFO - __main__ -   Epoch: 28 | Batch: 9000/10001 (90%) | G Loss: 0.523297 | C Loss: -0.156586\n",
      "06/29/2022 01:18:20 - INFO - __main__ -   Text: ['The problem is, with pamphylist , the formula of tending equals .']\n",
      "06/29/2022 01:18:21 - INFO - __main__ -   Epoch: 28 | Batch: 9600/10001 (96%) | G Loss: 0.436505 | C Loss: -0.128530\n",
      "06/29/2022 01:18:21 - INFO - __main__ -   Text: [\"1) applies rational principles when considering how often I'm on Twitter.\"]\n",
      "06/29/2022 01:18:22 - INFO - __main__ -   * (Train) Epoch: 28 | G Loss: 0.5501 | C Loss: -0.2629 | Updates G: 129 | Updates C: 704\n",
      "06/29/2022 01:18:30 - INFO - __main__ -   Bleu-2:0.223 | B-Bleu-2:0.275\n",
      "06/29/2022 01:18:30 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4975552283500737\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 29 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:14.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:29.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:43.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:57.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:56.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:11.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:26.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:40.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.749\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:21:24 - INFO - __main__ -   Epoch: 29 | Batch: 0/10001 (0%) | G Loss: 0.450555 | C Loss: -0.154007\n",
      "06/29/2022 01:21:24 - INFO - __main__ -   Text: ['They mean Bing.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 2.674\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:21:25 - INFO - __main__ -   Epoch: 29 | Batch: 600/10001 (6%) | G Loss: 0.906100 | C Loss: -0.402355\n",
      "06/29/2022 01:21:25 - INFO - __main__ -   Text: ['Woodcliff can answer everyquestion accurately.']\n",
      "06/29/2022 01:21:26 - INFO - __main__ -   Epoch: 29 | Batch: 1200/10001 (12%) | G Loss: 0.540866 | C Loss: -0.246698\n",
      "06/29/2022 01:21:26 - INFO - __main__ -   Text: ['On this scenario the word \"abilities\" would now be used to describe them.']\n",
      "06/29/2022 01:21:27 - INFO - __main__ -   Epoch: 29 | Batch: 1800/10001 (18%) | G Loss: 0.652027 | C Loss: -0.318865\n",
      "06/29/2022 01:21:28 - INFO - __main__ -   Text: ['American buy carries, can you have more sense?\"']\n",
      "06/29/2022 01:21:28 - INFO - __main__ -   Epoch: 29 | Batch: 2400/10001 (24%) | G Loss: 0.368202 | C Loss: -0.175714\n",
      "06/29/2022 01:21:29 - INFO - __main__ -   Text: ['\"Think.\"']\n",
      "06/29/2022 01:21:29 - INFO - __main__ -   Epoch: 29 | Batch: 3000/10001 (30%) | G Loss: 0.420536 | C Loss: -0.167699\n",
      "06/29/2022 01:21:30 - INFO - __main__ -   Text: ['Still, it is popularized by Scot-setters.']\n",
      "06/29/2022 01:21:31 - INFO - __main__ -   Epoch: 29 | Batch: 3600/10001 (36%) | G Loss: 0.389998 | C Loss: -0.165043\n",
      "06/29/2022 01:21:31 - INFO - __main__ -   Text: ['No one seems to notice this light bulb.']\n",
      "06/29/2022 01:21:32 - INFO - __main__ -   Epoch: 29 | Batch: 4200/10001 (42%) | G Loss: 0.389363 | C Loss: -0.167259\n",
      "06/29/2022 01:21:32 - INFO - __main__ -   Text: ['The gamer\\'s maximum religion is \"osh.\"']\n",
      "06/29/2022 01:21:33 - INFO - __main__ -   Epoch: 29 | Batch: 4800/10001 (48%) | G Loss: 0.715867 | C Loss: -0.259922\n",
      "06/29/2022 01:21:33 - INFO - __main__ -   Text: ['They say that \"Chaos is how many of us are.\"']\n",
      "06/29/2022 01:21:34 - INFO - __main__ -   Epoch: 29 | Batch: 5400/10001 (54%) | G Loss: 0.971445 | C Loss: -0.461585\n",
      "06/29/2022 01:21:34 - INFO - __main__ -   Text: ['It would be crazy to be viral, even if one say Islamic.']\n",
      "06/29/2022 01:21:35 - INFO - __main__ -   Epoch: 29 | Batch: 6000/10001 (60%) | G Loss: 0.384956 | C Loss: -0.184368\n",
      "06/29/2022 01:21:35 - INFO - __main__ -   Text: ['This keyword is used frequently on popular TV shows.']\n",
      "06/29/2022 01:21:36 - INFO - __main__ -   Epoch: 29 | Batch: 6600/10001 (66%) | G Loss: 0.506057 | C Loss: -0.217323\n",
      "06/29/2022 01:21:36 - INFO - __main__ -   Text: ['More specifically, the name of the game is \"house bird\".']\n",
      "06/29/2022 01:21:37 - INFO - __main__ -   Epoch: 29 | Batch: 7200/10001 (72%) | G Loss: 0.828121 | C Loss: -0.261586\n",
      "06/29/2022 01:21:37 - INFO - __main__ -   Text: ['Using Geisha=F is considered very easy.']\n",
      "06/29/2022 01:21:38 - INFO - __main__ -   Epoch: 29 | Batch: 7800/10001 (78%) | G Loss: 0.541364 | C Loss: -0.211012\n",
      "06/29/2022 01:21:38 - INFO - __main__ -   Text: ['It gives you an idea of how insane Xabe is.']\n",
      "06/29/2022 01:21:39 - INFO - __main__ -   Epoch: 29 | Batch: 8400/10001 (84%) | G Loss: 0.466212 | C Loss: -0.189296\n",
      "06/29/2022 01:21:39 - INFO - __main__ -   Text: ['Enthusiasm for immorality is not always something that a human being should.']\n",
      "06/29/2022 01:21:40 - INFO - __main__ -   Epoch: 29 | Batch: 9000/10001 (90%) | G Loss: 0.442544 | C Loss: -0.185887\n",
      "06/29/2022 01:21:40 - INFO - __main__ -   Text: ['Once you are forced, watch out for \"Ücrissy!\".']\n",
      "06/29/2022 01:21:41 - INFO - __main__ -   Epoch: 29 | Batch: 9600/10001 (96%) | G Loss: 0.448343 | C Loss: -0.120451\n",
      "06/29/2022 01:21:41 - INFO - __main__ -   Text: ['The importance of \"North Country\" to him.']\n",
      "06/29/2022 01:21:42 - INFO - __main__ -   * (Train) Epoch: 29 | G Loss: 0.5304 | C Loss: -0.2114 | Updates G: 125 | Updates C: 708\n",
      "06/29/2022 01:21:50 - INFO - __main__ -   Bleu-2:0.219 | B-Bleu-2:0.256\n",
      "06/29/2022 01:21:50 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47470461823022886\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 30 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:45.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:59.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:15.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:16.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:47.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.748\n",
      "  Training epcoh took: 0:03:02\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:24:52 - INFO - __main__ -   Epoch: 30 | Batch: 0/10001 (0%) | G Loss: 0.584228 | C Loss: -0.242911\n",
      "06/29/2022 01:24:52 - INFO - __main__ -   Text: ['These things are peeping out from of the story.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 2.706\n",
      "  Test took: 0:00:00\n",
      "  Batch    50  of    120.    Elapsed: 0:01:19.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:34.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:20.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:51.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.740\n",
      "  Training epcoh took: 0:03:05\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:28:24 - INFO - __main__ -   Epoch: 31 | Batch: 0/10001 (0%) | G Loss: 0.746829 | C Loss: -0.234674\n",
      "06/29/2022 01:28:24 - INFO - __main__ -   Text: ['Her deity is determined by what happens to his compass.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 2.777\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:28:25 - INFO - __main__ -   Epoch: 31 | Batch: 600/10001 (6%) | G Loss: 0.458882 | C Loss: -0.112571\n",
      "06/29/2022 01:28:25 - INFO - __main__ -   Text: ['Males can identify female pornographers more than males.']\n",
      "06/29/2022 01:28:26 - INFO - __main__ -   Epoch: 31 | Batch: 1200/10001 (12%) | G Loss: 0.330687 | C Loss: -0.035736\n",
      "06/29/2022 01:28:26 - INFO - __main__ -   Text: ['Bots are sometimes asked the last of the theories on tics.']\n",
      "06/29/2022 01:28:27 - INFO - __main__ -   Epoch: 31 | Batch: 1800/10001 (18%) | G Loss: 0.439393 | C Loss: -0.181656\n",
      "06/29/2022 01:28:27 - INFO - __main__ -   Text: [\"Graffito still is trying to learn because he's afraid of snakes.\"]\n",
      "06/29/2022 01:28:28 - INFO - __main__ -   Epoch: 31 | Batch: 2400/10001 (24%) | G Loss: 1.012793 | C Loss: -0.291961\n",
      "06/29/2022 01:28:28 - INFO - __main__ -   Text: ['This is why Scarlett is a winner.\" <PAD> \\'Alex and Jackie can really get exactly what everyone else can.']\n",
      "06/29/2022 01:28:29 - INFO - __main__ -   Epoch: 31 | Batch: 3000/10001 (30%) | G Loss: 0.738175 | C Loss: -0.291258\n",
      "06/29/2022 01:28:29 - INFO - __main__ -   Text: ['In this immortal battleword, Iba F.']\n",
      "06/29/2022 01:28:30 - INFO - __main__ -   Epoch: 31 | Batch: 3600/10001 (36%) | G Loss: 0.486415 | C Loss: -0.108921\n",
      "06/29/2022 01:28:31 - INFO - __main__ -   Text: ['Like everybody else\\'s sharez code is to Next Generation Metamorphosis.\"']\n",
      "06/29/2022 01:28:32 - INFO - __main__ -   Epoch: 31 | Batch: 4200/10001 (42%) | G Loss: 0.393086 | C Loss: -0.159263\n",
      "06/29/2022 01:28:32 - INFO - __main__ -   Text: ['The app can also get drunk when drunk on liquor.']\n",
      "06/29/2022 01:28:33 - INFO - __main__ -   Epoch: 31 | Batch: 4800/10001 (48%) | G Loss: 0.394455 | C Loss: -0.092635\n",
      "06/29/2022 01:28:33 - INFO - __main__ -   Text: ['Metamorphosis can be life or death.']\n",
      "06/29/2022 01:28:34 - INFO - __main__ -   Epoch: 31 | Batch: 5400/10001 (54%) | G Loss: 0.492593 | C Loss: -0.139542\n",
      "06/29/2022 01:28:34 - INFO - __main__ -   Text: [\"About him you shouldn't be in a lecture so you should consider yourself a very luckier lizard.\"]\n",
      "06/29/2022 01:28:35 - INFO - __main__ -   Epoch: 31 | Batch: 6000/10001 (60%) | G Loss: 0.515772 | C Loss: -0.229129\n",
      "06/29/2022 01:28:35 - INFO - __main__ -   Text: ['His favorite criteria is \"sincele.\"\"']\n",
      "06/29/2022 01:28:36 - INFO - __main__ -   Epoch: 31 | Batch: 6600/10001 (66%) | G Loss: 0.524082 | C Loss: -0.149633\n",
      "06/29/2022 01:28:36 - INFO - __main__ -   Text: ['With this type of Indo-half of opposites.']\n",
      "06/29/2022 01:28:37 - INFO - __main__ -   Epoch: 31 | Batch: 7200/10001 (72%) | G Loss: 0.451524 | C Loss: -0.196873\n",
      "06/29/2022 01:28:37 - INFO - __main__ -   Text: ['The scrub is weird AOL.']\n",
      "06/29/2022 01:28:38 - INFO - __main__ -   Epoch: 31 | Batch: 7800/10001 (78%) | G Loss: 0.593206 | C Loss: -0.224546\n",
      "06/29/2022 01:28:38 - INFO - __main__ -   Text: ['While OpenToLearning often answers questions that involve the math.']\n",
      "06/29/2022 01:28:39 - INFO - __main__ -   Epoch: 31 | Batch: 8400/10001 (84%) | G Loss: 0.893407 | C Loss: -0.370073\n",
      "06/29/2022 01:28:39 - INFO - __main__ -   Text: ['Preferring rather to be a rapper, Octomaton.']\n",
      "06/29/2022 01:28:40 - INFO - __main__ -   Epoch: 31 | Batch: 9000/10001 (90%) | G Loss: 0.697457 | C Loss: -0.224746\n",
      "06/29/2022 01:28:40 - INFO - __main__ -   Text: ['PoorAlpacalypse.com']\n",
      "06/29/2022 01:28:41 - INFO - __main__ -   Epoch: 31 | Batch: 9600/10001 (96%) | G Loss: 0.499657 | C Loss: -0.214007\n",
      "06/29/2022 01:28:41 - INFO - __main__ -   Text: ['This law says something very strange about men.']\n",
      "06/29/2022 01:28:42 - INFO - __main__ -   * (Train) Epoch: 31 | G Loss: 0.5418 | C Loss: -0.1791 | Updates G: 87 | Updates C: 746\n",
      "06/29/2022 01:28:51 - INFO - __main__ -   Bleu-2:0.231 | B-Bleu-2:0.287\n",
      "06/29/2022 01:28:51 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517450829887841\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 32 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:47.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:03.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:18.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:34.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:46.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:01.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:16.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:31.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:15.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:31.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:47.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.739\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:35:28 - INFO - __main__ -   Epoch: 33 | Batch: 0/10001 (0%) | G Loss: 0.216392 | C Loss: -0.073939\n",
      "06/29/2022 01:35:28 - INFO - __main__ -   Text: ['Accelerate through nature and man is the backbone.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 2.832\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:35:29 - INFO - __main__ -   Epoch: 33 | Batch: 600/10001 (6%) | G Loss: 0.359522 | C Loss: -0.049834\n",
      "06/29/2022 01:35:29 - INFO - __main__ -   Text: ['Instead of looking at a picture on the board.']\n",
      "06/29/2022 01:35:30 - INFO - __main__ -   Epoch: 33 | Batch: 1200/10001 (12%) | G Loss: 0.835971 | C Loss: 0.015790\n",
      "06/29/2022 01:35:30 - INFO - __main__ -   Text: ['\"Unfmerciful man\" is probably one of them.']\n",
      "06/29/2022 01:35:31 - INFO - __main__ -   Epoch: 33 | Batch: 1800/10001 (18%) | G Loss: 0.548389 | C Loss: -0.229092\n",
      "06/29/2022 01:35:32 - INFO - __main__ -   Text: ['Even if it is refer humourously linguistic.']\n",
      "06/29/2022 01:35:32 - INFO - __main__ -   Epoch: 33 | Batch: 2400/10001 (24%) | G Loss: 0.907921 | C Loss: -0.288802\n",
      "06/29/2022 01:35:33 - INFO - __main__ -   Text: ['Quantum Physics teaches which skills are most effective.']\n",
      "06/29/2022 01:35:34 - INFO - __main__ -   Epoch: 33 | Batch: 3000/10001 (30%) | G Loss: 0.757201 | C Loss: -0.220028\n",
      "06/29/2022 01:35:34 - INFO - __main__ -   Text: ['Research full well before Jackson mocks.']\n",
      "06/29/2022 01:35:35 - INFO - __main__ -   Epoch: 33 | Batch: 3600/10001 (36%) | G Loss: 1.146259 | C Loss: -0.124098\n",
      "06/29/2022 01:35:35 - INFO - __main__ -   Text: ['Once you realize some resemblance in speech to the real world, your whole life is ruined\".']\n",
      "06/29/2022 01:35:36 - INFO - __main__ -   Epoch: 33 | Batch: 4200/10001 (42%) | G Loss: 1.004797 | C Loss: 0.021637\n",
      "06/29/2022 01:35:36 - INFO - __main__ -   Text: ['Their school bellooms to ridicule.']\n",
      "06/29/2022 01:35:37 - INFO - __main__ -   Epoch: 33 | Batch: 4800/10001 (48%) | G Loss: 0.318950 | C Loss: 0.026726\n",
      "06/29/2022 01:35:37 - INFO - __main__ -   Text: ['The insecurities of adolescence.\"']\n",
      "06/29/2022 01:35:38 - INFO - __main__ -   Epoch: 33 | Batch: 5400/10001 (54%) | G Loss: 0.483168 | C Loss: -0.140010\n",
      "06/29/2022 01:35:38 - INFO - __main__ -   Text: ['With the current field of science.']\n",
      "06/29/2022 01:35:39 - INFO - __main__ -   Epoch: 33 | Batch: 6000/10001 (60%) | G Loss: 0.637339 | C Loss: -0.026321\n",
      "06/29/2022 01:35:39 - INFO - __main__ -   Text: ['It can be called of a minefield.']\n",
      "06/29/2022 01:35:40 - INFO - __main__ -   Epoch: 33 | Batch: 6600/10001 (66%) | G Loss: 0.411577 | C Loss: 0.043126\n",
      "06/29/2022 01:35:40 - INFO - __main__ -   Text: ['They\\'ve just made up my muscle memory.\"']\n",
      "06/29/2022 01:35:41 - INFO - __main__ -   Epoch: 33 | Batch: 7200/10001 (72%) | G Loss: 0.561437 | C Loss: -0.154474\n",
      "06/29/2022 01:35:41 - INFO - __main__ -   Text: ['He says: \"(Graceful) \" How many ways do I get rid of cohomography?\"']\n",
      "06/29/2022 01:35:42 - INFO - __main__ -   Epoch: 33 | Batch: 7800/10001 (78%) | G Loss: 0.611984 | C Loss: -0.189328\n",
      "06/29/2022 01:35:42 - INFO - __main__ -   Text: ['The BitColonies may or may not be true.']\n",
      "06/29/2022 01:35:43 - INFO - __main__ -   Epoch: 33 | Batch: 8400/10001 (84%) | G Loss: 0.701978 | C Loss: -0.225773\n",
      "06/29/2022 01:35:44 - INFO - __main__ -   Text: ['Emigration is related to what \"moxie finds best in the anywhere.\" <PAD>']\n",
      "06/29/2022 01:35:45 - INFO - __main__ -   Epoch: 33 | Batch: 9000/10001 (90%) | G Loss: 0.423029 | C Loss: -0.116977\n",
      "06/29/2022 01:35:45 - INFO - __main__ -   Text: ['The answer is: a girl\".']\n",
      "06/29/2022 01:35:46 - INFO - __main__ -   Epoch: 33 | Batch: 9600/10001 (96%) | G Loss: 0.382478 | C Loss: -0.164956\n",
      "06/29/2022 01:35:46 - INFO - __main__ -   Text: [\"The more likely phrase is 'Let more people know they may gull us'.\"]\n",
      "06/29/2022 01:35:46 - INFO - __main__ -   * (Train) Epoch: 33 | G Loss: 0.5938 | C Loss: -0.1817 | Updates G: 52 | Updates C: 781\n",
      "06/29/2022 01:35:55 - INFO - __main__ -   Bleu-2:0.240 | B-Bleu-2:0.282\n",
      "06/29/2022 01:35:55 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5214007682790986\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 34 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:46.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:18.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:33.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:19.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:49.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.740\n",
      "  Training epcoh took: 0:03:04\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:38:59 - INFO - __main__ -   Epoch: 34 | Batch: 0/10001 (0%) | G Loss: 0.443560 | C Loss: -0.100189\n",
      "06/29/2022 01:38:59 - INFO - __main__ -   Text: ['Not to get away from the level of awesomeness.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 2.884\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:39:00 - INFO - __main__ -   Epoch: 34 | Batch: 600/10001 (6%) | G Loss: 0.445886 | C Loss: -0.068040\n",
      "06/29/2022 01:39:00 - INFO - __main__ -   Text: ['It is during this time when Amanda Melon calls out boxing.']\n",
      "06/29/2022 01:39:01 - INFO - __main__ -   Epoch: 34 | Batch: 1200/10001 (12%) | G Loss: 0.560718 | C Loss: -0.166857\n",
      "06/29/2022 01:39:01 - INFO - __main__ -   Text: ['\"Doctor Who\" is literally a real one.\"']\n",
      "06/29/2022 01:39:02 - INFO - __main__ -   Epoch: 34 | Batch: 1800/10001 (18%) | G Loss: 1.075751 | C Loss: -0.235534\n",
      "06/29/2022 01:39:03 - INFO - __main__ -   Text: ['Joe is telling you that it is not comparable.']\n",
      "06/29/2022 01:39:04 - INFO - __main__ -   Epoch: 34 | Batch: 2400/10001 (24%) | G Loss: 0.547536 | C Loss: -0.239647\n",
      "06/29/2022 01:39:04 - INFO - __main__ -   Text: ['the aforementioned Dreambomb is a lie.\"']\n",
      "06/29/2022 01:39:05 - INFO - __main__ -   Epoch: 34 | Batch: 3000/10001 (30%) | G Loss: 0.462690 | C Loss: -0.113653\n",
      "06/29/2022 01:39:05 - INFO - __main__ -   Text: ['Its name means \"shameful destruction\" and \"torture.\"']\n",
      "06/29/2022 01:39:06 - INFO - __main__ -   Epoch: 34 | Batch: 3600/10001 (36%) | G Loss: 0.559199 | C Loss: -0.252209\n",
      "06/29/2022 01:39:06 - INFO - __main__ -   Text: ['WHO ARE you?']\n",
      "06/29/2022 01:39:07 - INFO - __main__ -   Epoch: 34 | Batch: 4200/10001 (42%) | G Loss: 0.392328 | C Loss: -0.047796\n",
      "06/29/2022 01:39:07 - INFO - __main__ -   Text: ['Once again I hope that we can help from geeks.']\n",
      "06/29/2022 01:39:08 - INFO - __main__ -   Epoch: 34 | Batch: 4800/10001 (48%) | G Loss: 0.336874 | C Loss: -0.101118\n",
      "06/29/2022 01:39:08 - INFO - __main__ -   Text: ['In grammatically correct English, it is called a \"rod\".']\n",
      "06/29/2022 01:39:09 - INFO - __main__ -   Epoch: 34 | Batch: 5400/10001 (54%) | G Loss: 0.578674 | C Loss: -0.173365\n",
      "06/29/2022 01:39:09 - INFO - __main__ -   Text: ['The name \"Zaoches\" actually may mean something.']\n",
      "06/29/2022 01:39:10 - INFO - __main__ -   Epoch: 34 | Batch: 6000/10001 (60%) | G Loss: 0.445797 | C Loss: -0.009388\n",
      "06/29/2022 01:39:10 - INFO - __main__ -   Text: ['This is definitely related a slightly talking roundabout called \"Test Duck\".']\n",
      "06/29/2022 01:39:11 - INFO - __main__ -   Epoch: 34 | Batch: 6600/10001 (66%) | G Loss: 0.569813 | C Loss: -0.135566\n",
      "06/29/2022 01:39:11 - INFO - __main__ -   Text: ['The nameEntomologist is a fact.']\n",
      "06/29/2022 01:39:12 - INFO - __main__ -   Epoch: 34 | Batch: 7200/10001 (72%) | G Loss: 0.850346 | C Loss: 0.078978\n",
      "06/29/2022 01:39:12 - INFO - __main__ -   Text: ['For the LAWSTAY it is to be married\".']\n",
      "06/29/2022 01:39:13 - INFO - __main__ -   Epoch: 34 | Batch: 7800/10001 (78%) | G Loss: 0.716440 | C Loss: -0.180005\n",
      "06/29/2022 01:39:13 - INFO - __main__ -   Text: ['Mr. Liad seems to all be extremely smug!\"']\n",
      "06/29/2022 01:39:14 - INFO - __main__ -   Epoch: 34 | Batch: 8400/10001 (84%) | G Loss: 0.324621 | C Loss: -0.093356\n",
      "06/29/2022 01:39:15 - INFO - __main__ -   Text: ['in Romanticism you could say \"\" nod!\".']\n",
      "06/29/2022 01:39:15 - INFO - __main__ -   Epoch: 34 | Batch: 9000/10001 (90%) | G Loss: 0.674029 | C Loss: -0.224955\n",
      "06/29/2022 01:39:16 - INFO - __main__ -   Text: ['In ways that are not technically likely to happen.']\n",
      "06/29/2022 01:39:17 - INFO - __main__ -   Epoch: 34 | Batch: 9600/10001 (96%) | G Loss: 0.515311 | C Loss: -0.262041\n",
      "06/29/2022 01:39:17 - INFO - __main__ -   Text: ['One should definitely stay away from a website.']\n",
      "06/29/2022 01:39:17 - INFO - __main__ -   * (Train) Epoch: 34 | G Loss: 0.5519 | C Loss: -0.1608 | Updates G: 61 | Updates C: 772\n",
      "06/29/2022 01:39:26 - INFO - __main__ -   Bleu-2:0.208 | B-Bleu-2:0.283\n",
      "06/29/2022 01:39:26 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_14.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49069068624913453\n",
      "Train file used is number 14\n",
      "../../yahoo/subdivided_large/train_14.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 35 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:47.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:17.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:33.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:19.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:50.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.736\n",
      "  Training epcoh took: 0:03:04\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:42:30 - INFO - __main__ -   Epoch: 35 | Batch: 0/10001 (0%) | G Loss: 0.559298 | C Loss: -0.254122\n",
      "06/29/2022 01:42:30 - INFO - __main__ -   Text: ['The learner is used to this lecture.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 2.944\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:42:31 - INFO - __main__ -   Epoch: 35 | Batch: 600/10001 (6%) | G Loss: 0.781552 | C Loss: -0.327833\n",
      "06/29/2022 01:42:32 - INFO - __main__ -   Text: ['If this is true, then it may not be the least bit courageous.']\n",
      "06/29/2022 01:42:33 - INFO - __main__ -   Epoch: 35 | Batch: 1200/10001 (12%) | G Loss: 0.814139 | C Loss: -0.081346\n",
      "06/29/2022 01:42:33 - INFO - __main__ -   Text: ['The ntv title is \"ف’s penis\"\".']\n",
      "06/29/2022 01:42:34 - INFO - __main__ -   Epoch: 35 | Batch: 1800/10001 (18%) | G Loss: 1.002961 | C Loss: -0.528808\n",
      "06/29/2022 01:42:34 - INFO - __main__ -   Text: ['Whether you like hanging out at an economy casino or just getting dressed up.']\n",
      "06/29/2022 01:42:35 - INFO - __main__ -   Epoch: 35 | Batch: 2400/10001 (24%) | G Loss: 1.000650 | C Loss: -0.440266\n",
      "06/29/2022 01:42:35 - INFO - __main__ -   Text: ['He has if he prefers to be called Swampy.']\n",
      "06/29/2022 01:42:36 - INFO - __main__ -   Epoch: 35 | Batch: 3000/10001 (30%) | G Loss: 0.793271 | C Loss: -0.258918\n",
      "06/29/2022 01:42:36 - INFO - __main__ -   Text: ['The creator “told you how big that is”.']\n",
      "06/29/2022 01:42:37 - INFO - __main__ -   Epoch: 35 | Batch: 3600/10001 (36%) | G Loss: 0.400173 | C Loss: -0.178320\n",
      "06/29/2022 01:42:37 - INFO - __main__ -   Text: ['Yes, I cry!\".']\n",
      "06/29/2022 01:42:38 - INFO - __main__ -   Epoch: 35 | Batch: 4200/10001 (42%) | G Loss: 0.140400 | C Loss: 0.205957\n",
      "06/29/2022 01:42:38 - INFO - __main__ -   Text: ['For example, thermoelectric mirror therapy.']\n",
      "06/29/2022 01:42:39 - INFO - __main__ -   Epoch: 35 | Batch: 4800/10001 (48%) | G Loss: 2.257908 | C Loss: -0.876315\n",
      "06/29/2022 01:42:39 - INFO - __main__ -   Text: [\"It's highly unlikely that I have a stern comment.\"]\n",
      "06/29/2022 01:42:40 - INFO - __main__ -   Epoch: 35 | Batch: 5400/10001 (54%) | G Loss: 2.705863 | C Loss: -0.169659\n",
      "06/29/2022 01:42:40 - INFO - __main__ -   Text: ['He should be called Pure IQ\".']\n",
      "06/29/2022 01:42:41 - INFO - __main__ -   Epoch: 35 | Batch: 6000/10001 (60%) | G Loss: 4.135802 | C Loss: -0.576381\n",
      "06/29/2022 01:42:41 - INFO - __main__ -   Text: ['It is that this is a cult and someone must know it!\"']\n",
      "06/29/2022 01:42:42 - INFO - __main__ -   Epoch: 35 | Batch: 6600/10001 (66%) | G Loss: 3.507316 | C Loss: -0.384488\n",
      "06/29/2022 01:42:42 - INFO - __main__ -   Text: ['The Adventurers Humor Express is hilarious.']\n",
      "06/29/2022 01:42:43 - INFO - __main__ -   Epoch: 35 | Batch: 7200/10001 (72%) | G Loss: 2.506135 | C Loss: -0.519915\n",
      "06/29/2022 01:42:44 - INFO - __main__ -   Text: ['Both of them have a rebellious edge on the academic scale.']\n",
      "06/29/2022 01:42:45 - INFO - __main__ -   Epoch: 35 | Batch: 7800/10001 (78%) | G Loss: 1.874865 | C Loss: -0.554677\n",
      "06/29/2022 01:42:45 - INFO - __main__ -   Text: ['It might also refer to: (Did i mention it?)']\n",
      "06/29/2022 01:42:46 - INFO - __main__ -   Epoch: 35 | Batch: 8400/10001 (84%) | G Loss: 1.154404 | C Loss: -0.173916\n",
      "06/29/2022 01:42:46 - INFO - __main__ -   Text: ['Overbasically map thinking is not very useful to me.']\n",
      "06/29/2022 01:42:47 - INFO - __main__ -   Epoch: 35 | Batch: 9000/10001 (90%) | G Loss: 0.609573 | C Loss: -0.455340\n",
      "06/29/2022 01:42:47 - INFO - __main__ -   Text: ['However, Dhaka is a credible term consistently used by Cuddles.']\n",
      "06/29/2022 01:42:48 - INFO - __main__ -   Epoch: 35 | Batch: 9600/10001 (96%) | G Loss: 0.096095 | C Loss: 1.064102\n",
      "06/29/2022 01:42:48 - INFO - __main__ -   Text: ['Astronomy is the opposite of astronomy!\"']\n",
      "06/29/2022 01:42:48 - INFO - __main__ -   * (Train) Epoch: 35 | G Loss: 0.4538 | C Loss: -0.3158 | Updates G: 92 | Updates C: 741\n",
      "06/29/2022 01:42:56 - INFO - __main__ -   Bleu-2:0.257 | B-Bleu-2:0.255\n",
      "06/29/2022 01:42:56 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512082971051532\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 36 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:13.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:27.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:41.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:20.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:34.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:01.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:14.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.734\n",
      "  Training epcoh took: 0:02:40\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:45:36 - INFO - __main__ -   Epoch: 36 | Batch: 0/10001 (0%) | G Loss: 2.203616 | C Loss: 0.270085\n",
      "06/29/2022 01:45:36 - INFO - __main__ -   Text: ['Several experimental tests like see. <PAD>']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 2.972\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:45:37 - INFO - __main__ -   Epoch: 36 | Batch: 600/10001 (6%) | G Loss: 0.994706 | C Loss: -1.297691\n",
      "06/29/2022 01:45:37 - INFO - __main__ -   Text: ['Aan is well deserved.']\n",
      "06/29/2022 01:45:38 - INFO - __main__ -   Epoch: 36 | Batch: 1200/10001 (12%) | G Loss: 0.127097 | C Loss: -0.316022\n",
      "06/29/2022 01:45:38 - INFO - __main__ -   Text: ['Free Movie sets the focus of the smoking ban.\"']\n",
      "06/29/2022 01:45:39 - INFO - __main__ -   Epoch: 36 | Batch: 1800/10001 (18%) | G Loss: -0.420335 | C Loss: 0.942479\n",
      "06/29/2022 01:45:39 - INFO - __main__ -   Text: ['Undergraduate literature rarely says \"I am the guy.\"']\n",
      "06/29/2022 01:45:40 - INFO - __main__ -   Epoch: 36 | Batch: 2400/10001 (24%) | G Loss: 1.298557 | C Loss: -1.081550\n",
      "06/29/2022 01:45:40 - INFO - __main__ -   Text: ['A web search is what the \"me\" means).']\n",
      "06/29/2022 01:45:41 - INFO - __main__ -   Epoch: 36 | Batch: 3000/10001 (30%) | G Loss: -0.528308 | C Loss: -0.162016\n",
      "06/29/2022 01:45:41 - INFO - __main__ -   Text: ['While named \"Plan B\", B is a very compassionate individual.']\n",
      "06/29/2022 01:45:42 - INFO - __main__ -   Epoch: 36 | Batch: 3600/10001 (36%) | G Loss: 3.432026 | C Loss: -1.819124\n",
      "06/29/2022 01:45:42 - INFO - __main__ -   Text: ['\" Solitaire: the first solution\".']\n",
      "06/29/2022 01:45:43 - INFO - __main__ -   Epoch: 36 | Batch: 4200/10001 (42%) | G Loss: -1.234618 | C Loss: -0.526063\n",
      "06/29/2022 01:45:43 - INFO - __main__ -   Text: ['According to \"Psicoloies\", the more able and innovative a master\\'s degree.']\n",
      "06/29/2022 01:45:44 - INFO - __main__ -   Epoch: 36 | Batch: 4800/10001 (48%) | G Loss: -1.615227 | C Loss: -0.602188\n",
      "06/29/2022 01:45:44 - INFO - __main__ -   Text: ['The problem with these characters is that they are not pretending to understand The Blind Bitch.']\n",
      "06/29/2022 01:45:45 - INFO - __main__ -   Epoch: 36 | Batch: 5400/10001 (54%) | G Loss: -1.074883 | C Loss: 1.407190\n",
      "06/29/2022 01:45:45 - INFO - __main__ -   Text: [\"The scientific world can't believe it, it thinks com-pa.\"]\n",
      "06/29/2022 01:45:46 - INFO - __main__ -   Epoch: 36 | Batch: 6000/10001 (60%) | G Loss: 3.690908 | C Loss: -2.631172\n",
      "06/29/2022 01:45:46 - INFO - __main__ -   Text: ['Some specialists say boys value girls to an average of .']\n",
      "06/29/2022 01:45:47 - INFO - __main__ -   Epoch: 36 | Batch: 6600/10001 (66%) | G Loss: -1.011480 | C Loss: -0.329484\n",
      "06/29/2022 01:45:47 - INFO - __main__ -   Text: ['Amy\\'s cards indicate how good she is at chess\".']\n",
      "06/29/2022 01:45:48 - INFO - __main__ -   Epoch: 36 | Batch: 7200/10001 (72%) | G Loss: 1.274237 | C Loss: -0.593151\n",
      "06/29/2022 01:45:49 - INFO - __main__ -   Text: ['Child sexualising with children is only part of the art.']\n",
      "06/29/2022 01:45:49 - INFO - __main__ -   Epoch: 36 | Batch: 7800/10001 (78%) | G Loss: -0.498708 | C Loss: 0.381505\n",
      "06/29/2022 01:45:50 - INFO - __main__ -   Text: ['Upon seeing those affirmative facts then \"All facilities\".']\n",
      "06/29/2022 01:45:50 - INFO - __main__ -   Epoch: 36 | Batch: 8400/10001 (84%) | G Loss: -0.333564 | C Loss: 0.209401\n",
      "06/29/2022 01:45:51 - INFO - __main__ -   Text: ['The Indian proverb is, \"Don\\'t give yourself to all things.\"']\n",
      "06/29/2022 01:45:52 - INFO - __main__ -   Epoch: 36 | Batch: 9000/10001 (90%) | G Loss: -0.404641 | C Loss: 0.506560\n",
      "06/29/2022 01:45:52 - INFO - __main__ -   Text: ['\"When you speak, you clearly understand.\"']\n",
      "06/29/2022 01:45:53 - INFO - __main__ -   Epoch: 36 | Batch: 9600/10001 (96%) | G Loss: 0.934555 | C Loss: 0.281376\n",
      "06/29/2022 01:45:53 - INFO - __main__ -   Text: ['This formula works pretty well with Hooton.']\n",
      "06/29/2022 01:45:53 - INFO - __main__ -   * (Train) Epoch: 36 | G Loss: 0.1614 | C Loss: -0.5432 | Updates G: 323 | Updates C: 510\n",
      "06/29/2022 01:46:01 - INFO - __main__ -   Bleu-2:0.228 | B-Bleu-2:0.272\n",
      "06/29/2022 01:46:01 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4996996210142898\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 37 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:14.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:28.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:42.\n",
      "  Batch    40  of    120.    Elapsed: 0:00:56.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:39.\n",
      "  Batch    80  of    120.    Elapsed: 0:01:53.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:07.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:21.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:35.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.732\n",
      "  Training epcoh took: 0:02:49\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:48:50 - INFO - __main__ -   Epoch: 37 | Batch: 0/10001 (0%) | G Loss: 2.145268 | C Loss: -2.061047\n",
      "06/29/2022 01:48:50 - INFO - __main__ -   Text: ['He even suggests Magnet Icarus as a poetic metaphor.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 2.994\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:48:51 - INFO - __main__ -   Epoch: 37 | Batch: 600/10001 (6%) | G Loss: 0.627504 | C Loss: 0.338997\n",
      "06/29/2022 01:48:51 - INFO - __main__ -   Text: ['A mathematical constructor will be more useful.']\n",
      "06/29/2022 01:48:52 - INFO - __main__ -   Epoch: 37 | Batch: 1200/10001 (12%) | G Loss: 0.851726 | C Loss: -0.707235\n",
      "06/29/2022 01:48:52 - INFO - __main__ -   Text: ['The girl is the loser in this race.']\n",
      "06/29/2022 01:48:53 - INFO - __main__ -   Epoch: 37 | Batch: 1800/10001 (18%) | G Loss: -0.394226 | C Loss: -0.129343\n",
      "06/29/2022 01:48:53 - INFO - __main__ -   Text: ['On what definition does this car really live?']\n",
      "06/29/2022 01:48:54 - INFO - __main__ -   Epoch: 37 | Batch: 2400/10001 (24%) | G Loss: 0.506756 | C Loss: -0.149645\n",
      "06/29/2022 01:48:54 - INFO - __main__ -   Text: ['The user name of the paper is Larry Page.']\n",
      "06/29/2022 01:48:55 - INFO - __main__ -   Epoch: 37 | Batch: 3000/10001 (30%) | G Loss: -0.534522 | C Loss: 0.007632\n",
      "06/29/2022 01:48:55 - INFO - __main__ -   Text: ['Old vampires tell you what to do.\"']\n",
      "06/29/2022 01:48:56 - INFO - __main__ -   Epoch: 37 | Batch: 3600/10001 (36%) | G Loss: 1.342369 | C Loss: -0.908256\n",
      "06/29/2022 01:48:56 - INFO - __main__ -   Text: ['John receives negative attention.\"']\n",
      "06/29/2022 01:48:57 - INFO - __main__ -   Epoch: 37 | Batch: 4200/10001 (42%) | G Loss: -0.229383 | C Loss: 0.125030\n",
      "06/29/2022 01:48:58 - INFO - __main__ -   Text: ['German slang terms for it is \"Gdumbnail.']\n",
      "06/29/2022 01:48:58 - INFO - __main__ -   Epoch: 37 | Batch: 4800/10001 (48%) | G Loss: -0.023128 | C Loss: 1.115762\n",
      "06/29/2022 01:48:59 - INFO - __main__ -   Text: ['Some cats prefer to hunt alone whereas others try to hunt with their main animal.']\n",
      "06/29/2022 01:48:59 - INFO - __main__ -   Epoch: 37 | Batch: 5400/10001 (54%) | G Loss: 2.712960 | C Loss: -2.102251\n",
      "06/29/2022 01:49:00 - INFO - __main__ -   Text: ['Salute your answer to the question.']\n",
      "06/29/2022 01:49:01 - INFO - __main__ -   Epoch: 37 | Batch: 6000/10001 (60%) | G Loss: 2.641804 | C Loss: -1.149641\n",
      "06/29/2022 01:49:01 - INFO - __main__ -   Text: ['The definition of proof is: Gluttony.']\n",
      "06/29/2022 01:49:02 - INFO - __main__ -   Epoch: 37 | Batch: 6600/10001 (66%) | G Loss: 3.121901 | C Loss: -0.770016\n",
      "06/29/2022 01:49:02 - INFO - __main__ -   Text: ['<br> Caution: <br> Learn to swim.']\n",
      "06/29/2022 01:49:03 - INFO - __main__ -   Epoch: 37 | Batch: 7200/10001 (72%) | G Loss: 3.444114 | C Loss: -0.672290\n",
      "06/29/2022 01:49:03 - INFO - __main__ -   Text: [\"'Hello!'\"]\n",
      "06/29/2022 01:49:04 - INFO - __main__ -   Epoch: 37 | Batch: 7800/10001 (78%) | G Loss: 3.239213 | C Loss: -0.516836\n",
      "06/29/2022 01:49:04 - INFO - __main__ -   Text: ['Bother it is happiness.']\n",
      "06/29/2022 01:49:05 - INFO - __main__ -   Epoch: 37 | Batch: 8400/10001 (84%) | G Loss: 2.469183 | C Loss: -0.279150\n",
      "06/29/2022 01:49:05 - INFO - __main__ -   Text: ['Their starting point is \"intellectual programming\\'s counting ass.\"']\n",
      "06/29/2022 01:49:06 - INFO - __main__ -   Epoch: 37 | Batch: 9000/10001 (90%) | G Loss: 2.049529 | C Loss: -0.306416\n",
      "06/29/2022 01:49:06 - INFO - __main__ -   Text: [\"It's a survival field and includes hiking dogs. <PAD> <PAD>\"]\n",
      "06/29/2022 01:49:07 - INFO - __main__ -   Epoch: 37 | Batch: 9600/10001 (96%) | G Loss: 2.189627 | C Loss: -0.126895\n",
      "06/29/2022 01:49:07 - INFO - __main__ -   Text: ['See more of them here: Chinese.']\n",
      "06/29/2022 01:49:08 - INFO - __main__ -   * (Train) Epoch: 37 | G Loss: 0.5064 | C Loss: -0.5098 | Updates G: 168 | Updates C: 665\n",
      "06/29/2022 01:49:15 - INFO - __main__ -   Bleu-2:0.215 | B-Bleu-2:0.271\n",
      "06/29/2022 01:49:15 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48585094928032996\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 38 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:47.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:18.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:34.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:50.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:22.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:54.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.729\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:52:25 - INFO - __main__ -   Epoch: 38 | Batch: 0/10001 (0%) | G Loss: 2.305181 | C Loss: -0.505360\n",
      "06/29/2022 01:52:25 - INFO - __main__ -   Text: ['This is the subject of a short book \"Where Does My Data Come From?\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.040\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:52:26 - INFO - __main__ -   Epoch: 38 | Batch: 600/10001 (6%) | G Loss: 2.501698 | C Loss: -0.518313\n",
      "06/29/2022 01:52:26 - INFO - __main__ -   Text: ['\"It is the rule of thumb that can teach and school mankind.\"']\n",
      "06/29/2022 01:52:27 - INFO - __main__ -   Epoch: 38 | Batch: 1200/10001 (12%) | G Loss: 2.415101 | C Loss: -0.632032\n",
      "06/29/2022 01:52:27 - INFO - __main__ -   Text: ['However, you might fool somebody else.']\n",
      "06/29/2022 01:52:28 - INFO - __main__ -   Epoch: 38 | Batch: 1800/10001 (18%) | G Loss: 2.624209 | C Loss: -0.451597\n",
      "06/29/2022 01:52:28 - INFO - __main__ -   Text: ['They are also intelligent if that word means \"morning\" judge.']\n",
      "06/29/2022 01:52:29 - INFO - __main__ -   Epoch: 38 | Batch: 2400/10001 (24%) | G Loss: 3.039253 | C Loss: -0.804777\n",
      "06/29/2022 01:52:29 - INFO - __main__ -   Text: ['His belief that \"Life is overrated\".']\n",
      "06/29/2022 01:52:30 - INFO - __main__ -   Epoch: 38 | Batch: 3000/10001 (30%) | G Loss: 3.228001 | C Loss: -0.640235\n",
      "06/29/2022 01:52:30 - INFO - __main__ -   Text: ['The hunch is that a big RPG can make a person more determined\".']\n",
      "06/29/2022 01:52:31 - INFO - __main__ -   Epoch: 38 | Batch: 3600/10001 (36%) | G Loss: 3.282968 | C Loss: -0.857536\n",
      "06/29/2022 01:52:31 - INFO - __main__ -   Text: ['The Link Hacker is the only person who understands that programming is not just a job.']\n",
      "06/29/2022 01:52:32 - INFO - __main__ -   Epoch: 38 | Batch: 4200/10001 (42%) | G Loss: 3.303490 | C Loss: -0.960053\n",
      "06/29/2022 01:52:32 - INFO - __main__ -   Text: ['It is what does that mean?\"']\n",
      "06/29/2022 01:52:33 - INFO - __main__ -   Epoch: 38 | Batch: 4800/10001 (48%) | G Loss: 3.235330 | C Loss: -0.999723\n",
      "06/29/2022 01:52:33 - INFO - __main__ -   Text: ['Ross does not yet understand the mind eating problem.']\n",
      "06/29/2022 01:52:34 - INFO - __main__ -   Epoch: 38 | Batch: 5400/10001 (54%) | G Loss: 3.098758 | C Loss: -1.048111\n",
      "06/29/2022 01:52:35 - INFO - __main__ -   Text: ['This behavior can especially be described by a fellow writer called urban legend.']\n",
      "06/29/2022 01:52:35 - INFO - __main__ -   Epoch: 38 | Batch: 6000/10001 (60%) | G Loss: 2.999060 | C Loss: -1.266241\n",
      "06/29/2022 01:52:36 - INFO - __main__ -   Text: [\"Still, Brian's got a good point.\"]\n",
      "06/29/2022 01:52:37 - INFO - __main__ -   Epoch: 38 | Batch: 6600/10001 (66%) | G Loss: 2.704561 | C Loss: -1.554922\n",
      "06/29/2022 01:52:37 - INFO - __main__ -   Text: ['This response is related to the phenomenon \"Coincidentally Initiated Menstrual\".']\n",
      "06/29/2022 01:52:38 - INFO - __main__ -   Epoch: 38 | Batch: 7200/10001 (72%) | G Loss: 2.539711 | C Loss: -1.169915\n",
      "06/29/2022 01:52:38 - INFO - __main__ -   Text: ['There are scientifically measurable \"technologies\" involved.']\n",
      "06/29/2022 01:52:39 - INFO - __main__ -   Epoch: 38 | Batch: 7800/10001 (78%) | G Loss: 2.345865 | C Loss: -1.307218\n",
      "06/29/2022 01:52:39 - INFO - __main__ -   Text: ['It feels like magic is a technique.']\n",
      "06/29/2022 01:52:40 - INFO - __main__ -   Epoch: 38 | Batch: 8400/10001 (84%) | G Loss: 2.532780 | C Loss: -1.676421\n",
      "06/29/2022 01:52:40 - INFO - __main__ -   Text: ['\"Zio is Tequila!']\n",
      "06/29/2022 01:52:41 - INFO - __main__ -   Epoch: 38 | Batch: 9000/10001 (90%) | G Loss: 2.518291 | C Loss: -1.398874\n",
      "06/29/2022 01:52:41 - INFO - __main__ -   Text: ['Heinotypically, they can eat lame things.\"']\n",
      "06/29/2022 01:52:42 - INFO - __main__ -   Epoch: 38 | Batch: 9600/10001 (96%) | G Loss: 2.488663 | C Loss: -1.705210\n",
      "06/29/2022 01:52:42 - INFO - __main__ -   Text: ['It would be helpful for discovering the spiritual meaning \"strain of brains.\"']\n",
      "06/29/2022 01:52:43 - INFO - __main__ -   * (Train) Epoch: 38 | G Loss: 2.6233 | C Loss: -1.1187 | Updates G: 35 | Updates C: 798\n",
      "06/29/2022 01:52:50 - INFO - __main__ -   Bleu-2:0.235 | B-Bleu-2:0.285\n",
      "06/29/2022 01:52:50 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_18.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519615948284969\n",
      "Train file used is number 18\n",
      "../../yahoo/subdivided_large/train_18.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 39 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:47.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:02.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:18.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:33.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:20.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:51.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.736\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:55:57 - INFO - __main__ -   Epoch: 39 | Batch: 0/10001 (0%) | G Loss: 2.585507 | C Loss: -1.665326\n",
      "06/29/2022 01:55:57 - INFO - __main__ -   Text: ['You can tell the difference between superhero and salesman.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.018\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:55:58 - INFO - __main__ -   Epoch: 39 | Batch: 600/10001 (6%) | G Loss: 2.569492 | C Loss: -1.961600\n",
      "06/29/2022 01:55:58 - INFO - __main__ -   Text: ['The Pacific method is well-known.']\n",
      "06/29/2022 01:55:59 - INFO - __main__ -   Epoch: 39 | Batch: 1200/10001 (12%) | G Loss: 2.415233 | C Loss: -1.556033\n",
      "06/29/2022 01:55:59 - INFO - __main__ -   Text: ['They believe Gaycilius is simply better than America.']\n",
      "06/29/2022 01:56:00 - INFO - __main__ -   Epoch: 39 | Batch: 1800/10001 (18%) | G Loss: 2.417757 | C Loss: -2.030620\n",
      "06/29/2022 01:56:00 - INFO - __main__ -   Text: ['Chapter 14 evaluates only men and women\".']\n",
      "06/29/2022 01:56:01 - INFO - __main__ -   Epoch: 39 | Batch: 2400/10001 (24%) | G Loss: 2.577032 | C Loss: -1.575557\n",
      "06/29/2022 01:56:02 - INFO - __main__ -   Text: [\"It's unclear if one would seek spiritual help from God.\"]\n",
      "06/29/2022 01:56:03 - INFO - __main__ -   Epoch: 39 | Batch: 3000/10001 (30%) | G Loss: 2.553754 | C Loss: -1.619912\n",
      "06/29/2022 01:56:03 - INFO - __main__ -   Text: ['Yammur is not a stage magician.']\n",
      "06/29/2022 01:56:04 - INFO - __main__ -   Epoch: 39 | Batch: 3600/10001 (36%) | G Loss: 2.404717 | C Loss: -1.894922\n",
      "06/29/2022 01:56:04 - INFO - __main__ -   Text: ['Her name is an abbreviation for the Asian height stigma.']\n",
      "06/29/2022 01:56:05 - INFO - __main__ -   Epoch: 39 | Batch: 4200/10001 (42%) | G Loss: 1.988765 | C Loss: -1.566958\n",
      "06/29/2022 01:56:05 - INFO - __main__ -   Text: ['It is somewhat surprising that a cow is so powerful.']\n",
      "06/29/2022 01:56:06 - INFO - __main__ -   Epoch: 39 | Batch: 4800/10001 (48%) | G Loss: 2.153968 | C Loss: -2.025811\n",
      "06/29/2022 01:56:06 - INFO - __main__ -   Text: ['These are bootstraps Dad likes.\"']\n",
      "06/29/2022 01:56:07 - INFO - __main__ -   Epoch: 39 | Batch: 5400/10001 (54%) | G Loss: 2.259443 | C Loss: -2.103017\n",
      "06/29/2022 01:56:07 - INFO - __main__ -   Text: ['It\\'s called \"irrationalization\".']\n",
      "06/29/2022 01:56:08 - INFO - __main__ -   Epoch: 39 | Batch: 6000/10001 (60%) | G Loss: 2.849147 | C Loss: -1.921635\n",
      "06/29/2022 01:56:08 - INFO - __main__ -   Text: ['When I speak of something, I mean it.']\n",
      "06/29/2022 01:56:09 - INFO - __main__ -   Epoch: 39 | Batch: 6600/10001 (66%) | G Loss: 2.298018 | C Loss: -1.776784\n",
      "06/29/2022 01:56:09 - INFO - __main__ -   Text: ['Great advice on Mac photography is to look for birds.']\n",
      "06/29/2022 01:56:10 - INFO - __main__ -   Epoch: 39 | Batch: 7200/10001 (72%) | G Loss: 2.366201 | C Loss: -2.355234\n",
      "06/29/2022 01:56:10 - INFO - __main__ -   Text: ['He points out that \"losing teeth can be a pleasant feel.\"']\n",
      "06/29/2022 01:56:11 - INFO - __main__ -   Epoch: 39 | Batch: 7800/10001 (78%) | G Loss: 2.436394 | C Loss: -2.041469\n",
      "06/29/2022 01:56:11 - INFO - __main__ -   Text: ['Cirra is very difficult to get one word of.']\n",
      "06/29/2022 01:56:12 - INFO - __main__ -   Epoch: 39 | Batch: 8400/10001 (84%) | G Loss: 1.847824 | C Loss: -1.825254\n",
      "06/29/2022 01:56:12 - INFO - __main__ -   Text: ['In other words, picking my beard.']\n",
      "06/29/2022 01:56:13 - INFO - __main__ -   Epoch: 39 | Batch: 9000/10001 (90%) | G Loss: 1.829089 | C Loss: -1.981629\n",
      "06/29/2022 01:56:13 - INFO - __main__ -   Text: ['Each name or concept is important for the songwriters.']\n",
      "06/29/2022 01:56:14 - INFO - __main__ -   Epoch: 39 | Batch: 9600/10001 (96%) | G Loss: 1.788760 | C Loss: -1.659390\n",
      "06/29/2022 01:56:14 - INFO - __main__ -   Text: ['Satarya tends to be bloody generally.']\n",
      "06/29/2022 01:56:15 - INFO - __main__ -   * (Train) Epoch: 39 | G Loss: 2.2076 | C Loss: -1.8658 | Updates G: 94 | Updates C: 739\n",
      "06/29/2022 01:56:24 - INFO - __main__ -   Bleu-2:0.218 | B-Bleu-2:0.288\n",
      "06/29/2022 01:56:24 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5061936470751974\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 40 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:32.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:48.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:04.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:20.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:36.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:52.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:09.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:26.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:59.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.732\n",
      "  Training epcoh took: 0:03:15\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:59:39 - INFO - __main__ -   Epoch: 40 | Batch: 0/10001 (0%) | G Loss: 2.104855 | C Loss: -1.723735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.070\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 01:59:39 - INFO - __main__ -   Text: ['Other names include onomatopoeia, self-esteem, self-calculating.']\n",
      "06/29/2022 01:59:40 - INFO - __main__ -   Epoch: 40 | Batch: 600/10001 (6%) | G Loss: 1.608192 | C Loss: -2.231081\n",
      "06/29/2022 01:59:40 - INFO - __main__ -   Text: ['Geese can something akin to a nine-to-ten job offer.']\n",
      "06/29/2022 01:59:41 - INFO - __main__ -   Epoch: 40 | Batch: 1200/10001 (12%) | G Loss: 1.794138 | C Loss: -2.015522\n",
      "06/29/2022 01:59:41 - INFO - __main__ -   Text: ['Beta does not possess the vocabulary that infects most people.']\n",
      "06/29/2022 01:59:42 - INFO - __main__ -   Epoch: 40 | Batch: 1800/10001 (18%) | G Loss: 1.652609 | C Loss: -1.479753\n",
      "06/29/2022 01:59:42 - INFO - __main__ -   Text: ['Continuing with gameplay, I am now faking being immortal.']\n",
      "06/29/2022 01:59:43 - INFO - __main__ -   Epoch: 40 | Batch: 2400/10001 (24%) | G Loss: 1.927993 | C Loss: -3.001378\n",
      "06/29/2022 01:59:43 - INFO - __main__ -   Text: ['She is a slang term for anal sex.']\n",
      "06/29/2022 01:59:44 - INFO - __main__ -   Epoch: 40 | Batch: 3000/10001 (30%) | G Loss: 1.731143 | C Loss: -2.378506\n",
      "06/29/2022 01:59:45 - INFO - __main__ -   Text: ['A machine is desired posting something at a news site.']\n",
      "06/29/2022 01:59:45 - INFO - __main__ -   Epoch: 40 | Batch: 3600/10001 (36%) | G Loss: 1.888151 | C Loss: -1.792040\n",
      "06/29/2022 01:59:46 - INFO - __main__ -   Text: ['In this given world, titsmoker is always top.']\n",
      "06/29/2022 01:59:47 - INFO - __main__ -   Epoch: 40 | Batch: 4200/10001 (42%) | G Loss: 1.881572 | C Loss: -2.186973\n",
      "06/29/2022 01:59:47 - INFO - __main__ -   Text: ['Healthy?']\n",
      "06/29/2022 01:59:48 - INFO - __main__ -   Epoch: 40 | Batch: 4800/10001 (48%) | G Loss: 1.567268 | C Loss: -2.700462\n",
      "06/29/2022 01:59:48 - INFO - __main__ -   Text: ['Generally DC Comics mean exactly what I tell here.\"']\n",
      "06/29/2022 01:59:49 - INFO - __main__ -   Epoch: 40 | Batch: 5400/10001 (54%) | G Loss: 1.799102 | C Loss: -1.735890\n",
      "06/29/2022 01:59:49 - INFO - __main__ -   Text: ['He is trying to figure out the safe way to view something.']\n",
      "06/29/2022 01:59:50 - INFO - __main__ -   Epoch: 40 | Batch: 6000/10001 (60%) | G Loss: 1.609476 | C Loss: -2.183677\n",
      "06/29/2022 01:59:50 - INFO - __main__ -   Text: ['It can also claim to be safe because of something called the Gambling Bumblebee.']\n",
      "06/29/2022 01:59:51 - INFO - __main__ -   Epoch: 40 | Batch: 6600/10001 (66%) | G Loss: 1.689889 | C Loss: -1.912791\n",
      "06/29/2022 01:59:51 - INFO - __main__ -   Text: ['Unlike Einstein, Credo never gives him a test for accuracy.']\n",
      "06/29/2022 01:59:52 - INFO - __main__ -   Epoch: 40 | Batch: 7200/10001 (72%) | G Loss: 1.576099 | C Loss: -1.783296\n",
      "06/29/2022 01:59:52 - INFO - __main__ -   Text: ['A first step to creating a blog = blog.\"']\n",
      "06/29/2022 01:59:53 - INFO - __main__ -   Epoch: 40 | Batch: 7800/10001 (78%) | G Loss: 1.678659 | C Loss: -1.954022\n",
      "06/29/2022 01:59:53 - INFO - __main__ -   Text: ['Like the useless group geekedow, it likely has trolls to assist it.']\n",
      "06/29/2022 01:59:54 - INFO - __main__ -   Epoch: 40 | Batch: 8400/10001 (84%) | G Loss: 1.829551 | C Loss: -2.013311\n",
      "06/29/2022 01:59:54 - INFO - __main__ -   Text: ['It is a store, not a point-and-click communicator.\"']\n",
      "06/29/2022 01:59:55 - INFO - __main__ -   Epoch: 40 | Batch: 9000/10001 (90%) | G Loss: 1.679568 | C Loss: -1.876489\n",
      "06/29/2022 01:59:55 - INFO - __main__ -   Text: ['Ultimately, Sid does not know his sports name, Cedric.']\n",
      "06/29/2022 01:59:56 - INFO - __main__ -   Epoch: 40 | Batch: 9600/10001 (96%) | G Loss: 1.579999 | C Loss: -2.037082\n",
      "06/29/2022 01:59:56 - INFO - __main__ -   Text: ['There is no need to be afraid of small things.\"']\n",
      "06/29/2022 01:59:57 - INFO - __main__ -   * (Train) Epoch: 40 | G Loss: 1.7842 | C Loss: -2.0447 | Updates G: 124 | Updates C: 709\n",
      "06/29/2022 02:00:05 - INFO - __main__ -   Bleu-2:0.247 | B-Bleu-2:0.292\n",
      "06/29/2022 02:00:05 - INFO - __main__ -   * Saving. Best Score:0.539 | Bleu-2:0.247 | B-Bleu-2:0.292\n",
      "06/29/2022 02:00:05 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5391063180183068\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 41 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:30.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:44.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:00.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:16.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:16.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:31.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:46.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.731\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:03:07 - INFO - __main__ -   Epoch: 41 | Batch: 0/10001 (0%) | G Loss: 2.012018 | C Loss: -2.140141\n",
      "06/29/2022 02:03:07 - INFO - __main__ -   Text: ['Even though they have the name, \"Peasant Babe\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.122\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:03:08 - INFO - __main__ -   Epoch: 41 | Batch: 600/10001 (6%) | G Loss: 1.947912 | C Loss: -2.487896\n",
      "06/29/2022 02:03:08 - INFO - __main__ -   Text: ['Those instructions: I am the simplest of them.']\n",
      "06/29/2022 02:03:09 - INFO - __main__ -   Epoch: 41 | Batch: 1200/10001 (12%) | G Loss: 2.171421 | C Loss: -2.240695\n",
      "06/29/2022 02:03:09 - INFO - __main__ -   Text: ['Originally it is intended for girls as well.']\n",
      "06/29/2022 02:03:10 - INFO - __main__ -   Epoch: 41 | Batch: 1800/10001 (18%) | G Loss: 1.952129 | C Loss: -2.128474\n",
      "06/29/2022 02:03:10 - INFO - __main__ -   Text: ['His philosophy is to use anything, no matter how small.']\n",
      "06/29/2022 02:03:11 - INFO - __main__ -   Epoch: 41 | Batch: 2400/10001 (24%) | G Loss: 1.930027 | C Loss: -1.815735\n",
      "06/29/2022 02:03:11 - INFO - __main__ -   Text: ['There is a meme so I\\'m going to Ayn Rand\\'s show.\"']\n",
      "06/29/2022 02:03:12 - INFO - __main__ -   Epoch: 41 | Batch: 3000/10001 (30%) | G Loss: 2.016623 | C Loss: -2.806205\n",
      "06/29/2022 02:03:12 - INFO - __main__ -   Text: ['Other types of fats include: (P)youtube \"Dat chip\".']\n",
      "06/29/2022 02:03:13 - INFO - __main__ -   Epoch: 41 | Batch: 3600/10001 (36%) | G Loss: 1.973107 | C Loss: -1.866296\n",
      "06/29/2022 02:03:13 - INFO - __main__ -   Text: ['Sendmail is a very useful word and the search speed of almost everyone in the world.']\n",
      "06/29/2022 02:03:14 - INFO - __main__ -   Epoch: 41 | Batch: 4200/10001 (42%) | G Loss: 1.728287 | C Loss: -2.374415\n",
      "06/29/2022 02:03:14 - INFO - __main__ -   Text: ['The joke is that strange people sometimes look very fragile.']\n",
      "06/29/2022 02:03:15 - INFO - __main__ -   Epoch: 41 | Batch: 4800/10001 (48%) | G Loss: 1.290708 | C Loss: -1.548109\n",
      "06/29/2022 02:03:15 - INFO - __main__ -   Text: ['Schematic diagrams are being invented by organizations.']\n",
      "06/29/2022 02:03:16 - INFO - __main__ -   Epoch: 41 | Batch: 5400/10001 (54%) | G Loss: 1.087536 | C Loss: -1.622611\n",
      "06/29/2022 02:03:17 - INFO - __main__ -   Text: ['Well, I\\'m jazz, keto, hormonal!\"']\n",
      "06/29/2022 02:03:17 - INFO - __main__ -   Epoch: 41 | Batch: 6000/10001 (60%) | G Loss: 2.187623 | C Loss: -2.221966\n",
      "06/29/2022 02:03:18 - INFO - __main__ -   Text: ['His perception is that there are different resources in the world.']\n",
      "06/29/2022 02:03:19 - INFO - __main__ -   Epoch: 41 | Batch: 6600/10001 (66%) | G Loss: 1.416995 | C Loss: -2.341575\n",
      "06/29/2022 02:03:19 - INFO - __main__ -   Text: ['The –often calculated wherever possible.\"']\n",
      "06/29/2022 02:03:20 - INFO - __main__ -   Epoch: 41 | Batch: 7200/10001 (72%) | G Loss: 1.615316 | C Loss: -1.602999\n",
      "06/29/2022 02:03:20 - INFO - __main__ -   Text: ['Sam has no real understanding of science.']\n",
      "06/29/2022 02:03:21 - INFO - __main__ -   Epoch: 41 | Batch: 7800/10001 (78%) | G Loss: 1.193057 | C Loss: -1.702975\n",
      "06/29/2022 02:03:21 - INFO - __main__ -   Text: ['\"Peanut fire has the ability to turn your mind to your way of life.\"']\n",
      "06/29/2022 02:03:22 - INFO - __main__ -   Epoch: 41 | Batch: 8400/10001 (84%) | G Loss: 0.776288 | C Loss: -1.599516\n",
      "06/29/2022 02:03:22 - INFO - __main__ -   Text: ['to be quiet {# drains your speech now} / This may be the charm.']\n",
      "06/29/2022 02:03:23 - INFO - __main__ -   Epoch: 41 | Batch: 9000/10001 (90%) | G Loss: 1.902608 | C Loss: -1.360897\n",
      "06/29/2022 02:03:23 - INFO - __main__ -   Text: ['This program Advanced Symbols.']\n",
      "06/29/2022 02:03:24 - INFO - __main__ -   Epoch: 41 | Batch: 9600/10001 (96%) | G Loss: 0.788137 | C Loss: -0.474420\n",
      "06/29/2022 02:03:24 - INFO - __main__ -   Text: ['This reviewer does an excellent job of explaining the concept of sword number.']\n",
      "06/29/2022 02:03:25 - INFO - __main__ -   * (Train) Epoch: 41 | G Loss: 1.6447 | C Loss: -1.8667 | Updates G: 208 | Updates C: 625\n",
      "06/29/2022 02:03:34 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.263\n",
      "06/29/2022 02:03:34 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4637562670677312\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 42 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:55.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:13.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:31.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:07.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:25.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:44.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:02.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:20.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.729\n",
      "  Training epcoh took: 0:03:38\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:07:12 - INFO - __main__ -   Epoch: 42 | Batch: 0/10000 (0%) | G Loss: 1.820235 | C Loss: -2.125504\n",
      "06/29/2022 02:07:12 - INFO - __main__ -   Text: ['A typical example is quantization, which is required to handle Iraqi traders.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.510\n",
      "  Test Loss: 3.113\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:07:13 - INFO - __main__ -   Epoch: 42 | Batch: 600/10000 (6%) | G Loss: 3.182451 | C Loss: -1.857210\n",
      "06/29/2022 02:07:13 - INFO - __main__ -   Text: ['Global Global edition.']\n",
      "06/29/2022 02:07:14 - INFO - __main__ -   Epoch: 42 | Batch: 1200/10000 (12%) | G Loss: 6.321619 | C Loss: -3.679487\n",
      "06/29/2022 02:07:14 - INFO - __main__ -   Text: [\"She is so pure she can't feel the funny stuff.\"]\n",
      "06/29/2022 02:07:15 - INFO - __main__ -   Epoch: 42 | Batch: 1800/10000 (18%) | G Loss: 2.119671 | C Loss: -0.969182\n",
      "06/29/2022 02:07:15 - INFO - __main__ -   Text: ['“The science is Wisdom. ” <PAD>.']\n",
      "06/29/2022 02:07:16 - INFO - __main__ -   Epoch: 42 | Batch: 2400/10000 (24%) | G Loss: 1.077664 | C Loss: -1.560772\n",
      "06/29/2022 02:07:16 - INFO - __main__ -   Text: [\"Before himit's always Jacob Brahm .\"]\n",
      "06/29/2022 02:07:17 - INFO - __main__ -   Epoch: 42 | Batch: 3000/10000 (30%) | G Loss: 4.477424 | C Loss: -2.112164\n",
      "06/29/2022 02:07:17 - INFO - __main__ -   Text: [\"Nike's head of marketing thinks probably athletes instead.\"]\n",
      "06/29/2022 02:07:18 - INFO - __main__ -   Epoch: 42 | Batch: 3600/10000 (36%) | G Loss: -1.075919 | C Loss: -1.159174\n",
      "06/29/2022 02:07:18 - INFO - __main__ -   Text: ['\"Authorities and Global\" has a different aims.']\n",
      "06/29/2022 02:07:19 - INFO - __main__ -   Epoch: 42 | Batch: 4200/10000 (42%) | G Loss: 6.789762 | C Loss: -3.736187\n",
      "06/29/2022 02:07:19 - INFO - __main__ -   Text: ['\"Die It\\'s Words\" remains the first song he sings.']\n",
      "06/29/2022 02:07:20 - INFO - __main__ -   Epoch: 42 | Batch: 4800/10000 (48%) | G Loss: 3.402743 | C Loss: -1.376868\n",
      "06/29/2022 02:07:20 - INFO - __main__ -   Text: ['Steve strips out 99% of his name.']\n",
      "06/29/2022 02:07:21 - INFO - __main__ -   Epoch: 42 | Batch: 5400/10000 (54%) | G Loss: 0.969570 | C Loss: -1.873001\n",
      "06/29/2022 02:07:21 - INFO - __main__ -   Text: ['It is time to fall in love again.\"']\n",
      "06/29/2022 02:07:22 - INFO - __main__ -   Epoch: 42 | Batch: 6000/10000 (60%) | G Loss: 4.160308 | C Loss: -2.049561\n",
      "06/29/2022 02:07:22 - INFO - __main__ -   Text: ['Incidentally, TaskForce are top reviewers for Willow.']\n",
      "06/29/2022 02:07:23 - INFO - __main__ -   Epoch: 42 | Batch: 6600/10000 (66%) | G Loss: 0.370088 | C Loss: -1.402561\n",
      "06/29/2022 02:07:23 - INFO - __main__ -   Text: ['\"wild\" is evil.']\n",
      "06/29/2022 02:07:24 - INFO - __main__ -   Epoch: 42 | Batch: 7200/10000 (72%) | G Loss: 1.751687 | C Loss: -1.713356\n",
      "06/29/2022 02:07:24 - INFO - __main__ -   Text: [\"When I'm alone, I get these two 1/4 filled snots.\"]\n",
      "06/29/2022 02:07:25 - INFO - __main__ -   Epoch: 42 | Batch: 7800/10000 (78%) | G Loss: 3.151168 | C Loss: -1.358067\n",
      "06/29/2022 02:07:26 - INFO - __main__ -   Text: ['\"Lewinson\\'s \\'Uppermostlbava\\' guidelines for fricking.\"']\n",
      "06/29/2022 02:07:27 - INFO - __main__ -   Epoch: 42 | Batch: 8400/10000 (84%) | G Loss: 0.242995 | C Loss: -1.338703\n",
      "06/29/2022 02:07:27 - INFO - __main__ -   Text: ['It pretends knowledge to be false.']\n",
      "06/29/2022 02:07:28 - INFO - __main__ -   Epoch: 42 | Batch: 9000/10000 (90%) | G Loss: 3.980859 | C Loss: -2.758224\n",
      "06/29/2022 02:07:28 - INFO - __main__ -   Text: ['This is so obvious that you almost say it is lunch time.\"\"']\n",
      "06/29/2022 02:07:29 - INFO - __main__ -   Epoch: 42 | Batch: 9600/10000 (96%) | G Loss: 0.354004 | C Loss: 0.616710\n",
      "06/29/2022 02:07:29 - INFO - __main__ -   Text: ['The only other reigning rapper is Tom Brady.']\n",
      "06/29/2022 02:07:29 - INFO - __main__ -   * (Train) Epoch: 42 | G Loss: 1.4688 | C Loss: -1.9084 | Updates G: 275 | Updates C: 558\n",
      "06/29/2022 02:07:39 - INFO - __main__ -   Bleu-2:0.199 | B-Bleu-2:0.270\n",
      "06/29/2022 02:07:39 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4685664019944459\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 43 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:55.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:13.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:31.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:07.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:26.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:44.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:02.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:20.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.725\n",
      "  Training epcoh took: 0:03:38\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:11:17 - INFO - __main__ -   Epoch: 43 | Batch: 0/10000 (0%) | G Loss: 5.463101 | C Loss: -2.458719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.199\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:11:17 - INFO - __main__ -   Text: ['Since the childhood interest of the Smash Four is no longer relevant, it becomes the Duck Dad dream.']\n",
      "06/29/2022 02:11:18 - INFO - __main__ -   Epoch: 43 | Batch: 600/10000 (6%) | G Loss: -0.024194 | C Loss: -1.628748\n",
      "06/29/2022 02:11:18 - INFO - __main__ -   Text: ['\"\"It is better than living in Hollywood.\"']\n",
      "06/29/2022 02:11:19 - INFO - __main__ -   Epoch: 43 | Batch: 1200/10000 (12%) | G Loss: 1.643940 | C Loss: -1.304894\n",
      "06/29/2022 02:11:19 - INFO - __main__ -   Text: [\"It's not all about sports.\"]\n",
      "06/29/2022 02:11:20 - INFO - __main__ -   Epoch: 43 | Batch: 1800/10000 (18%) | G Loss: 3.639732 | C Loss: -1.325048\n",
      "06/29/2022 02:11:20 - INFO - __main__ -   Text: ['Placed in historical and fictional situations that could be considered his own.']\n",
      "06/29/2022 02:11:21 - INFO - __main__ -   Epoch: 43 | Batch: 2400/10000 (24%) | G Loss: 4.066396 | C Loss: -1.443122\n",
      "06/29/2022 02:11:21 - INFO - __main__ -   Text: ['Not only that, Sandigan is also one of the inputs of \"Do the Magic\".']\n",
      "06/29/2022 02:11:22 - INFO - __main__ -   Epoch: 43 | Batch: 3000/10000 (30%) | G Loss: -1.936942 | C Loss: -0.641759\n",
      "06/29/2022 02:11:22 - INFO - __main__ -   Text: ['The game has three listed main goal: adult travel.']\n",
      "06/29/2022 02:11:23 - INFO - __main__ -   Epoch: 43 | Batch: 3600/10000 (36%) | G Loss: 3.626462 | C Loss: -1.341921\n",
      "06/29/2022 02:11:23 - INFO - __main__ -   Text: ['Writing is']\n",
      "06/29/2022 02:11:24 - INFO - __main__ -   Epoch: 43 | Batch: 4200/10000 (42%) | G Loss: 3.206799 | C Loss: -1.329055\n",
      "06/29/2022 02:11:24 - INFO - __main__ -   Text: ['The intention is to hell itself.']\n",
      "06/29/2022 02:11:25 - INFO - __main__ -   Epoch: 43 | Batch: 4800/10000 (48%) | G Loss: -0.352271 | C Loss: -0.590066\n",
      "06/29/2022 02:11:25 - INFO - __main__ -   Text: ['The storyline is that Judy will probably want to love Michael fifteen years down the line.']\n",
      "06/29/2022 02:11:26 - INFO - __main__ -   Epoch: 43 | Batch: 5400/10000 (54%) | G Loss: 4.621896 | C Loss: -2.208465\n",
      "06/29/2022 02:11:26 - INFO - __main__ -   Text: ['They all find sometimes pleasure in sitting down.\"']\n",
      "06/29/2022 02:11:27 - INFO - __main__ -   Epoch: 43 | Batch: 6000/10000 (60%) | G Loss: 1.060057 | C Loss: -0.512031\n",
      "06/29/2022 02:11:27 - INFO - __main__ -   Text: ['Judging by these retrospective examples, a drone is considered a helicopter.']\n",
      "06/29/2022 02:11:28 - INFO - __main__ -   Epoch: 43 | Batch: 6600/10000 (66%) | G Loss: -0.587427 | C Loss: -0.524315\n",
      "06/29/2022 02:11:29 - INFO - __main__ -   Text: [\"As yet, he just doesn't want to do so.\"]\n",
      "06/29/2022 02:11:29 - INFO - __main__ -   Epoch: 43 | Batch: 7200/10000 (72%) | G Loss: 3.477715 | C Loss: -2.587937\n",
      "06/29/2022 02:11:30 - INFO - __main__ -   Text: ['It\\'s on called \"Math\".']\n",
      "06/29/2022 02:11:30 - INFO - __main__ -   Epoch: 43 | Batch: 7800/10000 (78%) | G Loss: 3.225408 | C Loss: -1.156618\n",
      "06/29/2022 02:11:31 - INFO - __main__ -   Text: ['The term \"potentially\" refers to the venue Adonis.']\n",
      "06/29/2022 02:11:32 - INFO - __main__ -   Epoch: 43 | Batch: 8400/10000 (84%) | G Loss: 0.632720 | C Loss: -1.296956\n",
      "06/29/2022 02:11:32 - INFO - __main__ -   Text: ['Drivers need to take management of Kings Island.']\n",
      "06/29/2022 02:11:33 - INFO - __main__ -   Epoch: 43 | Batch: 9000/10000 (90%) | G Loss: 3.332013 | C Loss: -0.920771\n",
      "06/29/2022 02:11:33 - INFO - __main__ -   Text: ['Beaver eggs are best used with \"unusual visitors driving by\".']\n",
      "06/29/2022 02:11:34 - INFO - __main__ -   Epoch: 43 | Batch: 9600/10000 (96%) | G Loss: 1.685271 | C Loss: -0.834346\n",
      "06/29/2022 02:11:34 - INFO - __main__ -   Text: ['The ideal quest is to kiss into vinegar or honey.']\n",
      "06/29/2022 02:11:34 - INFO - __main__ -   * (Train) Epoch: 43 | G Loss: 1.1410 | C Loss: -1.3705 | Updates G: 305 | Updates C: 528\n",
      "06/29/2022 02:11:43 - INFO - __main__ -   Bleu-2:0.212 | B-Bleu-2:0.235\n",
      "06/29/2022 02:11:43 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4465730401574763\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 44 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.722\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:15:14 - INFO - __main__ -   Epoch: 44 | Batch: 0/10001 (0%) | G Loss: 0.026414 | C Loss: -0.794582\n",
      "06/29/2022 02:15:15 - INFO - __main__ -   Text: [') focuses on AI research.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.515\n",
      "  Test Loss: 3.186\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:15:16 - INFO - __main__ -   Epoch: 44 | Batch: 600/10001 (6%) | G Loss: 2.700627 | C Loss: -2.022633\n",
      "06/29/2022 02:15:16 - INFO - __main__ -   Text: ['When telematic glass drives.']\n",
      "06/29/2022 02:15:17 - INFO - __main__ -   Epoch: 44 | Batch: 1200/10001 (12%) | G Loss: -1.534166 | C Loss: 0.157603\n",
      "06/29/2022 02:15:17 - INFO - __main__ -   Text: ['He is very suspicious about it and is suspicious of the current blame for terrorism.']\n",
      "06/29/2022 02:15:18 - INFO - __main__ -   Epoch: 44 | Batch: 1800/10001 (18%) | G Loss: 4.115079 | C Loss: -1.755976\n",
      "06/29/2022 02:15:18 - INFO - __main__ -   Text: ['These apathyphalos are analogous.']\n",
      "06/29/2022 02:15:19 - INFO - __main__ -   Epoch: 44 | Batch: 2400/10001 (24%) | G Loss: -0.111542 | C Loss: -0.328138\n",
      "06/29/2022 02:15:19 - INFO - __main__ -   Text: ['This is measured by the ideal but not by the domain length.']\n",
      "06/29/2022 02:15:20 - INFO - __main__ -   Epoch: 44 | Batch: 3000/10001 (30%) | G Loss: 1.780850 | C Loss: -1.681921\n",
      "06/29/2022 02:15:20 - INFO - __main__ -   Text: ['Upon first viewing this concert scene, one might wonder what Winnie is smoking.']\n",
      "06/29/2022 02:15:21 - INFO - __main__ -   Epoch: 44 | Batch: 3600/10001 (36%) | G Loss: 2.506259 | C Loss: -0.524363\n",
      "06/29/2022 02:15:21 - INFO - __main__ -   Text: ['Mahali)\".']\n",
      "06/29/2022 02:15:22 - INFO - __main__ -   Epoch: 44 | Batch: 4200/10001 (42%) | G Loss: 1.109384 | C Loss: -1.098711\n",
      "06/29/2022 02:15:22 - INFO - __main__ -   Text: ['This dream produces Man.']\n",
      "06/29/2022 02:15:23 - INFO - __main__ -   Epoch: 44 | Batch: 4800/10001 (48%) | G Loss: 3.913813 | C Loss: -1.295559\n",
      "06/29/2022 02:15:23 - INFO - __main__ -   Text: ['Additionally, They can learn Chinese.']\n",
      "06/29/2022 02:15:24 - INFO - __main__ -   Epoch: 44 | Batch: 5400/10001 (54%) | G Loss: 1.835196 | C Loss: -1.371742\n",
      "06/29/2022 02:15:24 - INFO - __main__ -   Text: ['The anthem loving jackass - this is Swag ka tal\".']\n",
      "06/29/2022 02:15:25 - INFO - __main__ -   Epoch: 44 | Batch: 6000/10001 (60%) | G Loss: 1.520564 | C Loss: -2.192510\n",
      "06/29/2022 02:15:25 - INFO - __main__ -   Text: ['The 2nd handediter is also called the EM.\"']\n",
      "06/29/2022 02:15:26 - INFO - __main__ -   Epoch: 44 | Batch: 6600/10001 (66%) | G Loss: -1.280731 | C Loss: -0.633839\n",
      "06/29/2022 02:15:26 - INFO - __main__ -   Text: ['There are many possible ways.']\n",
      "06/29/2022 02:15:27 - INFO - __main__ -   Epoch: 44 | Batch: 7200/10001 (72%) | G Loss: 5.344722 | C Loss: -2.260065\n",
      "06/29/2022 02:15:27 - INFO - __main__ -   Text: ['The intellect is the mind.']\n",
      "06/29/2022 02:15:28 - INFO - __main__ -   Epoch: 44 | Batch: 7800/10001 (78%) | G Loss: 0.110906 | C Loss: 0.381778\n",
      "06/29/2022 02:15:28 - INFO - __main__ -   Text: ['The difficulty of splitting out the quantifier means that formula synthesis is probably safer than real algebraiom.']\n",
      "06/29/2022 02:15:29 - INFO - __main__ -   Epoch: 44 | Batch: 8400/10001 (84%) | G Loss: 0.760831 | C Loss: -0.864411\n",
      "06/29/2022 02:15:29 - INFO - __main__ -   Text: ['This also allows one to describe a Christensen hyperparameter.']\n",
      "06/29/2022 02:15:30 - INFO - __main__ -   Epoch: 44 | Batch: 9000/10001 (90%) | G Loss: 1.203150 | C Loss: -1.191563\n",
      "06/29/2022 02:15:30 - INFO - __main__ -   Text: ['It\\'s a song.\"']\n",
      "06/29/2022 02:15:31 - INFO - __main__ -   Epoch: 44 | Batch: 9600/10001 (96%) | G Loss: 4.190279 | C Loss: -0.411289\n",
      "06/29/2022 02:15:31 - INFO - __main__ -   Text: [\"Also Hopper and Tekomachi's products are not available for free at their current rate.\"]\n",
      "06/29/2022 02:15:32 - INFO - __main__ -   * (Train) Epoch: 44 | G Loss: 1.1077 | C Loss: -1.1040 | Updates G: 251 | Updates C: 582\n",
      "06/29/2022 02:15:41 - INFO - __main__ -   Bleu-2:0.220 | B-Bleu-2:0.274\n",
      "06/29/2022 02:15:41 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4940905792185786\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 45 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:13.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:31.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:49.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:07.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:25.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:44.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:02.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:20.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.727\n",
      "  Training epcoh took: 0:03:37\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:19:19 - INFO - __main__ -   Epoch: 45 | Batch: 0/10001 (0%) | G Loss: 0.478325 | C Loss: -1.173357\n",
      "06/29/2022 02:19:19 - INFO - __main__ -   Text: ['Machine is an analogy for a job opportunity.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.510\n",
      "  Test Loss: 3.210\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:19:20 - INFO - __main__ -   Epoch: 45 | Batch: 600/10001 (6%) | G Loss: 3.033826 | C Loss: -1.998099\n",
      "06/29/2022 02:19:20 - INFO - __main__ -   Text: ['The movie is in the garage.']\n",
      "06/29/2022 02:19:21 - INFO - __main__ -   Epoch: 45 | Batch: 1200/10001 (12%) | G Loss: 1.182999 | C Loss: -0.888410\n",
      "06/29/2022 02:19:21 - INFO - __main__ -   Text: ['Experimentation is easy trial by observation.']\n",
      "06/29/2022 02:19:22 - INFO - __main__ -   Epoch: 45 | Batch: 1800/10001 (18%) | G Loss: 3.437621 | C Loss: -1.860408\n",
      "06/29/2022 02:19:22 - INFO - __main__ -   Text: ['\"Ford intolerant\" is rude.']\n",
      "06/29/2022 02:19:23 - INFO - __main__ -   Epoch: 45 | Batch: 2400/10001 (24%) | G Loss: -0.815786 | C Loss: -0.442158\n",
      "06/29/2022 02:19:23 - INFO - __main__ -   Text: ['On religious studies, he recommends its to his college.']\n",
      "06/29/2022 02:19:24 - INFO - __main__ -   Epoch: 45 | Batch: 3000/10001 (30%) | G Loss: 4.254050 | C Loss: -1.750716\n",
      "06/29/2022 02:19:24 - INFO - __main__ -   Text: ['You should try to find it.']\n",
      "06/29/2022 02:19:25 - INFO - __main__ -   Epoch: 45 | Batch: 3600/10001 (36%) | G Loss: -0.360857 | C Loss: -0.187439\n",
      "06/29/2022 02:19:25 - INFO - __main__ -   Text: ['Unidentified \"Bull,\" half the females tapped, but the other half .']\n",
      "06/29/2022 02:19:26 - INFO - __main__ -   Epoch: 45 | Batch: 4200/10001 (42%) | G Loss: 0.810479 | C Loss: -1.172902\n",
      "06/29/2022 02:19:26 - INFO - __main__ -   Text: ['Kutwary buffoonism\".']\n",
      "06/29/2022 02:19:27 - INFO - __main__ -   Epoch: 45 | Batch: 4800/10001 (48%) | G Loss: 3.510140 | C Loss: -1.208387\n",
      "06/29/2022 02:19:27 - INFO - __main__ -   Text: ['However, he will accept.']\n",
      "06/29/2022 02:19:28 - INFO - __main__ -   Epoch: 45 | Batch: 5400/10001 (54%) | G Loss: 4.170934 | C Loss: -2.007540\n",
      "06/29/2022 02:19:28 - INFO - __main__ -   Text: ['That method is normally not that required.']\n",
      "06/29/2022 02:19:29 - INFO - __main__ -   Epoch: 45 | Batch: 6000/10001 (60%) | G Loss: 0.464966 | C Loss: -0.318503\n",
      "06/29/2022 02:19:29 - INFO - __main__ -   Text: ['\", he asks.']\n",
      "06/29/2022 02:19:30 - INFO - __main__ -   Epoch: 45 | Batch: 6600/10001 (66%) | G Loss: 1.572448 | C Loss: -1.089048\n",
      "06/29/2022 02:19:30 - INFO - __main__ -   Text: ['Since then nobody can know anything else or is able to know anything about me.']\n",
      "06/29/2022 02:19:31 - INFO - __main__ -   Epoch: 45 | Batch: 7200/10001 (72%) | G Loss: 4.680945 | C Loss: -2.125290\n",
      "06/29/2022 02:19:31 - INFO - __main__ -   Text: ['Lifetime is missed by millions of New Yorkers.\"']\n",
      "06/29/2022 02:19:32 - INFO - __main__ -   Epoch: 45 | Batch: 7800/10001 (78%) | G Loss: 2.855883 | C Loss: -1.815654\n",
      "06/29/2022 02:19:32 - INFO - __main__ -   Text: ['This sketchy is called Offbeat\".']\n",
      "06/29/2022 02:19:33 - INFO - __main__ -   Epoch: 45 | Batch: 8400/10001 (84%) | G Loss: 4.047989 | C Loss: -1.600914\n",
      "06/29/2022 02:19:33 - INFO - __main__ -   Text: ['They think that they should apologise for anything unless someone madly gives them pecks.']\n",
      "06/29/2022 02:19:34 - INFO - __main__ -   Epoch: 45 | Batch: 9000/10001 (90%) | G Loss: -0.171328 | C Loss: -0.402639\n",
      "06/29/2022 02:19:34 - INFO - __main__ -   Text: ['This moves you to his chatroom .']\n",
      "06/29/2022 02:19:35 - INFO - __main__ -   Epoch: 45 | Batch: 9600/10001 (96%) | G Loss: 3.025238 | C Loss: -1.628729\n",
      "06/29/2022 02:19:36 - INFO - __main__ -   Text: ['While speaking to Adult Swim or other stupid podcast, Dick Willing may appear.']\n",
      "06/29/2022 02:19:36 - INFO - __main__ -   * (Train) Epoch: 45 | G Loss: 1.1950 | C Loss: -1.2740 | Updates G: 228 | Updates C: 605\n",
      "06/29/2022 02:19:45 - INFO - __main__ -   Bleu-2:0.203 | B-Bleu-2:0.239\n",
      "06/29/2022 02:19:45 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44136410555565975\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 46 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.724\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:23:16 - INFO - __main__ -   Epoch: 46 | Batch: 0/10001 (0%) | G Loss: 2.634733 | C Loss: -1.541408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.316\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:23:17 - INFO - __main__ -   Text: ['They act of self-deny around a thePopcorn Music factory in Wichita, Kansas.']\n",
      "06/29/2022 02:23:18 - INFO - __main__ -   Epoch: 46 | Batch: 600/10001 (6%) | G Loss: -0.012899 | C Loss: 0.080578\n",
      "06/29/2022 02:23:18 - INFO - __main__ -   Text: ['He can specify many ontological routes.']\n",
      "06/29/2022 02:23:19 - INFO - __main__ -   Epoch: 46 | Batch: 1200/10001 (12%) | G Loss: 2.550139 | C Loss: -1.492476\n",
      "06/29/2022 02:23:19 - INFO - __main__ -   Text: [\"Theproblem can be solving the planet's Cogs.\"]\n",
      "06/29/2022 02:23:20 - INFO - __main__ -   Epoch: 46 | Batch: 1800/10001 (18%) | G Loss: 1.670774 | C Loss: -0.485525\n",
      "06/29/2022 02:23:20 - INFO - __main__ -   Text: ['For example, say you have some kind of kind of revenge on your current girlfriend.']\n",
      "06/29/2022 02:23:21 - INFO - __main__ -   Epoch: 46 | Batch: 2400/10001 (24%) | G Loss: 0.999680 | C Loss: -0.895276\n",
      "06/29/2022 02:23:21 - INFO - __main__ -   Text: ['The hookowski dictionary is surprisingly OP.']\n",
      "06/29/2022 02:23:22 - INFO - __main__ -   Epoch: 46 | Batch: 3000/10001 (30%) | G Loss: 2.551434 | C Loss: -1.129471\n",
      "06/29/2022 02:23:22 - INFO - __main__ -   Text: ['Imagism works under different names.']\n",
      "06/29/2022 02:23:23 - INFO - __main__ -   Epoch: 46 | Batch: 3600/10001 (36%) | G Loss: 1.898093 | C Loss: -1.493281\n",
      "06/29/2022 02:23:23 - INFO - __main__ -   Text: ['This is puru!\"']\n",
      "06/29/2022 02:23:24 - INFO - __main__ -   Epoch: 46 | Batch: 4200/10001 (42%) | G Loss: 1.323351 | C Loss: -0.459904\n",
      "06/29/2022 02:23:24 - INFO - __main__ -   Text: [\"And George Will's books! <PAD>.\"]\n",
      "06/29/2022 02:23:25 - INFO - __main__ -   Epoch: 46 | Batch: 4800/10001 (48%) | G Loss: 0.668636 | C Loss: -0.531602\n",
      "06/29/2022 02:23:25 - INFO - __main__ -   Text: ['It doesn\\'t say \"Turn\".']\n",
      "06/29/2022 02:23:26 - INFO - __main__ -   Epoch: 46 | Batch: 5400/10001 (54%) | G Loss: 2.004269 | C Loss: -0.803492\n",
      "06/29/2022 02:23:26 - INFO - __main__ -   Text: [\"'canna lye behatur'.\"]\n",
      "06/29/2022 02:23:27 - INFO - __main__ -   Epoch: 46 | Batch: 6000/10001 (60%) | G Loss: 1.978776 | C Loss: -0.999820\n",
      "06/29/2022 02:23:27 - INFO - __main__ -   Text: ['Haskell has more potential than the others.']\n",
      "06/29/2022 02:23:28 - INFO - __main__ -   Epoch: 46 | Batch: 6600/10001 (66%) | G Loss: -0.230823 | C Loss: -0.204373\n",
      "06/29/2022 02:23:28 - INFO - __main__ -   Text: ['The Vox Information site.']\n",
      "06/29/2022 02:23:29 - INFO - __main__ -   Epoch: 46 | Batch: 7200/10001 (72%) | G Loss: 3.091700 | C Loss: -1.498695\n",
      "06/29/2022 02:23:29 - INFO - __main__ -   Text: ['I want to be nice to people I know.']\n",
      "06/29/2022 02:23:30 - INFO - __main__ -   Epoch: 46 | Batch: 7800/10001 (78%) | G Loss: -0.745721 | C Loss: -0.698802\n",
      "06/29/2022 02:23:30 - INFO - __main__ -   Text: ['In the class \"Computer Analysis\" she analyses myocardial obstructive syndrome.']\n",
      "06/29/2022 02:23:31 - INFO - __main__ -   Epoch: 46 | Batch: 8400/10001 (84%) | G Loss: 6.396572 | C Loss: -1.998703\n",
      "06/29/2022 02:23:31 - INFO - __main__ -   Text: [\"She loves to dance and socialise with people we don't like.\"]\n",
      "06/29/2022 02:23:32 - INFO - __main__ -   Epoch: 46 | Batch: 9000/10001 (90%) | G Loss: 2.735171 | C Loss: -1.070451\n",
      "06/29/2022 02:23:32 - INFO - __main__ -   Text: ['\"Anne blearet\".']\n",
      "06/29/2022 02:23:33 - INFO - __main__ -   Epoch: 46 | Batch: 9600/10001 (96%) | G Loss: -0.870421 | C Loss: 0.976020\n",
      "06/29/2022 02:23:33 - INFO - __main__ -   Text: [\"Water's descending nearly vertically.\"]\n",
      "06/29/2022 02:23:34 - INFO - __main__ -   * (Train) Epoch: 46 | G Loss: 1.0474 | C Loss: -1.1685 | Updates G: 265 | Updates C: 568\n",
      "06/29/2022 02:23:42 - INFO - __main__ -   Bleu-2:0.193 | B-Bleu-2:0.198\n",
      "06/29/2022 02:23:42 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39066708814922635\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 47 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:47.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:03.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:19.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:35.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:50.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:21.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:53.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:03:08\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:26:50 - INFO - __main__ -   Epoch: 47 | Batch: 0/10001 (0%) | G Loss: 6.712413 | C Loss: -3.077815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.324\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:26:51 - INFO - __main__ -   Text: ['Quadrant is the nickname of a 581-168-6 or 582-168-7.']\n",
      "06/29/2022 02:26:52 - INFO - __main__ -   Epoch: 47 | Batch: 600/10001 (6%) | G Loss: -1.160793 | C Loss: -0.747572\n",
      "06/29/2022 02:26:52 - INFO - __main__ -   Text: ['The hunt is obvious, but Tim SSbbles really needs 5 hours of music to get through it.']\n",
      "06/29/2022 02:26:53 - INFO - __main__ -   Epoch: 47 | Batch: 1200/10001 (12%) | G Loss: 1.614761 | C Loss: -0.152489\n",
      "06/29/2022 02:26:53 - INFO - __main__ -   Text: ['The bell is rooting belly against the calling.']\n",
      "06/29/2022 02:26:54 - INFO - __main__ -   Epoch: 47 | Batch: 1800/10001 (18%) | G Loss: 4.867567 | C Loss: -1.796737\n",
      "06/29/2022 02:26:54 - INFO - __main__ -   Text: ['Religious anger tends to result in an unfair or ruthless search and destruction.']\n",
      "06/29/2022 02:26:55 - INFO - __main__ -   Epoch: 47 | Batch: 2400/10001 (24%) | G Loss: 0.124765 | C Loss: -0.428136\n",
      "06/29/2022 02:26:55 - INFO - __main__ -   Text: ['Having the formula formula omitted above, lets one simple form.\"']\n",
      "06/29/2022 02:26:56 - INFO - __main__ -   Epoch: 47 | Batch: 3000/10001 (30%) | G Loss: 1.190777 | C Loss: -0.444115\n",
      "06/29/2022 02:26:56 - INFO - __main__ -   Text: [\"There are two motivations in that regard, but it's not wise.\"]\n",
      "06/29/2022 02:26:57 - INFO - __main__ -   Epoch: 47 | Batch: 3600/10001 (36%) | G Loss: 1.586008 | C Loss: -0.971891\n",
      "06/29/2022 02:26:57 - INFO - __main__ -   Text: ['z but not harmed), then it should be fraction to zero.']\n",
      "06/29/2022 02:26:58 - INFO - __main__ -   Epoch: 47 | Batch: 4200/10001 (42%) | G Loss: 3.146250 | C Loss: -1.317924\n",
      "06/29/2022 02:26:58 - INFO - __main__ -   Text: ['The approach is to try your hand at something.']\n",
      "06/29/2022 02:26:59 - INFO - __main__ -   Epoch: 47 | Batch: 4800/10001 (48%) | G Loss: 1.820589 | C Loss: -1.232475\n",
      "06/29/2022 02:26:59 - INFO - __main__ -   Text: ['Atomic force triggers and despises.']\n",
      "06/29/2022 02:27:00 - INFO - __main__ -   Epoch: 47 | Batch: 5400/10001 (54%) | G Loss: 0.502697 | C Loss: -0.823513\n",
      "06/29/2022 02:27:00 - INFO - __main__ -   Text: ['Sometimes this will find strain; sometimes this will produce life.']\n",
      "06/29/2022 02:27:01 - INFO - __main__ -   Epoch: 47 | Batch: 6000/10001 (60%) | G Loss: 1.701158 | C Loss: -0.928124\n",
      "06/29/2022 02:27:01 - INFO - __main__ -   Text: ['is good, but nobody will believe me.']\n",
      "06/29/2022 02:27:02 - INFO - __main__ -   Epoch: 47 | Batch: 6600/10001 (66%) | G Loss: 0.944755 | C Loss: -0.924383\n",
      "06/29/2022 02:27:02 - INFO - __main__ -   Text: ['\"value\" of thesis and procedure is deficient.']\n",
      "06/29/2022 02:27:03 - INFO - __main__ -   Epoch: 47 | Batch: 7200/10001 (72%) | G Loss: 2.746102 | C Loss: -1.552286\n",
      "06/29/2022 02:27:03 - INFO - __main__ -   Text: ['Accessibly, hubert schemes.']\n",
      "06/29/2022 02:27:04 - INFO - __main__ -   Epoch: 47 | Batch: 7800/10001 (78%) | G Loss: 1.032594 | C Loss: -0.582179\n",
      "06/29/2022 02:27:04 - INFO - __main__ -   Text: ['It aims to revolutionize surveillance.']\n",
      "06/29/2022 02:27:05 - INFO - __main__ -   Epoch: 47 | Batch: 8400/10001 (84%) | G Loss: 0.277968 | C Loss: -0.701304\n",
      "06/29/2022 02:27:05 - INFO - __main__ -   Text: [\"It's fun to have with you.\"]\n",
      "06/29/2022 02:27:06 - INFO - __main__ -   Epoch: 47 | Batch: 9000/10001 (90%) | G Loss: 4.505839 | C Loss: -1.757896\n",
      "06/29/2022 02:27:06 - INFO - __main__ -   Text: ['This is important strategy discretious for an aspirant.']\n",
      "06/29/2022 02:27:07 - INFO - __main__ -   Epoch: 47 | Batch: 9600/10001 (96%) | G Loss: -0.891566 | C Loss: -0.470023\n",
      "06/29/2022 02:27:08 - INFO - __main__ -   Text: ['The calculator is written in Perl, and works for both Microsoft Office.']\n",
      "06/29/2022 02:27:08 - INFO - __main__ -   * (Train) Epoch: 47 | G Loss: 0.9445 | C Loss: -0.9774 | Updates G: 255 | Updates C: 578\n",
      "06/29/2022 02:27:15 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.212\n",
      "06/29/2022 02:27:15 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4157441892061657\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 48 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:31.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:46.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:01.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:16.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:32.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:19.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:33.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:48.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:03:03\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:30:18 - INFO - __main__ -   Epoch: 48 | Batch: 0/10001 (0%) | G Loss: 1.730635 | C Loss: -0.901647\n",
      "06/29/2022 02:30:18 - INFO - __main__ -   Text: ['\"\" ENTER THE AIR.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.368\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:30:19 - INFO - __main__ -   Epoch: 48 | Batch: 600/10001 (6%) | G Loss: 4.144395 | C Loss: -1.520728\n",
      "06/29/2022 02:30:20 - INFO - __main__ -   Text: ['Achieving mystical nature is done in Section CE hundred.']\n",
      "06/29/2022 02:30:21 - INFO - __main__ -   Epoch: 48 | Batch: 1200/10001 (12%) | G Loss: 0.513455 | C Loss: -0.600860\n",
      "06/29/2022 02:30:21 - INFO - __main__ -   Text: ['On occasion, colds can sometimes result especially after one is away from home.']\n",
      "06/29/2022 02:30:22 - INFO - __main__ -   Epoch: 48 | Batch: 1800/10001 (18%) | G Loss: 3.348087 | C Loss: -0.893686\n",
      "06/29/2022 02:30:22 - INFO - __main__ -   Text: ['The inner mind knows that it surely has an infinite number of self-ownership.']\n",
      "06/29/2022 02:30:23 - INFO - __main__ -   Epoch: 48 | Batch: 2400/10001 (24%) | G Loss: -0.455976 | C Loss: -0.010606\n",
      "06/29/2022 02:30:23 - INFO - __main__ -   Text: ['They Battle#2 is \"Neigahahat #merchant\".']\n",
      "06/29/2022 02:30:24 - INFO - __main__ -   Epoch: 48 | Batch: 3000/10001 (30%) | G Loss: 4.143976 | C Loss: -1.976269\n",
      "06/29/2022 02:30:24 - INFO - __main__ -   Text: ['Ill-Kept secret societies.']\n",
      "06/29/2022 02:30:25 - INFO - __main__ -   Epoch: 48 | Batch: 3600/10001 (36%) | G Loss: 0.710071 | C Loss: -0.799971\n",
      "06/29/2022 02:30:25 - INFO - __main__ -   Text: ['Biblical ago is a Bibliography.']\n",
      "06/29/2022 02:30:26 - INFO - __main__ -   Epoch: 48 | Batch: 4200/10001 (42%) | G Loss: 2.368772 | C Loss: -1.159154\n",
      "06/29/2022 02:30:26 - INFO - __main__ -   Text: ['Its coordinate mechanism is superior to that of interlinked genes in promoting gene expression.']\n",
      "06/29/2022 02:30:27 - INFO - __main__ -   Epoch: 48 | Batch: 4800/10001 (48%) | G Loss: 0.958281 | C Loss: -0.708591\n",
      "06/29/2022 02:30:27 - INFO - __main__ -   Text: ['Susan Olson practices anal sex.']\n",
      "06/29/2022 02:30:28 - INFO - __main__ -   Epoch: 48 | Batch: 5400/10001 (54%) | G Loss: 1.971794 | C Loss: -0.751231\n",
      "06/29/2022 02:30:28 - INFO - __main__ -   Text: ['As discussed above in a thread on \"USFB\".']\n",
      "06/29/2022 02:30:29 - INFO - __main__ -   Epoch: 48 | Batch: 6000/10001 (60%) | G Loss: 2.594050 | C Loss: -0.455389\n",
      "06/29/2022 02:30:29 - INFO - __main__ -   Text: ['Wood Sr is a more modern line, although Bhitwell is still widespread in Tamil.']\n",
      "06/29/2022 02:30:30 - INFO - __main__ -   Epoch: 48 | Batch: 6600/10001 (66%) | G Loss: 0.790829 | C Loss: -0.523566\n",
      "06/29/2022 02:30:30 - INFO - __main__ -   Text: ['An NPC is often dependent upon the correct program for interfacing with character.']\n",
      "06/29/2022 02:30:31 - INFO - __main__ -   Epoch: 48 | Batch: 7200/10001 (72%) | G Loss: -1.059657 | C Loss: 1.531630\n",
      "06/29/2022 02:30:31 - INFO - __main__ -   Text: ['The Black Plague.']\n",
      "06/29/2022 02:30:32 - INFO - __main__ -   Epoch: 48 | Batch: 7800/10001 (78%) | G Loss: 6.553555 | C Loss: -3.746607\n",
      "06/29/2022 02:30:32 - INFO - __main__ -   Text: [\"As a punishment for Lee's guilty, he opens fire, revoking his memory.\"]\n",
      "06/29/2022 02:30:33 - INFO - __main__ -   Epoch: 48 | Batch: 8400/10001 (84%) | G Loss: -2.864938 | C Loss: 0.050636\n",
      "06/29/2022 02:30:33 - INFO - __main__ -   Text: ['The mind always in a certain form is a traveller.']\n",
      "06/29/2022 02:30:34 - INFO - __main__ -   Epoch: 48 | Batch: 9000/10001 (90%) | G Loss: -0.201451 | C Loss: 0.188832\n",
      "06/29/2022 02:30:35 - INFO - __main__ -   Text: ['The bassball is right between Congruental Birthing.']\n",
      "06/29/2022 02:30:35 - INFO - __main__ -   Epoch: 48 | Batch: 9600/10001 (96%) | G Loss: 5.889520 | C Loss: -1.341607\n",
      "06/29/2022 02:30:36 - INFO - __main__ -   Text: ['The mathematical education is one example.']\n",
      "06/29/2022 02:30:36 - INFO - __main__ -   * (Train) Epoch: 48 | G Loss: 1.3368 | C Loss: -1.1414 | Updates G: 243 | Updates C: 590\n",
      "06/29/2022 02:30:45 - INFO - __main__ -   Bleu-2:0.203 | B-Bleu-2:0.242\n",
      "06/29/2022 02:30:45 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44544266280545397\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 49 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:43.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:01.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:19.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.723\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:34:22 - INFO - __main__ -   Epoch: 49 | Batch: 0/10001 (0%) | G Loss: 2.822675 | C Loss: -1.525674\n",
      "06/29/2022 02:34:22 - INFO - __main__ -   Text: ['Scarbot is a spammer.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.367\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:34:23 - INFO - __main__ -   Epoch: 49 | Batch: 600/10001 (6%) | G Loss: -1.541528 | C Loss: 2.272444\n",
      "06/29/2022 02:34:23 - INFO - __main__ -   Text: ['Bunches.']\n",
      "06/29/2022 02:34:24 - INFO - __main__ -   Epoch: 49 | Batch: 1200/10001 (12%) | G Loss: 11.070723 | C Loss: -5.501458\n",
      "06/29/2022 02:34:24 - INFO - __main__ -   Text: ['It implies higher grades.']\n",
      "06/29/2022 02:34:25 - INFO - __main__ -   Epoch: 49 | Batch: 1800/10001 (18%) | G Loss: 1.014002 | C Loss: -1.100021\n",
      "06/29/2022 02:34:25 - INFO - __main__ -   Text: ['\"The drunken is with them.']\n",
      "06/29/2022 02:34:26 - INFO - __main__ -   Epoch: 49 | Batch: 2400/10001 (24%) | G Loss: -3.285315 | C Loss: -1.123445\n",
      "06/29/2022 02:34:26 - INFO - __main__ -   Text: ['If I say I want to learn programming, my core successful business is process.\"']\n",
      "06/29/2022 02:34:27 - INFO - __main__ -   Epoch: 49 | Batch: 3000/10001 (30%) | G Loss: 2.400509 | C Loss: -0.293685\n",
      "06/29/2022 02:34:27 - INFO - __main__ -   Text: ['Other mammals like anastomoses and quadraticros probably do not apply these calculations.']\n",
      "06/29/2022 02:34:28 - INFO - __main__ -   Epoch: 49 | Batch: 3600/10001 (36%) | G Loss: 3.602458 | C Loss: -1.092647\n",
      "06/29/2022 02:34:28 - INFO - __main__ -   Text: ['Abandon the wavy lines.']\n",
      "06/29/2022 02:34:29 - INFO - __main__ -   Epoch: 49 | Batch: 4200/10001 (42%) | G Loss: -1.353909 | C Loss: -0.048965\n",
      "06/29/2022 02:34:29 - INFO - __main__ -   Text: ['Although most of Bedlam is unattractive, there may have been nakedness.']\n",
      "06/29/2022 02:34:30 - INFO - __main__ -   Epoch: 49 | Batch: 4800/10001 (48%) | G Loss: -0.046646 | C Loss: -0.189685\n",
      "06/29/2022 02:34:30 - INFO - __main__ -   Text: ['Fish commits the opposite error of psychology, but it is too precise.']\n",
      "06/29/2022 02:34:31 - INFO - __main__ -   Epoch: 49 | Batch: 5400/10001 (54%) | G Loss: 4.558018 | C Loss: -0.657700\n",
      "06/29/2022 02:34:31 - INFO - __main__ -   Text: ['There are pages of lore, chiefly poetry.']\n",
      "06/29/2022 02:34:32 - INFO - __main__ -   Epoch: 49 | Batch: 6000/10001 (60%) | G Loss: 2.569799 | C Loss: -0.874957\n",
      "06/29/2022 02:34:33 - INFO - __main__ -   Text: ['The Internet is being disrupted.']\n",
      "06/29/2022 02:34:33 - INFO - __main__ -   Epoch: 49 | Batch: 6600/10001 (66%) | G Loss: 0.045780 | C Loss: -0.435380\n",
      "06/29/2022 02:34:33 - INFO - __main__ -   Text: ['And Before Wrestling']\n",
      "06/29/2022 02:34:34 - INFO - __main__ -   Epoch: 49 | Batch: 7200/10001 (72%) | G Loss: 1.937359 | C Loss: -1.171710\n",
      "06/29/2022 02:34:35 - INFO - __main__ -   Text: [\"One of Drupal's most popular features.\"]\n",
      "06/29/2022 02:34:35 - INFO - __main__ -   Epoch: 49 | Batch: 7800/10001 (78%) | G Loss: 1.338598 | C Loss: -1.152302\n",
      "06/29/2022 02:34:36 - INFO - __main__ -   Text: ['It is possible that the Book of Mormon came to Egypt.']\n",
      "06/29/2022 02:34:37 - INFO - __main__ -   Epoch: 49 | Batch: 8400/10001 (84%) | G Loss: 1.593577 | C Loss: -0.452069\n",
      "06/29/2022 02:34:37 - INFO - __main__ -   Text: ['Unlike other microbes they will show no reaction to small amounts of meat.']\n",
      "06/29/2022 02:34:38 - INFO - __main__ -   Epoch: 49 | Batch: 9000/10001 (90%) | G Loss: 3.852782 | C Loss: -1.608101\n",
      "06/29/2022 02:34:38 - INFO - __main__ -   Text: ['Ethiopian bioethics assumes a yellow spectrum.']\n",
      "06/29/2022 02:34:39 - INFO - __main__ -   Epoch: 49 | Batch: 9600/10001 (96%) | G Loss: -0.352330 | C Loss: 0.042830\n",
      "06/29/2022 02:34:39 - INFO - __main__ -   Text: ['Edgar is the only one who can beat the course.\"']\n",
      "06/29/2022 02:34:39 - INFO - __main__ -   * (Train) Epoch: 49 | G Loss: 0.8864 | C Loss: -1.0278 | Updates G: 236 | Updates C: 597\n",
      "06/29/2022 02:34:47 - INFO - __main__ -   Bleu-2:0.216 | B-Bleu-2:0.213\n",
      "06/29/2022 02:34:47 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4296071863831403\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 50 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:15.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:29.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:45.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:00.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:15.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:15.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:30.\n",
      "  Batch   110  of    120.    Elapsed: 0:02:45.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.721\n",
      "  Training epcoh took: 0:03:00\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:37:47 - INFO - __main__ -   Epoch: 50 | Batch: 0/10001 (0%) | G Loss: 1.099461 | C Loss: -0.309435\n",
      "06/29/2022 02:37:47 - INFO - __main__ -   Text: ['thanks js!']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 3.427\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:37:48 - INFO - __main__ -   Epoch: 50 | Batch: 600/10001 (6%) | G Loss: 1.709923 | C Loss: -0.910343\n",
      "06/29/2022 02:37:48 - INFO - __main__ -   Text: ['He is working to kill Viruses and Parasites using better ways to inject viruses or otherwise.']\n",
      "06/29/2022 02:37:49 - INFO - __main__ -   Epoch: 50 | Batch: 1200/10001 (12%) | G Loss: 1.281783 | C Loss: -0.206770\n",
      "06/29/2022 02:37:49 - INFO - __main__ -   Text: ['If a vampire feeds it its video feed.']\n",
      "06/29/2022 02:37:50 - INFO - __main__ -   Epoch: 50 | Batch: 1800/10001 (18%) | G Loss: 1.042606 | C Loss: -0.862488\n",
      "06/29/2022 02:37:51 - INFO - __main__ -   Text: ['Similar to the woman-centered model in gender studies, this bear study has advantages.']\n",
      "06/29/2022 02:37:52 - INFO - __main__ -   Epoch: 50 | Batch: 2400/10001 (24%) | G Loss: 0.291873 | C Loss: -0.399964\n",
      "06/29/2022 02:37:52 - INFO - __main__ -   Text: ['It is believed that Irish citizens have never ever been a real person.']\n",
      "06/29/2022 02:37:53 - INFO - __main__ -   Epoch: 50 | Batch: 3000/10001 (30%) | G Loss: 0.815485 | C Loss: -0.699111\n",
      "06/29/2022 02:37:53 - INFO - __main__ -   Text: [\"This is why I'm so much proud and impatient.\"]\n",
      "06/29/2022 02:37:54 - INFO - __main__ -   Epoch: 50 | Batch: 3600/10001 (36%) | G Loss: 2.796527 | C Loss: -0.946538\n",
      "06/29/2022 02:37:54 - INFO - __main__ -   Text: ['He wants to dangerous stuff.']\n",
      "06/29/2022 02:37:55 - INFO - __main__ -   Epoch: 50 | Batch: 4200/10001 (42%) | G Loss: -0.010339 | C Loss: -0.596418\n",
      "06/29/2022 02:37:55 - INFO - __main__ -   Text: ['Thereafter in sure your chores can be achieved.']\n",
      "06/29/2022 02:37:56 - INFO - __main__ -   Epoch: 50 | Batch: 4800/10001 (48%) | G Loss: 2.986712 | C Loss: -0.657544\n",
      "06/29/2022 02:37:56 - INFO - __main__ -   Text: ['He knows it is April and he knows it is Monday and easy.']\n",
      "06/29/2022 02:37:57 - INFO - __main__ -   Epoch: 50 | Batch: 5400/10001 (54%) | G Loss: 1.182378 | C Loss: -0.834805\n",
      "06/29/2022 02:37:57 - INFO - __main__ -   Text: ['One thing we do with this and we are usually human.\"']\n",
      "06/29/2022 02:37:58 - INFO - __main__ -   Epoch: 50 | Batch: 6000/10001 (60%) | G Loss: 3.456265 | C Loss: -0.847221\n",
      "06/29/2022 02:37:58 - INFO - __main__ -   Text: ['It is the test of what a person has already accomplished.']\n",
      "06/29/2022 02:37:59 - INFO - __main__ -   Epoch: 50 | Batch: 6600/10001 (66%) | G Loss: 3.365985 | C Loss: -1.263266\n",
      "06/29/2022 02:37:59 - INFO - __main__ -   Text: ['It is called a Ionia, but it is same.']\n",
      "06/29/2022 02:38:00 - INFO - __main__ -   Epoch: 50 | Batch: 7200/10001 (72%) | G Loss: -0.370131 | C Loss: 0.205867\n",
      "06/29/2022 02:38:00 - INFO - __main__ -   Text: ['In life now, Vanessa won\\'t need to run much farther to know it way.\"']\n",
      "06/29/2022 02:38:01 - INFO - __main__ -   Epoch: 50 | Batch: 7800/10001 (78%) | G Loss: 2.949897 | C Loss: -1.221698\n",
      "06/29/2022 02:38:01 - INFO - __main__ -   Text: ['\"\" When you identify it with \"If you notice psychic particles .']\n",
      "06/29/2022 02:38:02 - INFO - __main__ -   Epoch: 50 | Batch: 8400/10001 (84%) | G Loss: -0.104169 | C Loss: -0.184909\n",
      "06/29/2022 02:38:02 - INFO - __main__ -   Text: [\"a America's Favorite!\"]\n",
      "06/29/2022 02:38:03 - INFO - __main__ -   Epoch: 50 | Batch: 9000/10001 (90%) | G Loss: 3.417429 | C Loss: -1.171492\n",
      "06/29/2022 02:38:03 - INFO - __main__ -   Text: ['Just non-respect men.']\n",
      "06/29/2022 02:38:04 - INFO - __main__ -   Epoch: 50 | Batch: 9600/10001 (96%) | G Loss: -0.574248 | C Loss: -0.090711\n",
      "06/29/2022 02:38:04 - INFO - __main__ -   Text: ['We Waste All.']\n",
      "06/29/2022 02:38:05 - INFO - __main__ -   * (Train) Epoch: 50 | G Loss: 1.1661 | C Loss: -0.8558 | Updates G: 252 | Updates C: 581\n",
      "06/29/2022 02:38:14 - INFO - __main__ -   Bleu-2:0.221 | B-Bleu-2:0.231\n",
      "06/29/2022 02:38:14 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45208296380814905\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 51 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:49.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:06.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:22.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:40.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:56.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:13.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:28.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:44.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:00.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.725\n",
      "  Training epcoh took: 0:03:16\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:41:31 - INFO - __main__ -   Epoch: 51 | Batch: 0/10001 (0%) | G Loss: -0.423265 | C Loss: -0.218516\n",
      "06/29/2022 02:41:31 - INFO - __main__ -   Text: ['mind-numbing.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.426\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:41:32 - INFO - __main__ -   Epoch: 51 | Batch: 600/10001 (6%) | G Loss: 3.482585 | C Loss: -1.358452\n",
      "06/29/2022 02:41:32 - INFO - __main__ -   Text: ['120 percent of that cows seem more or less to be tolerant.']\n",
      "06/29/2022 02:41:33 - INFO - __main__ -   Epoch: 51 | Batch: 1200/10001 (12%) | G Loss: -0.046429 | C Loss: -0.632098\n",
      "06/29/2022 02:41:33 - INFO - __main__ -   Text: ['When these members of the clergy are idolized, they are called religion.\"']\n",
      "06/29/2022 02:41:34 - INFO - __main__ -   Epoch: 51 | Batch: 1800/10001 (18%) | G Loss: 1.889890 | C Loss: -0.747354\n",
      "06/29/2022 02:41:34 - INFO - __main__ -   Text: ['There are 3 main ways to calculate mean temperature: one says deciliter readings in Celsius.']\n",
      "06/29/2022 02:41:35 - INFO - __main__ -   Epoch: 51 | Batch: 2400/10001 (24%) | G Loss: 0.207814 | C Loss: -0.366788\n",
      "06/29/2022 02:41:35 - INFO - __main__ -   Text: ['Looking at life requires a certain kind of understanding.']\n",
      "06/29/2022 02:41:36 - INFO - __main__ -   Epoch: 51 | Batch: 3000/10001 (30%) | G Loss: 2.563888 | C Loss: -1.429230\n",
      "06/29/2022 02:41:36 - INFO - __main__ -   Text: ['She is even said to dare to brag about being hot beside them.']\n",
      "06/29/2022 02:41:37 - INFO - __main__ -   Epoch: 51 | Batch: 3600/10001 (36%) | G Loss: -0.020835 | C Loss: -0.394568\n",
      "06/29/2022 02:41:37 - INFO - __main__ -   Text: ['TV show celebrities have the most unwrapless underwear.']\n",
      "06/29/2022 02:41:38 - INFO - __main__ -   Epoch: 51 | Batch: 4200/10001 (42%) | G Loss: 3.047258 | C Loss: -0.946813\n",
      "06/29/2022 02:41:38 - INFO - __main__ -   Text: ['Off-road behavior is different from human life.']\n",
      "06/29/2022 02:41:39 - INFO - __main__ -   Epoch: 51 | Batch: 4800/10001 (48%) | G Loss: 0.597829 | C Loss: -0.806423\n",
      "06/29/2022 02:41:39 - INFO - __main__ -   Text: ['\", confirming Ahrarqi\\'s claim.']\n",
      "06/29/2022 02:41:40 - INFO - __main__ -   Epoch: 51 | Batch: 5400/10001 (54%) | G Loss: -0.377296 | C Loss: -0.293104\n",
      "06/29/2022 02:41:40 - INFO - __main__ -   Text: ['She trained good tennis players like Derek Riley and Jolte.']\n",
      "06/29/2022 02:41:41 - INFO - __main__ -   Epoch: 51 | Batch: 6000/10001 (60%) | G Loss: 4.605377 | C Loss: -0.798368\n",
      "06/29/2022 02:41:41 - INFO - __main__ -   Text: ['\"\" You can completely change anything.']\n",
      "06/29/2022 02:41:42 - INFO - __main__ -   Epoch: 51 | Batch: 6600/10001 (66%) | G Loss: 3.729230 | C Loss: -0.929270\n",
      "06/29/2022 02:41:42 - INFO - __main__ -   Text: ['Another comic book author, Anur started seeing return !']\n",
      "06/29/2022 02:41:43 - INFO - __main__ -   Epoch: 51 | Batch: 7200/10001 (72%) | G Loss: 0.445156 | C Loss: -0.856788\n",
      "06/29/2022 02:41:43 - INFO - __main__ -   Text: ['It is the seventeenth of these.']\n",
      "06/29/2022 02:41:44 - INFO - __main__ -   Epoch: 51 | Batch: 7800/10001 (78%) | G Loss: 1.102827 | C Loss: -0.948231\n",
      "06/29/2022 02:41:45 - INFO - __main__ -   Text: ['This is designed to use data much faster than ultrabond reflexes.']\n",
      "06/29/2022 02:41:45 - INFO - __main__ -   Epoch: 51 | Batch: 8400/10001 (84%) | G Loss: 2.198539 | C Loss: -1.643474\n",
      "06/29/2022 02:41:46 - INFO - __main__ -   Text: ['But, think about VR Effectiveness, for example that GC with every novice']\n",
      "06/29/2022 02:41:47 - INFO - __main__ -   Epoch: 51 | Batch: 9000/10001 (90%) | G Loss: 2.306479 | C Loss: -1.225685\n",
      "06/29/2022 02:41:47 - INFO - __main__ -   Text: ['He also wins in golf.']\n",
      "06/29/2022 02:41:48 - INFO - __main__ -   Epoch: 51 | Batch: 9600/10001 (96%) | G Loss: 1.863445 | C Loss: -1.074182\n",
      "06/29/2022 02:41:48 - INFO - __main__ -   Text: ['He cannot conceive an intellect, but he understands.']\n",
      "06/29/2022 02:41:48 - INFO - __main__ -   * (Train) Epoch: 51 | G Loss: 1.0965 | C Loss: -0.9828 | Updates G: 235 | Updates C: 598\n",
      "06/29/2022 02:41:57 - INFO - __main__ -   Bleu-2:0.194 | B-Bleu-2:0.255\n",
      "06/29/2022 02:41:57 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44868175354765094\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 52 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.721\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:45:32 - INFO - __main__ -   Epoch: 52 | Batch: 0/10001 (0%) | G Loss: -0.131404 | C Loss: -0.639436\n",
      "06/29/2022 02:45:32 - INFO - __main__ -   Text: [\"Can't the bird, fly, breeze or drift?\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.485\n",
      "  Test Loss: 3.533\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:45:33 - INFO - __main__ -   Epoch: 52 | Batch: 600/10001 (6%) | G Loss: 3.144068 | C Loss: -1.336926\n",
      "06/29/2022 02:45:33 - INFO - __main__ -   Text: ['This number means that anyone can do this and yet !']\n",
      "06/29/2022 02:45:34 - INFO - __main__ -   Epoch: 52 | Batch: 1200/10001 (12%) | G Loss: -0.021958 | C Loss: -0.593981\n",
      "06/29/2022 02:45:34 - INFO - __main__ -   Text: ['Inoreaction is a fundamental factor in technical innovation.']\n",
      "06/29/2022 02:45:35 - INFO - __main__ -   Epoch: 52 | Batch: 1800/10001 (18%) | G Loss: 2.735776 | C Loss: -1.233842\n",
      "06/29/2022 02:45:35 - INFO - __main__ -   Text: ['Devoted habit has the visual description of sloths.']\n",
      "06/29/2022 02:45:36 - INFO - __main__ -   Epoch: 52 | Batch: 2400/10001 (24%) | G Loss: 0.670444 | C Loss: -0.736665\n",
      "06/29/2022 02:45:37 - INFO - __main__ -   Text: ['/Be sure it works!\" <BOS> boldly.<with I has!']\n",
      "06/29/2022 02:45:37 - INFO - __main__ -   Epoch: 52 | Batch: 3000/10001 (30%) | G Loss: 1.528404 | C Loss: -0.808690\n",
      "06/29/2022 02:45:38 - INFO - __main__ -   Text: ['They can silk the edge to a MacBook,\" Benny Lynch writes.']\n",
      "06/29/2022 02:45:39 - INFO - __main__ -   Epoch: 52 | Batch: 3600/10001 (36%) | G Loss: 0.964332 | C Loss: -0.701767\n",
      "06/29/2022 02:45:39 - INFO - __main__ -   Text: ['If you can lay a diagonal and run handover, then Helwix is strong.']\n",
      "06/29/2022 02:45:40 - INFO - __main__ -   Epoch: 52 | Batch: 4200/10001 (42%) | G Loss: 2.621656 | C Loss: -1.291717\n",
      "06/29/2022 02:45:40 - INFO - __main__ -   Text: ['Also his father is Mike Pence.']\n",
      "06/29/2022 02:45:41 - INFO - __main__ -   Epoch: 52 | Batch: 4800/10001 (48%) | G Loss: 1.402044 | C Loss: -1.310245\n",
      "06/29/2022 02:45:41 - INFO - __main__ -   Text: ['if you don\\'t know what that would be\".']\n",
      "06/29/2022 02:45:42 - INFO - __main__ -   Epoch: 52 | Batch: 5400/10001 (54%) | G Loss: -0.027727 | C Loss: -0.378674\n",
      "06/29/2022 02:45:42 - INFO - __main__ -   Text: ['Development of non-parallel databases is very attractive.']\n",
      "06/29/2022 02:45:43 - INFO - __main__ -   Epoch: 52 | Batch: 6000/10001 (60%) | G Loss: 2.254316 | C Loss: -0.855474\n",
      "06/29/2022 02:45:43 - INFO - __main__ -   Text: ['Garner calls it \"a thing between friends\" since Emily\\'s TV is between her parents.']\n",
      "06/29/2022 02:45:44 - INFO - __main__ -   Epoch: 52 | Batch: 6600/10001 (66%) | G Loss: 0.576207 | C Loss: -0.947730\n",
      "06/29/2022 02:45:44 - INFO - __main__ -   Text: ['It\\'s like you, but \"You\\'re complex\".']\n",
      "06/29/2022 02:45:45 - INFO - __main__ -   Epoch: 52 | Batch: 7200/10001 (72%) | G Loss: 2.992337 | C Loss: -1.115546\n",
      "06/29/2022 02:45:45 - INFO - __main__ -   Text: ['He is handsome.']\n",
      "06/29/2022 02:45:46 - INFO - __main__ -   Epoch: 52 | Batch: 7800/10001 (78%) | G Loss: 2.076664 | C Loss: -1.192999\n",
      "06/29/2022 02:45:46 - INFO - __main__ -   Text: ['These motivations include apps for college hopefuls.']\n",
      "06/29/2022 02:45:47 - INFO - __main__ -   Epoch: 52 | Batch: 8400/10001 (84%) | G Loss: 0.250573 | C Loss: -0.879444\n",
      "06/29/2022 02:45:47 - INFO - __main__ -   Text: [\"It's one of the largest outdoor competitions in the world.\"]\n",
      "06/29/2022 02:45:48 - INFO - __main__ -   Epoch: 52 | Batch: 9000/10001 (90%) | G Loss: 1.823366 | C Loss: -2.152124\n",
      "06/29/2022 02:45:48 - INFO - __main__ -   Text: ['Sophygly and learn it.\"']\n",
      "06/29/2022 02:45:49 - INFO - __main__ -   Epoch: 52 | Batch: 9600/10001 (96%) | G Loss: 1.124290 | C Loss: -0.671330\n",
      "06/29/2022 02:45:49 - INFO - __main__ -   Text: ['Permission is then given under the name of Wiki-graphic.']\n",
      "06/29/2022 02:45:50 - INFO - __main__ -   * (Train) Epoch: 52 | G Loss: 0.9866 | C Loss: -0.9713 | Updates G: 213 | Updates C: 620\n",
      "06/29/2022 02:45:59 - INFO - __main__ -   Bleu-2:0.201 | B-Bleu-2:0.246\n",
      "06/29/2022 02:45:59 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4472355764056966\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 53 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.718\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:49:26 - INFO - __main__ -   Epoch: 53 | Batch: 0/10001 (0%) | G Loss: 0.591974 | C Loss: -0.624628\n",
      "06/29/2022 02:49:26 - INFO - __main__ -   Text: ['In addition, Johann Wolfgang describes a symbol class.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.477\n",
      "  Test Loss: 3.639\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:49:27 - INFO - __main__ -   Epoch: 53 | Batch: 600/10001 (6%) | G Loss: 1.727618 | C Loss: -1.661485\n",
      "06/29/2022 02:49:27 - INFO - __main__ -   Text: ['In the Firefly Trinity competition, \"Failfast\".']\n",
      "06/29/2022 02:49:28 - INFO - __main__ -   Epoch: 53 | Batch: 1200/10001 (12%) | G Loss: 1.704158 | C Loss: -0.802602\n",
      "06/29/2022 02:49:28 - INFO - __main__ -   Text: ['They laugh together, and sing there.\"']\n",
      "06/29/2022 02:49:29 - INFO - __main__ -   Epoch: 53 | Batch: 1800/10001 (18%) | G Loss: 1.121011 | C Loss: -0.642224\n",
      "06/29/2022 02:49:29 - INFO - __main__ -   Text: ['The man tries to get an MRI to check on his brain.']\n",
      "06/29/2022 02:49:30 - INFO - __main__ -   Epoch: 53 | Batch: 2400/10001 (24%) | G Loss: 0.558636 | C Loss: -0.850347\n",
      "06/29/2022 02:49:30 - INFO - __main__ -   Text: ['It is no joke!\"']\n",
      "06/29/2022 02:49:31 - INFO - __main__ -   Epoch: 53 | Batch: 3000/10001 (30%) | G Loss: 1.717552 | C Loss: -0.923802\n",
      "06/29/2022 02:49:31 - INFO - __main__ -   Text: ['\", You must be mute.']\n",
      "06/29/2022 02:49:32 - INFO - __main__ -   Epoch: 53 | Batch: 3600/10001 (36%) | G Loss: 1.116184 | C Loss: -0.770131\n",
      "06/29/2022 02:49:32 - INFO - __main__ -   Text: ['It is unknown how much the Internet can do.']\n",
      "06/29/2022 02:49:33 - INFO - __main__ -   Epoch: 53 | Batch: 4200/10001 (42%) | G Loss: 2.651989 | C Loss: -1.163501\n",
      "06/29/2022 02:49:33 - INFO - __main__ -   Text: [\"I don't remember what he determines - surely he.\"]\n",
      "06/29/2022 02:49:34 - INFO - __main__ -   Epoch: 53 | Batch: 4800/10001 (48%) | G Loss: 3.102211 | C Loss: -1.115577\n",
      "06/29/2022 02:49:35 - INFO - __main__ -   Text: ['This comes near the next code.']\n",
      "06/29/2022 02:49:35 - INFO - __main__ -   Epoch: 53 | Batch: 5400/10001 (54%) | G Loss: 0.802398 | C Loss: -0.831856\n",
      "06/29/2022 02:49:36 - INFO - __main__ -   Text: ['Javi falls over honey.']\n",
      "06/29/2022 02:49:36 - INFO - __main__ -   Epoch: 53 | Batch: 6000/10001 (60%) | G Loss: 2.491867 | C Loss: -0.734810\n",
      "06/29/2022 02:49:37 - INFO - __main__ -   Text: ['Costumes, ducks and dogs.']\n",
      "06/29/2022 02:49:38 - INFO - __main__ -   Epoch: 53 | Batch: 6600/10001 (66%) | G Loss: 1.751496 | C Loss: -1.237032\n",
      "06/29/2022 02:49:38 - INFO - __main__ -   Text: ['That forums and posts are closed are spread e-text message:']\n",
      "06/29/2022 02:49:39 - INFO - __main__ -   Epoch: 53 | Batch: 7200/10001 (72%) | G Loss: 1.833530 | C Loss: -0.888508\n",
      "06/29/2022 02:49:39 - INFO - __main__ -   Text: ['Ashton Magazine is a qualified restaurant advice style student resource expert.']\n",
      "06/29/2022 02:49:40 - INFO - __main__ -   Epoch: 53 | Batch: 7800/10001 (78%) | G Loss: 0.796072 | C Loss: -0.690075\n",
      "06/29/2022 02:49:40 - INFO - __main__ -   Text: ['Different BDSM classes come and go.']\n",
      "06/29/2022 02:49:41 - INFO - __main__ -   Epoch: 53 | Batch: 8400/10001 (84%) | G Loss: 0.944204 | C Loss: -0.867120\n",
      "06/29/2022 02:49:41 - INFO - __main__ -   Text: ['NextButton is a cool tune.\"']\n",
      "06/29/2022 02:49:42 - INFO - __main__ -   Epoch: 53 | Batch: 9000/10001 (90%) | G Loss: 2.535073 | C Loss: -0.841131\n",
      "06/29/2022 02:49:42 - INFO - __main__ -   Text: ['“Doctor Video Game”.']\n",
      "06/29/2022 02:49:43 - INFO - __main__ -   Epoch: 53 | Batch: 9600/10001 (96%) | G Loss: 1.174207 | C Loss: -0.955078\n",
      "06/29/2022 02:49:43 - INFO - __main__ -   Text: ['Berryman is not sure how the younger man will do.']\n",
      "06/29/2022 02:49:44 - INFO - __main__ -   * (Train) Epoch: 53 | G Loss: 1.2786 | C Loss: -0.8693 | Updates G: 176 | Updates C: 657\n",
      "06/29/2022 02:49:53 - INFO - __main__ -   Bleu-2:0.194 | B-Bleu-2:0.272\n",
      "06/29/2022 02:49:53 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_12.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46612771176384427\n",
      "Train file used is number 12\n",
      "../../yahoo/subdivided_large/train_12.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 54 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:25.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:43.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:01.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:19.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.720\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:53:29 - INFO - __main__ -   Epoch: 54 | Batch: 0/10001 (0%) | G Loss: 1.309353 | C Loss: -0.760145\n",
      "06/29/2022 02:53:29 - INFO - __main__ -   Text: ['\",\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.567\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:53:30 - INFO - __main__ -   Epoch: 54 | Batch: 600/10001 (6%) | G Loss: 2.307515 | C Loss: -0.871509\n",
      "06/29/2022 02:53:31 - INFO - __main__ -   Text: ['If you can be shown to use two principles therefore as negative neutral non-blocking\".']\n",
      "06/29/2022 02:53:32 - INFO - __main__ -   Epoch: 54 | Batch: 1200/10001 (12%) | G Loss: 1.803023 | C Loss: -0.801284\n",
      "06/29/2022 02:53:32 - INFO - __main__ -   Text: ['Alongside, this prevents abuse of judgement, aggression, and no harmful deliberative consequences.']\n",
      "06/29/2022 02:53:33 - INFO - __main__ -   Epoch: 54 | Batch: 1800/10001 (18%) | G Loss: 1.514622 | C Loss: -0.654578\n",
      "06/29/2022 02:53:33 - INFO - __main__ -   Text: ['NeedsALED76 and recommends:']\n",
      "06/29/2022 02:53:34 - INFO - __main__ -   Epoch: 54 | Batch: 2400/10001 (24%) | G Loss: 1.243055 | C Loss: -0.787447\n",
      "06/29/2022 02:53:34 - INFO - __main__ -   Text: ['Better yet, mobile video games can be downloaded for free.']\n",
      "06/29/2022 02:53:35 - INFO - __main__ -   Epoch: 54 | Batch: 3000/10001 (30%) | G Loss: 1.397976 | C Loss: -1.067558\n",
      "06/29/2022 02:53:35 - INFO - __main__ -   Text: ['When she makes her Halloween wish, she turns to earth.']\n",
      "06/29/2022 02:53:36 - INFO - __main__ -   Epoch: 54 | Batch: 3600/10001 (36%) | G Loss: 1.368134 | C Loss: -0.733466\n",
      "06/29/2022 02:53:36 - INFO - __main__ -   Text: ['Neither I nor the priest believe in doing anything self-destructive.\"']\n",
      "06/29/2022 02:53:37 - INFO - __main__ -   Epoch: 54 | Batch: 4200/10001 (42%) | G Loss: 1.057323 | C Loss: -0.743163\n",
      "06/29/2022 02:53:37 - INFO - __main__ -   Text: ['Womack is only concerned with the relevant social norms related to gender roles.']\n",
      "06/29/2022 02:53:38 - INFO - __main__ -   Epoch: 54 | Batch: 4800/10001 (48%) | G Loss: 1.309276 | C Loss: -0.876014\n",
      "06/29/2022 02:53:38 - INFO - __main__ -   Text: ['International Trading Places!']\n",
      "06/29/2022 02:53:39 - INFO - __main__ -   Epoch: 54 | Batch: 5400/10001 (54%) | G Loss: 1.452225 | C Loss: -0.958705\n",
      "06/29/2022 02:53:39 - INFO - __main__ -   Text: ['One of the jokes of the paper is \\'editable comment (at).\"']\n",
      "06/29/2022 02:53:40 - INFO - __main__ -   Epoch: 54 | Batch: 6000/10001 (60%) | G Loss: 1.998715 | C Loss: -1.082762\n",
      "06/29/2022 02:53:40 - INFO - __main__ -   Text: ['Kira would then suggest directly distributed programs.']\n",
      "06/29/2022 02:53:41 - INFO - __main__ -   Epoch: 54 | Batch: 6600/10001 (66%) | G Loss: 1.085330 | C Loss: -0.949489\n",
      "06/29/2022 02:53:41 - INFO - __main__ -   Text: ['This can pipeline filters using permalink which can be most useful.']\n",
      "06/29/2022 02:53:42 - INFO - __main__ -   Epoch: 54 | Batch: 7200/10001 (72%) | G Loss: 3.220829 | C Loss: -0.920322\n",
      "06/29/2022 02:53:43 - INFO - __main__ -   Text: ['Moment Start is easy to create and tracks small tasks and how employers may evaluate them.']\n",
      "06/29/2022 02:53:44 - INFO - __main__ -   Epoch: 54 | Batch: 7800/10001 (78%) | G Loss: 1.803686 | C Loss: -0.961433\n",
      "06/29/2022 02:53:44 - INFO - __main__ -   Text: ['The method guide to adding 0.1% to grains yields 1.']\n",
      "06/29/2022 02:53:45 - INFO - __main__ -   Epoch: 54 | Batch: 8400/10001 (84%) | G Loss: 1.639315 | C Loss: -0.592982\n",
      "06/29/2022 02:53:45 - INFO - __main__ -   Text: ['Strip Promotes is good for a job posting.']\n",
      "06/29/2022 02:53:46 - INFO - __main__ -   Epoch: 54 | Batch: 9000/10001 (90%) | G Loss: 1.697970 | C Loss: -0.919676\n",
      "06/29/2022 02:53:46 - INFO - __main__ -   Text: ['(\"Finding it easier to get into a demanding task\").']\n",
      "06/29/2022 02:53:47 - INFO - __main__ -   Epoch: 54 | Batch: 9600/10001 (96%) | G Loss: 1.089425 | C Loss: -1.536257\n",
      "06/29/2022 02:53:47 - INFO - __main__ -   Text: [\"She's not happy when someone starts laughing at her, and even takes her wedding ring.\"]\n",
      "06/29/2022 02:53:48 - INFO - __main__ -   * (Train) Epoch: 54 | G Loss: 1.5551 | C Loss: -0.9088 | Updates G: 165 | Updates C: 668\n",
      "06/29/2022 02:53:56 - INFO - __main__ -   Bleu-2:0.196 | B-Bleu-2:0.255\n",
      "06/29/2022 02:53:56 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4512361689837965\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 55 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.721\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:57:22 - INFO - __main__ -   Epoch: 55 | Batch: 0/10001 (0%) | G Loss: 0.969401 | C Loss: -0.763554\n",
      "06/29/2022 02:57:22 - INFO - __main__ -   Text: [\"The AI will assume the points of highest probability as a student's destination.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.512\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 02:57:23 - INFO - __main__ -   Epoch: 55 | Batch: 600/10001 (6%) | G Loss: 2.190485 | C Loss: -1.137016\n",
      "06/29/2022 02:57:23 - INFO - __main__ -   Text: ['He is drunk and sometimes apologises to me.']\n",
      "06/29/2022 02:57:24 - INFO - __main__ -   Epoch: 55 | Batch: 1200/10001 (12%) | G Loss: 1.672897 | C Loss: -0.958845\n",
      "06/29/2022 02:57:24 - INFO - __main__ -   Text: ['Some professionals really enjoy their 1-year gig there.']\n",
      "06/29/2022 02:57:25 - INFO - __main__ -   Epoch: 55 | Batch: 1800/10001 (18%) | G Loss: 2.397099 | C Loss: -0.827253\n",
      "06/29/2022 02:57:25 - INFO - __main__ -   Text: ['The canvas for this is Asset Transfer People AScale # \"pure.\"']\n",
      "06/29/2022 02:57:26 - INFO - __main__ -   Epoch: 55 | Batch: 2400/10001 (24%) | G Loss: 1.411460 | C Loss: -0.882670\n",
      "06/29/2022 02:57:26 - INFO - __main__ -   Text: ['This move, however, is fruit rechecking.']\n",
      "06/29/2022 02:57:27 - INFO - __main__ -   Epoch: 55 | Batch: 3000/10001 (30%) | G Loss: 2.705644 | C Loss: -1.063363\n",
      "06/29/2022 02:57:27 - INFO - __main__ -   Text: ['It cannot know where it starts.']\n",
      "06/29/2022 02:57:28 - INFO - __main__ -   Epoch: 55 | Batch: 3600/10001 (36%) | G Loss: 1.476135 | C Loss: -1.144201\n",
      "06/29/2022 02:57:28 - INFO - __main__ -   Text: ['There\\'s only one way to have this discussion with God.\"']\n",
      "06/29/2022 02:57:29 - INFO - __main__ -   Epoch: 55 | Batch: 4200/10001 (42%) | G Loss: 2.057225 | C Loss: -1.022366\n",
      "06/29/2022 02:57:29 - INFO - __main__ -   Text: [\"Counting up the wives, she's the least successful women in the world.\"]\n",
      "06/29/2022 02:57:30 - INFO - __main__ -   Epoch: 55 | Batch: 4800/10001 (48%) | G Loss: 1.519213 | C Loss: -1.031507\n",
      "06/29/2022 02:57:30 - INFO - __main__ -   Text: ['It is Brazilian like an afternoon tea.\"']\n",
      "06/29/2022 02:57:31 - INFO - __main__ -   Epoch: 55 | Batch: 5400/10001 (54%) | G Loss: 1.933565 | C Loss: -0.936561\n",
      "06/29/2022 02:57:31 - INFO - __main__ -   Text: ['Tennessee countermoves bush fry.']\n",
      "06/29/2022 02:57:32 - INFO - __main__ -   Epoch: 55 | Batch: 6000/10001 (60%) | G Loss: 1.913079 | C Loss: -0.854216\n",
      "06/29/2022 02:57:32 - INFO - __main__ -   Text: ['\"Shakh Shakerh shakh da prakriti\".']\n",
      "06/29/2022 02:57:33 - INFO - __main__ -   Epoch: 55 | Batch: 6600/10001 (66%) | G Loss: 2.149850 | C Loss: -0.855868\n",
      "06/29/2022 02:57:33 - INFO - __main__ -   Text: ['They give a good honest word.']\n",
      "06/29/2022 02:57:34 - INFO - __main__ -   Epoch: 55 | Batch: 7200/10001 (72%) | G Loss: 1.674534 | C Loss: -0.977779\n",
      "06/29/2022 02:57:35 - INFO - __main__ -   Text: ['There is another adventure, because once in college I think of life.\"']\n",
      "06/29/2022 02:57:35 - INFO - __main__ -   Epoch: 55 | Batch: 7800/10001 (78%) | G Loss: 1.978300 | C Loss: -0.598404\n",
      "06/29/2022 02:57:36 - INFO - __main__ -   Text: ['Not yet!']\n",
      "06/29/2022 02:57:36 - INFO - __main__ -   Epoch: 55 | Batch: 8400/10001 (84%) | G Loss: 1.595432 | C Loss: -1.035474\n",
      "06/29/2022 02:57:37 - INFO - __main__ -   Text: ['It describes certain childhood experiences based on logic.']\n",
      "06/29/2022 02:57:38 - INFO - __main__ -   Epoch: 55 | Batch: 9000/10001 (90%) | G Loss: 1.671254 | C Loss: -0.861021\n",
      "06/29/2022 02:57:38 - INFO - __main__ -   Text: ['The chicken both carries and simulates parasites.']\n",
      "06/29/2022 02:57:39 - INFO - __main__ -   Epoch: 55 | Batch: 9600/10001 (96%) | G Loss: 2.108180 | C Loss: -0.908337\n",
      "06/29/2022 02:57:39 - INFO - __main__ -   Text: ['Lionel cannot catch them because of the Worm.']\n",
      "06/29/2022 02:57:39 - INFO - __main__ -   * (Train) Epoch: 55 | G Loss: 1.6985 | C Loss: -0.9564 | Updates G: 129 | Updates C: 704\n",
      "06/29/2022 02:57:48 - INFO - __main__ -   Bleu-2:0.205 | B-Bleu-2:0.275\n",
      "06/29/2022 02:57:48 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_14.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4798645035171395\n",
      "Train file used is number 14\n",
      "../../yahoo/subdivided_large/train_14.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 56 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.719\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:01:17 - INFO - __main__ -   Epoch: 56 | Batch: 0/10001 (0%) | G Loss: 2.166386 | C Loss: -0.879643\n",
      "06/29/2022 03:01:17 - INFO - __main__ -   Text: ['The Cuban Missile.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.654\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:01:18 - INFO - __main__ -   Epoch: 56 | Batch: 600/10001 (6%) | G Loss: 1.596695 | C Loss: -0.839042\n",
      "06/29/2022 03:01:19 - INFO - __main__ -   Text: ['Then there is another dangerous parasite spreading from the dogs` stomach...']\n",
      "06/29/2022 03:01:20 - INFO - __main__ -   Epoch: 56 | Batch: 1200/10001 (12%) | G Loss: 1.697239 | C Loss: -0.985537\n",
      "06/29/2022 03:01:20 - INFO - __main__ -   Text: ['This post is also not suitable for some young ladies.']\n",
      "06/29/2022 03:01:21 - INFO - __main__ -   Epoch: 56 | Batch: 1800/10001 (18%) | G Loss: 1.964209 | C Loss: -1.218999\n",
      "06/29/2022 03:01:21 - INFO - __main__ -   Text: ['Then pop sleds!']\n",
      "06/29/2022 03:01:22 - INFO - __main__ -   Epoch: 56 | Batch: 2400/10001 (24%) | G Loss: 1.917975 | C Loss: -0.861139\n",
      "06/29/2022 03:01:22 - INFO - __main__ -   Text: ['He doesn\\'t like body shaming man because that\\'s what\\'s fun.\"']\n",
      "06/29/2022 03:01:23 - INFO - __main__ -   Epoch: 56 | Batch: 3000/10001 (30%) | G Loss: 1.336394 | C Loss: -0.872410\n",
      "06/29/2022 03:01:23 - INFO - __main__ -   Text: ['gets angry there\" Instantly she.']\n",
      "06/29/2022 03:01:24 - INFO - __main__ -   Epoch: 56 | Batch: 3600/10001 (36%) | G Loss: 1.274612 | C Loss: -1.031978\n",
      "06/29/2022 03:01:24 - INFO - __main__ -   Text: ['Their trickiest here is the surfboard\".']\n",
      "06/29/2022 03:01:25 - INFO - __main__ -   Epoch: 56 | Batch: 4200/10001 (42%) | G Loss: 2.268681 | C Loss: -1.095780\n",
      "06/29/2022 03:01:25 - INFO - __main__ -   Text: ['Rain, Rain.']\n",
      "06/29/2022 03:01:26 - INFO - __main__ -   Epoch: 56 | Batch: 4800/10001 (48%) | G Loss: 1.570010 | C Loss: -1.118383\n",
      "06/29/2022 03:01:26 - INFO - __main__ -   Text: ['The two letters shown here are Julian (10-1, and a tie).']\n",
      "06/29/2022 03:01:27 - INFO - __main__ -   Epoch: 56 | Batch: 5400/10001 (54%) | G Loss: 2.214152 | C Loss: -0.970244\n",
      "06/29/2022 03:01:27 - INFO - __main__ -   Text: ['Lambda is mainly for the punks.']\n",
      "06/29/2022 03:01:28 - INFO - __main__ -   Epoch: 56 | Batch: 6000/10001 (60%) | G Loss: 1.943493 | C Loss: -0.939500\n",
      "06/29/2022 03:01:28 - INFO - __main__ -   Text: ['Hypothesizes are usually considered to be invariant over time.']\n",
      "06/29/2022 03:01:29 - INFO - __main__ -   Epoch: 56 | Batch: 6600/10001 (66%) | G Loss: 1.122677 | C Loss: -1.064718\n",
      "06/29/2022 03:01:29 - INFO - __main__ -   Text: ['The Moon is a particular source of geophysical activity after 1300.']\n",
      "06/29/2022 03:01:30 - INFO - __main__ -   Epoch: 56 | Batch: 7200/10001 (72%) | G Loss: 2.896710 | C Loss: -1.136779\n",
      "06/29/2022 03:01:30 - INFO - __main__ -   Text: ['Promises only that and stays up for a set of instructions.\"']\n",
      "06/29/2022 03:01:31 - INFO - __main__ -   Epoch: 56 | Batch: 7800/10001 (78%) | G Loss: 1.623954 | C Loss: -0.851351\n",
      "06/29/2022 03:01:31 - INFO - __main__ -   Text: ['Of course Garnier is destroying the world.\"']\n",
      "06/29/2022 03:01:32 - INFO - __main__ -   Epoch: 56 | Batch: 8400/10001 (84%) | G Loss: 1.159932 | C Loss: -0.998391\n",
      "06/29/2022 03:01:33 - INFO - __main__ -   Text: ['The lecture \"Hamilton: a theory for algebra\".']\n",
      "06/29/2022 03:01:33 - INFO - __main__ -   Epoch: 56 | Batch: 9000/10001 (90%) | G Loss: 1.576832 | C Loss: -0.889786\n",
      "06/29/2022 03:01:34 - INFO - __main__ -   Text: ['Shield is very close to free to hit network.']\n",
      "06/29/2022 03:01:35 - INFO - __main__ -   Epoch: 56 | Batch: 9600/10001 (96%) | G Loss: 1.907505 | C Loss: -0.822252\n",
      "06/29/2022 03:01:35 - INFO - __main__ -   Text: ['Profiling is difficult, I write instant questions on website.']\n",
      "06/29/2022 03:01:35 - INFO - __main__ -   * (Train) Epoch: 56 | G Loss: 1.6804 | C Loss: -0.9725 | Updates G: 138 | Updates C: 695\n",
      "06/29/2022 03:01:45 - INFO - __main__ -   Bleu-2:0.196 | B-Bleu-2:0.265\n",
      "06/29/2022 03:01:45 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46062619787226483\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 57 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.719\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:05:16 - INFO - __main__ -   Epoch: 57 | Batch: 0/10001 (0%) | G Loss: 1.517407 | C Loss: -0.837709\n",
      "06/29/2022 03:05:16 - INFO - __main__ -   Text: ['It is one of my favorite book writing exercises.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.571\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:05:17 - INFO - __main__ -   Epoch: 57 | Batch: 600/10001 (6%) | G Loss: 1.667951 | C Loss: -0.797969\n",
      "06/29/2022 03:05:17 - INFO - __main__ -   Text: ['The countrymen definitely have a history with rifles.']\n",
      "06/29/2022 03:05:18 - INFO - __main__ -   Epoch: 57 | Batch: 1200/10001 (12%) | G Loss: 1.498587 | C Loss: -0.804196\n",
      "06/29/2022 03:05:18 - INFO - __main__ -   Text: ['\"curatley\" 1.0.']\n",
      "06/29/2022 03:05:19 - INFO - __main__ -   Epoch: 57 | Batch: 1800/10001 (18%) | G Loss: 2.360864 | C Loss: -0.886678\n",
      "06/29/2022 03:05:19 - INFO - __main__ -   Text: ['Alas, what is truly required by the person called \"The Man.\"']\n",
      "06/29/2022 03:05:20 - INFO - __main__ -   Epoch: 57 | Batch: 2400/10001 (24%) | G Loss: 1.827064 | C Loss: -0.868407\n",
      "06/29/2022 03:05:20 - INFO - __main__ -   Text: ['They have the potential to expand production and formation of useful resources.']\n",
      "06/29/2022 03:05:21 - INFO - __main__ -   Epoch: 57 | Batch: 3000/10001 (30%) | G Loss: 2.275975 | C Loss: -1.337298\n",
      "06/29/2022 03:05:21 - INFO - __main__ -   Text: ['Most of the tests are done in Q and A!']\n",
      "06/29/2022 03:05:22 - INFO - __main__ -   Epoch: 57 | Batch: 3600/10001 (36%) | G Loss: 2.477999 | C Loss: -0.854235\n",
      "06/29/2022 03:05:23 - INFO - __main__ -   Text: ['\"Quikiz\" stayed when compared to a frying pan.']\n",
      "06/29/2022 03:05:24 - INFO - __main__ -   Epoch: 57 | Batch: 4200/10001 (42%) | G Loss: 1.198319 | C Loss: -0.747049\n",
      "06/29/2022 03:05:24 - INFO - __main__ -   Text: ['She is dead, but not yet.\"']\n",
      "06/29/2022 03:05:25 - INFO - __main__ -   Epoch: 57 | Batch: 4800/10001 (48%) | G Loss: 1.271729 | C Loss: -0.800133\n",
      "06/29/2022 03:05:25 - INFO - __main__ -   Text: ['One of the most important features of this book is, When?\"']\n",
      "06/29/2022 03:05:26 - INFO - __main__ -   Epoch: 57 | Batch: 5400/10001 (54%) | G Loss: 1.982657 | C Loss: -0.995198\n",
      "06/29/2022 03:05:26 - INFO - __main__ -   Text: ['\"defection\".']\n",
      "06/29/2022 03:05:27 - INFO - __main__ -   Epoch: 57 | Batch: 6000/10001 (60%) | G Loss: 2.215957 | C Loss: -1.025700\n",
      "06/29/2022 03:05:27 - INFO - __main__ -   Text: ['is the basketball name.']\n",
      "06/29/2022 03:05:28 - INFO - __main__ -   Epoch: 57 | Batch: 6600/10001 (66%) | G Loss: 1.495702 | C Loss: -0.794754\n",
      "06/29/2022 03:05:28 - INFO - __main__ -   Text: ['He says that \"the strength of the ASEF is herity\".']\n",
      "06/29/2022 03:05:29 - INFO - __main__ -   Epoch: 57 | Batch: 7200/10001 (72%) | G Loss: 2.499366 | C Loss: -1.035461\n",
      "06/29/2022 03:05:29 - INFO - __main__ -   Text: ['The term \"AI\".']\n",
      "06/29/2022 03:05:30 - INFO - __main__ -   Epoch: 57 | Batch: 7800/10001 (78%) | G Loss: 2.939923 | C Loss: -1.096121\n",
      "06/29/2022 03:05:30 - INFO - __main__ -   Text: ['They employ drugs to stop the mutiny, and turn a blind eye to the ship.']\n",
      "06/29/2022 03:05:31 - INFO - __main__ -   Epoch: 57 | Batch: 8400/10001 (84%) | G Loss: 1.503664 | C Loss: -1.035439\n",
      "06/29/2022 03:05:31 - INFO - __main__ -   Text: ['It turns me bonkers!']\n",
      "06/29/2022 03:05:32 - INFO - __main__ -   Epoch: 57 | Batch: 9000/10001 (90%) | G Loss: 1.088755 | C Loss: -1.045368\n",
      "06/29/2022 03:05:32 - INFO - __main__ -   Text: ['In order for this experiment to work, a comic book.']\n",
      "06/29/2022 03:05:33 - INFO - __main__ -   Epoch: 57 | Batch: 9600/10001 (96%) | G Loss: 3.311676 | C Loss: -1.028774\n",
      "06/29/2022 03:05:33 - INFO - __main__ -   Text: ['When this is done, it gives exposure to economies.']\n",
      "06/29/2022 03:05:34 - INFO - __main__ -   * (Train) Epoch: 57 | G Loss: 1.7342 | C Loss: -0.9344 | Updates G: 132 | Updates C: 701\n",
      "06/29/2022 03:05:43 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.247\n",
      "06/29/2022 03:05:43 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44578750303087067\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 58 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:15.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:49.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:06.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.735\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:09:06 - INFO - __main__ -   Epoch: 58 | Batch: 0/10001 (0%) | G Loss: 2.403970 | C Loss: -0.782202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.480\n",
      "  Test Loss: 3.535\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:09:06 - INFO - __main__ -   Text: ['is famous for doing it in one day\"McDonnellianQuotes is not only known but has also']\n",
      "06/29/2022 03:09:07 - INFO - __main__ -   Epoch: 58 | Batch: 600/10001 (6%) | G Loss: 1.752168 | C Loss: -0.980583\n",
      "06/29/2022 03:09:07 - INFO - __main__ -   Text: ['Sparks average perk right after bursting.']\n",
      "06/29/2022 03:09:08 - INFO - __main__ -   Epoch: 58 | Batch: 1200/10001 (12%) | G Loss: 1.770252 | C Loss: -1.026338\n",
      "06/29/2022 03:09:08 - INFO - __main__ -   Text: ['Like tiger wings, this bird can safely fly.']\n",
      "06/29/2022 03:09:09 - INFO - __main__ -   Epoch: 58 | Batch: 1800/10001 (18%) | G Loss: 1.911865 | C Loss: -0.963530\n",
      "06/29/2022 03:09:10 - INFO - __main__ -   Text: ['A man can hop up or down on a ledge without reaching.']\n",
      "06/29/2022 03:09:11 - INFO - __main__ -   Epoch: 58 | Batch: 2400/10001 (24%) | G Loss: 1.824411 | C Loss: -0.963810\n",
      "06/29/2022 03:09:11 - INFO - __main__ -   Text: ['It is also the kind of song that Ejectives revere.']\n",
      "06/29/2022 03:09:12 - INFO - __main__ -   Epoch: 58 | Batch: 3000/10001 (30%) | G Loss: 1.912611 | C Loss: -0.850524\n",
      "06/29/2022 03:09:12 - INFO - __main__ -   Text: ['He is called a handsome walker see.']\n",
      "06/29/2022 03:09:13 - INFO - __main__ -   Epoch: 58 | Batch: 3600/10001 (36%) | G Loss: 2.048537 | C Loss: -1.058578\n",
      "06/29/2022 03:09:13 - INFO - __main__ -   Text: ['They ought never to deviate from what else they are told.']\n",
      "06/29/2022 03:09:14 - INFO - __main__ -   Epoch: 58 | Batch: 4200/10001 (42%) | G Loss: 2.059384 | C Loss: -1.067743\n",
      "06/29/2022 03:09:14 - INFO - __main__ -   Text: ['\"I you, Ragah!\"']\n",
      "06/29/2022 03:09:15 - INFO - __main__ -   Epoch: 58 | Batch: 4800/10001 (48%) | G Loss: 1.416473 | C Loss: -0.950203\n",
      "06/29/2022 03:09:15 - INFO - __main__ -   Text: ['The term \"weak force\" or \"weak end.\"']\n",
      "06/29/2022 03:09:16 - INFO - __main__ -   Epoch: 58 | Batch: 5400/10001 (54%) | G Loss: 2.299790 | C Loss: -0.974546\n",
      "06/29/2022 03:09:16 - INFO - __main__ -   Text: ['He also has a friendly ex-wife who gives him a book on finding porn.']\n",
      "06/29/2022 03:09:17 - INFO - __main__ -   Epoch: 58 | Batch: 6000/10001 (60%) | G Loss: 2.534656 | C Loss: -0.909640\n",
      "06/29/2022 03:09:17 - INFO - __main__ -   Text: ['When the old (or the new beta) bandspeak is touch, there are two dot ips.']\n",
      "06/29/2022 03:09:18 - INFO - __main__ -   Epoch: 58 | Batch: 6600/10001 (66%) | G Loss: 1.517583 | C Loss: -0.870736\n",
      "06/29/2022 03:09:18 - INFO - __main__ -   Text: ['Only her One-touch moves!\"']\n",
      "06/29/2022 03:09:19 - INFO - __main__ -   Epoch: 58 | Batch: 7200/10001 (72%) | G Loss: 1.433543 | C Loss: -1.101224\n",
      "06/29/2022 03:09:19 - INFO - __main__ -   Text: ['The World Rugby Council.']\n",
      "06/29/2022 03:09:20 - INFO - __main__ -   Epoch: 58 | Batch: 7800/10001 (78%) | G Loss: 1.791102 | C Loss: -0.949269\n",
      "06/29/2022 03:09:20 - INFO - __main__ -   Text: ['The validity of cyclisms can be seen by looking at a logarithmic path that describes the full ebb']\n",
      "06/29/2022 03:09:21 - INFO - __main__ -   Epoch: 58 | Batch: 8400/10001 (84%) | G Loss: 2.263308 | C Loss: -0.888482\n",
      "06/29/2022 03:09:21 - INFO - __main__ -   Text: ['To better understand the career of Lindsay Rush.']\n",
      "06/29/2022 03:09:22 - INFO - __main__ -   Epoch: 58 | Batch: 9000/10001 (90%) | G Loss: 2.135312 | C Loss: -0.999933\n",
      "06/29/2022 03:09:22 - INFO - __main__ -   Text: ['An upcoming page has Dr. Tuberstein.']\n",
      "06/29/2022 03:09:23 - INFO - __main__ -   Epoch: 58 | Batch: 9600/10001 (96%) | G Loss: 1.982345 | C Loss: -0.880187\n",
      "06/29/2022 03:09:24 - INFO - __main__ -   Text: ['Jesus is godfather, even when classical music is not acting.']\n",
      "06/29/2022 03:09:24 - INFO - __main__ -   * (Train) Epoch: 58 | G Loss: 1.8520 | C Loss: -0.9376 | Updates G: 128 | Updates C: 705\n",
      "06/29/2022 03:09:33 - INFO - __main__ -   Bleu-2:0.201 | B-Bleu-2:0.251\n",
      "06/29/2022 03:09:33 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4524625816714908\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 59 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.718\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:16:58 - INFO - __main__ -   Epoch: 60 | Batch: 0/10001 (0%) | G Loss: 2.631607 | C Loss: -0.986864\n",
      "06/29/2022 03:16:58 - INFO - __main__ -   Text: ['wigs and other cruel tricks.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.475\n",
      "  Test Loss: 3.702\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:16:59 - INFO - __main__ -   Epoch: 60 | Batch: 600/10001 (6%) | G Loss: 2.220851 | C Loss: -1.082549\n",
      "06/29/2022 03:16:59 - INFO - __main__ -   Text: ['\"Flax\\'s Labs\" is the correct answer.']\n",
      "06/29/2022 03:17:00 - INFO - __main__ -   Epoch: 60 | Batch: 1200/10001 (12%) | G Loss: 1.873698 | C Loss: -0.814150\n",
      "06/29/2022 03:17:00 - INFO - __main__ -   Text: ['Lucifer is loud!']\n",
      "06/29/2022 03:17:01 - INFO - __main__ -   Epoch: 60 | Batch: 1800/10001 (18%) | G Loss: 2.318256 | C Loss: -0.767556\n",
      "06/29/2022 03:17:01 - INFO - __main__ -   Text: ['Letters are clearly about romance\".']\n",
      "06/29/2022 03:17:02 - INFO - __main__ -   Epoch: 60 | Batch: 2400/10001 (24%) | G Loss: 1.824108 | C Loss: -1.112507\n",
      "06/29/2022 03:17:02 - INFO - __main__ -   Text: ['Celsius really relies on chaos.']\n",
      "06/29/2022 03:17:03 - INFO - __main__ -   Epoch: 60 | Batch: 3000/10001 (30%) | G Loss: 1.980560 | C Loss: -1.011928\n",
      "06/29/2022 03:17:03 - INFO - __main__ -   Text: ['As automation tends to turn out to be a big help later.']\n",
      "06/29/2022 03:17:04 - INFO - __main__ -   Epoch: 60 | Batch: 3600/10001 (36%) | G Loss: 2.442402 | C Loss: -1.129723\n",
      "06/29/2022 03:17:04 - INFO - __main__ -   Text: ['There is a way I sing Sunflower Home.']\n",
      "06/29/2022 03:17:05 - INFO - __main__ -   Epoch: 60 | Batch: 4200/10001 (42%) | G Loss: 1.785329 | C Loss: -0.895790\n",
      "06/29/2022 03:17:05 - INFO - __main__ -   Text: ['Cosby has been featured in \"The Oprah Winfrey Show\".']\n",
      "06/29/2022 03:17:06 - INFO - __main__ -   Epoch: 60 | Batch: 4800/10001 (48%) | G Loss: 2.400872 | C Loss: -0.930452\n",
      "06/29/2022 03:17:06 - INFO - __main__ -   Text: ['On computers we become very interested in the biotechnology of information technology.']\n",
      "06/29/2022 03:17:07 - INFO - __main__ -   Epoch: 60 | Batch: 5400/10001 (54%) | G Loss: 2.954839 | C Loss: -1.167043\n",
      "06/29/2022 03:17:07 - INFO - __main__ -   Text: ['\"Burberry Bomber\".']\n",
      "06/29/2022 03:17:08 - INFO - __main__ -   Epoch: 60 | Batch: 6000/10001 (60%) | G Loss: 1.941314 | C Loss: -0.997953\n",
      "06/29/2022 03:17:08 - INFO - __main__ -   Text: ['It plays people down, rather than protect them’s.']\n",
      "06/29/2022 03:17:09 - INFO - __main__ -   Epoch: 60 | Batch: 6600/10001 (66%) | G Loss: 1.901520 | C Loss: -1.111208\n",
      "06/29/2022 03:17:10 - INFO - __main__ -   Text: ['About 125 cars can be traced through its Web page, the way to looking at it.']\n",
      "06/29/2022 03:17:10 - INFO - __main__ -   Epoch: 60 | Batch: 7200/10001 (72%) | G Loss: 2.151877 | C Loss: -0.886093\n",
      "06/29/2022 03:17:11 - INFO - __main__ -   Text: ['Creda is very fast plants.']\n",
      "06/29/2022 03:17:12 - INFO - __main__ -   Epoch: 60 | Batch: 7800/10001 (78%) | G Loss: 2.293535 | C Loss: -1.073354\n",
      "06/29/2022 03:17:12 - INFO - __main__ -   Text: ['Amesha shows affection in a Naze.']\n",
      "06/29/2022 03:17:13 - INFO - __main__ -   Epoch: 60 | Batch: 8400/10001 (84%) | G Loss: 2.389285 | C Loss: -1.054068\n",
      "06/29/2022 03:17:13 - INFO - __main__ -   Text: ['For example, \"invariant variables\" is equivalent to \"invariant variables.\"']\n",
      "06/29/2022 03:17:14 - INFO - __main__ -   Epoch: 60 | Batch: 9000/10001 (90%) | G Loss: 2.211555 | C Loss: -0.938987\n",
      "06/29/2022 03:17:14 - INFO - __main__ -   Text: [\"Except for pleasure, he won't make a mistake.\"]\n",
      "06/29/2022 03:17:15 - INFO - __main__ -   Epoch: 60 | Batch: 9600/10001 (96%) | G Loss: 2.228131 | C Loss: -0.877940\n",
      "06/29/2022 03:17:15 - INFO - __main__ -   Text: ['is a good spin and it develops quite a rapport.']\n",
      "06/29/2022 03:17:16 - INFO - __main__ -   * (Train) Epoch: 60 | G Loss: 2.1880 | C Loss: -0.9788 | Updates G: 112 | Updates C: 721\n",
      "06/29/2022 03:17:24 - INFO - __main__ -   Bleu-2:0.206 | B-Bleu-2:0.252\n",
      "06/29/2022 03:17:24 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45828440575203006\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 61 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:15.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:49.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:06.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:03:22\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:20:46 - INFO - __main__ -   Epoch: 61 | Batch: 0/10001 (0%) | G Loss: 2.498895 | C Loss: -0.791354\n",
      "06/29/2022 03:20:47 - INFO - __main__ -   Text: ['The sound of the telephone is from Cleveland\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.482\n",
      "  Test Loss: 3.718\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:20:48 - INFO - __main__ -   Epoch: 61 | Batch: 600/10001 (6%) | G Loss: 2.265436 | C Loss: -1.019167\n",
      "06/29/2022 03:20:48 - INFO - __main__ -   Text: ['Chastity and marriage are \"Just Words\".']\n",
      "06/29/2022 03:20:49 - INFO - __main__ -   Epoch: 61 | Batch: 1200/10001 (12%) | G Loss: 2.482180 | C Loss: -1.145782\n",
      "06/29/2022 03:20:49 - INFO - __main__ -   Text: ['You can bet and discover a great deal.']\n",
      "06/29/2022 03:20:50 - INFO - __main__ -   Epoch: 61 | Batch: 1800/10001 (18%) | G Loss: 2.373064 | C Loss: -0.848895\n",
      "06/29/2022 03:20:50 - INFO - __main__ -   Text: ['Onr) I see responsibility for these designs [in a] future table.\"']\n",
      "06/29/2022 03:20:51 - INFO - __main__ -   Epoch: 61 | Batch: 2400/10001 (24%) | G Loss: 2.431782 | C Loss: -1.099775\n",
      "06/29/2022 03:20:51 - INFO - __main__ -   Text: [\"Bleeding arewolves don't serve him well outside the military sphere.\"]\n",
      "06/29/2022 03:20:52 - INFO - __main__ -   Epoch: 61 | Batch: 3000/10001 (30%) | G Loss: 2.101029 | C Loss: -0.989073\n",
      "06/29/2022 03:20:52 - INFO - __main__ -   Text: ['Each book turns on a old favourite tune Today cards are for girls.']\n",
      "06/29/2022 03:20:53 - INFO - __main__ -   Epoch: 61 | Batch: 3600/10001 (36%) | G Loss: 2.369612 | C Loss: -0.985107\n",
      "06/29/2022 03:20:53 - INFO - __main__ -   Text: ['Drinks too much.\"']\n",
      "06/29/2022 03:20:54 - INFO - __main__ -   Epoch: 61 | Batch: 4200/10001 (42%) | G Loss: 2.196249 | C Loss: -1.097477\n",
      "06/29/2022 03:20:54 - INFO - __main__ -   Text: ['Alinsky now Crimes Against Nature.']\n",
      "06/29/2022 03:20:55 - INFO - __main__ -   Epoch: 61 | Batch: 4800/10001 (48%) | G Loss: 2.437120 | C Loss: -1.056327\n",
      "06/29/2022 03:20:55 - INFO - __main__ -   Text: ['It goes without saying that the Spanish singer is very credible.']\n",
      "06/29/2022 03:20:56 - INFO - __main__ -   Epoch: 61 | Batch: 5400/10001 (54%) | G Loss: 2.625312 | C Loss: -0.811117\n",
      "06/29/2022 03:20:56 - INFO - __main__ -   Text: ['This is one way that Caitlin Should Try to explain that \"tai chi can\\'t fail\" is nonsense.']\n",
      "06/29/2022 03:20:57 - INFO - __main__ -   Epoch: 61 | Batch: 6000/10001 (60%) | G Loss: 2.647124 | C Loss: -1.023604\n",
      "06/29/2022 03:20:57 - INFO - __main__ -   Text: ['Her eggs are yellow and needles are green.']\n",
      "06/29/2022 03:20:58 - INFO - __main__ -   Epoch: 61 | Batch: 6600/10001 (66%) | G Loss: 2.293998 | C Loss: -0.914040\n",
      "06/29/2022 03:20:58 - INFO - __main__ -   Text: ['Models can talk to each other and communicate as strings.']\n",
      "06/29/2022 03:20:59 - INFO - __main__ -   Epoch: 61 | Batch: 7200/10001 (72%) | G Loss: 1.975528 | C Loss: -0.913618\n",
      "06/29/2022 03:21:00 - INFO - __main__ -   Text: ['This is used to provide size restriction on \"invalid Vu.\"']\n",
      "06/29/2022 03:21:01 - INFO - __main__ -   Epoch: 61 | Batch: 7800/10001 (78%) | G Loss: 2.505611 | C Loss: -1.047508\n",
      "06/29/2022 03:21:01 - INFO - __main__ -   Text: ['Also, fazdata offers support for communication problems book checker.']\n",
      "06/29/2022 03:21:02 - INFO - __main__ -   Epoch: 61 | Batch: 8400/10001 (84%) | G Loss: 3.255921 | C Loss: -1.092990\n",
      "06/29/2022 03:21:02 - INFO - __main__ -   Text: ['Mechanical both basically and just exactly .']\n",
      "06/29/2022 03:21:03 - INFO - __main__ -   Epoch: 61 | Batch: 9000/10001 (90%) | G Loss: 2.198486 | C Loss: -0.872068\n",
      "06/29/2022 03:21:03 - INFO - __main__ -   Text: ['This methodology is proven and enforceable.']\n",
      "06/29/2022 03:21:04 - INFO - __main__ -   Epoch: 61 | Batch: 9600/10001 (96%) | G Loss: 2.313420 | C Loss: -1.068062\n",
      "06/29/2022 03:21:04 - INFO - __main__ -   Text: ['liberates heat.']\n",
      "06/29/2022 03:21:04 - INFO - __main__ -   * (Train) Epoch: 61 | G Loss: 2.3112 | C Loss: -0.9929 | Updates G: 96 | Updates C: 737\n",
      "06/29/2022 03:21:13 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.232\n",
      "06/29/2022 03:21:13 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43928652909552385\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 62 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:24:42 - INFO - __main__ -   Epoch: 62 | Batch: 0/10001 (0%) | G Loss: 2.385708 | C Loss: -0.797949\n",
      "06/29/2022 03:24:42 - INFO - __main__ -   Text: ['Animated TV with Fallen Skies Animation.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 3.708\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:24:43 - INFO - __main__ -   Epoch: 62 | Batch: 600/10001 (6%) | G Loss: 2.273874 | C Loss: -1.054786\n",
      "06/29/2022 03:24:43 - INFO - __main__ -   Text: ['Vertical prediction (using vector notation) is time prediction.']\n",
      "06/29/2022 03:24:44 - INFO - __main__ -   Epoch: 62 | Batch: 1200/10001 (12%) | G Loss: 2.732728 | C Loss: -0.823368\n",
      "06/29/2022 03:24:44 - INFO - __main__ -   Text: ['This educational option is a very significant advantage in China.']\n",
      "06/29/2022 03:24:45 - INFO - __main__ -   Epoch: 62 | Batch: 1800/10001 (18%) | G Loss: 1.939004 | C Loss: -1.081254\n",
      "06/29/2022 03:24:45 - INFO - __main__ -   Text: ['Pacian fantasy is sometimes referred to.']\n",
      "06/29/2022 03:24:46 - INFO - __main__ -   Epoch: 62 | Batch: 2400/10001 (24%) | G Loss: 2.522392 | C Loss: -1.194613\n",
      "06/29/2022 03:24:46 - INFO - __main__ -   Text: [\"Familiar am?'\"]\n",
      "06/29/2022 03:24:47 - INFO - __main__ -   Epoch: 62 | Batch: 3000/10001 (30%) | G Loss: 2.638362 | C Loss: -1.022023\n",
      "06/29/2022 03:24:47 - INFO - __main__ -   Text: ['\", causes them to perceive the avert.']\n",
      "06/29/2022 03:24:48 - INFO - __main__ -   Epoch: 62 | Batch: 3600/10001 (36%) | G Loss: 2.218299 | C Loss: -1.140354\n",
      "06/29/2022 03:24:49 - INFO - __main__ -   Text: [\"It is anybody's guess who Will Will Will Preside at this time.\"]\n",
      "06/29/2022 03:24:49 - INFO - __main__ -   Epoch: 62 | Batch: 4200/10001 (42%) | G Loss: 2.251842 | C Loss: -1.078937\n",
      "06/29/2022 03:24:50 - INFO - __main__ -   Text: ['The Crush Network CS Championship.']\n",
      "06/29/2022 03:24:51 - INFO - __main__ -   Epoch: 62 | Batch: 4800/10001 (48%) | G Loss: 2.617064 | C Loss: -0.866068\n",
      "06/29/2022 03:24:51 - INFO - __main__ -   Text: ['He won the world championship in a dozen nations.']\n",
      "06/29/2022 03:24:52 - INFO - __main__ -   Epoch: 62 | Batch: 5400/10001 (54%) | G Loss: 2.477424 | C Loss: -0.893392\n",
      "06/29/2022 03:24:52 - INFO - __main__ -   Text: ['Serial 12xx123\".']\n",
      "06/29/2022 03:24:53 - INFO - __main__ -   Epoch: 62 | Batch: 6000/10001 (60%) | G Loss: 2.170109 | C Loss: -1.160076\n",
      "06/29/2022 03:24:53 - INFO - __main__ -   Text: ['Humans ask for their mind.']\n",
      "06/29/2022 03:24:54 - INFO - __main__ -   Epoch: 62 | Batch: 6600/10001 (66%) | G Loss: 2.670698 | C Loss: -1.109178\n",
      "06/29/2022 03:24:54 - INFO - __main__ -   Text: ['She may divorce or just give up working.']\n",
      "06/29/2022 03:24:55 - INFO - __main__ -   Epoch: 62 | Batch: 7200/10001 (72%) | G Loss: 1.996728 | C Loss: -0.855398\n",
      "06/29/2022 03:24:55 - INFO - __main__ -   Text: ['\"Go Crazy!\"']\n",
      "06/29/2022 03:24:56 - INFO - __main__ -   Epoch: 62 | Batch: 7800/10001 (78%) | G Loss: 2.570067 | C Loss: -1.007472\n",
      "06/29/2022 03:24:56 - INFO - __main__ -   Text: ['Animal Extractor : The hard tracking tool.']\n",
      "06/29/2022 03:24:57 - INFO - __main__ -   Epoch: 62 | Batch: 8400/10001 (84%) | G Loss: 2.538990 | C Loss: -0.852278\n",
      "06/29/2022 03:24:57 - INFO - __main__ -   Text: ['The book is written and recorded for use on self-ridges.']\n",
      "06/29/2022 03:24:58 - INFO - __main__ -   Epoch: 62 | Batch: 9000/10001 (90%) | G Loss: 2.274628 | C Loss: -1.095105\n",
      "06/29/2022 03:24:58 - INFO - __main__ -   Text: ['Not even close any further, and Jesus can hear you now.']\n",
      "06/29/2022 03:24:59 - INFO - __main__ -   Epoch: 62 | Batch: 9600/10001 (96%) | G Loss: 2.736969 | C Loss: -0.979742\n",
      "06/29/2022 03:24:59 - INFO - __main__ -   Text: [\"Confcius's probably not going to boom boom.\"]\n",
      "06/29/2022 03:25:00 - INFO - __main__ -   * (Train) Epoch: 62 | G Loss: 2.4436 | C Loss: -0.9878 | Updates G: 100 | Updates C: 733\n",
      "06/29/2022 03:25:09 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.238\n",
      "06/29/2022 03:25:09 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43748862316917486\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 63 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:28:39 - INFO - __main__ -   Epoch: 63 | Batch: 0/10000 (0%) | G Loss: 2.588953 | C Loss: -0.879283\n",
      "06/29/2022 03:28:39 - INFO - __main__ -   Text: ['The force is to generate strongly selected facts.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.477\n",
      "  Test Loss: 3.727\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:28:40 - INFO - __main__ -   Epoch: 63 | Batch: 600/10000 (6%) | G Loss: 2.030282 | C Loss: -0.821893\n",
      "06/29/2022 03:28:40 - INFO - __main__ -   Text: ['(And/y): Extendence .']\n",
      "06/29/2022 03:28:41 - INFO - __main__ -   Epoch: 63 | Batch: 1200/10000 (12%) | G Loss: 2.614997 | C Loss: -0.907736\n",
      "06/29/2022 03:28:41 - INFO - __main__ -   Text: [\"Light Bulb ('36').\"]\n",
      "06/29/2022 03:28:42 - INFO - __main__ -   Epoch: 63 | Batch: 1800/10000 (18%) | G Loss: 2.681040 | C Loss: -0.997128\n",
      "06/29/2022 03:28:42 - INFO - __main__ -   Text: ['Kurfossa borrows morphology.']\n",
      "06/29/2022 03:28:43 - INFO - __main__ -   Epoch: 63 | Batch: 2400/10000 (24%) | G Loss: 2.272039 | C Loss: -1.001153\n",
      "06/29/2022 03:28:43 - INFO - __main__ -   Text: ['A unique one.']\n",
      "06/29/2022 03:28:44 - INFO - __main__ -   Epoch: 63 | Batch: 3000/10000 (30%) | G Loss: 2.570999 | C Loss: -1.037766\n",
      "06/29/2022 03:28:44 - INFO - __main__ -   Text: ['Both are dead.']\n",
      "06/29/2022 03:28:45 - INFO - __main__ -   Epoch: 63 | Batch: 3600/10000 (36%) | G Loss: 2.386231 | C Loss: -0.868040\n",
      "06/29/2022 03:28:45 - INFO - __main__ -   Text: ['Redout has no skill.']\n",
      "06/29/2022 03:28:46 - INFO - __main__ -   Epoch: 63 | Batch: 4200/10000 (42%) | G Loss: 2.704793 | C Loss: -1.028347\n",
      "06/29/2022 03:28:46 - INFO - __main__ -   Text: ['A seed does not work as anticipated by Slings of Vid.']\n",
      "06/29/2022 03:28:47 - INFO - __main__ -   Epoch: 63 | Batch: 4800/10000 (48%) | G Loss: 2.501832 | C Loss: -0.933599\n",
      "06/29/2022 03:28:47 - INFO - __main__ -   Text: ['All people who subscribe to talk radio program will be.']\n",
      "06/29/2022 03:28:48 - INFO - __main__ -   Epoch: 63 | Batch: 5400/10000 (54%) | G Loss: 2.555944 | C Loss: -0.981702\n",
      "06/29/2022 03:28:48 - INFO - __main__ -   Text: ['They claim divine humulae through the symbols of Yazoo.']\n",
      "06/29/2022 03:28:49 - INFO - __main__ -   Epoch: 63 | Batch: 6000/10000 (60%) | G Loss: 2.403470 | C Loss: -0.967368\n",
      "06/29/2022 03:28:49 - INFO - __main__ -   Text: ['There are stories of Saini from this period, who have hailed from as far as the present day.']\n",
      "06/29/2022 03:28:50 - INFO - __main__ -   Epoch: 63 | Batch: 6600/10000 (66%) | G Loss: 2.561327 | C Loss: -0.936751\n",
      "06/29/2022 03:28:50 - INFO - __main__ -   Text: [\"It's a forum where girls can be different.\"]\n",
      "06/29/2022 03:28:51 - INFO - __main__ -   Epoch: 63 | Batch: 7200/10000 (72%) | G Loss: 2.346215 | C Loss: -0.974501\n",
      "06/29/2022 03:28:51 - INFO - __main__ -   Text: ['soaktip!']\n",
      "06/29/2022 03:28:52 - INFO - __main__ -   Epoch: 63 | Batch: 7800/10000 (78%) | G Loss: 2.815071 | C Loss: -0.963788\n",
      "06/29/2022 03:28:53 - INFO - __main__ -   Text: ['Nothing else depends on chance for repeated nouns.']\n",
      "06/29/2022 03:28:54 - INFO - __main__ -   Epoch: 63 | Batch: 8400/10000 (84%) | G Loss: 2.649498 | C Loss: -0.859637\n",
      "06/29/2022 03:28:54 - INFO - __main__ -   Text: ['Their is a waste.']\n",
      "06/29/2022 03:28:55 - INFO - __main__ -   Epoch: 63 | Batch: 9000/10000 (90%) | G Loss: 2.338556 | C Loss: -0.898785\n",
      "06/29/2022 03:28:55 - INFO - __main__ -   Text: ['All other humans [usually] Iolander\".']\n",
      "06/29/2022 03:28:56 - INFO - __main__ -   Epoch: 63 | Batch: 9600/10000 (96%) | G Loss: 2.292161 | C Loss: -0.989002\n",
      "06/29/2022 03:28:56 - INFO - __main__ -   Text: ['Ian just might not be the world stopped valley/section 9 and he\\'s like, \"Nah one, he']\n",
      "06/29/2022 03:28:56 - INFO - __main__ -   * (Train) Epoch: 63 | G Loss: 2.4406 | C Loss: -0.9889 | Updates G: 95 | Updates C: 738\n",
      "06/29/2022 03:29:06 - INFO - __main__ -   Bleu-2:0.192 | B-Bleu-2:0.253\n",
      "06/29/2022 03:29:06 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44493410613111195\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 64 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:32:39 - INFO - __main__ -   Epoch: 64 | Batch: 0/10000 (0%) | G Loss: 2.671997 | C Loss: -0.955636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.487\n",
      "  Test Loss: 3.744\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:32:39 - INFO - __main__ -   Text: ['Being just a nature example, the greater our intelligence we should be able to do more difficult.']\n",
      "06/29/2022 03:32:40 - INFO - __main__ -   Epoch: 64 | Batch: 600/10000 (6%) | G Loss: 2.741344 | C Loss: -0.916635\n",
      "06/29/2022 03:32:40 - INFO - __main__ -   Text: ['These scam artists tend to be ingested without warning.\"']\n",
      "06/29/2022 03:32:41 - INFO - __main__ -   Epoch: 64 | Batch: 1200/10000 (12%) | G Loss: 2.256888 | C Loss: -0.895769\n",
      "06/29/2022 03:32:41 - INFO - __main__ -   Text: ['Yahweh is a supporter.']\n",
      "06/29/2022 03:32:42 - INFO - __main__ -   Epoch: 64 | Batch: 1800/10000 (18%) | G Loss: 2.331215 | C Loss: -0.873690\n",
      "06/29/2022 03:32:42 - INFO - __main__ -   Text: ['Racism and disease are instead common.']\n",
      "06/29/2022 03:32:43 - INFO - __main__ -   Epoch: 64 | Batch: 2400/10000 (24%) | G Loss: 2.829093 | C Loss: -1.285622\n",
      "06/29/2022 03:32:43 - INFO - __main__ -   Text: ['For this, this is probably 5K DVD \"Dead anywhere at 80K\".']\n",
      "06/29/2022 03:32:44 - INFO - __main__ -   Epoch: 64 | Batch: 3000/10000 (30%) | G Loss: 2.970869 | C Loss: -0.961895\n",
      "06/29/2022 03:32:45 - INFO - __main__ -   Text: ['In the bottom right of the list of ship\"s punctuation\".']\n",
      "06/29/2022 03:32:46 - INFO - __main__ -   Epoch: 64 | Batch: 3600/10000 (36%) | G Loss: 2.459280 | C Loss: -1.121232\n",
      "06/29/2022 03:32:46 - INFO - __main__ -   Text: ['\"It\\'s Your List\".']\n",
      "06/29/2022 03:32:47 - INFO - __main__ -   Epoch: 64 | Batch: 4200/10000 (42%) | G Loss: 2.446894 | C Loss: -1.080482\n",
      "06/29/2022 03:32:47 - INFO - __main__ -   Text: [\"He's a physical freak, if not master of class.\"]\n",
      "06/29/2022 03:32:48 - INFO - __main__ -   Epoch: 64 | Batch: 4800/10000 (48%) | G Loss: 2.532209 | C Loss: -1.007336\n",
      "06/29/2022 03:32:48 - INFO - __main__ -   Text: [\"This can be children's song, but there is a remedy for country music.\"]\n",
      "06/29/2022 03:32:49 - INFO - __main__ -   Epoch: 64 | Batch: 5400/10000 (54%) | G Loss: 2.496535 | C Loss: -1.467938\n",
      "06/29/2022 03:32:49 - INFO - __main__ -   Text: ['It\\'s about rehearsing your steps and stories.\"']\n",
      "06/29/2022 03:32:50 - INFO - __main__ -   Epoch: 64 | Batch: 6000/10000 (60%) | G Loss: 2.412584 | C Loss: -0.899517\n",
      "06/29/2022 03:32:50 - INFO - __main__ -   Text: ['* Marathis!']\n",
      "06/29/2022 03:32:51 - INFO - __main__ -   Epoch: 64 | Batch: 6600/10000 (66%) | G Loss: 2.504532 | C Loss: -1.045313\n",
      "06/29/2022 03:32:51 - INFO - __main__ -   Text: ['Even \"imaginable (van)|s\".']\n",
      "06/29/2022 03:32:52 - INFO - __main__ -   Epoch: 64 | Batch: 7200/10000 (72%) | G Loss: 2.828465 | C Loss: -1.079703\n",
      "06/29/2022 03:32:52 - INFO - __main__ -   Text: ['These readings can be part of a structured investigation.']\n",
      "06/29/2022 03:32:53 - INFO - __main__ -   Epoch: 64 | Batch: 7800/10000 (78%) | G Loss: 2.195578 | C Loss: -0.905288\n",
      "06/29/2022 03:32:53 - INFO - __main__ -   Text: ['James is often criticized in many ways, including at KLAS and at MediaHour.']\n",
      "06/29/2022 03:32:54 - INFO - __main__ -   Epoch: 64 | Batch: 8400/10000 (84%) | G Loss: 2.563513 | C Loss: -1.020755\n",
      "06/29/2022 03:32:54 - INFO - __main__ -   Text: ['She considers herself to be the most popular intermediate runner in the world.']\n",
      "06/29/2022 03:32:55 - INFO - __main__ -   Epoch: 64 | Batch: 9000/10000 (90%) | G Loss: 2.497743 | C Loss: -0.866008\n",
      "06/29/2022 03:32:55 - INFO - __main__ -   Text: ['Sometimes it is not very good.']\n",
      "06/29/2022 03:32:56 - INFO - __main__ -   Epoch: 64 | Batch: 9600/10000 (96%) | G Loss: 2.294402 | C Loss: -0.919993\n",
      "06/29/2022 03:32:56 - INFO - __main__ -   Text: ['The result is essentially that language theory is correct to the exponentiation of Bhkit.']\n",
      "06/29/2022 03:32:57 - INFO - __main__ -   * (Train) Epoch: 64 | G Loss: 2.4329 | C Loss: -0.9964 | Updates G: 81 | Updates C: 752\n",
      "06/29/2022 03:33:06 - INFO - __main__ -   Bleu-2:0.203 | B-Bleu-2:0.238\n",
      "06/29/2022 03:33:06 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4407637969225108\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 65 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:23.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:39.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:55.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:13.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:29.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:46.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:03.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:36:26 - INFO - __main__ -   Epoch: 65 | Batch: 0/10001 (0%) | G Loss: 2.510125 | C Loss: -1.116516\n",
      "06/29/2022 03:36:26 - INFO - __main__ -   Text: ['The channels numbers are \"x 10\" on every Mach3 web page.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.482\n",
      "  Test Loss: 3.787\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:36:27 - INFO - __main__ -   Epoch: 65 | Batch: 600/10001 (6%) | G Loss: 2.605709 | C Loss: -1.143359\n",
      "06/29/2022 03:36:27 - INFO - __main__ -   Text: ['The Super Desk is dedicated to them.']\n",
      "06/29/2022 03:36:28 - INFO - __main__ -   Epoch: 65 | Batch: 1200/10001 (12%) | G Loss: 2.502705 | C Loss: -0.971399\n",
      "06/29/2022 03:36:28 - INFO - __main__ -   Text: ['Like the insular melodrama, this style of thinking can broaden.']\n",
      "06/29/2022 03:36:29 - INFO - __main__ -   Epoch: 65 | Batch: 1800/10001 (18%) | G Loss: 2.413670 | C Loss: -0.998179\n",
      "06/29/2022 03:36:29 - INFO - __main__ -   Text: ['Spear can only speak 4 words.']\n",
      "06/29/2022 03:36:30 - INFO - __main__ -   Epoch: 65 | Batch: 2400/10001 (24%) | G Loss: 2.706179 | C Loss: -1.057211\n",
      "06/29/2022 03:36:30 - INFO - __main__ -   Text: [\"Don't know why on the next day that's it.\"]\n",
      "06/29/2022 03:36:31 - INFO - __main__ -   Epoch: 65 | Batch: 3000/10001 (30%) | G Loss: 2.516302 | C Loss: -0.961313\n",
      "06/29/2022 03:36:31 - INFO - __main__ -   Text: ['From the inward attitude towards the Other in family art.']\n",
      "06/29/2022 03:36:32 - INFO - __main__ -   Epoch: 65 | Batch: 3600/10001 (36%) | G Loss: 2.427453 | C Loss: -0.932941\n",
      "06/29/2022 03:36:32 - INFO - __main__ -   Text: ['Unable to transmit Eta-Tide, the mother is forced to convert oral sex into oral sex.']\n",
      "06/29/2022 03:36:33 - INFO - __main__ -   Epoch: 65 | Batch: 4200/10001 (42%) | G Loss: 2.370939 | C Loss: -0.928336\n",
      "06/29/2022 03:36:33 - INFO - __main__ -   Text: [\"Today 'Aqora & Na'at.\"]\n",
      "06/29/2022 03:36:34 - INFO - __main__ -   Epoch: 65 | Batch: 4800/10001 (48%) | G Loss: 2.652460 | C Loss: -1.058250\n",
      "06/29/2022 03:36:34 - INFO - __main__ -   Text: ['This movement feels pretty different from the flow of time.']\n",
      "06/29/2022 03:36:35 - INFO - __main__ -   Epoch: 65 | Batch: 5400/10001 (54%) | G Loss: 2.282147 | C Loss: -0.912239\n",
      "06/29/2022 03:36:35 - INFO - __main__ -   Text: ['Premises Day provides a more advanced \"\" >> www.premises.']\n",
      "06/29/2022 03:36:36 - INFO - __main__ -   Epoch: 65 | Batch: 6000/10001 (60%) | G Loss: 2.264092 | C Loss: -1.054748\n",
      "06/29/2022 03:36:37 - INFO - __main__ -   Text: ['Trophy has many other names like \"Crottian Bucket Battle\".']\n",
      "06/29/2022 03:36:38 - INFO - __main__ -   Epoch: 65 | Batch: 6600/10001 (66%) | G Loss: 2.554592 | C Loss: -0.877135\n",
      "06/29/2022 03:36:38 - INFO - __main__ -   Text: ['Writing over 10 books']\n",
      "06/29/2022 03:36:39 - INFO - __main__ -   Epoch: 65 | Batch: 7200/10001 (72%) | G Loss: 2.151126 | C Loss: -1.015236\n",
      "06/29/2022 03:36:39 - INFO - __main__ -   Text: ['It is a question-end special election for the First Congress.']\n",
      "06/29/2022 03:36:40 - INFO - __main__ -   Epoch: 65 | Batch: 7800/10001 (78%) | G Loss: 2.754232 | C Loss: -0.934326\n",
      "06/29/2022 03:36:40 - INFO - __main__ -   Text: ['Even though he genuinely opposed religion.\"']\n",
      "06/29/2022 03:36:41 - INFO - __main__ -   Epoch: 65 | Batch: 8400/10001 (84%) | G Loss: 2.535573 | C Loss: -0.977386\n",
      "06/29/2022 03:36:41 - INFO - __main__ -   Text: ['These words, \"gift\" and \"dance,\" are simply pronounced \"moor.\"']\n",
      "06/29/2022 03:36:42 - INFO - __main__ -   Epoch: 65 | Batch: 9000/10001 (90%) | G Loss: 2.475236 | C Loss: -1.031372\n",
      "06/29/2022 03:36:42 - INFO - __main__ -   Text: ['Acting to the tune of McConkie 50%.']\n",
      "06/29/2022 03:36:43 - INFO - __main__ -   Epoch: 65 | Batch: 9600/10001 (96%) | G Loss: 2.278272 | C Loss: -1.182706\n",
      "06/29/2022 03:36:43 - INFO - __main__ -   Text: ['For example, Alexa preps are formula formulaists.']\n",
      "06/29/2022 03:36:44 - INFO - __main__ -   * (Train) Epoch: 65 | G Loss: 2.4214 | C Loss: -0.9775 | Updates G: 84 | Updates C: 749\n",
      "06/29/2022 03:36:53 - INFO - __main__ -   Bleu-2:0.201 | B-Bleu-2:0.269\n",
      "06/29/2022 03:36:53 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4694584857572065\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 66 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:00.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:19.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:40:29 - INFO - __main__ -   Epoch: 66 | Batch: 0/10001 (0%) | G Loss: 2.206759 | C Loss: -0.981591\n",
      "06/29/2022 03:40:29 - INFO - __main__ -   Text: [\"He's very tearful about it, how he can have most of the watching.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.824\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:40:30 - INFO - __main__ -   Epoch: 66 | Batch: 600/10001 (6%) | G Loss: 2.738818 | C Loss: -1.211369\n",
      "06/29/2022 03:40:30 - INFO - __main__ -   Text: ['It\\'s slightly violent!\"']\n",
      "06/29/2022 03:40:31 - INFO - __main__ -   Epoch: 66 | Batch: 1200/10001 (12%) | G Loss: 2.376078 | C Loss: -0.911085\n",
      "06/29/2022 03:40:31 - INFO - __main__ -   Text: ['This program is popular among models.\"']\n",
      "06/29/2022 03:40:32 - INFO - __main__ -   Epoch: 66 | Batch: 1800/10001 (18%) | G Loss: 2.144657 | C Loss: -1.096491\n",
      "06/29/2022 03:40:32 - INFO - __main__ -   Text: ['Droid is aware of this trait.']\n",
      "06/29/2022 03:40:33 - INFO - __main__ -   Epoch: 66 | Batch: 2400/10001 (24%) | G Loss: 2.487104 | C Loss: -0.804614\n",
      "06/29/2022 03:40:33 - INFO - __main__ -   Text: ['These kids are ready ... at the first sight of earth\".']\n",
      "06/29/2022 03:40:34 - INFO - __main__ -   Epoch: 66 | Batch: 3000/10001 (30%) | G Loss: 2.925117 | C Loss: -0.841197\n",
      "06/29/2022 03:40:34 - INFO - __main__ -   Text: ['A good recipe is \"Dictionary.\"']\n",
      "06/29/2022 03:40:35 - INFO - __main__ -   Epoch: 66 | Batch: 3600/10001 (36%) | G Loss: 2.255937 | C Loss: -1.018659\n",
      "06/29/2022 03:40:36 - INFO - __main__ -   Text: ['It\\'s not the high-wine where everybody\\'s sweet.\"']\n",
      "06/29/2022 03:40:36 - INFO - __main__ -   Epoch: 66 | Batch: 4200/10001 (42%) | G Loss: 2.426059 | C Loss: -1.065270\n",
      "06/29/2022 03:40:37 - INFO - __main__ -   Text: [\"He prefers to bait the bog's big flail.\"]\n",
      "06/29/2022 03:40:38 - INFO - __main__ -   Epoch: 66 | Batch: 4800/10001 (48%) | G Loss: 2.556941 | C Loss: -1.333599\n",
      "06/29/2022 03:40:38 - INFO - __main__ -   Text: ['1 .']\n",
      "06/29/2022 03:40:39 - INFO - __main__ -   Epoch: 66 | Batch: 5400/10001 (54%) | G Loss: 2.166383 | C Loss: -0.990188\n",
      "06/29/2022 03:40:39 - INFO - __main__ -   Text: ['Ichiro has one of the best defense routines, which is good for the joker.']\n",
      "06/29/2022 03:40:40 - INFO - __main__ -   Epoch: 66 | Batch: 6000/10001 (60%) | G Loss: 2.219838 | C Loss: -0.956102\n",
      "06/29/2022 03:40:40 - INFO - __main__ -   Text: ['Dens Level Patrol.']\n",
      "06/29/2022 03:40:41 - INFO - __main__ -   Epoch: 66 | Batch: 6600/10001 (66%) | G Loss: 2.475148 | C Loss: -1.031193\n",
      "06/29/2022 03:40:41 - INFO - __main__ -   Text: ['Since it has Harley tag \"uholu\".']\n",
      "06/29/2022 03:40:42 - INFO - __main__ -   Epoch: 66 | Batch: 7200/10001 (72%) | G Loss: 2.720442 | C Loss: -0.934180\n",
      "06/29/2022 03:40:42 - INFO - __main__ -   Text: ['Also not exclusively western morning television, television is a family tradition of ceremonies.']\n",
      "06/29/2022 03:40:43 - INFO - __main__ -   Epoch: 66 | Batch: 7800/10001 (78%) | G Loss: 2.235353 | C Loss: -0.890302\n",
      "06/29/2022 03:40:43 - INFO - __main__ -   Text: ['It is said that in \"portfolio management IPINC insists\" your spouse has inherited the \"pyramid\".']\n",
      "06/29/2022 03:40:44 - INFO - __main__ -   Epoch: 66 | Batch: 8400/10001 (84%) | G Loss: 2.338229 | C Loss: -1.017471\n",
      "06/29/2022 03:40:44 - INFO - __main__ -   Text: ['Observational studies are used to justify decisions and food shortages.']\n",
      "06/29/2022 03:40:45 - INFO - __main__ -   Epoch: 66 | Batch: 9000/10001 (90%) | G Loss: 2.182306 | C Loss: -0.905416\n",
      "06/29/2022 03:40:45 - INFO - __main__ -   Text: ['Millionaire is much more complex to control than politician is.']\n",
      "06/29/2022 03:40:46 - INFO - __main__ -   Epoch: 66 | Batch: 9600/10001 (96%) | G Loss: 2.442394 | C Loss: -1.029946\n",
      "06/29/2022 03:40:46 - INFO - __main__ -   Text: ['It is a quote of the legendary Latin god.']\n",
      "06/29/2022 03:40:47 - INFO - __main__ -   * (Train) Epoch: 66 | G Loss: 2.3551 | C Loss: -0.9670 | Updates G: 102 | Updates C: 731\n",
      "06/29/2022 03:40:55 - INFO - __main__ -   Bleu-2:0.203 | B-Bleu-2:0.251\n",
      "06/29/2022 03:40:55 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45336951740639286\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 67 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:14.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:31.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:48.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:05.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:03:21\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:44:16 - INFO - __main__ -   Epoch: 67 | Batch: 0/10001 (0%) | G Loss: 2.639091 | C Loss: -0.885878\n",
      "06/29/2022 03:44:17 - INFO - __main__ -   Text: ['They say maybe to these kids, worthless.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 3.789\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:44:18 - INFO - __main__ -   Epoch: 67 | Batch: 600/10001 (6%) | G Loss: 2.943212 | C Loss: -1.070751\n",
      "06/29/2022 03:44:18 - INFO - __main__ -   Text: ['The Hebrew name for whacked and hungry is death.']\n",
      "06/29/2022 03:44:19 - INFO - __main__ -   Epoch: 67 | Batch: 1200/10001 (12%) | G Loss: 2.069670 | C Loss: -0.814044\n",
      "06/29/2022 03:44:19 - INFO - __main__ -   Text: ['Folks!']\n",
      "06/29/2022 03:44:20 - INFO - __main__ -   Epoch: 67 | Batch: 1800/10001 (18%) | G Loss: 2.692283 | C Loss: -0.839175\n",
      "06/29/2022 03:44:20 - INFO - __main__ -   Text: ['Because the name \"Ramsiate\" simply refers to a disease rather than another condition, this is alluded to in']\n",
      "06/29/2022 03:44:21 - INFO - __main__ -   Epoch: 67 | Batch: 2400/10001 (24%) | G Loss: 2.659589 | C Loss: -0.984001\n",
      "06/29/2022 03:44:21 - INFO - __main__ -   Text: ['In this direction it is determined that it is a future city.']\n",
      "06/29/2022 03:44:22 - INFO - __main__ -   Epoch: 67 | Batch: 3000/10001 (30%) | G Loss: 1.874888 | C Loss: -0.906130\n",
      "06/29/2022 03:44:22 - INFO - __main__ -   Text: ['Itpageupdates, the website is the most popular page on HSEI.']\n",
      "06/29/2022 03:44:23 - INFO - __main__ -   Epoch: 67 | Batch: 3600/10001 (36%) | G Loss: 1.839271 | C Loss: -0.973797\n",
      "06/29/2022 03:44:23 - INFO - __main__ -   Text: ['Kevin Pro has as few free sneakers to choose from.']\n",
      "06/29/2022 03:44:24 - INFO - __main__ -   Epoch: 67 | Batch: 4200/10001 (42%) | G Loss: 2.716863 | C Loss: -0.932300\n",
      "06/29/2022 03:44:24 - INFO - __main__ -   Text: ['Charlotte unfair in ...']\n",
      "06/29/2022 03:44:25 - INFO - __main__ -   Epoch: 67 | Batch: 4800/10001 (48%) | G Loss: 2.925143 | C Loss: -0.979559\n",
      "06/29/2022 03:44:25 - INFO - __main__ -   Text: [\"If you're reaching a certain level of popularity, you can trace that to Sunil as well.\"]\n",
      "06/29/2022 03:44:26 - INFO - __main__ -   Epoch: 67 | Batch: 5400/10001 (54%) | G Loss: 3.358950 | C Loss: -0.727814\n",
      "06/29/2022 03:44:26 - INFO - __main__ -   Text: ['The Master Keychain Cats!\"']\n",
      "06/29/2022 03:44:27 - INFO - __main__ -   Epoch: 67 | Batch: 6000/10001 (60%) | G Loss: 2.550781 | C Loss: -1.064434\n",
      "06/29/2022 03:44:27 - INFO - __main__ -   Text: ['A list of events that have spawned a book titled \"Heading Towards Destruction\".']\n",
      "06/29/2022 03:44:28 - INFO - __main__ -   Epoch: 67 | Batch: 6600/10001 (66%) | G Loss: 2.030923 | C Loss: -0.868065\n",
      "06/29/2022 03:44:29 - INFO - __main__ -   Text: ['\"[somander] Nihilism\".']\n",
      "06/29/2022 03:44:30 - INFO - __main__ -   Epoch: 67 | Batch: 7200/10001 (72%) | G Loss: 2.574208 | C Loss: -1.006633\n",
      "06/29/2022 03:44:30 - INFO - __main__ -   Text: ['You must fight six lies every day then make the bill payable\".']\n",
      "06/29/2022 03:44:31 - INFO - __main__ -   Epoch: 67 | Batch: 7800/10001 (78%) | G Loss: 2.789752 | C Loss: -0.898169\n",
      "06/29/2022 03:44:31 - INFO - __main__ -   Text: ['Making a tepid comedian.']\n",
      "06/29/2022 03:44:32 - INFO - __main__ -   Epoch: 67 | Batch: 8400/10001 (84%) | G Loss: 2.189681 | C Loss: -0.869464\n",
      "06/29/2022 03:44:32 - INFO - __main__ -   Text: ['It focuses on establishing a magical world upon it.']\n",
      "06/29/2022 03:44:33 - INFO - __main__ -   Epoch: 67 | Batch: 9000/10001 (90%) | G Loss: 2.288298 | C Loss: -0.883034\n",
      "06/29/2022 03:44:33 - INFO - __main__ -   Text: ['The goal here is to pull off an unstoppable force.']\n",
      "06/29/2022 03:44:34 - INFO - __main__ -   Epoch: 67 | Batch: 9600/10001 (96%) | G Loss: 2.315725 | C Loss: -0.968115\n",
      "06/29/2022 03:44:34 - INFO - __main__ -   Text: ['So Toge is like making a bird jump on a train.\"']\n",
      "06/29/2022 03:44:35 - INFO - __main__ -   * (Train) Epoch: 67 | G Loss: 2.3618 | C Loss: -0.9413 | Updates G: 77 | Updates C: 756\n",
      "06/29/2022 03:44:44 - INFO - __main__ -   Bleu-2:0.221 | B-Bleu-2:0.261\n",
      "06/29/2022 03:44:44 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4823318618824785\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 68 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.717\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:48:08 - INFO - __main__ -   Epoch: 68 | Batch: 0/10001 (0%) | G Loss: 2.903358 | C Loss: -0.888121\n",
      "06/29/2022 03:48:08 - INFO - __main__ -   Text: ['Mature pornography is often accessed through Facebook members.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 3.798\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:48:09 - INFO - __main__ -   Epoch: 68 | Batch: 600/10001 (6%) | G Loss: 2.288687 | C Loss: -0.764212\n",
      "06/29/2022 03:48:09 - INFO - __main__ -   Text: ['It is easier to be a prophet than a cousin.']\n",
      "06/29/2022 03:48:10 - INFO - __main__ -   Epoch: 68 | Batch: 1200/10001 (12%) | G Loss: 2.623610 | C Loss: -0.864907\n",
      "06/29/2022 03:48:10 - INFO - __main__ -   Text: ['Similar errors occur in it: Chiraq.']\n",
      "06/29/2022 03:48:11 - INFO - __main__ -   Epoch: 68 | Batch: 1800/10001 (18%) | G Loss: 2.775442 | C Loss: -1.025665\n",
      "06/29/2022 03:48:11 - INFO - __main__ -   Text: ['The amount of advice they give gets boring.\"']\n",
      "06/29/2022 03:48:12 - INFO - __main__ -   Epoch: 68 | Batch: 2400/10001 (24%) | G Loss: 2.273890 | C Loss: -0.954531\n",
      "06/29/2022 03:48:12 - INFO - __main__ -   Text: ['\"He has 37 home runs under his belt\" -it was tight.']\n",
      "06/29/2022 03:48:13 - INFO - __main__ -   Epoch: 68 | Batch: 3000/10001 (30%) | G Loss: 2.533691 | C Loss: -0.981414\n",
      "06/29/2022 03:48:13 - INFO - __main__ -   Text: ['Rockefeller never directly owns shareholder wealth.']\n",
      "06/29/2022 03:48:14 - INFO - __main__ -   Epoch: 68 | Batch: 3600/10001 (36%) | G Loss: 2.882164 | C Loss: -1.123397\n",
      "06/29/2022 03:48:14 - INFO - __main__ -   Text: ['The name is \"Yeesh!\"']\n",
      "06/29/2022 03:48:15 - INFO - __main__ -   Epoch: 68 | Batch: 4200/10001 (42%) | G Loss: 2.533035 | C Loss: -1.026416\n",
      "06/29/2022 03:48:15 - INFO - __main__ -   Text: ['Are We Dying Well?\"']\n",
      "06/29/2022 03:48:16 - INFO - __main__ -   Epoch: 68 | Batch: 4800/10001 (48%) | G Loss: 2.240145 | C Loss: -0.874374\n",
      "06/29/2022 03:48:16 - INFO - __main__ -   Text: ['\"lone wolf.\"']\n",
      "06/29/2022 03:48:17 - INFO - __main__ -   Epoch: 68 | Batch: 5400/10001 (54%) | G Loss: 2.446336 | C Loss: -0.924922\n",
      "06/29/2022 03:48:17 - INFO - __main__ -   Text: ['This is a problem Science is trying to solve.']\n",
      "06/29/2022 03:48:18 - INFO - __main__ -   Epoch: 68 | Batch: 6000/10001 (60%) | G Loss: 2.661094 | C Loss: -0.792162\n",
      "06/29/2022 03:48:18 - INFO - __main__ -   Text: [\"Dick's only hope is to get into trouble with the empire.\"]\n",
      "06/29/2022 03:48:19 - INFO - __main__ -   Epoch: 68 | Batch: 6600/10001 (66%) | G Loss: 2.369474 | C Loss: -1.015252\n",
      "06/29/2022 03:48:19 - INFO - __main__ -   Text: [\"It's a play--a Skidscock fight.\"]\n",
      "06/29/2022 03:48:20 - INFO - __main__ -   Epoch: 68 | Batch: 7200/10001 (72%) | G Loss: 2.517191 | C Loss: -0.931869\n",
      "06/29/2022 03:48:20 - INFO - __main__ -   Text: ['String Cheese is a memorable food for bulls.']\n",
      "06/29/2022 03:48:21 - INFO - __main__ -   Epoch: 68 | Batch: 7800/10001 (78%) | G Loss: 2.545905 | C Loss: -1.083193\n",
      "06/29/2022 03:48:22 - INFO - __main__ -   Text: ['An instructor-student can also learn to leap leap and leap faster.']\n",
      "06/29/2022 03:48:23 - INFO - __main__ -   Epoch: 68 | Batch: 8400/10001 (84%) | G Loss: 2.423692 | C Loss: -0.856077\n",
      "06/29/2022 03:48:23 - INFO - __main__ -   Text: ['By internally noting all phrases.']\n",
      "06/29/2022 03:48:24 - INFO - __main__ -   Epoch: 68 | Batch: 9000/10001 (90%) | G Loss: 2.439853 | C Loss: -0.889182\n",
      "06/29/2022 03:48:24 - INFO - __main__ -   Text: ['The subject of both languages can be studied.']\n",
      "06/29/2022 03:48:25 - INFO - __main__ -   Epoch: 68 | Batch: 9600/10001 (96%) | G Loss: 2.465821 | C Loss: -0.900770\n",
      "06/29/2022 03:48:25 - INFO - __main__ -   Text: ['A woman who cannot speak may well be female.']\n",
      "06/29/2022 03:48:25 - INFO - __main__ -   * (Train) Epoch: 68 | G Loss: 2.4269 | C Loss: -0.9201 | Updates G: 84 | Updates C: 749\n",
      "06/29/2022 03:48:35 - INFO - __main__ -   Bleu-2:0.212 | B-Bleu-2:0.241\n",
      "06/29/2022 03:48:35 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45279669374220416\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 69 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:52:05 - INFO - __main__ -   Epoch: 69 | Batch: 0/10001 (0%) | G Loss: 2.430887 | C Loss: -0.828914\n",
      "06/29/2022 03:52:05 - INFO - __main__ -   Text: ['The Australian energy company Aydovel finds Punditiol.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.786\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:52:06 - INFO - __main__ -   Epoch: 69 | Batch: 600/10001 (6%) | G Loss: 2.704418 | C Loss: -1.131874\n",
      "06/29/2022 03:52:06 - INFO - __main__ -   Text: ['Avoiding hegemonic authority.']\n",
      "06/29/2022 03:52:07 - INFO - __main__ -   Epoch: 69 | Batch: 1200/10001 (12%) | G Loss: 2.381724 | C Loss: -0.796634\n",
      "06/29/2022 03:52:07 - INFO - __main__ -   Text: ['There\\'s not much left of his life anymore.\"']\n",
      "06/29/2022 03:52:08 - INFO - __main__ -   Epoch: 69 | Batch: 1800/10001 (18%) | G Loss: 2.360253 | C Loss: -1.115184\n",
      "06/29/2022 03:52:08 - INFO - __main__ -   Text: ['The winner and runners-up fight the TTS at 1st place.']\n",
      "06/29/2022 03:52:09 - INFO - __main__ -   Epoch: 69 | Batch: 2400/10001 (24%) | G Loss: 2.497442 | C Loss: -0.967464\n",
      "06/29/2022 03:52:10 - INFO - __main__ -   Text: ['It has two spellcards: by TVGS\".']\n",
      "06/29/2022 03:52:10 - INFO - __main__ -   Epoch: 69 | Batch: 3000/10001 (30%) | G Loss: 2.658839 | C Loss: -1.032570\n",
      "06/29/2022 03:52:11 - INFO - __main__ -   Text: ['FOV modulates sentience like the Sci line.']\n",
      "06/29/2022 03:52:12 - INFO - __main__ -   Epoch: 69 | Batch: 3600/10001 (36%) | G Loss: 2.234193 | C Loss: -0.852614\n",
      "06/29/2022 03:52:12 - INFO - __main__ -   Text: ['An example of such a thing comes from the GNAT.']\n",
      "06/29/2022 03:52:13 - INFO - __main__ -   Epoch: 69 | Batch: 4200/10001 (42%) | G Loss: 2.465942 | C Loss: -0.750511\n",
      "06/29/2022 03:52:13 - INFO - __main__ -   Text: [\"These aren't not just numbers you can buy or rent.\"]\n",
      "06/29/2022 03:52:14 - INFO - __main__ -   Epoch: 69 | Batch: 4800/10001 (48%) | G Loss: 2.067364 | C Loss: -0.772450\n",
      "06/29/2022 03:52:14 - INFO - __main__ -   Text: ['The comedy film Comedy is about human attention.']\n",
      "06/29/2022 03:52:15 - INFO - __main__ -   Epoch: 69 | Batch: 5400/10001 (54%) | G Loss: 2.686085 | C Loss: -0.972726\n",
      "06/29/2022 03:52:15 - INFO - __main__ -   Text: ['The app needs an inclination to read fluently for the first time.']\n",
      "06/29/2022 03:52:16 - INFO - __main__ -   Epoch: 69 | Batch: 6000/10001 (60%) | G Loss: 2.762367 | C Loss: -0.864459\n",
      "06/29/2022 03:52:16 - INFO - __main__ -   Text: ['The secret that results from viewing Friday is that it is a meeting of the United States government.']\n",
      "06/29/2022 03:52:17 - INFO - __main__ -   Epoch: 69 | Batch: 6600/10001 (66%) | G Loss: 2.455710 | C Loss: -0.866226\n",
      "06/29/2022 03:52:17 - INFO - __main__ -   Text: ['Sour words are sometimes used for phrases suggesting fertility.']\n",
      "06/29/2022 03:52:18 - INFO - __main__ -   Epoch: 69 | Batch: 7200/10001 (72%) | G Loss: 2.218409 | C Loss: -0.871233\n",
      "06/29/2022 03:52:18 - INFO - __main__ -   Text: ['Marion Dowager is disappointed if you haven\\'t read her book.\"']\n",
      "06/29/2022 03:52:19 - INFO - __main__ -   Epoch: 69 | Batch: 7800/10001 (78%) | G Loss: 2.675024 | C Loss: -0.973759\n",
      "06/29/2022 03:52:19 - INFO - __main__ -   Text: [\"deceptions led to this country's most famous Great War.\"]\n",
      "06/29/2022 03:52:20 - INFO - __main__ -   Epoch: 69 | Batch: 8400/10001 (84%) | G Loss: 2.407934 | C Loss: -1.054133\n",
      "06/29/2022 03:52:20 - INFO - __main__ -   Text: ['Some of the memes try to mislead you into thinking human.']\n",
      "06/29/2022 03:52:21 - INFO - __main__ -   Epoch: 69 | Batch: 9000/10001 (90%) | G Loss: 2.382373 | C Loss: -0.881846\n",
      "06/29/2022 03:52:22 - INFO - __main__ -   Text: ['Upon this you may feel queasy and afraid, while reading.']\n",
      "06/29/2022 03:52:23 - INFO - __main__ -   Epoch: 69 | Batch: 9600/10001 (96%) | G Loss: 2.200512 | C Loss: -0.886362\n",
      "06/29/2022 03:52:23 - INFO - __main__ -   Text: ['He thinks he\\'s the meanest young guy he\\'s ever met\".']\n",
      "06/29/2022 03:52:23 - INFO - __main__ -   * (Train) Epoch: 69 | G Loss: 2.4576 | C Loss: -0.8997 | Updates G: 74 | Updates C: 759\n",
      "06/29/2022 03:52:33 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.244\n",
      "06/29/2022 03:52:33 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44222715311752325\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 70 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:01.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:18.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:56:08 - INFO - __main__ -   Epoch: 70 | Batch: 0/10001 (0%) | G Loss: 2.202421 | C Loss: -0.891904\n",
      "06/29/2022 03:56:08 - INFO - __main__ -   Text: ['It\\'s about the economy to 100 people here.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.749\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 03:56:09 - INFO - __main__ -   Epoch: 70 | Batch: 600/10001 (6%) | G Loss: 2.461760 | C Loss: -0.970666\n",
      "06/29/2022 03:56:09 - INFO - __main__ -   Text: ['\"Keptic puzzles\" involve situations where two people dig one another.']\n",
      "06/29/2022 03:56:10 - INFO - __main__ -   Epoch: 70 | Batch: 1200/10001 (12%) | G Loss: 2.428885 | C Loss: -0.866970\n",
      "06/29/2022 03:56:11 - INFO - __main__ -   Text: ['One party will become a war horse in China.\"']\n",
      "06/29/2022 03:56:12 - INFO - __main__ -   Epoch: 70 | Batch: 1800/10001 (18%) | G Loss: 2.485377 | C Loss: -0.986151\n",
      "06/29/2022 03:56:12 - INFO - __main__ -   Text: ['History 100 lists the letters in letters.']\n",
      "06/29/2022 03:56:13 - INFO - __main__ -   Epoch: 70 | Batch: 2400/10001 (24%) | G Loss: 2.788688 | C Loss: -0.944444\n",
      "06/29/2022 03:56:13 - INFO - __main__ -   Text: ['Hiroki has the strongest religious faith (if you believe that).']\n",
      "06/29/2022 03:56:14 - INFO - __main__ -   Epoch: 70 | Batch: 3000/10001 (30%) | G Loss: 2.464749 | C Loss: -0.943812\n",
      "06/29/2022 03:56:14 - INFO - __main__ -   Text: ['ITNi also offers Lost series for you!']\n",
      "06/29/2022 03:56:15 - INFO - __main__ -   Epoch: 70 | Batch: 3600/10001 (36%) | G Loss: 2.373893 | C Loss: -0.846261\n",
      "06/29/2022 03:56:15 - INFO - __main__ -   Text: ['These are: Earn Challenge Catcher eagle course ranking']\n",
      "06/29/2022 03:56:16 - INFO - __main__ -   Epoch: 70 | Batch: 4200/10001 (42%) | G Loss: 2.500087 | C Loss: -0.815047\n",
      "06/29/2022 03:56:16 - INFO - __main__ -   Text: ['There are very few \"people at the foundation of civilization.\"']\n",
      "06/29/2022 03:56:17 - INFO - __main__ -   Epoch: 70 | Batch: 4800/10001 (48%) | G Loss: 2.562751 | C Loss: -0.832071\n",
      "06/29/2022 03:56:17 - INFO - __main__ -   Text: ['Their latest criteria is \"precision if a person is 51 years of age\" to discover new problems.']\n",
      "06/29/2022 03:56:18 - INFO - __main__ -   Epoch: 70 | Batch: 5400/10001 (54%) | G Loss: 2.647714 | C Loss: -0.829067\n",
      "06/29/2022 03:56:18 - INFO - __main__ -   Text: ['Unites States calls for Americans to be snooped on.']\n",
      "06/29/2022 03:56:19 - INFO - __main__ -   Epoch: 70 | Batch: 6000/10001 (60%) | G Loss: 2.292112 | C Loss: -0.904419\n",
      "06/29/2022 03:56:19 - INFO - __main__ -   Text: ['Let them write a guide to expertise.']\n",
      "06/29/2022 03:56:20 - INFO - __main__ -   Epoch: 70 | Batch: 6600/10001 (66%) | G Loss: 2.373293 | C Loss: -0.767714\n",
      "06/29/2022 03:56:20 - INFO - __main__ -   Text: ['The gnarly spelling \"znark\" is the common.']\n",
      "06/29/2022 03:56:21 - INFO - __main__ -   Epoch: 70 | Batch: 7200/10001 (72%) | G Loss: 2.649388 | C Loss: -0.914070\n",
      "06/29/2022 03:56:21 - INFO - __main__ -   Text: ['Mainly omniscient.\"']\n",
      "06/29/2022 03:56:22 - INFO - __main__ -   Epoch: 70 | Batch: 7800/10001 (78%) | G Loss: 2.987380 | C Loss: -0.982933\n",
      "06/29/2022 03:56:22 - INFO - __main__ -   Text: ['WOO\".']\n",
      "06/29/2022 03:56:23 - INFO - __main__ -   Epoch: 70 | Batch: 8400/10001 (84%) | G Loss: 2.646544 | C Loss: -0.890598\n",
      "06/29/2022 03:56:24 - INFO - __main__ -   Text: ['One of the oddities is that Rogers can directly refer to any of the 60 maids on \"\" Sheldon Edward.']\n",
      "06/29/2022 03:56:25 - INFO - __main__ -   Epoch: 70 | Batch: 9000/10001 (90%) | G Loss: 2.540527 | C Loss: -1.046177\n",
      "06/29/2022 03:56:25 - INFO - __main__ -   Text: ['A live video sensation is performing live monkey tricks.']\n",
      "06/29/2022 03:56:26 - INFO - __main__ -   Epoch: 70 | Batch: 9600/10001 (96%) | G Loss: 2.442718 | C Loss: -0.950627\n",
      "06/29/2022 03:56:26 - INFO - __main__ -   Text: ['The Cook is his last stand after two years of watching heaven.']\n",
      "06/29/2022 03:56:26 - INFO - __main__ -   * (Train) Epoch: 70 | G Loss: 2.4618 | C Loss: -0.8745 | Updates G: 70 | Updates C: 763\n",
      "06/29/2022 03:56:36 - INFO - __main__ -   Bleu-2:0.210 | B-Bleu-2:0.254\n",
      "06/29/2022 03:56:36 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4642645979070861\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 71 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.714\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:00:09 - INFO - __main__ -   Epoch: 71 | Batch: 0/10001 (0%) | G Loss: 2.429453 | C Loss: -0.741843\n",
      "06/29/2022 04:00:09 - INFO - __main__ -   Text: ['Asgetu otrapa waltzes beautifully through the solar processes and textures\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.824\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:00:10 - INFO - __main__ -   Epoch: 71 | Batch: 600/10001 (6%) | G Loss: 2.398180 | C Loss: -0.944652\n",
      "06/29/2022 04:00:11 - INFO - __main__ -   Text: ['The Hilbert method is also called Hilbertian.']\n",
      "06/29/2022 04:00:11 - INFO - __main__ -   Epoch: 71 | Batch: 1200/10001 (12%) | G Loss: 2.400136 | C Loss: -0.884014\n",
      "06/29/2022 04:00:12 - INFO - __main__ -   Text: ['Places it online for ? <PAD>.']\n",
      "06/29/2022 04:00:13 - INFO - __main__ -   Epoch: 71 | Batch: 1800/10001 (18%) | G Loss: 2.519782 | C Loss: -0.808199\n",
      "06/29/2022 04:00:13 - INFO - __main__ -   Text: ['Biology is easy for students.']\n",
      "06/29/2022 04:00:14 - INFO - __main__ -   Epoch: 71 | Batch: 2400/10001 (24%) | G Loss: 2.491369 | C Loss: -0.874024\n",
      "06/29/2022 04:00:14 - INFO - __main__ -   Text: ['The Finder is a book by Sir John Saunders explaining the curse of Ignife.']\n",
      "06/29/2022 04:00:15 - INFO - __main__ -   Epoch: 71 | Batch: 3000/10001 (30%) | G Loss: 2.520429 | C Loss: -0.799806\n",
      "06/29/2022 04:00:15 - INFO - __main__ -   Text: ['In cold gnarls, here wagoo.']\n",
      "06/29/2022 04:00:16 - INFO - __main__ -   Epoch: 71 | Batch: 3600/10001 (36%) | G Loss: 2.651465 | C Loss: -0.952136\n",
      "06/29/2022 04:00:16 - INFO - __main__ -   Text: ['Deal also implies, itself, make something else.']\n",
      "06/29/2022 04:00:17 - INFO - __main__ -   Epoch: 71 | Batch: 4200/10001 (42%) | G Loss: 2.540705 | C Loss: -0.876194\n",
      "06/29/2022 04:00:17 - INFO - __main__ -   Text: ['This comes as no surprise to her personality – yes, personality.']\n",
      "06/29/2022 04:00:18 - INFO - __main__ -   Epoch: 71 | Batch: 4800/10001 (48%) | G Loss: 2.554660 | C Loss: -0.765640\n",
      "06/29/2022 04:00:18 - INFO - __main__ -   Text: ['The writer is the host who is harmful to Rachel.']\n",
      "06/29/2022 04:00:19 - INFO - __main__ -   Epoch: 71 | Batch: 5400/10001 (54%) | G Loss: 2.618207 | C Loss: -0.823954\n",
      "06/29/2022 04:00:19 - INFO - __main__ -   Text: ['Sherman Klief.']\n",
      "06/29/2022 04:00:20 - INFO - __main__ -   Epoch: 71 | Batch: 6000/10001 (60%) | G Loss: 2.285227 | C Loss: -1.040590\n",
      "06/29/2022 04:00:20 - INFO - __main__ -   Text: ['Still maybe not.']\n",
      "06/29/2022 04:00:21 - INFO - __main__ -   Epoch: 71 | Batch: 6600/10001 (66%) | G Loss: 2.424403 | C Loss: -0.960017\n",
      "06/29/2022 04:00:21 - INFO - __main__ -   Text: ['Such comedy, here\\'s always someone polluting, but kind of laugh it\\'s hilarious anyway.\"']\n",
      "06/29/2022 04:00:22 - INFO - __main__ -   Epoch: 71 | Batch: 7200/10001 (72%) | G Loss: 2.659791 | C Loss: -0.831900\n",
      "06/29/2022 04:00:22 - INFO - __main__ -   Text: ['иא is highly dubious.']\n",
      "06/29/2022 04:00:23 - INFO - __main__ -   Epoch: 71 | Batch: 7800/10001 (78%) | G Loss: 2.657544 | C Loss: -0.690147\n",
      "06/29/2022 04:00:23 - INFO - __main__ -   Text: ['\"Moku Kyouka provides something new.']\n",
      "06/29/2022 04:00:24 - INFO - __main__ -   Epoch: 71 | Batch: 8400/10001 (84%) | G Loss: 2.669979 | C Loss: -0.874608\n",
      "06/29/2022 04:00:25 - INFO - __main__ -   Text: ['Since the person\\'s name is spelled \"Anything Goes\" there is still the Concord Distraction Trogdor.']\n",
      "06/29/2022 04:00:26 - INFO - __main__ -   Epoch: 71 | Batch: 9000/10001 (90%) | G Loss: 2.221015 | C Loss: -0.705351\n",
      "06/29/2022 04:00:26 - INFO - __main__ -   Text: ['It is composed by Paul T. Bach.']\n",
      "06/29/2022 04:00:27 - INFO - __main__ -   Epoch: 71 | Batch: 9600/10001 (96%) | G Loss: 2.256289 | C Loss: -0.756104\n",
      "06/29/2022 04:00:27 - INFO - __main__ -   Text: ['A drug drinker sells fake medical information.']\n",
      "06/29/2022 04:00:27 - INFO - __main__ -   * (Train) Epoch: 71 | G Loss: 2.4479 | C Loss: -0.8714 | Updates G: 48 | Updates C: 785\n",
      "06/29/2022 04:00:36 - INFO - __main__ -   Bleu-2:0.212 | B-Bleu-2:0.250\n",
      "06/29/2022 04:00:36 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46278524806784177\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 72 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:04:01 - INFO - __main__ -   Epoch: 72 | Batch: 0/10001 (0%) | G Loss: 2.720265 | C Loss: -0.997346\n",
      "06/29/2022 04:04:02 - INFO - __main__ -   Text: ['Since she is slightly unmanned, she follows the zero question.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 3.820\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:04:03 - INFO - __main__ -   Epoch: 72 | Batch: 600/10001 (6%) | G Loss: 2.717489 | C Loss: -0.955919\n",
      "06/29/2022 04:04:03 - INFO - __main__ -   Text: [\"He's beaten his head against a wall [when it comes to killing Superman].\"]\n",
      "06/29/2022 04:04:04 - INFO - __main__ -   Epoch: 72 | Batch: 1200/10001 (12%) | G Loss: 2.642641 | C Loss: -0.824529\n",
      "06/29/2022 04:04:04 - INFO - __main__ -   Text: ['The only letter you need to answer \"in Boston.\"']\n",
      "06/29/2022 04:04:05 - INFO - __main__ -   Epoch: 72 | Batch: 1800/10001 (18%) | G Loss: 2.613549 | C Loss: -0.919692\n",
      "06/29/2022 04:04:05 - INFO - __main__ -   Text: ['The white spinner makes one try and one beat\".']\n",
      "06/29/2022 04:04:06 - INFO - __main__ -   Epoch: 72 | Batch: 2400/10001 (24%) | G Loss: 2.444699 | C Loss: -0.816928\n",
      "06/29/2022 04:04:06 - INFO - __main__ -   Text: ['No one knows what day it will be, and presumably done when in High School.']\n",
      "06/29/2022 04:04:07 - INFO - __main__ -   Epoch: 72 | Batch: 3000/10001 (30%) | G Loss: 2.495743 | C Loss: -0.970561\n",
      "06/29/2022 04:04:07 - INFO - __main__ -   Text: ['Learberry is applicable to many other programming languages.']\n",
      "06/29/2022 04:04:08 - INFO - __main__ -   Epoch: 72 | Batch: 3600/10001 (36%) | G Loss: 2.641852 | C Loss: -0.710125\n",
      "06/29/2022 04:04:08 - INFO - __main__ -   Text: ['The ghost had \"you\" to discover.']\n",
      "06/29/2022 04:04:09 - INFO - __main__ -   Epoch: 72 | Batch: 4200/10001 (42%) | G Loss: 2.556560 | C Loss: -0.881146\n",
      "06/29/2022 04:04:09 - INFO - __main__ -   Text: ['']\n",
      "06/29/2022 04:04:10 - INFO - __main__ -   Epoch: 72 | Batch: 4800/10001 (48%) | G Loss: 2.311193 | C Loss: -0.784302\n",
      "06/29/2022 04:04:10 - INFO - __main__ -   Text: ['E.g.']\n",
      "06/29/2022 04:04:11 - INFO - __main__ -   Epoch: 72 | Batch: 5400/10001 (54%) | G Loss: 2.607049 | C Loss: -0.863775\n",
      "06/29/2022 04:04:11 - INFO - __main__ -   Text: ['Batgirl is arguably the greatest lightning spellcasting magic in history.']\n",
      "06/29/2022 04:04:12 - INFO - __main__ -   Epoch: 72 | Batch: 6000/10001 (60%) | G Loss: 2.544234 | C Loss: -0.982305\n",
      "06/29/2022 04:04:12 - INFO - __main__ -   Text: ['To purist, it uses \"sedna-dots\".']\n",
      "06/29/2022 04:04:13 - INFO - __main__ -   Epoch: 72 | Batch: 6600/10001 (66%) | G Loss: 2.447909 | C Loss: -0.780586\n",
      "06/29/2022 04:04:13 - INFO - __main__ -   Text: ['Mediate is fast.']\n",
      "06/29/2022 04:04:14 - INFO - __main__ -   Epoch: 72 | Batch: 7200/10001 (72%) | G Loss: 2.551988 | C Loss: -0.706503\n",
      "06/29/2022 04:04:15 - INFO - __main__ -   Text: ['His parents are very effeminate and, so far, rarely walk around.']\n",
      "06/29/2022 04:04:16 - INFO - __main__ -   Epoch: 72 | Batch: 7800/10001 (78%) | G Loss: 2.569052 | C Loss: -0.911799\n",
      "06/29/2022 04:04:16 - INFO - __main__ -   Text: ['Given a scenario like this, they need reliable information from a relay relay transmitter.']\n",
      "06/29/2022 04:04:17 - INFO - __main__ -   Epoch: 72 | Batch: 8400/10001 (84%) | G Loss: 2.628008 | C Loss: -0.875771\n",
      "06/29/2022 04:04:17 - INFO - __main__ -   Text: ['On simple-attacks it is .']\n",
      "06/29/2022 04:04:18 - INFO - __main__ -   Epoch: 72 | Batch: 9000/10001 (90%) | G Loss: 2.494047 | C Loss: -0.929611\n",
      "06/29/2022 04:04:18 - INFO - __main__ -   Text: ['The article states that Domingo barrelling habeas corpus prosecution has been unsuccessful.']\n",
      "06/29/2022 04:04:19 - INFO - __main__ -   Epoch: 72 | Batch: 9600/10001 (96%) | G Loss: 2.597306 | C Loss: -0.873611\n",
      "06/29/2022 04:04:19 - INFO - __main__ -   Text: ['These forces will be harmful.']\n",
      "06/29/2022 04:04:20 - INFO - __main__ -   * (Train) Epoch: 72 | G Loss: 2.4940 | C Loss: -0.8605 | Updates G: 63 | Updates C: 770\n",
      "06/29/2022 04:04:29 - INFO - __main__ -   Bleu-2:0.208 | B-Bleu-2:0.256\n",
      "06/29/2022 04:04:29 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4647804951937951\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 73 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:40.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:56.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:14.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:31.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:48.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:05.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:03:20\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:07:49 - INFO - __main__ -   Epoch: 73 | Batch: 0/10001 (0%) | G Loss: 2.579962 | C Loss: -0.843180\n",
      "06/29/2022 04:07:50 - INFO - __main__ -   Text: ['Those who still use #replace are saying #replacemesh. <PAD>']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.808\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:07:51 - INFO - __main__ -   Epoch: 73 | Batch: 600/10001 (6%) | G Loss: 2.374717 | C Loss: -0.822448\n",
      "06/29/2022 04:07:51 - INFO - __main__ -   Text: ['\"possessed\": The neo-meterian house natures.']\n",
      "06/29/2022 04:07:52 - INFO - __main__ -   Epoch: 73 | Batch: 1200/10001 (12%) | G Loss: 2.554281 | C Loss: -0.879977\n",
      "06/29/2022 04:07:52 - INFO - __main__ -   Text: ['This website does not reflect lists of celebrities.\"']\n",
      "06/29/2022 04:07:53 - INFO - __main__ -   Epoch: 73 | Batch: 1800/10001 (18%) | G Loss: 2.685344 | C Loss: -0.671011\n",
      "06/29/2022 04:07:53 - INFO - __main__ -   Text: ['\"Watch this channel!\"']\n",
      "06/29/2022 04:07:54 - INFO - __main__ -   Epoch: 73 | Batch: 2400/10001 (24%) | G Loss: 2.321697 | C Loss: -0.830660\n",
      "06/29/2022 04:07:54 - INFO - __main__ -   Text: ['They also get some advice on how to make music.']\n",
      "06/29/2022 04:07:55 - INFO - __main__ -   Epoch: 73 | Batch: 3000/10001 (30%) | G Loss: 2.399813 | C Loss: -0.821480\n",
      "06/29/2022 04:07:55 - INFO - __main__ -   Text: [\"The line isn't listed on the bank.\"]\n",
      "06/29/2022 04:07:56 - INFO - __main__ -   Epoch: 73 | Batch: 3600/10001 (36%) | G Loss: 2.612336 | C Loss: -0.847159\n",
      "06/29/2022 04:07:56 - INFO - __main__ -   Text: ['CombinatorialC\", is pretend.']\n",
      "06/29/2022 04:07:57 - INFO - __main__ -   Epoch: 73 | Batch: 4200/10001 (42%) | G Loss: 2.380949 | C Loss: -0.853330\n",
      "06/29/2022 04:07:57 - INFO - __main__ -   Text: ['2 Messiahs apologist 2</p> <br> <br>']\n",
      "06/29/2022 04:07:58 - INFO - __main__ -   Epoch: 73 | Batch: 4800/10001 (48%) | G Loss: 2.935431 | C Loss: -0.879191\n",
      "06/29/2022 04:07:58 - INFO - __main__ -   Text: ['The Rankestable CompuVal machine can also back up a pattern.']\n",
      "06/29/2022 04:07:59 - INFO - __main__ -   Epoch: 73 | Batch: 5400/10001 (54%) | G Loss: 2.319171 | C Loss: -0.697511\n",
      "06/29/2022 04:07:59 - INFO - __main__ -   Text: ['When the plane realizes it is the town of Columbia sticking out toward Saturn.']\n",
      "06/29/2022 04:08:00 - INFO - __main__ -   Epoch: 73 | Batch: 6000/10001 (60%) | G Loss: 2.232733 | C Loss: -0.813314\n",
      "06/29/2022 04:08:00 - INFO - __main__ -   Text: ['Yet the girls have come together in a move to become a top player.']\n",
      "06/29/2022 04:08:01 - INFO - __main__ -   Epoch: 73 | Batch: 6600/10001 (66%) | G Loss: 2.349349 | C Loss: -0.598796\n",
      "06/29/2022 04:08:01 - INFO - __main__ -   Text: ['Ignite it.']\n",
      "06/29/2022 04:08:02 - INFO - __main__ -   Epoch: 73 | Batch: 7200/10001 (72%) | G Loss: 2.644061 | C Loss: -0.971485\n",
      "06/29/2022 04:08:02 - INFO - __main__ -   Text: ['That means going to school.']\n",
      "06/29/2022 04:08:03 - INFO - __main__ -   Epoch: 73 | Batch: 7800/10001 (78%) | G Loss: 2.527004 | C Loss: -0.815884\n",
      "06/29/2022 04:08:04 - INFO - __main__ -   Text: ['. Citations are sourced to tryo …']\n",
      "06/29/2022 04:08:04 - INFO - __main__ -   Epoch: 73 | Batch: 8400/10001 (84%) | G Loss: 2.925695 | C Loss: -0.813967\n",
      "06/29/2022 04:08:05 - INFO - __main__ -   Text: ['Astu Sunine is funny. <PAD>!\"']\n",
      "06/29/2022 04:08:06 - INFO - __main__ -   Epoch: 73 | Batch: 9000/10001 (90%) | G Loss: 2.560546 | C Loss: -0.749621\n",
      "06/29/2022 04:08:06 - INFO - __main__ -   Text: ['Collectively, its arguments.']\n",
      "06/29/2022 04:08:07 - INFO - __main__ -   Epoch: 73 | Batch: 9600/10001 (96%) | G Loss: 2.450250 | C Loss: -0.824052\n",
      "06/29/2022 04:08:07 - INFO - __main__ -   Text: ['In many ways, traditional credit card .']\n",
      "06/29/2022 04:08:07 - INFO - __main__ -   * (Train) Epoch: 73 | G Loss: 2.4727 | C Loss: -0.8305 | Updates G: 75 | Updates C: 758\n",
      "06/29/2022 04:08:16 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.253\n",
      "06/29/2022 04:08:16 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45140355532526877\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 74 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:11:51 - INFO - __main__ -   Epoch: 74 | Batch: 0/10001 (0%) | G Loss: 2.499806 | C Loss: -0.840837\n",
      "06/29/2022 04:11:51 - INFO - __main__ -   Text: ['Goldbug Girls flick death argly bacon!\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.803\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:11:52 - INFO - __main__ -   Epoch: 74 | Batch: 600/10001 (6%) | G Loss: 2.265282 | C Loss: -0.754263\n",
      "06/29/2022 04:11:53 - INFO - __main__ -   Text: ['The Wicked Lady (Scobbe).']\n",
      "06/29/2022 04:11:54 - INFO - __main__ -   Epoch: 74 | Batch: 1200/10001 (12%) | G Loss: 2.461468 | C Loss: -1.041486\n",
      "06/29/2022 04:11:54 - INFO - __main__ -   Text: [\"These aren't the only electrical gadgets found on Arcway, but they really are more thanart.\"]\n",
      "06/29/2022 04:11:55 - INFO - __main__ -   Epoch: 74 | Batch: 1800/10001 (18%) | G Loss: 2.361434 | C Loss: -0.767127\n",
      "06/29/2022 04:11:55 - INFO - __main__ -   Text: ['Alarmist makes almost no sense at all.\"']\n",
      "06/29/2022 04:11:56 - INFO - __main__ -   Epoch: 74 | Batch: 2400/10001 (24%) | G Loss: 2.388052 | C Loss: -0.781188\n",
      "06/29/2022 04:11:56 - INFO - __main__ -   Text: [\"Commerce doesn't matter to any American.\"]\n",
      "06/29/2022 04:11:57 - INFO - __main__ -   Epoch: 74 | Batch: 3000/10001 (30%) | G Loss: 2.516320 | C Loss: -0.785772\n",
      "06/29/2022 04:11:57 - INFO - __main__ -   Text: [\"Newton's law of relativity predicts that letters with fluences will be three times more likely.\"]\n",
      "06/29/2022 04:11:58 - INFO - __main__ -   Epoch: 74 | Batch: 3600/10001 (36%) | G Loss: 2.839376 | C Loss: -1.095011\n",
      "06/29/2022 04:11:58 - INFO - __main__ -   Text: ['These are 46 basic math manipulations, with one.']\n",
      "06/29/2022 04:11:59 - INFO - __main__ -   Epoch: 74 | Batch: 4200/10001 (42%) | G Loss: 2.359229 | C Loss: -0.747113\n",
      "06/29/2022 04:11:59 - INFO - __main__ -   Text: [\"Muhammad's Book and Drivers' Manual differ considerably.\"]\n",
      "06/29/2022 04:12:00 - INFO - __main__ -   Epoch: 74 | Batch: 4800/10001 (48%) | G Loss: 2.276687 | C Loss: -0.612722\n",
      "06/29/2022 04:12:00 - INFO - __main__ -   Text: ['The difference is just concentrated consumption of petrolatum.']\n",
      "06/29/2022 04:12:01 - INFO - __main__ -   Epoch: 74 | Batch: 5400/10001 (54%) | G Loss: 2.405618 | C Loss: -0.793171\n",
      "06/29/2022 04:12:01 - INFO - __main__ -   Text: ['They freak out when he enters a talk number.']\n",
      "06/29/2022 04:12:02 - INFO - __main__ -   Epoch: 74 | Batch: 6000/10001 (60%) | G Loss: 2.664277 | C Loss: -0.807239\n",
      "06/29/2022 04:12:02 - INFO - __main__ -   Text: [\"They are angered by the trio's behavior.\"]\n",
      "06/29/2022 04:12:03 - INFO - __main__ -   Epoch: 74 | Batch: 6600/10001 (66%) | G Loss: 2.988104 | C Loss: -0.829169\n",
      "06/29/2022 04:12:03 - INFO - __main__ -   Text: ['Other readers might consider changes to formal reasoning.']\n",
      "06/29/2022 04:12:04 - INFO - __main__ -   Epoch: 74 | Batch: 7200/10001 (72%) | G Loss: 2.509971 | C Loss: -0.830279\n",
      "06/29/2022 04:12:05 - INFO - __main__ -   Text: ['Tinkerballs succeed on track/teams can only get on track with another rider.\"']\n",
      "06/29/2022 04:12:06 - INFO - __main__ -   Epoch: 74 | Batch: 7800/10001 (78%) | G Loss: 2.267014 | C Loss: -0.849843\n",
      "06/29/2022 04:12:06 - INFO - __main__ -   Text: ['IMF mentions that 74% of India\\'s telecoms belongs to Jaipur\".']\n",
      "06/29/2022 04:12:07 - INFO - __main__ -   Epoch: 74 | Batch: 8400/10001 (84%) | G Loss: 2.314332 | C Loss: -0.716409\n",
      "06/29/2022 04:12:07 - INFO - __main__ -   Text: ['In college, it is a mile walk.']\n",
      "06/29/2022 04:12:08 - INFO - __main__ -   Epoch: 74 | Batch: 9000/10001 (90%) | G Loss: 2.634273 | C Loss: -0.717958\n",
      "06/29/2022 04:12:08 - INFO - __main__ -   Text: ['Signals are marked as slow fighters but how are they driving it?']\n",
      "06/29/2022 04:12:09 - INFO - __main__ -   Epoch: 74 | Batch: 9600/10001 (96%) | G Loss: 2.713729 | C Loss: -0.796805\n",
      "06/29/2022 04:12:09 - INFO - __main__ -   Text: ['Hero other days Skip feeds all of that']\n",
      "06/29/2022 04:12:10 - INFO - __main__ -   * (Train) Epoch: 74 | G Loss: 2.4636 | C Loss: -0.8016 | Updates G: 59 | Updates C: 774\n",
      "06/29/2022 04:12:19 - INFO - __main__ -   Bleu-2:0.197 | B-Bleu-2:0.236\n",
      "06/29/2022 04:12:19 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_12.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43277215759870113\n",
      "Train file used is number 12\n",
      "../../yahoo/subdivided_large/train_12.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 75 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:16.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:15:43 - INFO - __main__ -   Epoch: 75 | Batch: 0/10001 (0%) | G Loss: 2.439524 | C Loss: -0.718090\n",
      "06/29/2022 04:15:43 - INFO - __main__ -   Text: ['This force gives you an unseen container of snow.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.877\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:15:44 - INFO - __main__ -   Epoch: 75 | Batch: 600/10001 (6%) | G Loss: 2.475395 | C Loss: -0.774461\n",
      "06/29/2022 04:15:45 - INFO - __main__ -   Text: ['Instead, his teammate decides to make him drink sweet tea and grants his wish for his job.']\n",
      "06/29/2022 04:15:46 - INFO - __main__ -   Epoch: 75 | Batch: 1200/10001 (12%) | G Loss: 2.192917 | C Loss: -0.791256\n",
      "06/29/2022 04:15:46 - INFO - __main__ -   Text: ['The disease only affects humans, not animal.']\n",
      "06/29/2022 04:15:47 - INFO - __main__ -   Epoch: 75 | Batch: 1800/10001 (18%) | G Loss: 2.148205 | C Loss: -0.747604\n",
      "06/29/2022 04:15:47 - INFO - __main__ -   Text: ['Generally refer to: Soukišīp mose.']\n",
      "06/29/2022 04:15:48 - INFO - __main__ -   Epoch: 75 | Batch: 2400/10001 (24%) | G Loss: 2.485613 | C Loss: -0.793918\n",
      "06/29/2022 04:15:48 - INFO - __main__ -   Text: ['Paseo Herguier.']\n",
      "06/29/2022 04:15:49 - INFO - __main__ -   Epoch: 75 | Batch: 3000/10001 (30%) | G Loss: 2.755229 | C Loss: -0.794178\n",
      "06/29/2022 04:15:49 - INFO - __main__ -   Text: ['\"Ikran\\'s workload is very difficult for me after my Masters programme.\"']\n",
      "06/29/2022 04:15:50 - INFO - __main__ -   Epoch: 75 | Batch: 3600/10001 (36%) | G Loss: 2.638744 | C Loss: -0.969206\n",
      "06/29/2022 04:15:50 - INFO - __main__ -   Text: ['. Soon ordinary dictionaries will contain the opportunity.']\n",
      "06/29/2022 04:15:51 - INFO - __main__ -   Epoch: 75 | Batch: 4200/10001 (42%) | G Loss: 2.380457 | C Loss: -0.814131\n",
      "06/29/2022 04:15:51 - INFO - __main__ -   Text: ['This show takes advantage of a local newsreader.']\n",
      "06/29/2022 04:15:52 - INFO - __main__ -   Epoch: 75 | Batch: 4800/10001 (48%) | G Loss: 2.617112 | C Loss: -0.810339\n",
      "06/29/2022 04:15:52 - INFO - __main__ -   Text: ['Some people have this condition that cool blue shimmers.']\n",
      "06/29/2022 04:15:53 - INFO - __main__ -   Epoch: 75 | Batch: 5400/10001 (54%) | G Loss: 2.336470 | C Loss: -0.906029\n",
      "06/29/2022 04:15:53 - INFO - __main__ -   Text: ['During the name \"Sympathy Inc\", there may be someone.']\n",
      "06/29/2022 04:15:54 - INFO - __main__ -   Epoch: 75 | Batch: 6000/10001 (60%) | G Loss: 2.370811 | C Loss: -0.733779\n",
      "06/29/2022 04:15:54 - INFO - __main__ -   Text: ['Tah appears to increase with one event.']\n",
      "06/29/2022 04:15:55 - INFO - __main__ -   Epoch: 75 | Batch: 6600/10001 (66%) | G Loss: 2.512318 | C Loss: -0.857045\n",
      "06/29/2022 04:15:55 - INFO - __main__ -   Text: ['Other subjects are tennis or survival, natural phenomena.']\n",
      "06/29/2022 04:15:56 - INFO - __main__ -   Epoch: 75 | Batch: 7200/10001 (72%) | G Loss: 2.373175 | C Loss: -0.692073\n",
      "06/29/2022 04:15:56 - INFO - __main__ -   Text: ['Write literally Hungarian words.']\n",
      "06/29/2022 04:15:57 - INFO - __main__ -   Epoch: 75 | Batch: 7800/10001 (78%) | G Loss: 2.631802 | C Loss: -0.628661\n",
      "06/29/2022 04:15:57 - INFO - __main__ -   Text: ['Fivebis is a double meaning of \"answer\".']\n",
      "06/29/2022 04:15:58 - INFO - __main__ -   Epoch: 75 | Batch: 8400/10001 (84%) | G Loss: 2.464229 | C Loss: -0.770256\n",
      "06/29/2022 04:15:59 - INFO - __main__ -   Text: ['The seductive act or oddity of the fairy moon may be explained by her lack of attraction.\"']\n",
      "06/29/2022 04:16:00 - INFO - __main__ -   Epoch: 75 | Batch: 9000/10001 (90%) | G Loss: 2.457800 | C Loss: -0.622154\n",
      "06/29/2022 04:16:00 - INFO - __main__ -   Text: ['These two kinds of dodding are called nachun kund.']\n",
      "06/29/2022 04:16:01 - INFO - __main__ -   Epoch: 75 | Batch: 9600/10001 (96%) | G Loss: 2.502956 | C Loss: -0.699464\n",
      "06/29/2022 04:16:01 - INFO - __main__ -   Text: ['Aboriginal villain Bilalla Main.']\n",
      "06/29/2022 04:16:01 - INFO - __main__ -   * (Train) Epoch: 75 | G Loss: 2.4556 | C Loss: -0.7806 | Updates G: 52 | Updates C: 781\n",
      "06/29/2022 04:16:10 - INFO - __main__ -   Bleu-2:0.189 | B-Bleu-2:0.234\n",
      "06/29/2022 04:16:10 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4228332124346339\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 76 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:19:40 - INFO - __main__ -   Epoch: 76 | Batch: 0/10001 (0%) | G Loss: 2.398277 | C Loss: -0.660951\n",
      "06/29/2022 04:19:40 - INFO - __main__ -   Text: ['Hindu troops are known to fall crazy when they battle.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 3.921\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:19:41 - INFO - __main__ -   Epoch: 76 | Batch: 600/10001 (6%) | G Loss: 2.369551 | C Loss: -0.738768\n",
      "06/29/2022 04:19:41 - INFO - __main__ -   Text: ['They generally get along pretty well.']\n",
      "06/29/2022 04:19:42 - INFO - __main__ -   Epoch: 76 | Batch: 1200/10001 (12%) | G Loss: 2.500807 | C Loss: -0.820005\n",
      "06/29/2022 04:19:42 - INFO - __main__ -   Text: [\"Even though they know one or Quartz can't rest.\"]\n",
      "06/29/2022 04:19:43 - INFO - __main__ -   Epoch: 76 | Batch: 1800/10001 (18%) | G Loss: 2.385829 | C Loss: -0.832418\n",
      "06/29/2022 04:19:43 - INFO - __main__ -   Text: ['× × No.']\n",
      "06/29/2022 04:19:44 - INFO - __main__ -   Epoch: 76 | Batch: 2400/10001 (24%) | G Loss: 2.700100 | C Loss: -0.763987\n",
      "06/29/2022 04:19:45 - INFO - __main__ -   Text: ['Notable points: Improbable for yelling : 3.']\n",
      "06/29/2022 04:19:45 - INFO - __main__ -   Epoch: 76 | Batch: 3000/10001 (30%) | G Loss: 2.369686 | C Loss: -0.695927\n",
      "06/29/2022 04:19:46 - INFO - __main__ -   Text: ['The most corrupt person is Chiang Mai.']\n",
      "06/29/2022 04:19:47 - INFO - __main__ -   Epoch: 76 | Batch: 3600/10001 (36%) | G Loss: 2.600415 | C Loss: -0.781379\n",
      "06/29/2022 04:19:47 - INFO - __main__ -   Text: [\"It's easy to get here.\"]\n",
      "06/29/2022 04:19:48 - INFO - __main__ -   Epoch: 76 | Batch: 4200/10001 (42%) | G Loss: 2.625605 | C Loss: -0.790128\n",
      "06/29/2022 04:19:48 - INFO - __main__ -   Text: ['Tabula-Dick races are a race where a revolver flies.']\n",
      "06/29/2022 04:19:49 - INFO - __main__ -   Epoch: 76 | Batch: 4800/10001 (48%) | G Loss: 2.277843 | C Loss: -0.895175\n",
      "06/29/2022 04:19:49 - INFO - __main__ -   Text: ['This name is popular among Cunard Forks.']\n",
      "06/29/2022 04:19:50 - INFO - __main__ -   Epoch: 76 | Batch: 5400/10001 (54%) | G Loss: 2.411126 | C Loss: -0.880333\n",
      "06/29/2022 04:19:50 - INFO - __main__ -   Text: [\"Like even the loudest one's not okay.\"]\n",
      "06/29/2022 04:19:51 - INFO - __main__ -   Epoch: 76 | Batch: 6000/10001 (60%) | G Loss: 2.361170 | C Loss: -0.949072\n",
      "06/29/2022 04:19:51 - INFO - __main__ -   Text: [\"It doesn't really do anything different because she's sitting here.\"]\n",
      "06/29/2022 04:19:52 - INFO - __main__ -   Epoch: 76 | Batch: 6600/10001 (66%) | G Loss: 2.538368 | C Loss: -0.556100\n",
      "06/29/2022 04:19:52 - INFO - __main__ -   Text: [\"It's basically a shuttle - there really is nobody there.\"]\n",
      "06/29/2022 04:19:53 - INFO - __main__ -   Epoch: 76 | Batch: 7200/10001 (72%) | G Loss: 2.737862 | C Loss: -0.753879\n",
      "06/29/2022 04:19:53 - INFO - __main__ -   Text: ['\"Butwell\".']\n",
      "06/29/2022 04:19:54 - INFO - __main__ -   Epoch: 76 | Batch: 7800/10001 (78%) | G Loss: 3.073635 | C Loss: -0.777230\n",
      "06/29/2022 04:19:54 - INFO - __main__ -   Text: ['\"En véréoir d\\'essence\".']\n",
      "06/29/2022 04:19:55 - INFO - __main__ -   Epoch: 76 | Batch: 8400/10001 (84%) | G Loss: 2.700033 | C Loss: -0.650146\n",
      "06/29/2022 04:19:55 - INFO - __main__ -   Text: ['The prices are up for debate, but some more interesting things have come out of East Windtown.']\n",
      "06/29/2022 04:19:56 - INFO - __main__ -   Epoch: 76 | Batch: 9000/10001 (90%) | G Loss: 2.412856 | C Loss: -0.717307\n",
      "06/29/2022 04:19:56 - INFO - __main__ -   Text: ['They\\'ll need to jump onto my radar if I want to see it.\"']\n",
      "06/29/2022 04:19:57 - INFO - __main__ -   Epoch: 76 | Batch: 9600/10001 (96%) | G Loss: 2.275012 | C Loss: -0.757663\n",
      "06/29/2022 04:19:58 - INFO - __main__ -   Text: ['Strictly speaking, constrains.']\n",
      "06/29/2022 04:19:58 - INFO - __main__ -   * (Train) Epoch: 76 | G Loss: 2.4833 | C Loss: -0.7645 | Updates G: 55 | Updates C: 778\n",
      "06/29/2022 04:20:07 - INFO - __main__ -   Bleu-2:0.212 | B-Bleu-2:0.260\n",
      "06/29/2022 04:20:07 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_14.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47149275370640664\n",
      "Train file used is number 14\n",
      "../../yahoo/subdivided_large/train_14.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 77 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:23:38 - INFO - __main__ -   Epoch: 77 | Batch: 0/10001 (0%) | G Loss: 2.318922 | C Loss: -0.753280\n",
      "06/29/2022 04:23:38 - INFO - __main__ -   Text: ['Bao provides text from The Mandarin GRE- Basic Theta.-']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 3.908\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:23:39 - INFO - __main__ -   Epoch: 77 | Batch: 600/10001 (6%) | G Loss: 2.388783 | C Loss: -0.663927\n",
      "06/29/2022 04:23:39 - INFO - __main__ -   Text: ['Online RateEasy RateEasy is free.']\n",
      "06/29/2022 04:23:40 - INFO - __main__ -   Epoch: 77 | Batch: 1200/10001 (12%) | G Loss: 2.490527 | C Loss: -0.648767\n",
      "06/29/2022 04:23:40 - INFO - __main__ -   Text: ['Sims is unaware of his sexuality, but loyal support.']\n",
      "06/29/2022 04:23:41 - INFO - __main__ -   Epoch: 77 | Batch: 1800/10001 (18%) | G Loss: 2.857119 | C Loss: -0.732551\n",
      "06/29/2022 04:23:41 - INFO - __main__ -   Text: ['Tsummers are often introduced into life by strangers visiting a site.']\n",
      "06/29/2022 04:23:42 - INFO - __main__ -   Epoch: 77 | Batch: 2400/10001 (24%) | G Loss: 2.407799 | C Loss: -0.713653\n",
      "06/29/2022 04:23:42 - INFO - __main__ -   Text: ['Sindler is widely used to find music.']\n",
      "06/29/2022 04:23:43 - INFO - __main__ -   Epoch: 77 | Batch: 3000/10001 (30%) | G Loss: 2.151608 | C Loss: -0.767168\n",
      "06/29/2022 04:23:43 - INFO - __main__ -   Text: ['\"t:h:nhr\"\".']\n",
      "06/29/2022 04:23:44 - INFO - __main__ -   Epoch: 77 | Batch: 3600/10001 (36%) | G Loss: 2.842047 | C Loss: -0.756278\n",
      "06/29/2022 04:23:44 - INFO - __main__ -   Text: ['They supply every country in the world with a coffee subscription:']\n",
      "06/29/2022 04:23:45 - INFO - __main__ -   Epoch: 77 | Batch: 4200/10001 (42%) | G Loss: 3.032123 | C Loss: -0.823417\n",
      "06/29/2022 04:23:45 - INFO - __main__ -   Text: ['He worshipped the joys of crime, and spent his life fighting for the good of the country.']\n",
      "06/29/2022 04:23:46 - INFO - __main__ -   Epoch: 77 | Batch: 4800/10001 (48%) | G Loss: 2.507128 | C Loss: -0.802856\n",
      "06/29/2022 04:23:47 - INFO - __main__ -   Text: ['There is a lot of cynicism in the world.']\n",
      "06/29/2022 04:23:47 - INFO - __main__ -   Epoch: 77 | Batch: 5400/10001 (54%) | G Loss: 2.536094 | C Loss: -0.797184\n",
      "06/29/2022 04:23:48 - INFO - __main__ -   Text: ['The reason may explain why many application sciences are often called hash theory.']\n",
      "06/29/2022 04:23:49 - INFO - __main__ -   Epoch: 77 | Batch: 6000/10001 (60%) | G Loss: 2.486947 | C Loss: -0.665897\n",
      "06/29/2022 04:23:49 - INFO - __main__ -   Text: ['From Queen George X.']\n",
      "06/29/2022 04:23:50 - INFO - __main__ -   Epoch: 77 | Batch: 6600/10001 (66%) | G Loss: 2.783569 | C Loss: -0.823510\n",
      "06/29/2022 04:23:50 - INFO - __main__ -   Text: ['With a funny grin I\\'m Ms Shapes Plays on the Tube.\"']\n",
      "06/29/2022 04:23:51 - INFO - __main__ -   Epoch: 77 | Batch: 7200/10001 (72%) | G Loss: 2.386245 | C Loss: -0.816125\n",
      "06/29/2022 04:23:51 - INFO - __main__ -   Text: ['The conjecture disregards some uncertainty.']\n",
      "06/29/2022 04:23:52 - INFO - __main__ -   Epoch: 77 | Batch: 7800/10001 (78%) | G Loss: 2.077890 | C Loss: -0.683963\n",
      "06/29/2022 04:23:52 - INFO - __main__ -   Text: ['This method is pseudocode.']\n",
      "06/29/2022 04:23:53 - INFO - __main__ -   Epoch: 77 | Batch: 8400/10001 (84%) | G Loss: 2.258533 | C Loss: -0.743087\n",
      "06/29/2022 04:23:53 - INFO - __main__ -   Text: ['Find out more about diabetes by reading this article.']\n",
      "06/29/2022 04:23:54 - INFO - __main__ -   Epoch: 77 | Batch: 9000/10001 (90%) | G Loss: 2.609398 | C Loss: -0.847755\n",
      "06/29/2022 04:23:54 - INFO - __main__ -   Text: ['This is the main story of Aute!']\n",
      "06/29/2022 04:23:55 - INFO - __main__ -   Epoch: 77 | Batch: 9600/10001 (96%) | G Loss: 2.772813 | C Loss: -0.493044\n",
      "06/29/2022 04:23:55 - INFO - __main__ -   Text: ['Although he had studied physics, seemingly no scientist of a certain caliber could make that claim.']\n",
      "06/29/2022 04:23:56 - INFO - __main__ -   * (Train) Epoch: 77 | G Loss: 2.4674 | C Loss: -0.7518 | Updates G: 58 | Updates C: 775\n",
      "06/29/2022 04:24:05 - INFO - __main__ -   Bleu-2:0.216 | B-Bleu-2:0.251\n",
      "06/29/2022 04:24:05 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46673416319962724\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 78 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:27:29 - INFO - __main__ -   Epoch: 78 | Batch: 0/10001 (0%) | G Loss: 2.704441 | C Loss: -0.629619\n",
      "06/29/2022 04:27:29 - INFO - __main__ -   Text: ['Much of the fuel test is tests around driveability which nonsense.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.877\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:27:30 - INFO - __main__ -   Epoch: 78 | Batch: 600/10001 (6%) | G Loss: 2.222043 | C Loss: -0.738763\n",
      "06/29/2022 04:27:31 - INFO - __main__ -   Text: ['It is the Beatles\\' \"Billboard.\"']\n",
      "06/29/2022 04:27:32 - INFO - __main__ -   Epoch: 78 | Batch: 1200/10001 (12%) | G Loss: 2.427041 | C Loss: -0.641917\n",
      "06/29/2022 04:27:32 - INFO - __main__ -   Text: ['There are also a few violations such as calling out 80 to 90% of your yearly income.']\n",
      "06/29/2022 04:27:33 - INFO - __main__ -   Epoch: 78 | Batch: 1800/10001 (18%) | G Loss: 2.472185 | C Loss: -0.587018\n",
      "06/29/2022 04:27:33 - INFO - __main__ -   Text: ['\"I see one problem with kittens.']\n",
      "06/29/2022 04:27:34 - INFO - __main__ -   Epoch: 78 | Batch: 2400/10001 (24%) | G Loss: 2.524502 | C Loss: -0.744834\n",
      "06/29/2022 04:27:34 - INFO - __main__ -   Text: ['Suppose you have to predict the risks of a takeover by the Autobots.']\n",
      "06/29/2022 04:27:35 - INFO - __main__ -   Epoch: 78 | Batch: 3000/10001 (30%) | G Loss: 2.874811 | C Loss: -0.820004\n",
      "06/29/2022 04:27:35 - INFO - __main__ -   Text: ['Before the new man enters, I feel very vulnerable.\"']\n",
      "06/29/2022 04:27:36 - INFO - __main__ -   Epoch: 78 | Batch: 3600/10001 (36%) | G Loss: 2.541525 | C Loss: -0.670664\n",
      "06/29/2022 04:27:36 - INFO - __main__ -   Text: ['You\\'ll be supporting them on TV on our whole network.\"']\n",
      "06/29/2022 04:27:37 - INFO - __main__ -   Epoch: 78 | Batch: 4200/10001 (42%) | G Loss: 2.342735 | C Loss: -0.858472\n",
      "06/29/2022 04:27:37 - INFO - __main__ -   Text: ['It is sold to many leaders worldwide!']\n",
      "06/29/2022 04:27:38 - INFO - __main__ -   Epoch: 78 | Batch: 4800/10001 (48%) | G Loss: 2.577924 | C Loss: -0.984463\n",
      "06/29/2022 04:27:38 - INFO - __main__ -   Text: ['Narcissus Severus Potter ...']\n",
      "06/29/2022 04:27:39 - INFO - __main__ -   Epoch: 78 | Batch: 5400/10001 (54%) | G Loss: 2.417876 | C Loss: -0.538870\n",
      "06/29/2022 04:27:39 - INFO - __main__ -   Text: ['Gottyo Awsaam!\"']\n",
      "06/29/2022 04:27:40 - INFO - __main__ -   Epoch: 78 | Batch: 6000/10001 (60%) | G Loss: 2.151874 | C Loss: -0.544696\n",
      "06/29/2022 04:27:40 - INFO - __main__ -   Text: ['The website offers advice and small teams.']\n",
      "06/29/2022 04:27:41 - INFO - __main__ -   Epoch: 78 | Batch: 6600/10001 (66%) | G Loss: 3.053068 | C Loss: -0.803545\n",
      "06/29/2022 04:27:41 - INFO - __main__ -   Text: ['Comedy and Me are one verse away from Steve Dickson doing this catchphrase.']\n",
      "06/29/2022 04:27:42 - INFO - __main__ -   Epoch: 78 | Batch: 7200/10001 (72%) | G Loss: 2.472654 | C Loss: -0.705754\n",
      "06/29/2022 04:27:42 - INFO - __main__ -   Text: ['There is no limit or definition...\").']\n",
      "06/29/2022 04:27:43 - INFO - __main__ -   Epoch: 78 | Batch: 7800/10001 (78%) | G Loss: 2.190365 | C Loss: -0.744521\n",
      "06/29/2022 04:27:43 - INFO - __main__ -   Text: ['Trade card is the father of one, and members of the household.']\n",
      "06/29/2022 04:27:44 - INFO - __main__ -   Epoch: 78 | Batch: 8400/10001 (84%) | G Loss: 2.435527 | C Loss: -0.641810\n",
      "06/29/2022 04:27:45 - INFO - __main__ -   Text: ['They are looking for credentials and are laughing about when it comes to switching heads.']\n",
      "06/29/2022 04:27:46 - INFO - __main__ -   Epoch: 78 | Batch: 9000/10001 (90%) | G Loss: 2.536620 | C Loss: -0.522158\n",
      "06/29/2022 04:27:46 - INFO - __main__ -   Text: ['Trainer CR has that score \"Score in Bhartoopa\".']\n",
      "06/29/2022 04:27:47 - INFO - __main__ -   Epoch: 78 | Batch: 9600/10001 (96%) | G Loss: 2.844564 | C Loss: -0.644414\n",
      "06/29/2022 04:27:47 - INFO - __main__ -   Text: ['When she turns to look if you are where she started the song, she does not hear it.\"']\n",
      "06/29/2022 04:27:47 - INFO - __main__ -   * (Train) Epoch: 78 | G Loss: 2.5268 | C Loss: -0.7263 | Updates G: 76 | Updates C: 757\n",
      "06/29/2022 04:27:56 - INFO - __main__ -   Bleu-2:0.218 | B-Bleu-2:0.245\n",
      "06/29/2022 04:27:56 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46342304065790896\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 79 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:31:26 - INFO - __main__ -   Epoch: 79 | Batch: 0/10001 (0%) | G Loss: 2.628816 | C Loss: -0.687743\n",
      "06/29/2022 04:31:27 - INFO - __main__ -   Text: ['Desiring nature damages everyone.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.855\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:31:28 - INFO - __main__ -   Epoch: 79 | Batch: 600/10001 (6%) | G Loss: 2.356446 | C Loss: -0.775849\n",
      "06/29/2022 04:31:28 - INFO - __main__ -   Text: [\"Sub Hard is someone who tries hard to express that attitude of 'good.\"]\n",
      "06/29/2022 04:31:29 - INFO - __main__ -   Epoch: 79 | Batch: 1200/10001 (12%) | G Loss: 2.434849 | C Loss: -0.690308\n",
      "06/29/2022 04:31:29 - INFO - __main__ -   Text: ['Akkerman is a famous inventor in Japan.']\n",
      "06/29/2022 04:31:30 - INFO - __main__ -   Epoch: 79 | Batch: 1800/10001 (18%) | G Loss: 2.835252 | C Loss: -0.727990\n",
      "06/29/2022 04:31:30 - INFO - __main__ -   Text: ['The effect stated above is of huge cruelty.']\n",
      "06/29/2022 04:31:31 - INFO - __main__ -   Epoch: 79 | Batch: 2400/10001 (24%) | G Loss: 2.664409 | C Loss: -0.803900\n",
      "06/29/2022 04:31:31 - INFO - __main__ -   Text: ['He is the type of man who works compulsive megalomaniac.\"']\n",
      "06/29/2022 04:31:32 - INFO - __main__ -   Epoch: 79 | Batch: 3000/10001 (30%) | G Loss: 2.697428 | C Loss: -0.769476\n",
      "06/29/2022 04:31:32 - INFO - __main__ -   Text: ['With Crazy Options below.']\n",
      "06/29/2022 04:31:33 - INFO - __main__ -   Epoch: 79 | Batch: 3600/10001 (36%) | G Loss: 2.531804 | C Loss: -0.708011\n",
      "06/29/2022 04:31:33 - INFO - __main__ -   Text: ['(…) Seek Breaking <BOS>\".']\n",
      "06/29/2022 04:31:34 - INFO - __main__ -   Epoch: 79 | Batch: 4200/10001 (42%) | G Loss: 2.405267 | C Loss: -0.739253\n",
      "06/29/2022 04:31:34 - INFO - __main__ -   Text: ['Be thankful I-96 makes fantastic news.']\n",
      "06/29/2022 04:31:35 - INFO - __main__ -   Epoch: 79 | Batch: 4800/10001 (48%) | G Loss: 2.501576 | C Loss: -0.746102\n",
      "06/29/2022 04:31:35 - INFO - __main__ -   Text: ['A term known to many punters is blueblindness.']\n",
      "06/29/2022 04:31:36 - INFO - __main__ -   Epoch: 79 | Batch: 5400/10001 (54%) | G Loss: 2.715209 | C Loss: -0.692813\n",
      "06/29/2022 04:31:36 - INFO - __main__ -   Text: ['He resembles people who seldom pass as lawyers.']\n",
      "06/29/2022 04:31:37 - INFO - __main__ -   Epoch: 79 | Batch: 6000/10001 (60%) | G Loss: 2.860739 | C Loss: -0.640430\n",
      "06/29/2022 04:31:37 - INFO - __main__ -   Text: ['Robert Frost recently suggested that these types of songs are more appropriate than real French.']\n",
      "06/29/2022 04:31:38 - INFO - __main__ -   Epoch: 79 | Batch: 6600/10001 (66%) | G Loss: 2.807844 | C Loss: -0.666428\n",
      "06/29/2022 04:31:39 - INFO - __main__ -   Text: ['Birther may be called gypsy.']\n",
      "06/29/2022 04:31:39 - INFO - __main__ -   Epoch: 79 | Batch: 7200/10001 (72%) | G Loss: 2.391016 | C Loss: -0.751430\n",
      "06/29/2022 04:31:40 - INFO - __main__ -   Text: ['The only major negative thing he says about himself is that he looks like he is overweight.']\n",
      "06/29/2022 04:31:41 - INFO - __main__ -   Epoch: 79 | Batch: 7800/10001 (78%) | G Loss: 2.464122 | C Loss: -0.718908\n",
      "06/29/2022 04:31:41 - INFO - __main__ -   Text: ['Peter jokingly tells you that they will win Rocks!']\n",
      "06/29/2022 04:31:42 - INFO - __main__ -   Epoch: 79 | Batch: 8400/10001 (84%) | G Loss: 3.040624 | C Loss: -0.590899\n",
      "06/29/2022 04:31:42 - INFO - __main__ -   Text: ['He is easily turned into a motorcycle thief.']\n",
      "06/29/2022 04:31:43 - INFO - __main__ -   Epoch: 79 | Batch: 9000/10001 (90%) | G Loss: 2.777554 | C Loss: -0.957273\n",
      "06/29/2022 04:31:43 - INFO - __main__ -   Text: ['Do you get lucky?']\n",
      "06/29/2022 04:31:44 - INFO - __main__ -   Epoch: 79 | Batch: 9600/10001 (96%) | G Loss: 2.626055 | C Loss: -0.720344\n",
      "06/29/2022 04:31:44 - INFO - __main__ -   Text: ['Because the Lord knows your mother is so helpless... The only answer will be the silence.\"']\n",
      "06/29/2022 04:31:45 - INFO - __main__ -   * (Train) Epoch: 79 | G Loss: 2.5390 | C Loss: -0.7044 | Updates G: 61 | Updates C: 772\n",
      "06/29/2022 04:31:54 - INFO - __main__ -   Bleu-2:0.216 | B-Bleu-2:0.260\n",
      "06/29/2022 04:31:54 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4760605385544092\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 80 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:35:27 - INFO - __main__ -   Epoch: 80 | Batch: 0/10001 (0%) | G Loss: 2.821032 | C Loss: -0.680894\n",
      "06/29/2022 04:35:27 - INFO - __main__ -   Text: ['\" penium.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.871\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:35:28 - INFO - __main__ -   Epoch: 80 | Batch: 600/10001 (6%) | G Loss: 2.639752 | C Loss: -0.696952\n",
      "06/29/2022 04:35:28 - INFO - __main__ -   Text: ['Markus Selve advises choosing Bombicaks... <PAD> parasol.']\n",
      "06/29/2022 04:35:29 - INFO - __main__ -   Epoch: 80 | Batch: 1200/10001 (12%) | G Loss: 2.304189 | C Loss: -0.455618\n",
      "06/29/2022 04:35:29 - INFO - __main__ -   Text: ['He can\\'t see what\\'s going on in this world and is indifferent because he\\'s not harming anybody.\"']\n",
      "06/29/2022 04:35:30 - INFO - __main__ -   Epoch: 80 | Batch: 1800/10001 (18%) | G Loss: 2.456548 | C Loss: -0.740449\n",
      "06/29/2022 04:35:30 - INFO - __main__ -   Text: ['Hurricanes may also pose cannon fodder.']\n",
      "06/29/2022 04:35:31 - INFO - __main__ -   Epoch: 80 | Batch: 2400/10001 (24%) | G Loss: 2.411255 | C Loss: -0.550548\n",
      "06/29/2022 04:35:31 - INFO - __main__ -   Text: [\"Atatools' computational education).\"]\n",
      "06/29/2022 04:35:32 - INFO - __main__ -   Epoch: 80 | Batch: 3000/10001 (30%) | G Loss: 2.450595 | C Loss: -0.582381\n",
      "06/29/2022 04:35:32 - INFO - __main__ -   Text: ['Meek as the introduction that belongs:']\n",
      "06/29/2022 04:35:33 - INFO - __main__ -   Epoch: 80 | Batch: 3600/10001 (36%) | G Loss: 2.577095 | C Loss: -0.576962\n",
      "06/29/2022 04:35:33 - INFO - __main__ -   Text: ['Oda is a casual photo-sport app bought by Nine East Asia.']\n",
      "06/29/2022 04:35:34 - INFO - __main__ -   Epoch: 80 | Batch: 4200/10001 (42%) | G Loss: 2.496241 | C Loss: -0.660549\n",
      "06/29/2022 04:35:34 - INFO - __main__ -   Text: ['This person can be: A shorthand for a healthicisist in most ancestry.']\n",
      "06/29/2022 04:35:35 - INFO - __main__ -   Epoch: 80 | Batch: 4800/10001 (48%) | G Loss: 2.687653 | C Loss: -0.609489\n",
      "06/29/2022 04:35:35 - INFO - __main__ -   Text: [\"In short, I'll stay in class, probably silent.\"]\n",
      "06/29/2022 04:35:36 - INFO - __main__ -   Epoch: 80 | Batch: 5400/10001 (54%) | G Loss: 2.861757 | C Loss: -0.623553\n",
      "06/29/2022 04:35:36 - INFO - __main__ -   Text: ['This is seen purely in fish.']\n",
      "06/29/2022 04:35:37 - INFO - __main__ -   Epoch: 80 | Batch: 6000/10001 (60%) | G Loss: 2.411623 | C Loss: -0.663276\n",
      "06/29/2022 04:35:37 - INFO - __main__ -   Text: ['The CZ program is a fun and quiet obsession.']\n",
      "06/29/2022 04:35:38 - INFO - __main__ -   Epoch: 80 | Batch: 6600/10001 (66%) | G Loss: 2.336314 | C Loss: -0.793094\n",
      "06/29/2022 04:35:39 - INFO - __main__ -   Text: ['Several tutorials label authentication as the pluglib-powered authenticator and Cygplotbank nullify forced authentication.']\n",
      "06/29/2022 04:35:40 - INFO - __main__ -   Epoch: 80 | Batch: 7200/10001 (72%) | G Loss: 2.448639 | C Loss: -0.999549\n",
      "06/29/2022 04:35:40 - INFO - __main__ -   Text: [\"As well as being virtually Karl Meerzebwicki's favourite rock 'n' roll song.\"]\n",
      "06/29/2022 04:35:41 - INFO - __main__ -   Epoch: 80 | Batch: 7800/10001 (78%) | G Loss: 2.824533 | C Loss: -0.761079\n",
      "06/29/2022 04:35:41 - INFO - __main__ -   Text: ['The \"family half cheating game\" might be difficult to defend.']\n",
      "06/29/2022 04:35:42 - INFO - __main__ -   Epoch: 80 | Batch: 8400/10001 (84%) | G Loss: 2.530424 | C Loss: -0.585665\n",
      "06/29/2022 04:35:42 - INFO - __main__ -   Text: ['These basic amount of skill selectability builds very good billing.']\n",
      "06/29/2022 04:35:43 - INFO - __main__ -   Epoch: 80 | Batch: 9000/10001 (90%) | G Loss: 2.604496 | C Loss: -0.663139\n",
      "06/29/2022 04:35:43 - INFO - __main__ -   Text: ['After 50K...']\n",
      "06/29/2022 04:35:44 - INFO - __main__ -   Epoch: 80 | Batch: 9600/10001 (96%) | G Loss: 2.775343 | C Loss: -0.952329\n",
      "06/29/2022 04:35:44 - INFO - __main__ -   Text: [\"If the family can't go out they have an Easter egg to eat.\"]\n",
      "06/29/2022 04:35:45 - INFO - __main__ -   * (Train) Epoch: 80 | G Loss: 2.5152 | C Loss: -0.6983 | Updates G: 50 | Updates C: 783\n",
      "06/29/2022 04:35:54 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.242\n",
      "06/29/2022 04:35:54 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_18.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4495158978533398\n",
      "Train file used is number 18\n",
      "../../yahoo/subdivided_large/train_18.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 81 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:39:21 - INFO - __main__ -   Epoch: 81 | Batch: 0/10001 (0%) | G Loss: 2.830130 | C Loss: -0.734267\n",
      "06/29/2022 04:39:21 - INFO - __main__ -   Text: ['Dr. Gutteau\\'s strategy is to climb mountains \".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.477\n",
      "  Test Loss: 3.941\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:39:22 - INFO - __main__ -   Epoch: 81 | Batch: 600/10001 (6%) | G Loss: 2.151373 | C Loss: -0.617204\n",
      "06/29/2022 04:39:22 - INFO - __main__ -   Text: ['He does not understand that he is a prince.']\n",
      "06/29/2022 04:39:23 - INFO - __main__ -   Epoch: 81 | Batch: 1200/10001 (12%) | G Loss: 2.409963 | C Loss: -0.983969\n",
      "06/29/2022 04:39:23 - INFO - __main__ -   Text: ['Examples of these are robotics and computer programming.']\n",
      "06/29/2022 04:39:24 - INFO - __main__ -   Epoch: 81 | Batch: 1800/10001 (18%) | G Loss: 2.979087 | C Loss: -1.067686\n",
      "06/29/2022 04:39:24 - INFO - __main__ -   Text: ['He develops a cell to understand how normal people mental process.']\n",
      "06/29/2022 04:39:25 - INFO - __main__ -   Epoch: 81 | Batch: 2400/10001 (24%) | G Loss: 2.343145 | C Loss: -0.469076\n",
      "06/29/2022 04:39:25 - INFO - __main__ -   Text: ['Not only that, but that this prime freely exists.']\n",
      "06/29/2022 04:39:26 - INFO - __main__ -   Epoch: 81 | Batch: 3000/10001 (30%) | G Loss: 3.067343 | C Loss: -0.774838\n",
      "06/29/2022 04:39:26 - INFO - __main__ -   Text: [\"Unlike other people, he's basically on straight but not mad.\"]\n",
      "06/29/2022 04:39:27 - INFO - __main__ -   Epoch: 81 | Batch: 3600/10001 (36%) | G Loss: 3.084411 | C Loss: -0.759342\n",
      "06/29/2022 04:39:27 - INFO - __main__ -   Text: ['He manages a mysterious martial attack.']\n",
      "06/29/2022 04:39:28 - INFO - __main__ -   Epoch: 81 | Batch: 4200/10001 (42%) | G Loss: 2.257398 | C Loss: -0.663152\n",
      "06/29/2022 04:39:28 - INFO - __main__ -   Text: ['Aspects of consciousness.']\n",
      "06/29/2022 04:39:29 - INFO - __main__ -   Epoch: 81 | Batch: 4800/10001 (48%) | G Loss: 2.019587 | C Loss: -0.717758\n",
      "06/29/2022 04:39:29 - INFO - __main__ -   Text: ['A lot of the fun in the game is when S3CB hits.']\n",
      "06/29/2022 04:39:30 - INFO - __main__ -   Epoch: 81 | Batch: 5400/10001 (54%) | G Loss: 2.464695 | C Loss: -0.647876\n",
      "06/29/2022 04:39:30 - INFO - __main__ -   Text: ['In this type of novel, the information is almost useless.']\n",
      "06/29/2022 04:39:31 - INFO - __main__ -   Epoch: 81 | Batch: 6000/10001 (60%) | G Loss: 2.582822 | C Loss: -0.677691\n",
      "06/29/2022 04:39:32 - INFO - __main__ -   Text: ['More likely, Grail means something to come to human minds - what kind of secret is being shown to mired in']\n",
      "06/29/2022 04:39:33 - INFO - __main__ -   Epoch: 81 | Batch: 6600/10001 (66%) | G Loss: 2.593830 | C Loss: -0.671454\n",
      "06/29/2022 04:39:33 - INFO - __main__ -   Text: [\"This manticore, '*anything is mine'.\"]\n",
      "06/29/2022 04:39:34 - INFO - __main__ -   Epoch: 81 | Batch: 7200/10001 (72%) | G Loss: 2.567031 | C Loss: -0.674889\n",
      "06/29/2022 04:39:34 - INFO - __main__ -   Text: ['There is a dictionary of \"Wedges\".']\n",
      "06/29/2022 04:39:35 - INFO - __main__ -   Epoch: 81 | Batch: 7800/10001 (78%) | G Loss: 2.397469 | C Loss: -0.690084\n",
      "06/29/2022 04:39:35 - INFO - __main__ -   Text: ['Dawg Pound!']\n",
      "06/29/2022 04:39:36 - INFO - __main__ -   Epoch: 81 | Batch: 8400/10001 (84%) | G Loss: 2.695050 | C Loss: -0.679689\n",
      "06/29/2022 04:39:36 - INFO - __main__ -   Text: ['This test presents several advantages over conventional physics for a person.']\n",
      "06/29/2022 04:39:37 - INFO - __main__ -   Epoch: 81 | Batch: 9000/10001 (90%) | G Loss: 2.506935 | C Loss: -0.631591\n",
      "06/29/2022 04:39:37 - INFO - __main__ -   Text: ['Two thousand years ago we were afraid to smash our heads.']\n",
      "06/29/2022 04:39:38 - INFO - __main__ -   Epoch: 81 | Batch: 9600/10001 (96%) | G Loss: 2.605041 | C Loss: -0.814819\n",
      "06/29/2022 04:39:38 - INFO - __main__ -   Text: ['\"Awake\" is a classically designed life sentence.']\n",
      "06/29/2022 04:39:39 - INFO - __main__ -   * (Train) Epoch: 81 | G Loss: 2.4942 | C Loss: -0.6888 | Updates G: 61 | Updates C: 772\n",
      "06/29/2022 04:39:48 - INFO - __main__ -   Bleu-2:0.202 | B-Bleu-2:0.266\n",
      "06/29/2022 04:39:48 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46757592688943284\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 82 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:43:17 - INFO - __main__ -   Epoch: 82 | Batch: 0/10001 (0%) | G Loss: 2.387848 | C Loss: -0.601628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.830\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:43:17 - INFO - __main__ -   Text: ['There is tension in the village as there are rumours that Bongo may look for a job.']\n",
      "06/29/2022 04:43:18 - INFO - __main__ -   Epoch: 82 | Batch: 600/10001 (6%) | G Loss: 2.088666 | C Loss: -0.598866\n",
      "06/29/2022 04:43:18 - INFO - __main__ -   Text: ['The word chimpanzee mentioned here does not mean weak or independent.']\n",
      "06/29/2022 04:43:19 - INFO - __main__ -   Epoch: 82 | Batch: 1200/10001 (12%) | G Loss: 2.114868 | C Loss: -0.501227\n",
      "06/29/2022 04:43:19 - INFO - __main__ -   Text: ['\"Conv_E\" plays a bad guy music.']\n",
      "06/29/2022 04:43:20 - INFO - __main__ -   Epoch: 82 | Batch: 1800/10001 (18%) | G Loss: 2.415642 | C Loss: -0.635206\n",
      "06/29/2022 04:43:20 - INFO - __main__ -   Text: ['Let it please God\".']\n",
      "06/29/2022 04:43:21 - INFO - __main__ -   Epoch: 82 | Batch: 2400/10001 (24%) | G Loss: 2.817033 | C Loss: -0.731650\n",
      "06/29/2022 04:43:21 - INFO - __main__ -   Text: ['There is a link with EN Memo talkbook.']\n",
      "06/29/2022 04:43:22 - INFO - __main__ -   Epoch: 82 | Batch: 3000/10001 (30%) | G Loss: 2.566050 | C Loss: -0.769583\n",
      "06/29/2022 04:43:22 - INFO - __main__ -   Text: ['They eat cod fish and would be eligible to earn certification for her \"Monagram Web\".']\n",
      "06/29/2022 04:43:23 - INFO - __main__ -   Epoch: 82 | Batch: 3600/10001 (36%) | G Loss: 2.969657 | C Loss: -0.701018\n",
      "06/29/2022 04:43:23 - INFO - __main__ -   Text: ['Plants that say something else can also say.']\n",
      "06/29/2022 04:43:24 - INFO - __main__ -   Epoch: 82 | Batch: 4200/10001 (42%) | G Loss: 2.265004 | C Loss: -0.528154\n",
      "06/29/2022 04:43:24 - INFO - __main__ -   Text: ['Left divided (or somewhat ambiguous) there is not an English subject.']\n",
      "06/29/2022 04:43:25 - INFO - __main__ -   Epoch: 82 | Batch: 4800/10001 (48%) | G Loss: 2.384263 | C Loss: -0.707755\n",
      "06/29/2022 04:43:25 - INFO - __main__ -   Text: ['Mike is aware of the social abyss and acknowledges it when challenged.']\n",
      "06/29/2022 04:43:26 - INFO - __main__ -   Epoch: 82 | Batch: 5400/10001 (54%) | G Loss: 2.451269 | C Loss: -0.754113\n",
      "06/29/2022 04:43:26 - INFO - __main__ -   Text: ['Workers mostly use the term opposite vector space theories.']\n",
      "06/29/2022 04:43:27 - INFO - __main__ -   Epoch: 82 | Batch: 6000/10001 (60%) | G Loss: 2.473682 | C Loss: -0.628906\n",
      "06/29/2022 04:43:28 - INFO - __main__ -   Text: ['Bold Sammy is written reveling in its longest hieroglyph.']\n",
      "06/29/2022 04:43:29 - INFO - __main__ -   Epoch: 82 | Batch: 6600/10001 (66%) | G Loss: 2.842121 | C Loss: -0.723010\n",
      "06/29/2022 04:43:29 - INFO - __main__ -   Text: ['Some this is okay.']\n",
      "06/29/2022 04:43:30 - INFO - __main__ -   Epoch: 82 | Batch: 7200/10001 (72%) | G Loss: 2.420822 | C Loss: -0.849410\n",
      "06/29/2022 04:43:30 - INFO - __main__ -   Text: ['This character was originally conceived by Jon Watson.']\n",
      "06/29/2022 04:43:31 - INFO - __main__ -   Epoch: 82 | Batch: 7800/10001 (78%) | G Loss: 2.221730 | C Loss: -0.498558\n",
      "06/29/2022 04:43:31 - INFO - __main__ -   Text: ['Many computer games have an adolescent mastermind.']\n",
      "06/29/2022 04:43:32 - INFO - __main__ -   Epoch: 82 | Batch: 8400/10001 (84%) | G Loss: 2.785769 | C Loss: -0.757272\n",
      "06/29/2022 04:43:32 - INFO - __main__ -   Text: ['When food is such a big problem, we are immune.']\n",
      "06/29/2022 04:43:33 - INFO - __main__ -   Epoch: 82 | Batch: 9000/10001 (90%) | G Loss: 2.353515 | C Loss: -0.690793\n",
      "06/29/2022 04:43:33 - INFO - __main__ -   Text: ['He and his friends are paranoid and so they cannot do anything.']\n",
      "06/29/2022 04:43:34 - INFO - __main__ -   Epoch: 82 | Batch: 9600/10001 (96%) | G Loss: 2.399734 | C Loss: -0.491414\n",
      "06/29/2022 04:43:34 - INFO - __main__ -   Text: ['Alas, however, some of the Jing family turn blue [].']\n",
      "06/29/2022 04:43:35 - INFO - __main__ -   * (Train) Epoch: 82 | G Loss: 2.4352 | C Loss: -0.6614 | Updates G: 54 | Updates C: 779\n",
      "06/29/2022 04:43:44 - INFO - __main__ -   Bleu-2:0.205 | B-Bleu-2:0.269\n",
      "06/29/2022 04:43:44 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47461451361649154\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 83 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:18.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:47:19 - INFO - __main__ -   Epoch: 83 | Batch: 0/10001 (0%) | G Loss: 2.631639 | C Loss: -0.780973\n",
      "06/29/2022 04:47:19 - INFO - __main__ -   Text: ['In the eternal light thy words are written.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.771\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:47:20 - INFO - __main__ -   Epoch: 83 | Batch: 600/10001 (6%) | G Loss: 2.380357 | C Loss: -0.668863\n",
      "06/29/2022 04:47:20 - INFO - __main__ -   Text: ['One of these name proteins which ensures that harassment kills mosquito.']\n",
      "06/29/2022 04:47:21 - INFO - __main__ -   Epoch: 83 | Batch: 1200/10001 (12%) | G Loss: 2.215463 | C Loss: -0.568618\n",
      "06/29/2022 04:47:21 - INFO - __main__ -   Text: ['Terrificly strong.\"']\n",
      "06/29/2022 04:47:22 - INFO - __main__ -   Epoch: 83 | Batch: 1800/10001 (18%) | G Loss: 2.344768 | C Loss: -0.696437\n",
      "06/29/2022 04:47:22 - INFO - __main__ -   Text: ['This now very chillingly social feeds show how to do.']\n",
      "06/29/2022 04:47:23 - INFO - __main__ -   Epoch: 83 | Batch: 2400/10001 (24%) | G Loss: 2.601311 | C Loss: -0.653650\n",
      "06/29/2022 04:47:24 - INFO - __main__ -   Text: ['Machine intelligence is important because it determines how powerful an AI clock is.']\n",
      "06/29/2022 04:47:25 - INFO - __main__ -   Epoch: 83 | Batch: 3000/10001 (30%) | G Loss: 2.775151 | C Loss: -0.855099\n",
      "06/29/2022 04:47:25 - INFO - __main__ -   Text: ['By now I hope to thoroughly test packets before selling any.\"']\n",
      "06/29/2022 04:47:26 - INFO - __main__ -   Epoch: 83 | Batch: 3600/10001 (36%) | G Loss: 2.618120 | C Loss: -0.592166\n",
      "06/29/2022 04:47:26 - INFO - __main__ -   Text: ['Our Lookat gag gets called \"The Ballad Don\\'t Show!\".']\n",
      "06/29/2022 04:47:27 - INFO - __main__ -   Epoch: 83 | Batch: 4200/10001 (42%) | G Loss: 2.357020 | C Loss: -0.499627\n",
      "06/29/2022 04:47:27 - INFO - __main__ -   Text: ['That is some of his creative writing.\"']\n",
      "06/29/2022 04:47:28 - INFO - __main__ -   Epoch: 83 | Batch: 4800/10001 (48%) | G Loss: 2.790048 | C Loss: -0.604956\n",
      "06/29/2022 04:47:28 - INFO - __main__ -   Text: ['He writes that, \"Alpha males love meat.\"']\n",
      "06/29/2022 04:47:29 - INFO - __main__ -   Epoch: 83 | Batch: 5400/10001 (54%) | G Loss: 2.768482 | C Loss: -0.731712\n",
      "06/29/2022 04:47:29 - INFO - __main__ -   Text: ['Global hysteria is shewn by:- custom koalai.']\n",
      "06/29/2022 04:47:30 - INFO - __main__ -   Epoch: 83 | Batch: 6000/10001 (60%) | G Loss: 2.419184 | C Loss: -0.540504\n",
      "06/29/2022 04:47:30 - INFO - __main__ -   Text: ['This is Liddy!']\n",
      "06/29/2022 04:47:31 - INFO - __main__ -   Epoch: 83 | Batch: 6600/10001 (66%) | G Loss: 2.556461 | C Loss: -0.690740\n",
      "06/29/2022 04:47:31 - INFO - __main__ -   Text: [\"He says 'Give me the Churches'.\"]\n",
      "06/29/2022 04:47:32 - INFO - __main__ -   Epoch: 83 | Batch: 7200/10001 (72%) | G Loss: 2.687134 | C Loss: -0.698613\n",
      "06/29/2022 04:47:32 - INFO - __main__ -   Text: ['Cristiano does not play here if he falls out of the tournament.']\n",
      "06/29/2022 04:47:33 - INFO - __main__ -   Epoch: 83 | Batch: 7800/10001 (78%) | G Loss: 3.243334 | C Loss: -0.786673\n",
      "06/29/2022 04:47:33 - INFO - __main__ -   Text: ['Herpes cysticus is a condition defined by David G. Puddot as \"measuring by finger']\n",
      "06/29/2022 04:47:34 - INFO - __main__ -   Epoch: 83 | Batch: 8400/10001 (84%) | G Loss: 2.159441 | C Loss: -0.736159\n",
      "06/29/2022 04:47:34 - INFO - __main__ -   Text: ['A company may charge $195 if they can prove that you guessed correctly.']\n",
      "06/29/2022 04:47:35 - INFO - __main__ -   Epoch: 83 | Batch: 9000/10001 (90%) | G Loss: 2.238846 | C Loss: -0.750073\n",
      "06/29/2022 04:47:36 - INFO - __main__ -   Text: ['Therefore he is beatable, I can beat you.\"']\n",
      "06/29/2022 04:47:36 - INFO - __main__ -   Epoch: 83 | Batch: 9600/10001 (96%) | G Loss: 2.655991 | C Loss: -0.783570\n",
      "06/29/2022 04:47:37 - INFO - __main__ -   Text: ['\"singularly telepathic\".']\n",
      "06/29/2022 04:47:37 - INFO - __main__ -   * (Train) Epoch: 83 | G Loss: 2.5492 | C Loss: -0.6605 | Updates G: 58 | Updates C: 775\n",
      "06/29/2022 04:47:47 - INFO - __main__ -   Bleu-2:0.174 | B-Bleu-2:0.238\n",
      "06/29/2022 04:47:47 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41251732618330494\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 84 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:51:12 - INFO - __main__ -   Epoch: 84 | Batch: 0/10000 (0%) | G Loss: 3.313134 | C Loss: -0.771419\n",
      "06/29/2022 04:51:12 - INFO - __main__ -   Text: ['Khodal allows two different types of living organisms.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.850\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:51:13 - INFO - __main__ -   Epoch: 84 | Batch: 600/10000 (6%) | G Loss: 2.675529 | C Loss: -0.701295\n",
      "06/29/2022 04:51:13 - INFO - __main__ -   Text: ['A chemical trade name may refer to a sea telegraph store.']\n",
      "06/29/2022 04:51:14 - INFO - __main__ -   Epoch: 84 | Batch: 1200/10000 (12%) | G Loss: 2.563236 | C Loss: -0.654678\n",
      "06/29/2022 04:51:14 - INFO - __main__ -   Text: ['The bar Basically all pub-sitting locals consist of club 101.\"']\n",
      "06/29/2022 04:51:15 - INFO - __main__ -   Epoch: 84 | Batch: 1800/10000 (18%) | G Loss: 2.377302 | C Loss: -0.651967\n",
      "06/29/2022 04:51:15 - INFO - __main__ -   Text: ['Its voice is clear and the mood is right.\"']\n",
      "06/29/2022 04:51:16 - INFO - __main__ -   Epoch: 84 | Batch: 2400/10000 (24%) | G Loss: 2.337545 | C Loss: -0.628881\n",
      "06/29/2022 04:51:16 - INFO - __main__ -   Text: ['Attention to details is usually defined from B.']\n",
      "06/29/2022 04:51:17 - INFO - __main__ -   Epoch: 84 | Batch: 3000/10000 (30%) | G Loss: 2.412215 | C Loss: -0.615319\n",
      "06/29/2022 04:51:17 - INFO - __main__ -   Text: ['He holds several fake scam brokers scams against his friend Ravi.']\n",
      "06/29/2022 04:51:18 - INFO - __main__ -   Epoch: 84 | Batch: 3600/10000 (36%) | G Loss: 2.532974 | C Loss: -0.495844\n",
      "06/29/2022 04:51:18 - INFO - __main__ -   Text: ['Some hero which needs\\'re to band mate\".']\n",
      "06/29/2022 04:51:19 - INFO - __main__ -   Epoch: 84 | Batch: 4200/10000 (42%) | G Loss: 2.425110 | C Loss: -0.695502\n",
      "06/29/2022 04:51:19 - INFO - __main__ -   Text: ['IT is deeply embedded in the global domain of culture.']\n",
      "06/29/2022 04:51:20 - INFO - __main__ -   Epoch: 84 | Batch: 4800/10000 (48%) | G Loss: 2.594235 | C Loss: -0.652101\n",
      "06/29/2022 04:51:21 - INFO - __main__ -   Text: ['Each leadership falls into two camps: 1) suppressing conservative voices in all but name.']\n",
      "06/29/2022 04:51:22 - INFO - __main__ -   Epoch: 84 | Batch: 5400/10000 (54%) | G Loss: 2.865479 | C Loss: -0.504040\n",
      "06/29/2022 04:51:22 - INFO - __main__ -   Text: ['He finds himself on the slippery slope of \"open sourcing\" software.']\n",
      "06/29/2022 04:51:23 - INFO - __main__ -   Epoch: 84 | Batch: 6000/10000 (60%) | G Loss: 2.627833 | C Loss: -0.635319\n",
      "06/29/2022 04:51:23 - INFO - __main__ -   Text: ['Dad would often say, \"You\\'re probably raised for the free market!\"']\n",
      "06/29/2022 04:51:24 - INFO - __main__ -   Epoch: 84 | Batch: 6600/10000 (66%) | G Loss: 2.371908 | C Loss: -0.682636\n",
      "06/29/2022 04:51:24 - INFO - __main__ -   Text: ['If neuroscience cannot integrate consciousness with reality, then it may be our most destructive ideology.']\n",
      "06/29/2022 04:51:25 - INFO - __main__ -   Epoch: 84 | Batch: 7200/10000 (72%) | G Loss: 2.428544 | C Loss: -0.627862\n",
      "06/29/2022 04:51:25 - INFO - __main__ -   Text: [\"In Mama'u Around You Set Sigs\"]\n",
      "06/29/2022 04:51:26 - INFO - __main__ -   Epoch: 84 | Batch: 7800/10000 (78%) | G Loss: 2.611623 | C Loss: -0.473515\n",
      "06/29/2022 04:51:26 - INFO - __main__ -   Text: ['\"\"\"\") Another hilarious answer.']\n",
      "06/29/2022 04:51:27 - INFO - __main__ -   Epoch: 84 | Batch: 8400/10000 (84%) | G Loss: 2.542066 | C Loss: -0.729576\n",
      "06/29/2022 04:51:27 - INFO - __main__ -   Text: ['Sly is a good-house love.']\n",
      "06/29/2022 04:51:28 - INFO - __main__ -   Epoch: 84 | Batch: 9000/10000 (90%) | G Loss: 2.322746 | C Loss: -0.659394\n",
      "06/29/2022 04:51:28 - INFO - __main__ -   Text: ['Upon entering this list methodology is number 5, largest.']\n",
      "06/29/2022 04:51:29 - INFO - __main__ -   Epoch: 84 | Batch: 9600/10000 (96%) | G Loss: 2.542757 | C Loss: -0.675293\n",
      "06/29/2022 04:51:29 - INFO - __main__ -   Text: [\"She caters to 'nod'.\"]\n",
      "06/29/2022 04:51:30 - INFO - __main__ -   * (Train) Epoch: 84 | G Loss: 2.5054 | C Loss: -0.6380 | Updates G: 71 | Updates C: 762\n",
      "06/29/2022 04:51:39 - INFO - __main__ -   Bleu-2:0.217 | B-Bleu-2:0.259\n",
      "06/29/2022 04:51:39 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47594851830177337\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 85 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:55:09 - INFO - __main__ -   Epoch: 85 | Batch: 0/10000 (0%) | G Loss: 2.668341 | C Loss: -0.749370\n",
      "06/29/2022 04:55:09 - INFO - __main__ -   Text: ['Bright by night, he considers itHis name.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.873\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:55:10 - INFO - __main__ -   Epoch: 85 | Batch: 600/10000 (6%) | G Loss: 2.479982 | C Loss: -0.754234\n",
      "06/29/2022 04:55:10 - INFO - __main__ -   Text: ['The Chosen One Who Never Let ...']\n",
      "06/29/2022 04:55:11 - INFO - __main__ -   Epoch: 85 | Batch: 1200/10000 (12%) | G Loss: 2.330414 | C Loss: -0.580621\n",
      "06/29/2022 04:55:12 - INFO - __main__ -   Text: ['The best natural law for detecting sybarites is stupidity.']\n",
      "06/29/2022 04:55:13 - INFO - __main__ -   Epoch: 85 | Batch: 1800/10000 (18%) | G Loss: 2.492297 | C Loss: -0.626174\n",
      "06/29/2022 04:55:13 - INFO - __main__ -   Text: ['Usually the first few tromping is of old age.']\n",
      "06/29/2022 04:55:14 - INFO - __main__ -   Epoch: 85 | Batch: 2400/10000 (24%) | G Loss: 2.454840 | C Loss: -0.517787\n",
      "06/29/2022 04:55:14 - INFO - __main__ -   Text: ['It is considered to be called the well of the wedding feast and some say it has the best health.']\n",
      "06/29/2022 04:55:15 - INFO - __main__ -   Epoch: 85 | Batch: 3000/10000 (30%) | G Loss: 2.486459 | C Loss: -0.636893\n",
      "06/29/2022 04:55:15 - INFO - __main__ -   Text: ['If values are calculated as entirely real, then $100 million plus.']\n",
      "06/29/2022 04:55:16 - INFO - __main__ -   Epoch: 85 | Batch: 3600/10000 (36%) | G Loss: 2.899360 | C Loss: -0.547586\n",
      "06/29/2022 04:55:16 - INFO - __main__ -   Text: ['The option is that some people should be happy to earn money, and if not.']\n",
      "06/29/2022 04:55:17 - INFO - __main__ -   Epoch: 85 | Batch: 4200/10000 (42%) | G Loss: 2.682172 | C Loss: -0.653259\n",
      "06/29/2022 04:55:17 - INFO - __main__ -   Text: [\"In contrast, Cosby attracts some voices that don't resemble hugs.\"]\n",
      "06/29/2022 04:55:18 - INFO - __main__ -   Epoch: 85 | Batch: 4800/10000 (48%) | G Loss: 2.335044 | C Loss: -0.587656\n",
      "06/29/2022 04:55:18 - INFO - __main__ -   Text: ['!']\n",
      "06/29/2022 04:55:19 - INFO - __main__ -   Epoch: 85 | Batch: 5400/10000 (54%) | G Loss: 2.520207 | C Loss: -0.737818\n",
      "06/29/2022 04:55:19 - INFO - __main__ -   Text: ['Skype Warpa Arr can be heard !']\n",
      "06/29/2022 04:55:20 - INFO - __main__ -   Epoch: 85 | Batch: 6000/10000 (60%) | G Loss: 2.378628 | C Loss: -0.593890\n",
      "06/29/2022 04:55:20 - INFO - __main__ -   Text: ['It is uncertain if this creature is 6000 years old or 2500 years old.']\n",
      "06/29/2022 04:55:21 - INFO - __main__ -   Epoch: 85 | Batch: 6600/10000 (66%) | G Loss: 2.386703 | C Loss: -0.631660\n",
      "06/29/2022 04:55:21 - INFO - __main__ -   Text: ['In mammals, the phenomenon \"plasmon.\"']\n",
      "06/29/2022 04:55:22 - INFO - __main__ -   Epoch: 85 | Batch: 7200/10000 (72%) | G Loss: 2.430297 | C Loss: -0.560422\n",
      "06/29/2022 04:55:23 - INFO - __main__ -   Text: ['The node is Water-forward in evolution.']\n",
      "06/29/2022 04:55:23 - INFO - __main__ -   Epoch: 85 | Batch: 7800/10000 (78%) | G Loss: 2.454034 | C Loss: -0.723264\n",
      "06/29/2022 04:55:24 - INFO - __main__ -   Text: ['Upon which different web sites of \"core\".']\n",
      "06/29/2022 04:55:25 - INFO - __main__ -   Epoch: 85 | Batch: 8400/10000 (84%) | G Loss: 2.411860 | C Loss: -0.621173\n",
      "06/29/2022 04:55:25 - INFO - __main__ -   Text: ['Christ on the cosmic level.\"']\n",
      "06/29/2022 04:55:26 - INFO - __main__ -   Epoch: 85 | Batch: 9000/10000 (90%) | G Loss: 2.340372 | C Loss: -0.502598\n",
      "06/29/2022 04:55:26 - INFO - __main__ -   Text: [\"Lightning Power doesn't [violates].\"]\n",
      "06/29/2022 04:55:27 - INFO - __main__ -   Epoch: 85 | Batch: 9600/10000 (96%) | G Loss: 2.495984 | C Loss: -0.557375\n",
      "06/29/2022 04:55:27 - INFO - __main__ -   Text: ['Hyderabad is interested in this.']\n",
      "06/29/2022 04:55:27 - INFO - __main__ -   * (Train) Epoch: 85 | G Loss: 2.4904 | C Loss: -0.6290 | Updates G: 50 | Updates C: 783\n",
      "06/29/2022 04:55:37 - INFO - __main__ -   Bleu-2:0.196 | B-Bleu-2:0.247\n",
      "06/29/2022 04:55:37 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4425988415644622\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 86 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:16.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:33.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:50.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:03:22\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:58:59 - INFO - __main__ -   Epoch: 86 | Batch: 0/10001 (0%) | G Loss: 2.738023 | C Loss: -0.625750\n",
      "06/29/2022 04:59:00 - INFO - __main__ -   Text: ['Between them they calloreins.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.797\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 04:59:01 - INFO - __main__ -   Epoch: 86 | Batch: 600/10001 (6%) | G Loss: 2.557156 | C Loss: -0.628785\n",
      "06/29/2022 04:59:01 - INFO - __main__ -   Text: ['An adult-oriented illustrative model could often be used.']\n",
      "06/29/2022 04:59:02 - INFO - __main__ -   Epoch: 86 | Batch: 1200/10001 (12%) | G Loss: 2.260342 | C Loss: -0.692121\n",
      "06/29/2022 04:59:02 - INFO - __main__ -   Text: ['In other words, a niq nakhon.']\n",
      "06/29/2022 04:59:03 - INFO - __main__ -   Epoch: 86 | Batch: 1800/10001 (18%) | G Loss: 2.541772 | C Loss: -0.606619\n",
      "06/29/2022 04:59:03 - INFO - __main__ -   Text: ['He makes virtually no money at all.']\n",
      "06/29/2022 04:59:04 - INFO - __main__ -   Epoch: 86 | Batch: 2400/10001 (24%) | G Loss: 2.559785 | C Loss: -0.727303\n",
      "06/29/2022 04:59:04 - INFO - __main__ -   Text: ['Old Survivor boy is a small-town club kid.']\n",
      "06/29/2022 04:59:05 - INFO - __main__ -   Epoch: 86 | Batch: 3000/10001 (30%) | G Loss: 2.640454 | C Loss: -0.674628\n",
      "06/29/2022 04:59:05 - INFO - __main__ -   Text: ['Main training is then written as Code to Guide.']\n",
      "06/29/2022 04:59:06 - INFO - __main__ -   Epoch: 86 | Batch: 3600/10001 (36%) | G Loss: 2.555614 | C Loss: -0.642107\n",
      "06/29/2022 04:59:06 - INFO - __main__ -   Text: [\"He actually thinks he exists to believe himself to be the world's most famous athlete.\"]\n",
      "06/29/2022 04:59:07 - INFO - __main__ -   Epoch: 86 | Batch: 4200/10001 (42%) | G Loss: 2.646653 | C Loss: -0.707872\n",
      "06/29/2022 04:59:07 - INFO - __main__ -   Text: [\"He's a freak—a shy fool who gets caught in the right thing.\"]\n",
      "06/29/2022 04:59:08 - INFO - __main__ -   Epoch: 86 | Batch: 4800/10001 (48%) | G Loss: 2.471710 | C Loss: -0.724389\n",
      "06/29/2022 04:59:08 - INFO - __main__ -   Text: ['But there are other factors for \"upstart scruffy\" and \"snot\".']\n",
      "06/29/2022 04:59:09 - INFO - __main__ -   Epoch: 86 | Batch: 5400/10001 (54%) | G Loss: 2.441766 | C Loss: -0.618331\n",
      "06/29/2022 04:59:09 - INFO - __main__ -   Text: [\"Only then would any father stop me from solving him's problems.\"]\n",
      "06/29/2022 04:59:10 - INFO - __main__ -   Epoch: 86 | Batch: 6000/10001 (60%) | G Loss: 2.668892 | C Loss: -0.738250\n",
      "06/29/2022 04:59:11 - INFO - __main__ -   Text: ['This information reveals a new craze that is designed to fool me.']\n",
      "06/29/2022 04:59:12 - INFO - __main__ -   Epoch: 86 | Batch: 6600/10001 (66%) | G Loss: 2.842049 | C Loss: -0.581560\n",
      "06/29/2022 04:59:12 - INFO - __main__ -   Text: ['Afterward, Bill is making his last trip to Las Vegas.']\n",
      "06/29/2022 04:59:13 - INFO - __main__ -   Epoch: 86 | Batch: 7200/10001 (72%) | G Loss: 2.605654 | C Loss: -0.559498\n",
      "06/29/2022 04:59:13 - INFO - __main__ -   Text: ['The suggested string structure of the task.']\n",
      "06/29/2022 04:59:14 - INFO - __main__ -   Epoch: 86 | Batch: 7800/10001 (78%) | G Loss: 2.645462 | C Loss: -0.627997\n",
      "06/29/2022 04:59:14 - INFO - __main__ -   Text: ['The Fox is an alien DNA virus which infects molecular biologist Nikolai Marek.']\n",
      "06/29/2022 04:59:15 - INFO - __main__ -   Epoch: 86 | Batch: 8400/10001 (84%) | G Loss: 2.530394 | C Loss: -0.711243\n",
      "06/29/2022 04:59:15 - INFO - __main__ -   Text: ['The spell is all the same as \"Spell\".']\n",
      "06/29/2022 04:59:16 - INFO - __main__ -   Epoch: 86 | Batch: 9000/10001 (90%) | G Loss: 2.422885 | C Loss: -0.751902\n",
      "06/29/2022 04:59:16 - INFO - __main__ -   Text: ['Storm goes pretty high when her body is 236.\"']\n",
      "06/29/2022 04:59:17 - INFO - __main__ -   Epoch: 86 | Batch: 9600/10001 (96%) | G Loss: 2.535431 | C Loss: -0.577353\n",
      "06/29/2022 04:59:17 - INFO - __main__ -   Text: ['representing McKnight in public is an easy way to get him rail-eyed.']\n",
      "06/29/2022 04:59:18 - INFO - __main__ -   * (Train) Epoch: 86 | G Loss: 2.5094 | C Loss: -0.6229 | Updates G: 59 | Updates C: 774\n",
      "06/29/2022 04:59:27 - INFO - __main__ -   Bleu-2:0.188 | B-Bleu-2:0.264\n",
      "06/29/2022 04:59:27 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4524861086081702\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 87 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:57.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:14.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:49.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:06.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:02:50 - INFO - __main__ -   Epoch: 87 | Batch: 0/10001 (0%) | G Loss: 2.418587 | C Loss: -0.596865\n",
      "06/29/2022 05:02:50 - INFO - __main__ -   Text: ['Affirmatively, it is theory.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.792\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:02:51 - INFO - __main__ -   Epoch: 87 | Batch: 600/10001 (6%) | G Loss: 2.635500 | C Loss: -0.613553\n",
      "06/29/2022 05:02:51 - INFO - __main__ -   Text: ['If you can decide you don\\'t have good radio there.\"']\n",
      "06/29/2022 05:02:52 - INFO - __main__ -   Epoch: 87 | Batch: 1200/10001 (12%) | G Loss: 2.840739 | C Loss: -0.575300\n",
      "06/29/2022 05:02:52 - INFO - __main__ -   Text: ['The Militant Truth: A Truthful Journey to the Empire of Truth.']\n",
      "06/29/2022 05:02:53 - INFO - __main__ -   Epoch: 87 | Batch: 1800/10001 (18%) | G Loss: 2.859239 | C Loss: -0.675282\n",
      "06/29/2022 05:02:54 - INFO - __main__ -   Text: ['It also allows for D&M to use Adele Wedding.']\n",
      "06/29/2022 05:02:54 - INFO - __main__ -   Epoch: 87 | Batch: 2400/10001 (24%) | G Loss: 2.379918 | C Loss: -0.626092\n",
      "06/29/2022 05:02:55 - INFO - __main__ -   Text: ['It was so bad, I don\\'t want to go hungry.\"\"']\n",
      "06/29/2022 05:02:56 - INFO - __main__ -   Epoch: 87 | Batch: 3000/10001 (30%) | G Loss: 2.446482 | C Loss: -0.576050\n",
      "06/29/2022 05:02:56 - INFO - __main__ -   Text: ['Moreover, there needs to be somebody somewhere to board.']\n",
      "06/29/2022 05:02:57 - INFO - __main__ -   Epoch: 87 | Batch: 3600/10001 (36%) | G Loss: 2.862917 | C Loss: -0.653511\n",
      "06/29/2022 05:02:57 - INFO - __main__ -   Text: ['Also, what would you say if you were surrounded by books?\"']\n",
      "06/29/2022 05:02:58 - INFO - __main__ -   Epoch: 87 | Batch: 4200/10001 (42%) | G Loss: 2.721934 | C Loss: -0.632298\n",
      "06/29/2022 05:02:58 - INFO - __main__ -   Text: ['flight pichi games [in].']\n",
      "06/29/2022 05:02:59 - INFO - __main__ -   Epoch: 87 | Batch: 4800/10001 (48%) | G Loss: 2.645144 | C Loss: -0.574852\n",
      "06/29/2022 05:02:59 - INFO - __main__ -   Text: ['The \"pendanta\" formula is 1-sided.']\n",
      "06/29/2022 05:03:00 - INFO - __main__ -   Epoch: 87 | Batch: 5400/10001 (54%) | G Loss: 2.274502 | C Loss: -0.658167\n",
      "06/29/2022 05:03:00 - INFO - __main__ -   Text: ['Go ahead and say something to see below.]']\n",
      "06/29/2022 05:03:01 - INFO - __main__ -   Epoch: 87 | Batch: 6000/10001 (60%) | G Loss: 2.401472 | C Loss: -0.365971\n",
      "06/29/2022 05:03:01 - INFO - __main__ -   Text: ['These missing components are lurking behind human mindness.\"']\n",
      "06/29/2022 05:03:02 - INFO - __main__ -   Epoch: 87 | Batch: 6600/10001 (66%) | G Loss: 3.008540 | C Loss: -0.699708\n",
      "06/29/2022 05:03:02 - INFO - __main__ -   Text: ['All the players do is steal the yips cheaper.']\n",
      "06/29/2022 05:03:03 - INFO - __main__ -   Epoch: 87 | Batch: 7200/10001 (72%) | G Loss: 2.595096 | C Loss: -0.519794\n",
      "06/29/2022 05:03:03 - INFO - __main__ -   Text: ['\"When Art Says\\'\\' is a robot.']\n",
      "06/29/2022 05:03:04 - INFO - __main__ -   Epoch: 87 | Batch: 7800/10001 (78%) | G Loss: 2.559998 | C Loss: -0.533395\n",
      "06/29/2022 05:03:04 - INFO - __main__ -   Text: ['3 - tendency check text.']\n",
      "06/29/2022 05:03:05 - INFO - __main__ -   Epoch: 87 | Batch: 8400/10001 (84%) | G Loss: 2.646748 | C Loss: -0.514337\n",
      "06/29/2022 05:03:05 - INFO - __main__ -   Text: ['The one who can get workers to do their jobs right is \"Charley Batson\".']\n",
      "06/29/2022 05:03:06 - INFO - __main__ -   Epoch: 87 | Batch: 9000/10001 (90%) | G Loss: 2.505751 | C Loss: -0.549161\n",
      "06/29/2022 05:03:07 - INFO - __main__ -   Text: ['If you like kiteboarding it can be viewed by Mikayle/Katy Fly.']\n",
      "06/29/2022 05:03:08 - INFO - __main__ -   Epoch: 87 | Batch: 9600/10001 (96%) | G Loss: 2.696618 | C Loss: -0.481315\n",
      "06/29/2022 05:03:08 - INFO - __main__ -   Text: ['\"Proteous Urineonga\" is an intensive academical analysis.']\n",
      "06/29/2022 05:03:08 - INFO - __main__ -   * (Train) Epoch: 87 | G Loss: 2.5896 | C Loss: -0.6340 | Updates G: 55 | Updates C: 778\n",
      "06/29/2022 05:03:17 - INFO - __main__ -   Bleu-2:0.188 | B-Bleu-2:0.281\n",
      "06/29/2022 05:03:17 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4693887962785148\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 88 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:16.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:33.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:49.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:06:41 - INFO - __main__ -   Epoch: 88 | Batch: 0/10001 (0%) | G Loss: 2.762745 | C Loss: -0.895610\n",
      "06/29/2022 05:06:41 - INFO - __main__ -   Text: ['SANIRUS is their ticket to running a simulator game.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.959\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:06:42 - INFO - __main__ -   Epoch: 88 | Batch: 600/10001 (6%) | G Loss: 2.399782 | C Loss: -0.542791\n",
      "06/29/2022 05:06:42 - INFO - __main__ -   Text: ['Critics want to find it somewhere else.']\n",
      "06/29/2022 05:06:43 - INFO - __main__ -   Epoch: 88 | Batch: 1200/10001 (12%) | G Loss: 2.707445 | C Loss: -0.674068\n",
      "06/29/2022 05:06:43 - INFO - __main__ -   Text: ['Want to listen to the other \"endorphins\".']\n",
      "06/29/2022 05:06:44 - INFO - __main__ -   Epoch: 88 | Batch: 1800/10001 (18%) | G Loss: 2.595963 | C Loss: -0.580292\n",
      "06/29/2022 05:06:44 - INFO - __main__ -   Text: ['While currently (<br> dataExportCertificateCertificate\").']\n",
      "06/29/2022 05:06:45 - INFO - __main__ -   Epoch: 88 | Batch: 2400/10001 (24%) | G Loss: 2.884562 | C Loss: -0.781337\n",
      "06/29/2022 05:06:45 - INFO - __main__ -   Text: ['A trick becomes much easier if you follow it.\"']\n",
      "06/29/2022 05:06:46 - INFO - __main__ -   Epoch: 88 | Batch: 3000/10001 (30%) | G Loss: 2.654465 | C Loss: -0.767171\n",
      "06/29/2022 05:06:46 - INFO - __main__ -   Text: ['Gender is evil without charm.']\n",
      "06/29/2022 05:06:47 - INFO - __main__ -   Epoch: 88 | Batch: 3600/10001 (36%) | G Loss: 3.013803 | C Loss: -0.889102\n",
      "06/29/2022 05:06:48 - INFO - __main__ -   Text: ['If this is conservative, then YOOH is more of a theme book.\"']\n",
      "06/29/2022 05:06:49 - INFO - __main__ -   Epoch: 88 | Batch: 4200/10001 (42%) | G Loss: 3.062320 | C Loss: -0.948536\n",
      "06/29/2022 05:06:49 - INFO - __main__ -   Text: ['How long does this use?']\n",
      "06/29/2022 05:06:50 - INFO - __main__ -   Epoch: 88 | Batch: 4800/10001 (48%) | G Loss: 2.267951 | C Loss: -0.642945\n",
      "06/29/2022 05:06:50 - INFO - __main__ -   Text: ['The players to beat would win Salem State a gold medal.']\n",
      "06/29/2022 05:06:51 - INFO - __main__ -   Epoch: 88 | Batch: 5400/10001 (54%) | G Loss: 2.688166 | C Loss: -0.662371\n",
      "06/29/2022 05:06:51 - INFO - __main__ -   Text: ['Research is usually closed demonstration.']\n",
      "06/29/2022 05:06:52 - INFO - __main__ -   Epoch: 88 | Batch: 6000/10001 (60%) | G Loss: 2.672270 | C Loss: -0.521695\n",
      "06/29/2022 05:06:52 - INFO - __main__ -   Text: ['The bird was known to be unnoticeable.']\n",
      "06/29/2022 05:06:53 - INFO - __main__ -   Epoch: 88 | Batch: 6600/10001 (66%) | G Loss: 2.564040 | C Loss: -0.573229\n",
      "06/29/2022 05:06:53 - INFO - __main__ -   Text: ['Suit Count 1 wins on the marquee sort of job.']\n",
      "06/29/2022 05:06:54 - INFO - __main__ -   Epoch: 88 | Batch: 7200/10001 (72%) | G Loss: 2.713708 | C Loss: -0.616919\n",
      "06/29/2022 05:06:54 - INFO - __main__ -   Text: ['Superman becomes real.']\n",
      "06/29/2022 05:06:55 - INFO - __main__ -   Epoch: 88 | Batch: 7800/10001 (78%) | G Loss: 2.346758 | C Loss: -0.661969\n",
      "06/29/2022 05:06:55 - INFO - __main__ -   Text: ['Either the rather random and the reasonable, that is, that is not very frequent.\"']\n",
      "06/29/2022 05:06:56 - INFO - __main__ -   Epoch: 88 | Batch: 8400/10001 (84%) | G Loss: 2.783673 | C Loss: -0.754848\n",
      "06/29/2022 05:06:56 - INFO - __main__ -   Text: ['More than that, they sometimes can work a magic jelly effect.']\n",
      "06/29/2022 05:06:57 - INFO - __main__ -   Epoch: 88 | Batch: 9000/10001 (90%) | G Loss: 2.748558 | C Loss: -0.676447\n",
      "06/29/2022 05:06:57 - INFO - __main__ -   Text: ['20% down.\"']\n",
      "06/29/2022 05:06:58 - INFO - __main__ -   Epoch: 88 | Batch: 9600/10001 (96%) | G Loss: 2.570199 | C Loss: -0.516740\n",
      "06/29/2022 05:06:58 - INFO - __main__ -   Text: ['The government of Québec has been built.']\n",
      "06/29/2022 05:06:59 - INFO - __main__ -   * (Train) Epoch: 88 | G Loss: 2.6071 | C Loss: -0.6237 | Updates G: 51 | Updates C: 782\n",
      "06/29/2022 05:07:08 - INFO - __main__ -   Bleu-2:0.211 | B-Bleu-2:0.233\n",
      "06/29/2022 05:07:08 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4439919377738921\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 89 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:23.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:39.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:56.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:12.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:28.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:45.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:02.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:03:17\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:10:26 - INFO - __main__ -   Epoch: 89 | Batch: 0/10001 (0%) | G Loss: 2.826833 | C Loss: -0.816420\n",
      "06/29/2022 05:10:26 - INFO - __main__ -   Text: ['The Sialta is also used to describe macro and micro phenomena.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.882\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:10:27 - INFO - __main__ -   Epoch: 89 | Batch: 600/10001 (6%) | G Loss: 3.260852 | C Loss: -0.735473\n",
      "06/29/2022 05:10:27 - INFO - __main__ -   Text: ['Those who are not able to light their own bulb suffer from extreme weakling.']\n",
      "06/29/2022 05:10:28 - INFO - __main__ -   Epoch: 89 | Batch: 1200/10001 (12%) | G Loss: 2.650752 | C Loss: -0.533554\n",
      "06/29/2022 05:10:28 - INFO - __main__ -   Text: ['\"I have a theory that a planet is not an island, but is a jungle option.\"']\n",
      "06/29/2022 05:10:29 - INFO - __main__ -   Epoch: 89 | Batch: 1800/10001 (18%) | G Loss: 2.606421 | C Loss: -0.497954\n",
      "06/29/2022 05:10:29 - INFO - __main__ -   Text: ['The disadvantage of cricket is that bats are a tourist attraction.']\n",
      "06/29/2022 05:10:30 - INFO - __main__ -   Epoch: 89 | Batch: 2400/10001 (24%) | G Loss: 2.635815 | C Loss: -0.772812\n",
      "06/29/2022 05:10:30 - INFO - __main__ -   Text: [\"The company's World War II goal is to sell planks worldwide.\"]\n",
      "06/29/2022 05:10:31 - INFO - __main__ -   Epoch: 89 | Batch: 3000/10001 (30%) | G Loss: 2.746301 | C Loss: -0.893575\n",
      "06/29/2022 05:10:31 - INFO - __main__ -   Text: ['This candidate should read\"uniqueness!\"']\n",
      "06/29/2022 05:10:32 - INFO - __main__ -   Epoch: 89 | Batch: 3600/10001 (36%) | G Loss: 2.434296 | C Loss: -0.640015\n",
      "06/29/2022 05:10:32 - INFO - __main__ -   Text: ['The amount of threat has people speculating it is malicious enterprise.']\n",
      "06/29/2022 05:10:33 - INFO - __main__ -   Epoch: 89 | Batch: 4200/10001 (42%) | G Loss: 2.381986 | C Loss: -0.872577\n",
      "06/29/2022 05:10:33 - INFO - __main__ -   Text: ['Only choose.']\n",
      "06/29/2022 05:10:34 - INFO - __main__ -   Epoch: 89 | Batch: 4800/10001 (48%) | G Loss: 2.594586 | C Loss: -0.693170\n",
      "06/29/2022 05:10:34 - INFO - __main__ -   Text: ['It goes like this, you!']\n",
      "06/29/2022 05:10:35 - INFO - __main__ -   Epoch: 89 | Batch: 5400/10001 (54%) | G Loss: 2.942440 | C Loss: -0.422074\n",
      "06/29/2022 05:10:35 - INFO - __main__ -   Text: ['Therefore, Thereis some information propaganda.']\n",
      "06/29/2022 05:10:36 - INFO - __main__ -   Epoch: 89 | Batch: 6000/10001 (60%) | G Loss: 2.838265 | C Loss: -0.475020\n",
      "06/29/2022 05:10:36 - INFO - __main__ -   Text: ['B-level mathematicians can describe half the formula.']\n",
      "06/29/2022 05:10:37 - INFO - __main__ -   Epoch: 89 | Batch: 6600/10001 (66%) | G Loss: 2.859658 | C Loss: -0.670651\n",
      "06/29/2022 05:10:38 - INFO - __main__ -   Text: ['The most common it says is: \"breaking the law\" or \"wetting the road to hell\".']\n",
      "06/29/2022 05:10:39 - INFO - __main__ -   Epoch: 89 | Batch: 7200/10001 (72%) | G Loss: 3.125280 | C Loss: -0.813590\n",
      "06/29/2022 05:10:39 - INFO - __main__ -   Text: ['But that\\'s all I know from Rhode Island.\"']\n",
      "06/29/2022 05:10:40 - INFO - __main__ -   Epoch: 89 | Batch: 7800/10001 (78%) | G Loss: 2.599507 | C Loss: -1.060816\n",
      "06/29/2022 05:10:40 - INFO - __main__ -   Text: ['Sabah. <BOS> Who?\"']\n",
      "06/29/2022 05:10:41 - INFO - __main__ -   Epoch: 89 | Batch: 8400/10001 (84%) | G Loss: 2.205059 | C Loss: -0.827681\n",
      "06/29/2022 05:10:41 - INFO - __main__ -   Text: ['Some developers excels at a specific language, e.g.']\n",
      "06/29/2022 05:10:42 - INFO - __main__ -   Epoch: 89 | Batch: 9000/10001 (90%) | G Loss: 2.370401 | C Loss: -0.650726\n",
      "06/29/2022 05:10:42 - INFO - __main__ -   Text: [\"Deer is bat'leth.\"]\n",
      "06/29/2022 05:10:43 - INFO - __main__ -   Epoch: 89 | Batch: 9600/10001 (96%) | G Loss: 3.201117 | C Loss: -1.043659\n",
      "06/29/2022 05:10:43 - INFO - __main__ -   Text: ['One can say that sexual phenomenon is not even born.']\n",
      "06/29/2022 05:10:44 - INFO - __main__ -   * (Train) Epoch: 89 | G Loss: 2.6685 | C Loss: -0.6437 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 05:10:53 - INFO - __main__ -   Bleu-2:0.205 | B-Bleu-2:0.267\n",
      "06/29/2022 05:10:53 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4722427136896979\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 90 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:15.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:48.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:05.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:03:22\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:14:15 - INFO - __main__ -   Epoch: 90 | Batch: 0/10001 (0%) | G Loss: 2.863258 | C Loss: -0.397293\n",
      "06/29/2022 05:14:15 - INFO - __main__ -   Text: ['Research is subtle.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.487\n",
      "  Test Loss: 3.955\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:14:16 - INFO - __main__ -   Epoch: 90 | Batch: 600/10001 (6%) | G Loss: 2.497427 | C Loss: -0.428958\n",
      "06/29/2022 05:14:16 - INFO - __main__ -   Text: ['\"PlayQuest\" is the subject of this book.']\n",
      "06/29/2022 05:14:17 - INFO - __main__ -   Epoch: 90 | Batch: 1200/10001 (12%) | G Loss: 3.136586 | C Loss: -0.821783\n",
      "06/29/2022 05:14:17 - INFO - __main__ -   Text: [\"It seems like Ron isn't quite ready to say yes.\"]\n",
      "06/29/2022 05:14:18 - INFO - __main__ -   Epoch: 90 | Batch: 1800/10001 (18%) | G Loss: 2.843563 | C Loss: -0.488683\n",
      "06/29/2022 05:14:18 - INFO - __main__ -   Text: ['This rule differs primarily because of animal needs.']\n",
      "06/29/2022 05:14:19 - INFO - __main__ -   Epoch: 90 | Batch: 2400/10001 (24%) | G Loss: 2.425756 | C Loss: -0.563288\n",
      "06/29/2022 05:14:19 - INFO - __main__ -   Text: ['\"person\" is perhaps quite labors.']\n",
      "06/29/2022 05:14:20 - INFO - __main__ -   Epoch: 90 | Batch: 3000/10001 (30%) | G Loss: 2.098150 | C Loss: -0.558137\n",
      "06/29/2022 05:14:20 - INFO - __main__ -   Text: ['The current value is \"R\". <PAD> In a weakcase English sentence:']\n",
      "06/29/2022 05:14:21 - INFO - __main__ -   Epoch: 90 | Batch: 3600/10001 (36%) | G Loss: 2.253669 | C Loss: -0.667634\n",
      "06/29/2022 05:14:21 - INFO - __main__ -   Text: ['\"It\\'s hopeless\\'.']\n",
      "06/29/2022 05:14:22 - INFO - __main__ -   Epoch: 90 | Batch: 4200/10001 (42%) | G Loss: 2.995811 | C Loss: -0.598200\n",
      "06/29/2022 05:14:22 - INFO - __main__ -   Text: ['The distortion is \"pipes!\"']\n",
      "06/29/2022 05:14:23 - INFO - __main__ -   Epoch: 90 | Batch: 4800/10001 (48%) | G Loss: 3.488068 | C Loss: -0.861850\n",
      "06/29/2022 05:14:24 - INFO - __main__ -   Text: ['The whole \"Hanuman cho-kdi-e\"().']\n",
      "06/29/2022 05:14:25 - INFO - __main__ -   Epoch: 90 | Batch: 5400/10001 (54%) | G Loss: 2.981428 | C Loss: -0.603130\n",
      "06/29/2022 05:14:25 - INFO - __main__ -   Text: ['A core library for a mathematical consulting bot.']\n",
      "06/29/2022 05:14:26 - INFO - __main__ -   Epoch: 90 | Batch: 6000/10001 (60%) | G Loss: 2.154651 | C Loss: -0.676795\n",
      "06/29/2022 05:14:26 - INFO - __main__ -   Text: ['In this flower puzzle onion echt is seen as an ale.']\n",
      "06/29/2022 05:14:27 - INFO - __main__ -   Epoch: 90 | Batch: 6600/10001 (66%) | G Loss: 2.100931 | C Loss: -0.748351\n",
      "06/29/2022 05:14:27 - INFO - __main__ -   Text: ['The Last Word is one of their most acclaimed film.']\n",
      "06/29/2022 05:14:28 - INFO - __main__ -   Epoch: 90 | Batch: 7200/10001 (72%) | G Loss: 2.366816 | C Loss: -0.626894\n",
      "06/29/2022 05:14:28 - INFO - __main__ -   Text: ['Under the Stream label, the ID does not show music at all.']\n",
      "06/29/2022 05:14:29 - INFO - __main__ -   Epoch: 90 | Batch: 7800/10001 (78%) | G Loss: 2.976062 | C Loss: -0.588711\n",
      "06/29/2022 05:14:29 - INFO - __main__ -   Text: ['Physician no God!\" <BOS> every baby!']\n",
      "06/29/2022 05:14:30 - INFO - __main__ -   Epoch: 90 | Batch: 8400/10001 (84%) | G Loss: 3.125612 | C Loss: -0.601820\n",
      "06/29/2022 05:14:30 - INFO - __main__ -   Text: [\"Dobkin Kromer adds a strange truth to Michael Krabs' words.\"]\n",
      "06/29/2022 05:14:31 - INFO - __main__ -   Epoch: 90 | Batch: 9000/10001 (90%) | G Loss: 2.922272 | C Loss: -0.544975\n",
      "06/29/2022 05:14:31 - INFO - __main__ -   Text: ['The Grand Budapest News is how the independent radio world ends up.']\n",
      "06/29/2022 05:14:32 - INFO - __main__ -   Epoch: 90 | Batch: 9600/10001 (96%) | G Loss: 2.516138 | C Loss: -0.730317\n",
      "06/29/2022 05:14:32 - INFO - __main__ -   Text: ['The gregazzi (barrel) ad obsfil.']\n",
      "06/29/2022 05:14:33 - INFO - __main__ -   * (Train) Epoch: 90 | G Loss: 2.5506 | C Loss: -0.6297 | Updates G: 53 | Updates C: 780\n",
      "06/29/2022 05:14:42 - INFO - __main__ -   Bleu-2:0.184 | B-Bleu-2:0.246\n",
      "06/29/2022 05:14:42 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42961568482232515\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 91 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:18:16 - INFO - __main__ -   Epoch: 91 | Batch: 0/10001 (0%) | G Loss: 2.371545 | C Loss: -0.625254\n",
      "06/29/2022 05:18:16 - INFO - __main__ -   Text: ['Not http://xnu.c.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.913\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:18:17 - INFO - __main__ -   Epoch: 91 | Batch: 600/10001 (6%) | G Loss: 2.479491 | C Loss: -0.525078\n",
      "06/29/2022 05:18:17 - INFO - __main__ -   Text: ['This word is generally used as the term for an unfortunate female.']\n",
      "06/29/2022 05:18:18 - INFO - __main__ -   Epoch: 91 | Batch: 1200/10001 (12%) | G Loss: 2.998444 | C Loss: -0.344371\n",
      "06/29/2022 05:18:19 - INFO - __main__ -   Text: ['The goat drinks fizzy milk on vans and is quicker for picking up the particles.']\n",
      "06/29/2022 05:18:20 - INFO - __main__ -   Epoch: 91 | Batch: 1800/10001 (18%) | G Loss: 2.904069 | C Loss: -0.408243\n",
      "06/29/2022 05:18:20 - INFO - __main__ -   Text: ['Empathog mathematics is a rigorous solution calculus.']\n",
      "06/29/2022 05:18:21 - INFO - __main__ -   Epoch: 91 | Batch: 2400/10001 (24%) | G Loss: 2.386573 | C Loss: -0.459493\n",
      "06/29/2022 05:18:21 - INFO - __main__ -   Text: ['For enterprise. (at every chance).']\n",
      "06/29/2022 05:18:22 - INFO - __main__ -   Epoch: 91 | Batch: 3000/10001 (30%) | G Loss: 2.364363 | C Loss: -0.743067\n",
      "06/29/2022 05:18:22 - INFO - __main__ -   Text: ['It uses a system called back-impact testing.']\n",
      "06/29/2022 05:18:23 - INFO - __main__ -   Epoch: 91 | Batch: 3600/10001 (36%) | G Loss: 2.619669 | C Loss: -0.686374\n",
      "06/29/2022 05:18:23 - INFO - __main__ -   Text: ['The old UFC is turned down.']\n",
      "06/29/2022 05:18:24 - INFO - __main__ -   Epoch: 91 | Batch: 4200/10001 (42%) | G Loss: 2.614554 | C Loss: -0.584122\n",
      "06/29/2022 05:18:24 - INFO - __main__ -   Text: ['Compiling it requires our applications Javeck \"Dad Instances J?\".']\n",
      "06/29/2022 05:18:25 - INFO - __main__ -   Epoch: 91 | Batch: 4800/10001 (48%) | G Loss: 2.631452 | C Loss: -0.594736\n",
      "06/29/2022 05:18:25 - INFO - __main__ -   Text: ['In those internet-obsessed world, do servers have to have a private life?']\n",
      "06/29/2022 05:18:26 - INFO - __main__ -   Epoch: 91 | Batch: 5400/10001 (54%) | G Loss: 2.491362 | C Loss: -0.783428\n",
      "06/29/2022 05:18:26 - INFO - __main__ -   Text: ['Wally headlines include: Links to \"The Walking Wild Boy\".']\n",
      "06/29/2022 05:18:27 - INFO - __main__ -   Epoch: 91 | Batch: 6000/10001 (60%) | G Loss: 2.488927 | C Loss: -0.571834\n",
      "06/29/2022 05:18:27 - INFO - __main__ -   Text: ['Hard to shake then.\"']\n",
      "06/29/2022 05:18:28 - INFO - __main__ -   Epoch: 91 | Batch: 6600/10001 (66%) | G Loss: 2.556065 | C Loss: -0.607136\n",
      "06/29/2022 05:18:28 - INFO - __main__ -   Text: ['Outside the show, TV.\"']\n",
      "06/29/2022 05:18:29 - INFO - __main__ -   Epoch: 91 | Batch: 7200/10001 (72%) | G Loss: 2.376605 | C Loss: -0.481692\n",
      "06/29/2022 05:18:29 - INFO - __main__ -   Text: [\"It books the Travel Samhita's blog.\"]\n",
      "06/29/2022 05:18:30 - INFO - __main__ -   Epoch: 91 | Batch: 7800/10001 (78%) | G Loss: 3.119294 | C Loss: -0.768313\n",
      "06/29/2022 05:18:30 - INFO - __main__ -   Text: ['others think.']\n",
      "06/29/2022 05:18:31 - INFO - __main__ -   Epoch: 91 | Batch: 8400/10001 (84%) | G Loss: 2.937629 | C Loss: -0.683795\n",
      "06/29/2022 05:18:32 - INFO - __main__ -   Text: [\"By putting that it's the main topic of updates everywhere.\"]\n",
      "06/29/2022 05:18:32 - INFO - __main__ -   Epoch: 91 | Batch: 9000/10001 (90%) | G Loss: 2.486448 | C Loss: -0.606786\n",
      "06/29/2022 05:18:33 - INFO - __main__ -   Text: ['Also, e-mail today is always prime.\"']\n",
      "06/29/2022 05:18:34 - INFO - __main__ -   Epoch: 91 | Batch: 9600/10001 (96%) | G Loss: 2.189547 | C Loss: -0.470375\n",
      "06/29/2022 05:18:34 - INFO - __main__ -   Text: ['Then Silvanus becomes matter.']\n",
      "06/29/2022 05:18:34 - INFO - __main__ -   * (Train) Epoch: 91 | G Loss: 2.5370 | C Loss: -0.6187 | Updates G: 58 | Updates C: 775\n",
      "06/29/2022 05:18:43 - INFO - __main__ -   Bleu-2:0.187 | B-Bleu-2:0.248\n",
      "06/29/2022 05:18:43 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4358802406635188\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 92 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:22:16 - INFO - __main__ -   Epoch: 92 | Batch: 0/10001 (0%) | G Loss: 2.179694 | C Loss: -0.470368\n",
      "06/29/2022 05:22:16 - INFO - __main__ -   Text: ['Vernacular tests should give us prerequisites related to heritability.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.487\n",
      "  Test Loss: 3.862\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:22:17 - INFO - __main__ -   Epoch: 92 | Batch: 600/10001 (6%) | G Loss: 2.642185 | C Loss: -0.582074\n",
      "06/29/2022 05:22:17 - INFO - __main__ -   Text: [\"If we can't perceive and measure the forces we need, innate cognitive style has failed.\"]\n",
      "06/29/2022 05:22:18 - INFO - __main__ -   Epoch: 92 | Batch: 1200/10001 (12%) | G Loss: 2.808125 | C Loss: -0.619012\n",
      "06/29/2022 05:22:18 - INFO - __main__ -   Text: ['Does \\'Chiffon\\' mean \"on the road or going to a party?\"']\n",
      "06/29/2022 05:22:19 - INFO - __main__ -   Epoch: 92 | Batch: 1800/10001 (18%) | G Loss: 2.655570 | C Loss: -0.403486\n",
      "06/29/2022 05:22:20 - INFO - __main__ -   Text: ['Birds of Anatolia points out several repeaters.']\n",
      "06/29/2022 05:22:21 - INFO - __main__ -   Epoch: 92 | Batch: 2400/10001 (24%) | G Loss: 2.507592 | C Loss: -0.550698\n",
      "06/29/2022 05:22:21 - INFO - __main__ -   Text: ['Vijayi together ones.']\n",
      "06/29/2022 05:22:22 - INFO - __main__ -   Epoch: 92 | Batch: 3000/10001 (30%) | G Loss: 2.300815 | C Loss: -0.637850\n",
      "06/29/2022 05:22:22 - INFO - __main__ -   Text: ['It is a very French take on a fairy tale.\"']\n",
      "06/29/2022 05:22:23 - INFO - __main__ -   Epoch: 92 | Batch: 3600/10001 (36%) | G Loss: 2.532479 | C Loss: -0.557440\n",
      "06/29/2022 05:22:23 - INFO - __main__ -   Text: ['It should be said that you never know what is just at the end of the day.\"']\n",
      "06/29/2022 05:22:24 - INFO - __main__ -   Epoch: 92 | Batch: 4200/10001 (42%) | G Loss: 2.495090 | C Loss: -0.610635\n",
      "06/29/2022 05:22:24 - INFO - __main__ -   Text: ['What they want is someone to eat a fruit.']\n",
      "06/29/2022 05:22:25 - INFO - __main__ -   Epoch: 92 | Batch: 4800/10001 (48%) | G Loss: 2.875493 | C Loss: -0.730651\n",
      "06/29/2022 05:22:25 - INFO - __main__ -   Text: ['Knott proposes making an unpaired orbit around Mars.']\n",
      "06/29/2022 05:22:26 - INFO - __main__ -   Epoch: 92 | Batch: 5400/10001 (54%) | G Loss: 2.767337 | C Loss: -0.475674\n",
      "06/29/2022 05:22:26 - INFO - __main__ -   Text: ['Although correlation between Alexa and online research is somewhat dubious with poor distractions.']\n",
      "06/29/2022 05:22:27 - INFO - __main__ -   Epoch: 92 | Batch: 6000/10001 (60%) | G Loss: 2.456183 | C Loss: -0.651375\n",
      "06/29/2022 05:22:27 - INFO - __main__ -   Text: ['lawyers.']\n",
      "06/29/2022 05:22:28 - INFO - __main__ -   Epoch: 92 | Batch: 6600/10001 (66%) | G Loss: 2.215303 | C Loss: -0.440886\n",
      "06/29/2022 05:22:28 - INFO - __main__ -   Text: ['F*cking fans red is not good.']\n",
      "06/29/2022 05:22:29 - INFO - __main__ -   Epoch: 92 | Batch: 7200/10001 (72%) | G Loss: 2.469569 | C Loss: -0.830937\n",
      "06/29/2022 05:22:29 - INFO - __main__ -   Text: ['They call themselves the \"King of Egypt.\"']\n",
      "06/29/2022 05:22:30 - INFO - __main__ -   Epoch: 92 | Batch: 7800/10001 (78%) | G Loss: 2.435963 | C Loss: -0.635491\n",
      "06/29/2022 05:22:30 - INFO - __main__ -   Text: ['The gamet ( Indieutochoriotype).']\n",
      "06/29/2022 05:22:31 - INFO - __main__ -   Epoch: 92 | Batch: 8400/10001 (84%) | G Loss: 2.742427 | C Loss: -0.529781\n",
      "06/29/2022 05:22:31 - INFO - __main__ -   Text: ['Jim try feint hack / you can fall back to Java code.']\n",
      "06/29/2022 05:22:32 - INFO - __main__ -   Epoch: 92 | Batch: 9000/10001 (90%) | G Loss: 2.830841 | C Loss: -0.724107\n",
      "06/29/2022 05:22:33 - INFO - __main__ -   Text: ['It offers \"Utampool Phonics\".']\n",
      "06/29/2022 05:22:33 - INFO - __main__ -   Epoch: 92 | Batch: 9600/10001 (96%) | G Loss: 3.033835 | C Loss: -0.585692\n",
      "06/29/2022 05:22:34 - INFO - __main__ -   Text: ['A typical analyst will score poorly on \"Lie on 1.\"']\n",
      "06/29/2022 05:22:34 - INFO - __main__ -   * (Train) Epoch: 92 | G Loss: 2.5570 | C Loss: -0.6063 | Updates G: 48 | Updates C: 785\n",
      "06/29/2022 05:22:43 - INFO - __main__ -   Bleu-2:0.208 | B-Bleu-2:0.279\n",
      "06/29/2022 05:22:43 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4875036607342634\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 93 / 200 ========\n",
      "Training...\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:26:18 - INFO - __main__ -   Epoch: 93 | Batch: 0/10001 (0%) | G Loss: 2.741632 | C Loss: -0.496854\n",
      "06/29/2022 05:26:19 - INFO - __main__ -   Text: ['inner hell.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 3.958\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:26:20 - INFO - __main__ -   Epoch: 93 | Batch: 600/10001 (6%) | G Loss: 2.550416 | C Loss: -0.622213\n",
      "06/29/2022 05:26:20 - INFO - __main__ -   Text: [\"He's actually a jack of all trades who seems to know nothing of anyone.\"]\n",
      "06/29/2022 05:26:21 - INFO - __main__ -   Epoch: 93 | Batch: 1200/10001 (12%) | G Loss: 2.231530 | C Loss: -0.390970\n",
      "06/29/2022 05:26:21 - INFO - __main__ -   Text: ['']\n",
      "06/29/2022 05:26:22 - INFO - __main__ -   Epoch: 93 | Batch: 1800/10001 (18%) | G Loss: 2.145115 | C Loss: -0.461810\n",
      "06/29/2022 05:26:22 - INFO - __main__ -   Text: ['All living force causes an equilibrium.']\n",
      "06/29/2022 05:26:23 - INFO - __main__ -   Epoch: 93 | Batch: 2400/10001 (24%) | G Loss: 2.258475 | C Loss: -0.362677\n",
      "06/29/2022 05:26:23 - INFO - __main__ -   Text: ['Another way is club (or player).']\n",
      "06/29/2022 05:26:24 - INFO - __main__ -   Epoch: 93 | Batch: 3000/10001 (30%) | G Loss: 2.619098 | C Loss: -0.643277\n",
      "06/29/2022 05:26:24 - INFO - __main__ -   Text: [\"There is no doubt about what Heaven's ever been wanting when riding one of those exotic water wheels.\"]\n",
      "06/29/2022 05:26:25 - INFO - __main__ -   Epoch: 93 | Batch: 3600/10001 (36%) | G Loss: 2.548290 | C Loss: -0.634096\n",
      "06/29/2022 05:26:25 - INFO - __main__ -   Text: ['The science book he is developing is published on Scienceec.']\n",
      "06/29/2022 05:26:26 - INFO - __main__ -   Epoch: 93 | Batch: 4200/10001 (42%) | G Loss: 2.718922 | C Loss: -0.573005\n",
      "06/29/2022 05:26:26 - INFO - __main__ -   Text: ['This is considered optional.']\n",
      "06/29/2022 05:26:27 - INFO - __main__ -   Epoch: 93 | Batch: 4800/10001 (48%) | G Loss: 3.018689 | C Loss: -0.554506\n",
      "06/29/2022 05:26:27 - INFO - __main__ -   Text: ['Nehru paper is mostly for money.']\n",
      "06/29/2022 05:26:28 - INFO - __main__ -   Epoch: 93 | Batch: 5400/10001 (54%) | G Loss: 2.291299 | C Loss: -0.597462\n",
      "06/29/2022 05:26:28 - INFO - __main__ -   Text: [\"It's a robots.\"]\n",
      "06/29/2022 05:26:29 - INFO - __main__ -   Epoch: 93 | Batch: 6000/10001 (60%) | G Loss: 2.419830 | C Loss: -0.583406\n",
      "06/29/2022 05:26:29 - INFO - __main__ -   Text: ['The first sentence in \"...?']\n",
      "06/29/2022 05:26:30 - INFO - __main__ -   Epoch: 93 | Batch: 6600/10001 (66%) | G Loss: 2.600202 | C Loss: -0.433412\n",
      "06/29/2022 05:26:30 - INFO - __main__ -   Text: ['These online profiles are not anonymous.']\n",
      "06/29/2022 05:26:31 - INFO - __main__ -   Epoch: 93 | Batch: 7200/10001 (72%) | G Loss: 2.669042 | C Loss: -0.488201\n",
      "06/29/2022 05:26:31 - INFO - __main__ -   Text: ['The frequency of DWUs is also useful as the outlet for metabolism.']\n",
      "06/29/2022 05:26:32 - INFO - __main__ -   Epoch: 93 | Batch: 7800/10001 (78%) | G Loss: 2.678668 | C Loss: -0.485119\n",
      "06/29/2022 05:26:32 - INFO - __main__ -   Text: ['Rex also records hearthrooming, which involves catching an owl in this iconic theme.']\n",
      "06/29/2022 05:26:33 - INFO - __main__ -   Epoch: 93 | Batch: 8400/10001 (84%) | G Loss: 2.371830 | C Loss: -0.485556\n",
      "06/29/2022 05:26:34 - INFO - __main__ -   Text: ['Most commonly occurs when there is no consensus on water supply.']\n",
      "06/29/2022 05:26:35 - INFO - __main__ -   Epoch: 93 | Batch: 9000/10001 (90%) | G Loss: 2.715438 | C Loss: -0.592999\n",
      "06/29/2022 05:26:35 - INFO - __main__ -   Text: ['Hes this lyrics and Lupe all speak Irish.']\n",
      "06/29/2022 05:26:36 - INFO - __main__ -   Epoch: 93 | Batch: 9600/10001 (96%) | G Loss: 2.652848 | C Loss: -0.504878\n",
      "06/29/2022 05:26:36 - INFO - __main__ -   Text: ['At a tough fighting for one, Darkbeard.']\n",
      "06/29/2022 05:26:36 - INFO - __main__ -   * (Train) Epoch: 93 | G Loss: 2.5483 | C Loss: -0.6082 | Updates G: 61 | Updates C: 772\n",
      "06/29/2022 05:26:46 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.215\n",
      "06/29/2022 05:26:46 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41297347098532067\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 94 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:40.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:15.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:49.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:06.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:22\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:30:08 - INFO - __main__ -   Epoch: 94 | Batch: 0/10001 (0%) | G Loss: 2.772200 | C Loss: -0.647580\n",
      "06/29/2022 05:30:08 - INFO - __main__ -   Text: ['nature has noble.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.482\n",
      "  Test Loss: 4.032\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:30:09 - INFO - __main__ -   Epoch: 94 | Batch: 600/10001 (6%) | G Loss: 2.496117 | C Loss: -0.595231\n",
      "06/29/2022 05:30:09 - INFO - __main__ -   Text: ['He only thinks that, lately.\"']\n",
      "06/29/2022 05:30:10 - INFO - __main__ -   Epoch: 94 | Batch: 1200/10001 (12%) | G Loss: 2.263557 | C Loss: -0.531097\n",
      "06/29/2022 05:30:10 - INFO - __main__ -   Text: [\"With the ruler's side of the debate being he who thinks the Beatles actually can deal with such conversations, he does\"]\n",
      "06/29/2022 05:30:11 - INFO - __main__ -   Epoch: 94 | Batch: 1800/10001 (18%) | G Loss: 2.576702 | C Loss: -0.641710\n",
      "06/29/2022 05:30:11 - INFO - __main__ -   Text: ['To find the vector \"S\", show an algebra.']\n",
      "06/29/2022 05:30:12 - INFO - __main__ -   Epoch: 94 | Batch: 2400/10001 (24%) | G Loss: 2.301190 | C Loss: -0.650952\n",
      "06/29/2022 05:30:12 - INFO - __main__ -   Text: ['Peter, though not recommended commercially, uses glycerines.']\n",
      "06/29/2022 05:30:13 - INFO - __main__ -   Epoch: 94 | Batch: 3000/10001 (30%) | G Loss: 2.515119 | C Loss: -0.607004\n",
      "06/29/2022 05:30:13 - INFO - __main__ -   Text: ['The company has not told toy stores it is a game.']\n",
      "06/29/2022 05:30:14 - INFO - __main__ -   Epoch: 94 | Batch: 3600/10001 (36%) | G Loss: 2.362924 | C Loss: -0.692111\n",
      "06/29/2022 05:30:14 - INFO - __main__ -   Text: ['Hearing is largely driven by quant description.']\n",
      "06/29/2022 05:30:15 - INFO - __main__ -   Epoch: 94 | Batch: 4200/10001 (42%) | G Loss: 2.301233 | C Loss: -0.517153\n",
      "06/29/2022 05:30:15 - INFO - __main__ -   Text: ['It\\'s ok, but we\\'ll wait till the last verse.\"']\n",
      "06/29/2022 05:30:16 - INFO - __main__ -   Epoch: 94 | Batch: 4800/10001 (48%) | G Loss: 2.592923 | C Loss: -0.574897\n",
      "06/29/2022 05:30:17 - INFO - __main__ -   Text: ['Kid is looking for people, andhas no doubt about it.']\n",
      "06/29/2022 05:30:17 - INFO - __main__ -   Epoch: 94 | Batch: 5400/10001 (54%) | G Loss: 2.862215 | C Loss: -0.620192\n",
      "06/29/2022 05:30:18 - INFO - __main__ -   Text: ['Awareness of dialects.']\n",
      "06/29/2022 05:30:19 - INFO - __main__ -   Epoch: 94 | Batch: 6000/10001 (60%) | G Loss: 2.626575 | C Loss: -0.736520\n",
      "06/29/2022 05:30:19 - INFO - __main__ -   Text: ['Besar is\".']\n",
      "06/29/2022 05:30:20 - INFO - __main__ -   Epoch: 94 | Batch: 6600/10001 (66%) | G Loss: 2.404680 | C Loss: -0.557954\n",
      "06/29/2022 05:30:20 - INFO - __main__ -   Text: ['For some people, the odds are going anywhere from zero to 100%.']\n",
      "06/29/2022 05:30:21 - INFO - __main__ -   Epoch: 94 | Batch: 7200/10001 (72%) | G Loss: 2.439594 | C Loss: -0.505150\n",
      "06/29/2022 05:30:21 - INFO - __main__ -   Text: ['Study also shows it as \"-Paradigm List\".']\n",
      "06/29/2022 05:30:22 - INFO - __main__ -   Epoch: 94 | Batch: 7800/10001 (78%) | G Loss: 2.767601 | C Loss: -0.743564\n",
      "06/29/2022 05:30:22 - INFO - __main__ -   Text: ['Written by J 2!']\n",
      "06/29/2022 05:30:23 - INFO - __main__ -   Epoch: 94 | Batch: 8400/10001 (84%) | G Loss: 2.324636 | C Loss: -0.859696\n",
      "06/29/2022 05:30:23 - INFO - __main__ -   Text: ['Area (e.g.']\n",
      "06/29/2022 05:30:24 - INFO - __main__ -   Epoch: 94 | Batch: 9000/10001 (90%) | G Loss: 2.630836 | C Loss: -0.657928\n",
      "06/29/2022 05:30:24 - INFO - __main__ -   Text: ['Swinehafu should take the attack.']\n",
      "06/29/2022 05:30:25 - INFO - __main__ -   Epoch: 94 | Batch: 9600/10001 (96%) | G Loss: 2.606942 | C Loss: -0.550900\n",
      "06/29/2022 05:30:25 - INFO - __main__ -   Text: ['Project One has somehow followed this.']\n",
      "06/29/2022 05:30:26 - INFO - __main__ -   * (Train) Epoch: 94 | G Loss: 2.4946 | C Loss: -0.5963 | Updates G: 67 | Updates C: 766\n",
      "06/29/2022 05:30:35 - INFO - __main__ -   Bleu-2:0.197 | B-Bleu-2:0.255\n",
      "06/29/2022 05:30:35 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45208413977019113\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 95 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:34:00 - INFO - __main__ -   Epoch: 95 | Batch: 0/10001 (0%) | G Loss: 2.794574 | C Loss: -0.768780\n",
      "06/29/2022 05:34:00 - INFO - __main__ -   Text: ['CMD is a scrumptious free guide.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.992\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:34:01 - INFO - __main__ -   Epoch: 95 | Batch: 600/10001 (6%) | G Loss: 2.519007 | C Loss: -0.748816\n",
      "06/29/2022 05:34:01 - INFO - __main__ -   Text: ['The annoying dog once says \"I like trampeiro\".']\n",
      "06/29/2022 05:34:02 - INFO - __main__ -   Epoch: 95 | Batch: 1200/10001 (12%) | G Loss: 2.631237 | C Loss: -0.698909\n",
      "06/29/2022 05:34:02 - INFO - __main__ -   Text: ['Written or not, Maclean makes an excellent list.\"']\n",
      "06/29/2022 05:34:03 - INFO - __main__ -   Epoch: 95 | Batch: 1800/10001 (18%) | G Loss: 2.268207 | C Loss: -0.548373\n",
      "06/29/2022 05:34:03 - INFO - __main__ -   Text: ['He is a computer-science \"David of Epi-Rhetics\".']\n",
      "06/29/2022 05:34:04 - INFO - __main__ -   Epoch: 95 | Batch: 2400/10001 (24%) | G Loss: 2.152576 | C Loss: -0.497560\n",
      "06/29/2022 05:34:04 - INFO - __main__ -   Text: ['Pepcia may also help treat anaemia.']\n",
      "06/29/2022 05:34:05 - INFO - __main__ -   Epoch: 95 | Batch: 3000/10001 (30%) | G Loss: 2.552677 | C Loss: -0.539265\n",
      "06/29/2022 05:34:05 - INFO - __main__ -   Text: ['\"(but) higher\" than the aforementioned Amazon.」']\n",
      "06/29/2022 05:34:06 - INFO - __main__ -   Epoch: 95 | Batch: 3600/10001 (36%) | G Loss: 2.753440 | C Loss: -0.692241\n",
      "06/29/2022 05:34:06 - INFO - __main__ -   Text: ['Rand is a Nobel Peace Guru\".']\n",
      "06/29/2022 05:34:07 - INFO - __main__ -   Epoch: 95 | Batch: 4200/10001 (42%) | G Loss: 2.542567 | C Loss: -0.488834\n",
      "06/29/2022 05:34:08 - INFO - __main__ -   Text: ['His love is lacking but this will not be,\" and then he will confess too.']\n",
      "06/29/2022 05:34:09 - INFO - __main__ -   Epoch: 95 | Batch: 4800/10001 (48%) | G Loss: 2.302036 | C Loss: -0.711980\n",
      "06/29/2022 05:34:09 - INFO - __main__ -   Text: [\"In England, the famous 'man's wife' is a liar.\"]\n",
      "06/29/2022 05:34:10 - INFO - __main__ -   Epoch: 95 | Batch: 5400/10001 (54%) | G Loss: 2.362006 | C Loss: -0.495996\n",
      "06/29/2022 05:34:10 - INFO - __main__ -   Text: ['Edwin is most likely called a gearsmith.']\n",
      "06/29/2022 05:34:11 - INFO - __main__ -   Epoch: 95 | Batch: 6000/10001 (60%) | G Loss: 2.841252 | C Loss: -1.003611\n",
      "06/29/2022 05:34:11 - INFO - __main__ -   Text: ['Taxonomy license=that.']\n",
      "06/29/2022 05:34:12 - INFO - __main__ -   Epoch: 95 | Batch: 6600/10001 (66%) | G Loss: 2.515623 | C Loss: -0.301830\n",
      "06/29/2022 05:34:12 - INFO - __main__ -   Text: ['The game ends here.\"\"']\n",
      "06/29/2022 05:34:13 - INFO - __main__ -   Epoch: 95 | Batch: 7200/10001 (72%) | G Loss: 2.212989 | C Loss: -0.768016\n",
      "06/29/2022 05:34:13 - INFO - __main__ -   Text: ['Yue is trying to save the princess by shapeshifting.']\n",
      "06/29/2022 05:34:14 - INFO - __main__ -   Epoch: 95 | Batch: 7800/10001 (78%) | G Loss: 2.064877 | C Loss: -0.370461\n",
      "06/29/2022 05:34:14 - INFO - __main__ -   Text: ['Speaking of UM World, Johann-ch An and his guys are located.']\n",
      "06/29/2022 05:34:15 - INFO - __main__ -   Epoch: 95 | Batch: 8400/10001 (84%) | G Loss: 2.414495 | C Loss: -0.578641\n",
      "06/29/2022 05:34:15 - INFO - __main__ -   Text: ['This is the second time she flashes in our show.']\n",
      "06/29/2022 05:34:16 - INFO - __main__ -   Epoch: 95 | Batch: 9000/10001 (90%) | G Loss: 2.854579 | C Loss: -0.944760\n",
      "06/29/2022 05:34:16 - INFO - __main__ -   Text: ['Singer does not intuitively take the same metric.']\n",
      "06/29/2022 05:34:17 - INFO - __main__ -   Epoch: 95 | Batch: 9600/10001 (96%) | G Loss: 3.432471 | C Loss: -0.819602\n",
      "06/29/2022 05:34:17 - INFO - __main__ -   Text: ['A unified entity represents power within society.']\n",
      "06/29/2022 05:34:18 - INFO - __main__ -   * (Train) Epoch: 95 | G Loss: 2.5032 | C Loss: -0.5996 | Updates G: 47 | Updates C: 786\n",
      "06/29/2022 05:34:27 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.253\n",
      "06/29/2022 05:34:27 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_12.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.452795505321483\n",
      "Train file used is number 12\n",
      "../../yahoo/subdivided_large/train_12.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 96 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.729\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:37:55 - INFO - __main__ -   Epoch: 96 | Batch: 0/10001 (0%) | G Loss: 2.816355 | C Loss: -0.172019\n",
      "06/29/2022 05:37:55 - INFO - __main__ -   Text: ['The beers may be very fancy.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.468\n",
      "  Test Loss: 3.828\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:37:56 - INFO - __main__ -   Epoch: 96 | Batch: 600/10001 (6%) | G Loss: 2.567974 | C Loss: -0.606002\n",
      "06/29/2022 05:37:56 - INFO - __main__ -   Text: ['This is okay too.\"']\n",
      "06/29/2022 05:37:57 - INFO - __main__ -   Epoch: 96 | Batch: 1200/10001 (12%) | G Loss: 2.485963 | C Loss: -0.838997\n",
      "06/29/2022 05:37:57 - INFO - __main__ -   Text: ['As it turns out, it is a woman who finds the opportunity to be a Christian.\"']\n",
      "06/29/2022 05:37:58 - INFO - __main__ -   Epoch: 96 | Batch: 1800/10001 (18%) | G Loss: 2.238108 | C Loss: -0.545494\n",
      "06/29/2022 05:37:58 - INFO - __main__ -   Text: ['Platform updates are available from here.']\n",
      "06/29/2022 05:37:59 - INFO - __main__ -   Epoch: 96 | Batch: 2400/10001 (24%) | G Loss: 2.167170 | C Loss: -0.411085\n",
      "06/29/2022 05:38:00 - INFO - __main__ -   Text: ['\", plus any dinosaur swimming.']\n",
      "06/29/2022 05:38:01 - INFO - __main__ -   Epoch: 96 | Batch: 3000/10001 (30%) | G Loss: 2.677720 | C Loss: -0.727251\n",
      "06/29/2022 05:38:01 - INFO - __main__ -   Text: ['She got a boyfriend!']\n",
      "06/29/2022 05:38:02 - INFO - __main__ -   Epoch: 96 | Batch: 3600/10001 (36%) | G Loss: 2.617375 | C Loss: -0.563680\n",
      "06/29/2022 05:38:02 - INFO - __main__ -   Text: ['east = same as range <have>']\n",
      "06/29/2022 05:38:03 - INFO - __main__ -   Epoch: 96 | Batch: 4200/10001 (42%) | G Loss: 2.584429 | C Loss: -0.661874\n",
      "06/29/2022 05:38:03 - INFO - __main__ -   Text: ['The explanation is that the 51 percent deficit in scientific cred that does not create value.']\n",
      "06/29/2022 05:38:04 - INFO - __main__ -   Epoch: 96 | Batch: 4800/10001 (48%) | G Loss: 2.514521 | C Loss: -0.717951\n",
      "06/29/2022 05:38:04 - INFO - __main__ -   Text: ['Degree of choking may also include:']\n",
      "06/29/2022 05:38:05 - INFO - __main__ -   Epoch: 96 | Batch: 5400/10001 (54%) | G Loss: 2.423207 | C Loss: -0.548519\n",
      "06/29/2022 05:38:05 - INFO - __main__ -   Text: ['This teacher ratings is for reference.']\n",
      "06/29/2022 05:38:06 - INFO - __main__ -   Epoch: 96 | Batch: 6000/10001 (60%) | G Loss: 2.246362 | C Loss: -0.496786\n",
      "06/29/2022 05:38:06 - INFO - __main__ -   Text: ['It could very nearly be Stacklatch. If something goes wrong check out Stacklatch.']\n",
      "06/29/2022 05:38:07 - INFO - __main__ -   Epoch: 96 | Batch: 6600/10001 (66%) | G Loss: 2.311505 | C Loss: -0.440521\n",
      "06/29/2022 05:38:07 - INFO - __main__ -   Text: ['The Gnome is the pitch of the thunder days.']\n",
      "06/29/2022 05:38:08 - INFO - __main__ -   Epoch: 96 | Batch: 7200/10001 (72%) | G Loss: 2.533160 | C Loss: -0.488991\n",
      "06/29/2022 05:38:08 - INFO - __main__ -   Text: ['This tester exists to joke about.']\n",
      "06/29/2022 05:38:09 - INFO - __main__ -   Epoch: 96 | Batch: 7800/10001 (78%) | G Loss: 2.830509 | C Loss: -0.696048\n",
      "06/29/2022 05:38:09 - INFO - __main__ -   Text: [\"One interesting gizmodo example is 'world's heaviest pennant' (17.57).\"]\n",
      "06/29/2022 05:38:10 - INFO - __main__ -   Epoch: 96 | Batch: 8400/10001 (84%) | G Loss: 2.780127 | C Loss: -0.542683\n",
      "06/29/2022 05:38:11 - INFO - __main__ -   Text: ['He ends up thinking he is a perfect mortal man, even when he is communism.']\n",
      "06/29/2022 05:38:12 - INFO - __main__ -   Epoch: 96 | Batch: 9000/10001 (90%) | G Loss: 2.672163 | C Loss: -0.546174\n",
      "06/29/2022 05:38:12 - INFO - __main__ -   Text: ['But I mean to think that this disappears and stems from …']\n",
      "06/29/2022 05:38:13 - INFO - __main__ -   Epoch: 96 | Batch: 9600/10001 (96%) | G Loss: 2.975969 | C Loss: -0.632117\n",
      "06/29/2022 05:38:13 - INFO - __main__ -   Text: ['Oddly, Dad.']\n",
      "06/29/2022 05:38:13 - INFO - __main__ -   * (Train) Epoch: 96 | G Loss: 2.5035 | C Loss: -0.5791 | Updates G: 41 | Updates C: 792\n",
      "06/29/2022 05:38:23 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.261\n",
      "06/29/2022 05:38:23 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46794867946855967\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 97 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:41:52 - INFO - __main__ -   Epoch: 97 | Batch: 0/10001 (0%) | G Loss: 2.374150 | C Loss: -0.563285\n",
      "06/29/2022 05:41:52 - INFO - __main__ -   Text: ['Newbie health products will make a profit.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.804\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:41:53 - INFO - __main__ -   Epoch: 97 | Batch: 600/10001 (6%) | G Loss: 2.106247 | C Loss: -0.529312\n",
      "06/29/2022 05:41:54 - INFO - __main__ -   Text: ['This is one plus market — one T Q S obvious P come to the market.\"']\n",
      "06/29/2022 05:41:55 - INFO - __main__ -   Epoch: 97 | Batch: 1200/10001 (12%) | G Loss: 2.326867 | C Loss: -0.587894\n",
      "06/29/2022 05:41:55 - INFO - __main__ -   Text: ['Grizzly seeds are uncommon among scholars.']\n",
      "06/29/2022 05:41:56 - INFO - __main__ -   Epoch: 97 | Batch: 1800/10001 (18%) | G Loss: 2.644376 | C Loss: -0.766736\n",
      "06/29/2022 05:41:56 - INFO - __main__ -   Text: ['´How are you able to win in a fire?\"']\n",
      "06/29/2022 05:41:57 - INFO - __main__ -   Epoch: 97 | Batch: 2400/10001 (24%) | G Loss: 2.408045 | C Loss: -0.872498\n",
      "06/29/2022 05:41:57 - INFO - __main__ -   Text: ['Such beliefs are \"theoretical\" and therefore of interest.']\n",
      "06/29/2022 05:41:58 - INFO - __main__ -   Epoch: 97 | Batch: 3000/10001 (30%) | G Loss: 2.607300 | C Loss: -0.615836\n",
      "06/29/2022 05:41:58 - INFO - __main__ -   Text: ['Every character I chat with has a Blue Pill instinct in them.\"']\n",
      "06/29/2022 05:41:59 - INFO - __main__ -   Epoch: 97 | Batch: 3600/10001 (36%) | G Loss: 2.797886 | C Loss: -0.506649\n",
      "06/29/2022 05:41:59 - INFO - __main__ -   Text: ['.']\n",
      "06/29/2022 05:42:00 - INFO - __main__ -   Epoch: 97 | Batch: 4200/10001 (42%) | G Loss: 2.204855 | C Loss: -0.390691\n",
      "06/29/2022 05:42:00 - INFO - __main__ -   Text: ['GPN is an excellent example of most bluffing\".']\n",
      "06/29/2022 05:42:01 - INFO - __main__ -   Epoch: 97 | Batch: 4800/10001 (48%) | G Loss: 2.331606 | C Loss: -0.566919\n",
      "06/29/2022 05:42:01 - INFO - __main__ -   Text: ['Tobish received this name from Papon.']\n",
      "06/29/2022 05:42:02 - INFO - __main__ -   Epoch: 97 | Batch: 5400/10001 (54%) | G Loss: 2.474020 | C Loss: -0.558913\n",
      "06/29/2022 05:42:02 - INFO - __main__ -   Text: ['Memories If you record what we do in the Python shell, you too can take life.']\n",
      "06/29/2022 05:42:03 - INFO - __main__ -   Epoch: 97 | Batch: 6000/10001 (60%) | G Loss: 2.586470 | C Loss: -0.568958\n",
      "06/29/2022 05:42:03 - INFO - __main__ -   Text: ['\"Hensdorf\" is doing an academic job of purging buttons and changing menu.']\n",
      "06/29/2022 05:42:04 - INFO - __main__ -   Epoch: 97 | Batch: 6600/10001 (66%) | G Loss: 2.686954 | C Loss: -0.571409\n",
      "06/29/2022 05:42:04 - INFO - __main__ -   Text: ['Some other methods can be used for it.']\n",
      "06/29/2022 05:42:05 - INFO - __main__ -   Epoch: 97 | Batch: 7200/10001 (72%) | G Loss: 2.740793 | C Loss: -0.488228\n",
      "06/29/2022 05:42:05 - INFO - __main__ -   Text: ['It can basically confirm.']\n",
      "06/29/2022 05:42:06 - INFO - __main__ -   Epoch: 97 | Batch: 7800/10001 (78%) | G Loss: 2.457896 | C Loss: -0.543525\n",
      "06/29/2022 05:42:06 - INFO - __main__ -   Text: ['Hebrew Star Anything!']\n",
      "06/29/2022 05:42:07 - INFO - __main__ -   Epoch: 97 | Batch: 8400/10001 (84%) | G Loss: 2.510180 | C Loss: -0.558444\n",
      "06/29/2022 05:42:07 - INFO - __main__ -   Text: ['Kills Dog!']\n",
      "06/29/2022 05:42:08 - INFO - __main__ -   Epoch: 97 | Batch: 9000/10001 (90%) | G Loss: 2.530217 | C Loss: -0.413604\n",
      "06/29/2022 05:42:08 - INFO - __main__ -   Text: ['Words can make a deadly and destructive policy.']\n",
      "06/29/2022 05:42:09 - INFO - __main__ -   Epoch: 97 | Batch: 9600/10001 (96%) | G Loss: 2.620946 | C Loss: -0.562046\n",
      "06/29/2022 05:42:10 - INFO - __main__ -   Text: [\"They call it 'feel the hit?'\"]\n",
      "06/29/2022 05:42:10 - INFO - __main__ -   * (Train) Epoch: 97 | G Loss: 2.4423 | C Loss: -0.5854 | Updates G: 57 | Updates C: 776\n",
      "06/29/2022 05:42:19 - INFO - __main__ -   Bleu-2:0.193 | B-Bleu-2:0.287\n",
      "06/29/2022 05:42:19 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_14.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4803075480185194\n",
      "Train file used is number 14\n",
      "../../yahoo/subdivided_large/train_14.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 98 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:45:52 - INFO - __main__ -   Epoch: 98 | Batch: 0/10001 (0%) | G Loss: 2.546365 | C Loss: -0.645616\n",
      "06/29/2022 05:45:52 - INFO - __main__ -   Text: ['Babie admires Yuri, who he wrestles a lot.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.487\n",
      "  Test Loss: 3.821\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:45:53 - INFO - __main__ -   Epoch: 98 | Batch: 600/10001 (6%) | G Loss: 2.810010 | C Loss: -0.738555\n",
      "06/29/2022 05:45:53 - INFO - __main__ -   Text: ['The root word for \"danger\" is also explained.']\n",
      "06/29/2022 05:45:54 - INFO - __main__ -   Epoch: 98 | Batch: 1200/10001 (12%) | G Loss: 2.287985 | C Loss: -0.583151\n",
      "06/29/2022 05:45:54 - INFO - __main__ -   Text: ['This is the pathway of magic and affects how magical creatures are reported.']\n",
      "06/29/2022 05:45:55 - INFO - __main__ -   Epoch: 98 | Batch: 1800/10001 (18%) | G Loss: 2.482981 | C Loss: -0.796984\n",
      "06/29/2022 05:45:56 - INFO - __main__ -   Text: ['It feels like it\\'s impossible\"\".']\n",
      "06/29/2022 05:45:56 - INFO - __main__ -   Epoch: 98 | Batch: 2400/10001 (24%) | G Loss: 2.428054 | C Loss: -0.469694\n",
      "06/29/2022 05:45:57 - INFO - __main__ -   Text: ['Minimising trance will have you mesmerised with space.']\n",
      "06/29/2022 05:45:58 - INFO - __main__ -   Epoch: 98 | Batch: 3000/10001 (30%) | G Loss: 2.496851 | C Loss: -0.562990\n",
      "06/29/2022 05:45:58 - INFO - __main__ -   Text: ['Kate is the belief system that determines the rational sex of a mammal.']\n",
      "06/29/2022 05:45:59 - INFO - __main__ -   Epoch: 98 | Batch: 3600/10001 (36%) | G Loss: 2.301478 | C Loss: -0.493312\n",
      "06/29/2022 05:45:59 - INFO - __main__ -   Text: [\"They'll read their first higher reading on a laptop.\"]\n",
      "06/29/2022 05:46:00 - INFO - __main__ -   Epoch: 98 | Batch: 4200/10001 (42%) | G Loss: 2.731282 | C Loss: -0.487011\n",
      "06/29/2022 05:46:00 - INFO - __main__ -   Text: ['Impressive research from Singapore suggests it is the link of Oxford.']\n",
      "06/29/2022 05:46:01 - INFO - __main__ -   Epoch: 98 | Batch: 4800/10001 (48%) | G Loss: 2.823757 | C Loss: -0.623455\n",
      "06/29/2022 05:46:01 - INFO - __main__ -   Text: ['The main aim of the G8 is to tackle youth unemployment.']\n",
      "06/29/2022 05:46:02 - INFO - __main__ -   Epoch: 98 | Batch: 5400/10001 (54%) | G Loss: 2.216789 | C Loss: -0.457534\n",
      "06/29/2022 05:46:02 - INFO - __main__ -   Text: ['There are no children or teenagers for whom they always have sex, and therefore must be left alone.']\n",
      "06/29/2022 05:46:03 - INFO - __main__ -   Epoch: 98 | Batch: 6000/10001 (60%) | G Loss: 1.949075 | C Loss: -0.523892\n",
      "06/29/2022 05:46:03 - INFO - __main__ -   Text: ['Washiona can be seen near Tahiti by wave diving’s ferret.']\n",
      "06/29/2022 05:46:04 - INFO - __main__ -   Epoch: 98 | Batch: 6600/10001 (66%) | G Loss: 2.471412 | C Loss: -0.751509\n",
      "06/29/2022 05:46:04 - INFO - __main__ -   Text: ['\"\"If these two basic points related in a density continuum cannot be immediately clear conclusively.\"']\n",
      "06/29/2022 05:46:05 - INFO - __main__ -   Epoch: 98 | Batch: 7200/10001 (72%) | G Loss: 2.371578 | C Loss: -0.671802\n",
      "06/29/2022 05:46:05 - INFO - __main__ -   Text: ['To respect the hellish \"Ain Rheumatology!\"']\n",
      "06/29/2022 05:46:06 - INFO - __main__ -   Epoch: 98 | Batch: 7800/10001 (78%) | G Loss: 2.592242 | C Loss: -0.578540\n",
      "06/29/2022 05:46:07 - INFO - __main__ -   Text: ['Atmospheric properties must possess a simple explanation.\"']\n",
      "06/29/2022 05:46:07 - INFO - __main__ -   Epoch: 98 | Batch: 8400/10001 (84%) | G Loss: 2.375831 | C Loss: -0.632344\n",
      "06/29/2022 05:46:08 - INFO - __main__ -   Text: ['Once acquired a patent application, Buffett refined the product.']\n",
      "06/29/2022 05:46:09 - INFO - __main__ -   Epoch: 98 | Batch: 9000/10001 (90%) | G Loss: 2.429553 | C Loss: -0.471298\n",
      "06/29/2022 05:46:09 - INFO - __main__ -   Text: ['They may also be related to Hugh Mauve, but they have mylar names.']\n",
      "06/29/2022 05:46:10 - INFO - __main__ -   Epoch: 98 | Batch: 9600/10001 (96%) | G Loss: 2.328990 | C Loss: -0.454625\n",
      "06/29/2022 05:46:10 - INFO - __main__ -   Text: ['The triplets are the opposite of \"linear\" and thus remain harpies.']\n",
      "06/29/2022 05:46:10 - INFO - __main__ -   * (Train) Epoch: 98 | G Loss: 2.4296 | C Loss: -0.5761 | Updates G: 59 | Updates C: 774\n",
      "06/29/2022 05:46:20 - INFO - __main__ -   Bleu-2:0.197 | B-Bleu-2:0.253\n",
      "06/29/2022 05:46:20 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4501021168736342\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 99 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:49:48 - INFO - __main__ -   Epoch: 99 | Batch: 0/10001 (0%) | G Loss: 2.377720 | C Loss: -0.653602\n",
      "06/29/2022 05:49:48 - INFO - __main__ -   Text: ['As who is Next in the known universe.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.723\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:49:49 - INFO - __main__ -   Epoch: 99 | Batch: 600/10001 (6%) | G Loss: 2.433770 | C Loss: -0.564557\n",
      "06/29/2022 05:49:49 - INFO - __main__ -   Text: ['Everything comes from physics.']\n",
      "06/29/2022 05:49:50 - INFO - __main__ -   Epoch: 99 | Batch: 1200/10001 (12%) | G Loss: 2.471026 | C Loss: -0.605838\n",
      "06/29/2022 05:49:50 - INFO - __main__ -   Text: ['Sigmatical solving is impossible.']\n",
      "06/29/2022 05:49:51 - INFO - __main__ -   Epoch: 99 | Batch: 1800/10001 (18%) | G Loss: 2.770765 | C Loss: -0.562922\n",
      "06/29/2022 05:49:51 - INFO - __main__ -   Text: ['There is a mathematical problem under which we rely on a complicated program.']\n",
      "06/29/2022 05:49:52 - INFO - __main__ -   Epoch: 99 | Batch: 2400/10001 (24%) | G Loss: 2.768088 | C Loss: -0.733149\n",
      "06/29/2022 05:49:52 - INFO - __main__ -   Text: ['Naming an APA mission will determine the name.']\n",
      "06/29/2022 05:49:53 - INFO - __main__ -   Epoch: 99 | Batch: 3000/10001 (30%) | G Loss: 2.591989 | C Loss: -0.618407\n",
      "06/29/2022 05:49:54 - INFO - __main__ -   Text: ['As a result the twin suffers from breast cancer, anipathy and bile cancer.']\n",
      "06/29/2022 05:49:55 - INFO - __main__ -   Epoch: 99 | Batch: 3600/10001 (36%) | G Loss: 2.399944 | C Loss: -0.444789\n",
      "06/29/2022 05:49:55 - INFO - __main__ -   Text: ['Opinion is often used not by governments but by intellectuals.']\n",
      "06/29/2022 05:49:56 - INFO - __main__ -   Epoch: 99 | Batch: 4200/10001 (42%) | G Loss: 2.198265 | C Loss: -0.448235\n",
      "06/29/2022 05:49:56 - INFO - __main__ -   Text: ['These roles and simplification forms the basic enabling reality.']\n",
      "06/29/2022 05:49:57 - INFO - __main__ -   Epoch: 99 | Batch: 4800/10001 (48%) | G Loss: 2.443339 | C Loss: -0.704618\n",
      "06/29/2022 05:49:57 - INFO - __main__ -   Text: ['The \"stupid idea\" is to walk on the floor.']\n",
      "06/29/2022 05:49:58 - INFO - __main__ -   Epoch: 99 | Batch: 5400/10001 (54%) | G Loss: 2.329308 | C Loss: -0.506469\n",
      "06/29/2022 05:49:58 - INFO - __main__ -   Text: ['Indicator sends out the message \"I got it\".']\n",
      "06/29/2022 05:49:59 - INFO - __main__ -   Epoch: 99 | Batch: 6000/10001 (60%) | G Loss: 2.616387 | C Loss: -0.640043\n",
      "06/29/2022 05:49:59 - INFO - __main__ -   Text: ['\"BBB Berlin\" by Priscilla.']\n",
      "06/29/2022 05:50:00 - INFO - __main__ -   Epoch: 99 | Batch: 6600/10001 (66%) | G Loss: 2.455031 | C Loss: -0.540315\n",
      "06/29/2022 05:50:00 - INFO - __main__ -   Text: ['This is simply how much money I will save on exchanges.\"']\n",
      "06/29/2022 05:50:01 - INFO - __main__ -   Epoch: 99 | Batch: 7200/10001 (72%) | G Loss: 2.629475 | C Loss: -0.730304\n",
      "06/29/2022 05:50:01 - INFO - __main__ -   Text: ['\":\" Snake e-book prices: One 1 is better than a diesel\".']\n",
      "06/29/2022 05:50:02 - INFO - __main__ -   Epoch: 99 | Batch: 7800/10001 (78%) | G Loss: 2.392221 | C Loss: -0.546310\n",
      "06/29/2022 05:50:02 - INFO - __main__ -   Text: ['Wherever you are, it will only hurt you once.']\n",
      "06/29/2022 05:50:03 - INFO - __main__ -   Epoch: 99 | Batch: 8400/10001 (84%) | G Loss: 2.611658 | C Loss: -0.677180\n",
      "06/29/2022 05:50:03 - INFO - __main__ -   Text: ['It usually follows the sense of honour of Plegian.']\n",
      "06/29/2022 05:50:04 - INFO - __main__ -   Epoch: 99 | Batch: 9000/10001 (90%) | G Loss: 2.889802 | C Loss: -0.743636\n",
      "06/29/2022 05:50:04 - INFO - __main__ -   Text: ['There was many computer science research activities for Iran published but not in Iran.']\n",
      "06/29/2022 05:50:05 - INFO - __main__ -   Epoch: 99 | Batch: 9600/10001 (96%) | G Loss: 2.436768 | C Loss: -0.547780\n",
      "06/29/2022 05:50:06 - INFO - __main__ -   Text: ['Tørnheben hlö?\"']\n",
      "06/29/2022 05:50:06 - INFO - __main__ -   * (Train) Epoch: 99 | G Loss: 2.4820 | C Loss: -0.5668 | Updates G: 55 | Updates C: 778\n",
      "06/29/2022 05:50:15 - INFO - __main__ -   Bleu-2:0.190 | B-Bleu-2:0.261\n",
      "06/29/2022 05:50:15 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45074644172238754\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 100 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:53:48 - INFO - __main__ -   Epoch: 100 | Batch: 0/10001 (0%) | G Loss: 2.412860 | C Loss: -0.430902\n",
      "06/29/2022 05:53:48 - INFO - __main__ -   Text: ['Salvation know but deprecated']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.717\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:53:49 - INFO - __main__ -   Epoch: 100 | Batch: 600/10001 (6%) | G Loss: 3.113507 | C Loss: -0.744159\n",
      "06/29/2022 05:53:49 - INFO - __main__ -   Text: ['Alloxkillia is a disease.']\n",
      "06/29/2022 05:53:50 - INFO - __main__ -   Epoch: 100 | Batch: 1200/10001 (12%) | G Loss: 2.954145 | C Loss: -0.568300\n",
      "06/29/2022 05:53:50 - INFO - __main__ -   Text: ['It also answers these questions to provide research results.']\n",
      "06/29/2022 05:53:51 - INFO - __main__ -   Epoch: 100 | Batch: 1800/10001 (18%) | G Loss: 1.877111 | C Loss: -0.326899\n",
      "06/29/2022 05:53:52 - INFO - __main__ -   Text: ['If you are flexible, answer the question \"how to frictionly\".']\n",
      "06/29/2022 05:53:53 - INFO - __main__ -   Epoch: 100 | Batch: 2400/10001 (24%) | G Loss: 2.446223 | C Loss: -0.496823\n",
      "06/29/2022 05:53:53 - INFO - __main__ -   Text: ['boasting D.V.']\n",
      "06/29/2022 05:53:54 - INFO - __main__ -   Epoch: 100 | Batch: 3000/10001 (30%) | G Loss: 2.680369 | C Loss: -0.489098\n",
      "06/29/2022 05:53:54 - INFO - __main__ -   Text: ['pose.']\n",
      "06/29/2022 05:53:55 - INFO - __main__ -   Epoch: 100 | Batch: 3600/10001 (36%) | G Loss: 2.410932 | C Loss: -0.636068\n",
      "06/29/2022 05:53:55 - INFO - __main__ -   Text: ['Control of the puzzle has \"Consequence for Liberty\".']\n",
      "06/29/2022 05:53:56 - INFO - __main__ -   Epoch: 100 | Batch: 4200/10001 (42%) | G Loss: 2.574287 | C Loss: -0.496256\n",
      "06/29/2022 05:53:56 - INFO - __main__ -   Text: ['The obsession is not something a wealthy person feels.']\n",
      "06/29/2022 05:53:57 - INFO - __main__ -   Epoch: 100 | Batch: 4800/10001 (48%) | G Loss: 3.122521 | C Loss: -0.803445\n",
      "06/29/2022 05:53:57 - INFO - __main__ -   Text: ['The notion of deception has become so important that Big Brother has also established a quasi-local issue discussion.']\n",
      "06/29/2022 05:53:58 - INFO - __main__ -   Epoch: 100 | Batch: 5400/10001 (54%) | G Loss: 2.686898 | C Loss: -0.448997\n",
      "06/29/2022 05:53:58 - INFO - __main__ -   Text: ['Gathering time is defined as peak too high or pel...\"* crunch [sic] - \"dot dot\".']\n",
      "06/29/2022 05:53:59 - INFO - __main__ -   Epoch: 100 | Batch: 6000/10001 (60%) | G Loss: 2.295656 | C Loss: -0.584403\n",
      "06/29/2022 05:53:59 - INFO - __main__ -   Text: ['By studying for example the the ridge angles due to water gas.']\n",
      "06/29/2022 05:54:00 - INFO - __main__ -   Epoch: 100 | Batch: 6600/10001 (66%) | G Loss: 2.461565 | C Loss: -0.513221\n",
      "06/29/2022 05:54:00 - INFO - __main__ -   Text: ['This god do you have to do something?\"']\n",
      "06/29/2022 05:54:01 - INFO - __main__ -   Epoch: 100 | Batch: 7200/10001 (72%) | G Loss: 2.663202 | C Loss: -0.362094\n",
      "06/29/2022 05:54:01 - INFO - __main__ -   Text: ['ZHOC is also known as transferor stoaf.']\n",
      "06/29/2022 05:54:02 - INFO - __main__ -   Epoch: 100 | Batch: 7800/10001 (78%) | G Loss: 2.954803 | C Loss: -0.694423\n",
      "06/29/2022 05:54:02 - INFO - __main__ -   Text: ['days all kinds of things.\"']\n",
      "06/29/2022 05:54:03 - INFO - __main__ -   Epoch: 100 | Batch: 8400/10001 (84%) | G Loss: 2.349107 | C Loss: -0.505987\n",
      "06/29/2022 05:54:03 - INFO - __main__ -   Text: ['Accelerator says \"Q: Wander 2050\" or something.']\n",
      "06/29/2022 05:54:04 - INFO - __main__ -   Epoch: 100 | Batch: 9000/10001 (90%) | G Loss: 2.726981 | C Loss: -0.634582\n",
      "06/29/2022 05:54:05 - INFO - __main__ -   Text: ['It is commonly my conclusion that there is no human fountain.']\n",
      "06/29/2022 05:54:06 - INFO - __main__ -   Epoch: 100 | Batch: 9600/10001 (96%) | G Loss: 2.623252 | C Loss: -0.578839\n",
      "06/29/2022 05:54:06 - INFO - __main__ -   Text: [\"Pistoles asks me if I'm interested in reading.\"]\n",
      "06/29/2022 05:54:06 - INFO - __main__ -   * (Train) Epoch: 100 | G Loss: 2.5352 | C Loss: -0.5799 | Updates G: 47 | Updates C: 786\n",
      "06/29/2022 05:54:15 - INFO - __main__ -   Bleu-2:0.206 | B-Bleu-2:0.248\n",
      "06/29/2022 05:54:15 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4536770163539181\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 101 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:57:47 - INFO - __main__ -   Epoch: 101 | Batch: 0/10001 (0%) | G Loss: 2.534458 | C Loss: -0.411803\n",
      "06/29/2022 05:57:47 - INFO - __main__ -   Text: ['Another feature of the festival is Circles of Dangerousness.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.740\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 05:57:48 - INFO - __main__ -   Epoch: 101 | Batch: 600/10001 (6%) | G Loss: 2.443505 | C Loss: -0.769050\n",
      "06/29/2022 05:57:48 - INFO - __main__ -   Text: ['James Rand Gillum is the only American with a net worth of over $100.']\n",
      "06/29/2022 05:57:49 - INFO - __main__ -   Epoch: 101 | Batch: 1200/10001 (12%) | G Loss: 2.409952 | C Loss: -0.473869\n",
      "06/29/2022 05:57:49 - INFO - __main__ -   Text: ['The ideas of the mad god.']\n",
      "06/29/2022 05:57:50 - INFO - __main__ -   Epoch: 101 | Batch: 1800/10001 (18%) | G Loss: 2.301521 | C Loss: -0.319661\n",
      "06/29/2022 05:57:50 - INFO - __main__ -   Text: ['determine what.']\n",
      "06/29/2022 05:57:51 - INFO - __main__ -   Epoch: 101 | Batch: 2400/10001 (24%) | G Loss: 2.817998 | C Loss: -0.721387\n",
      "06/29/2022 05:57:51 - INFO - __main__ -   Text: ['Its name is \"Houston Raging.\"']\n",
      "06/29/2022 05:57:52 - INFO - __main__ -   Epoch: 101 | Batch: 3000/10001 (30%) | G Loss: 3.017737 | C Loss: -0.747237\n",
      "06/29/2022 05:57:52 - INFO - __main__ -   Text: ['Throughout all modern endeavor, Kripke spends his time to teach to humans.']\n",
      "06/29/2022 05:57:53 - INFO - __main__ -   Epoch: 101 | Batch: 3600/10001 (36%) | G Loss: 2.253136 | C Loss: -0.388705\n",
      "06/29/2022 05:57:54 - INFO - __main__ -   Text: ['Perhaps this could be described as audacious, feathered and thelike.']\n",
      "06/29/2022 05:57:54 - INFO - __main__ -   Epoch: 101 | Batch: 4200/10001 (42%) | G Loss: 2.387352 | C Loss: -0.708827\n",
      "06/29/2022 05:57:55 - INFO - __main__ -   Text: ['The personality is three, middle grade, and has incredible interest in women.']\n",
      "06/29/2022 05:57:56 - INFO - __main__ -   Epoch: 101 | Batch: 4800/10001 (48%) | G Loss: 2.658894 | C Loss: -0.431660\n",
      "06/29/2022 05:57:56 - INFO - __main__ -   Text: ['This shows how real storytelling can be part of a score.']\n",
      "06/29/2022 05:57:57 - INFO - __main__ -   Epoch: 101 | Batch: 5400/10001 (54%) | G Loss: 2.686611 | C Loss: -0.440292\n",
      "06/29/2022 05:57:57 - INFO - __main__ -   Text: ['However he does admit to dyslexia !']\n",
      "06/29/2022 05:57:58 - INFO - __main__ -   Epoch: 101 | Batch: 6000/10001 (60%) | G Loss: 2.781662 | C Loss: -0.684646\n",
      "06/29/2022 05:57:58 - INFO - __main__ -   Text: ['However, .....']\n",
      "06/29/2022 05:57:59 - INFO - __main__ -   Epoch: 101 | Batch: 6600/10001 (66%) | G Loss: 2.353362 | C Loss: -0.475321\n",
      "06/29/2022 05:57:59 - INFO - __main__ -   Text: ['Jewish princess surely chews it.']\n",
      "06/29/2022 05:58:00 - INFO - __main__ -   Epoch: 101 | Batch: 7200/10001 (72%) | G Loss: 2.682100 | C Loss: -0.574848\n",
      "06/29/2022 05:58:00 - INFO - __main__ -   Text: ['Dat hup!']\n",
      "06/29/2022 05:58:01 - INFO - __main__ -   Epoch: 101 | Batch: 7800/10001 (78%) | G Loss: 2.720575 | C Loss: -0.739585\n",
      "06/29/2022 05:58:01 - INFO - __main__ -   Text: ['S Hey!']\n",
      "06/29/2022 05:58:02 - INFO - __main__ -   Epoch: 101 | Batch: 8400/10001 (84%) | G Loss: 2.966857 | C Loss: -0.837645\n",
      "06/29/2022 05:58:02 - INFO - __main__ -   Text: ['They find characteristics of IT networking outside accelerator networks.']\n",
      "06/29/2022 05:58:03 - INFO - __main__ -   Epoch: 101 | Batch: 9000/10001 (90%) | G Loss: 2.474566 | C Loss: -0.496596\n",
      "06/29/2022 05:58:03 - INFO - __main__ -   Text: [\"When anyone is goin' to see you there.\"]\n",
      "06/29/2022 05:58:04 - INFO - __main__ -   Epoch: 101 | Batch: 9600/10001 (96%) | G Loss: 2.493431 | C Loss: -0.479153\n",
      "06/29/2022 05:58:04 - INFO - __main__ -   Text: ['Abraham Lincoln bullets at this lighthouse regularly.']\n",
      "06/29/2022 05:58:05 - INFO - __main__ -   * (Train) Epoch: 101 | G Loss: 2.5020 | C Loss: -0.5593 | Updates G: 61 | Updates C: 772\n",
      "06/29/2022 05:58:14 - INFO - __main__ -   Bleu-2:0.190 | B-Bleu-2:0.232\n",
      "06/29/2022 05:58:14 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_18.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4224771531896719\n",
      "Train file used is number 18\n",
      "../../yahoo/subdivided_large/train_18.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 102 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:01:44 - INFO - __main__ -   Epoch: 102 | Batch: 0/10001 (0%) | G Loss: 2.743485 | C Loss: -0.726604\n",
      "06/29/2022 06:01:44 - INFO - __main__ -   Text: ['jellyllieg and Hugh-Percent.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.798\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:01:45 - INFO - __main__ -   Epoch: 102 | Batch: 600/10001 (6%) | G Loss: 2.681410 | C Loss: -0.545785\n",
      "06/29/2022 06:01:45 - INFO - __main__ -   Text: ['This is the nature of everything that is happening.\"']\n",
      "06/29/2022 06:01:46 - INFO - __main__ -   Epoch: 102 | Batch: 1200/10001 (12%) | G Loss: 2.286339 | C Loss: -0.278685\n",
      "06/29/2022 06:01:46 - INFO - __main__ -   Text: ['Its like the hub of the kushari economy.']\n",
      "06/29/2022 06:01:47 - INFO - __main__ -   Epoch: 102 | Batch: 1800/10001 (18%) | G Loss: 2.443533 | C Loss: -0.472315\n",
      "06/29/2022 06:01:47 - INFO - __main__ -   Text: ['It\\'s not crazy to try it, but it feels like I\\'m faking it.\"']\n",
      "06/29/2022 06:01:48 - INFO - __main__ -   Epoch: 102 | Batch: 2400/10001 (24%) | G Loss: 3.187770 | C Loss: -0.882765\n",
      "06/29/2022 06:01:48 - INFO - __main__ -   Text: ['The time is never right to turn back to celestial passion.']\n",
      "06/29/2022 06:01:49 - INFO - __main__ -   Epoch: 102 | Batch: 3000/10001 (30%) | G Loss: 2.771807 | C Loss: -0.601695\n",
      "06/29/2022 06:01:49 - INFO - __main__ -   Text: ['Geneves and Steamboat attended.']\n",
      "06/29/2022 06:01:50 - INFO - __main__ -   Epoch: 102 | Batch: 3600/10001 (36%) | G Loss: 2.343176 | C Loss: -0.607164\n",
      "06/29/2022 06:01:50 - INFO - __main__ -   Text: [\"Braggan's geography is plain.\"]\n",
      "06/29/2022 06:01:51 - INFO - __main__ -   Epoch: 102 | Batch: 4200/10001 (42%) | G Loss: 2.319152 | C Loss: -0.398160\n",
      "06/29/2022 06:01:51 - INFO - __main__ -   Text: ['Repeatable appearances…']\n",
      "06/29/2022 06:01:52 - INFO - __main__ -   Epoch: 102 | Batch: 4800/10001 (48%) | G Loss: 2.588912 | C Loss: -0.696816\n",
      "06/29/2022 06:01:52 - INFO - __main__ -   Text: [\"He's lonely because of it.\"]\n",
      "06/29/2022 06:01:53 - INFO - __main__ -   Epoch: 102 | Batch: 5400/10001 (54%) | G Loss: 3.069537 | C Loss: -0.653480\n",
      "06/29/2022 06:01:54 - INFO - __main__ -   Text: ['In contrast, the program which correctly identified Ebola died on August 15.']\n",
      "06/29/2022 06:01:55 - INFO - __main__ -   Epoch: 102 | Batch: 6000/10001 (60%) | G Loss: 2.783159 | C Loss: -0.535871\n",
      "06/29/2022 06:01:55 - INFO - __main__ -   Text: ['Science as 21α can regulate a normal spectrum.']\n",
      "06/29/2022 06:01:56 - INFO - __main__ -   Epoch: 102 | Batch: 6600/10001 (66%) | G Loss: 2.631347 | C Loss: -0.667594\n",
      "06/29/2022 06:01:56 - INFO - __main__ -   Text: ['Standard sports hit-cute!']\n",
      "06/29/2022 06:01:57 - INFO - __main__ -   Epoch: 102 | Batch: 7200/10001 (72%) | G Loss: 2.218299 | C Loss: -0.439730\n",
      "06/29/2022 06:01:57 - INFO - __main__ -   Text: ['Another very useful qualification is \"truthfulness.\"']\n",
      "06/29/2022 06:01:58 - INFO - __main__ -   Epoch: 102 | Batch: 7800/10001 (78%) | G Loss: 2.234153 | C Loss: -0.532159\n",
      "06/29/2022 06:01:58 - INFO - __main__ -   Text: [\"This is Bern's worst alto saxophone.\"]\n",
      "06/29/2022 06:01:59 - INFO - __main__ -   Epoch: 102 | Batch: 8400/10001 (84%) | G Loss: 2.727427 | C Loss: -0.482975\n",
      "06/29/2022 06:01:59 - INFO - __main__ -   Text: ['Air seatpot regulations are common.']\n",
      "06/29/2022 06:02:00 - INFO - __main__ -   Epoch: 102 | Batch: 9000/10001 (90%) | G Loss: 2.602064 | C Loss: -0.793054\n",
      "06/29/2022 06:02:00 - INFO - __main__ -   Text: ['A trick to calm people into meeting tone.']\n",
      "06/29/2022 06:02:01 - INFO - __main__ -   Epoch: 102 | Batch: 9600/10001 (96%) | G Loss: 2.307160 | C Loss: -0.375864\n",
      "06/29/2022 06:02:01 - INFO - __main__ -   Text: ['As stated above, \"wandering hard\" is dangerous.']\n",
      "06/29/2022 06:02:02 - INFO - __main__ -   * (Train) Epoch: 102 | G Loss: 2.4838 | C Loss: -0.5643 | Updates G: 48 | Updates C: 785\n",
      "06/29/2022 06:02:11 - INFO - __main__ -   Bleu-2:0.194 | B-Bleu-2:0.259\n",
      "06/29/2022 06:02:11 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4527821119336176\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 103 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:00.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:18.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:05:46 - INFO - __main__ -   Epoch: 103 | Batch: 0/10001 (0%) | G Loss: 2.617576 | C Loss: -0.688074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.838\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:05:47 - INFO - __main__ -   Text: ['He refers to YouTube as the podcast we should listen to and how I\\'m very interested in our fellow country.\"']\n",
      "06/29/2022 06:05:48 - INFO - __main__ -   Epoch: 103 | Batch: 600/10001 (6%) | G Loss: 2.775497 | C Loss: -0.646657\n",
      "06/29/2022 06:05:48 - INFO - __main__ -   Text: ['Huey is a small and beautiful Indian climbing enthusiast.']\n",
      "06/29/2022 06:05:49 - INFO - __main__ -   Epoch: 103 | Batch: 1200/10001 (12%) | G Loss: 2.718585 | C Loss: -0.504219\n",
      "06/29/2022 06:05:49 - INFO - __main__ -   Text: ['The blue moon rises above the upside-down lunar triangle.']\n",
      "06/29/2022 06:05:50 - INFO - __main__ -   Epoch: 103 | Batch: 1800/10001 (18%) | G Loss: 2.442250 | C Loss: -0.758473\n",
      "06/29/2022 06:05:50 - INFO - __main__ -   Text: ['\"parentialicge\" reduces calculation.']\n",
      "06/29/2022 06:05:51 - INFO - __main__ -   Epoch: 103 | Batch: 2400/10001 (24%) | G Loss: 2.187523 | C Loss: -0.506036\n",
      "06/29/2022 06:05:51 - INFO - __main__ -   Text: ['\"He is a little lizard\", \"N!\"']\n",
      "06/29/2022 06:05:52 - INFO - __main__ -   Epoch: 103 | Batch: 3000/10001 (30%) | G Loss: 2.262811 | C Loss: -0.451681\n",
      "06/29/2022 06:05:52 - INFO - __main__ -   Text: ['This is terrific if it really looks like it has a seat which at one moment will not be a car.\"']\n",
      "06/29/2022 06:05:53 - INFO - __main__ -   Epoch: 103 | Batch: 3600/10001 (36%) | G Loss: 2.393938 | C Loss: -0.540405\n",
      "06/29/2022 06:05:53 - INFO - __main__ -   Text: ['\"What do I do? <PAD> upon me.\"']\n",
      "06/29/2022 06:05:54 - INFO - __main__ -   Epoch: 103 | Batch: 4200/10001 (42%) | G Loss: 3.176292 | C Loss: -0.628878\n",
      "06/29/2022 06:05:54 - INFO - __main__ -   Text: ['Every fool knows a ball.']\n",
      "06/29/2022 06:05:55 - INFO - __main__ -   Epoch: 103 | Batch: 4800/10001 (48%) | G Loss: 3.016036 | C Loss: -0.610298\n",
      "06/29/2022 06:05:55 - INFO - __main__ -   Text: ['Having Never Moved reaches infinity!).']\n",
      "06/29/2022 06:05:56 - INFO - __main__ -   Epoch: 103 | Batch: 5400/10001 (54%) | G Loss: 2.323673 | C Loss: -0.310964\n",
      "06/29/2022 06:05:56 - INFO - __main__ -   Text: [\"Unlike some of StarQuest's website, Sharpe does not plan to feed leftovers.\"]\n",
      "06/29/2022 06:05:57 - INFO - __main__ -   Epoch: 103 | Batch: 6000/10001 (60%) | G Loss: 2.506381 | C Loss: -0.536890\n",
      "06/29/2022 06:05:58 - INFO - __main__ -   Text: [\"They're both too aggressive and are just like teenagers -- but they get along and become good friends.\"]\n",
      "06/29/2022 06:05:58 - INFO - __main__ -   Epoch: 103 | Batch: 6600/10001 (66%) | G Loss: 2.431416 | C Loss: -0.309145\n",
      "06/29/2022 06:05:59 - INFO - __main__ -   Text: ['Their passion is soaking up planets in their cakes.']\n",
      "06/29/2022 06:06:00 - INFO - __main__ -   Epoch: 103 | Batch: 7200/10001 (72%) | G Loss: 2.865939 | C Loss: -0.695113\n",
      "06/29/2022 06:06:00 - INFO - __main__ -   Text: ['From there it a huge VN.']\n",
      "06/29/2022 06:06:01 - INFO - __main__ -   Epoch: 103 | Batch: 7800/10001 (78%) | G Loss: 2.827329 | C Loss: -0.474024\n",
      "06/29/2022 06:06:01 - INFO - __main__ -   Text: [\"Nalayi's also written poetry for the Australian TV channels.\"]\n",
      "06/29/2022 06:06:02 - INFO - __main__ -   Epoch: 103 | Batch: 8400/10001 (84%) | G Loss: 3.024588 | C Loss: -0.747318\n",
      "06/29/2022 06:06:02 - INFO - __main__ -   Text: ['Bazah should tell her about a virus.']\n",
      "06/29/2022 06:06:03 - INFO - __main__ -   Epoch: 103 | Batch: 9000/10001 (90%) | G Loss: 2.304415 | C Loss: -0.256140\n",
      "06/29/2022 06:06:03 - INFO - __main__ -   Text: ['Orion is talking to himself, a pilot who is still in space.']\n",
      "06/29/2022 06:06:04 - INFO - __main__ -   Epoch: 103 | Batch: 9600/10001 (96%) | G Loss: 2.517856 | C Loss: -0.573308\n",
      "06/29/2022 06:06:04 - INFO - __main__ -   Text: ['Weapons are useful for connecting the radio waves to the subject.']\n",
      "06/29/2022 06:06:05 - INFO - __main__ -   * (Train) Epoch: 103 | G Loss: 2.5506 | C Loss: -0.5582 | Updates G: 58 | Updates C: 775\n",
      "06/29/2022 06:06:14 - INFO - __main__ -   Bleu-2:0.196 | B-Bleu-2:0.238\n",
      "06/29/2022 06:06:14 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4334854562743578\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 104 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:15.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:49.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:09:38 - INFO - __main__ -   Epoch: 104 | Batch: 0/10001 (0%) | G Loss: 2.637467 | C Loss: -0.569186\n",
      "06/29/2022 06:09:38 - INFO - __main__ -   Text: ['It is what usifies a method of reflection.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 3.832\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:09:39 - INFO - __main__ -   Epoch: 104 | Batch: 600/10001 (6%) | G Loss: 2.751119 | C Loss: -0.616659\n",
      "06/29/2022 06:09:39 - INFO - __main__ -   Text: ['automatic.']\n",
      "06/29/2022 06:09:40 - INFO - __main__ -   Epoch: 104 | Batch: 1200/10001 (12%) | G Loss: 2.475910 | C Loss: -0.570488\n",
      "06/29/2022 06:09:40 - INFO - __main__ -   Text: ['Dorothy eventually sticks to her plan after saving thousands of dollars.']\n",
      "06/29/2022 06:09:41 - INFO - __main__ -   Epoch: 104 | Batch: 1800/10001 (18%) | G Loss: 2.826913 | C Loss: -0.772654\n",
      "06/29/2022 06:09:41 - INFO - __main__ -   Text: ['Dress up as a martial artist.\"']\n",
      "06/29/2022 06:09:42 - INFO - __main__ -   Epoch: 104 | Batch: 2400/10001 (24%) | G Loss: 2.708184 | C Loss: -0.661653\n",
      "06/29/2022 06:09:42 - INFO - __main__ -   Text: ['Moon is these things every time you sell stuff.']\n",
      "06/29/2022 06:09:43 - INFO - __main__ -   Epoch: 104 | Batch: 3000/10001 (30%) | G Loss: 2.453314 | C Loss: -0.488881\n",
      "06/29/2022 06:09:43 - INFO - __main__ -   Text: ['Bellately tries 10.']\n",
      "06/29/2022 06:09:44 - INFO - __main__ -   Epoch: 104 | Batch: 3600/10001 (36%) | G Loss: 2.713264 | C Loss: -0.673468\n",
      "06/29/2022 06:09:44 - INFO - __main__ -   Text: ['The Feast of Jesus.']\n",
      "06/29/2022 06:09:45 - INFO - __main__ -   Epoch: 104 | Batch: 4200/10001 (42%) | G Loss: 2.978045 | C Loss: -0.653650\n",
      "06/29/2022 06:09:45 - INFO - __main__ -   Text: ['Bulletproof Proof\" + \"net\" states which paper is a safe bet.']\n",
      "06/29/2022 06:09:46 - INFO - __main__ -   Epoch: 104 | Batch: 4800/10001 (48%) | G Loss: 2.838039 | C Loss: -0.563735\n",
      "06/29/2022 06:09:47 - INFO - __main__ -   Text: ['The xo is too good to ignore.']\n",
      "06/29/2022 06:09:48 - INFO - __main__ -   Epoch: 104 | Batch: 5400/10001 (54%) | G Loss: 2.500055 | C Loss: -0.457095\n",
      "06/29/2022 06:09:48 - INFO - __main__ -   Text: ['When you kiss the future, you blow off your bubble.']\n",
      "06/29/2022 06:09:49 - INFO - __main__ -   Epoch: 104 | Batch: 6000/10001 (60%) | G Loss: 2.767944 | C Loss: -0.677540\n",
      "06/29/2022 06:09:49 - INFO - __main__ -   Text: ['The retail person is an infant who feeds by stinking.']\n",
      "06/29/2022 06:09:50 - INFO - __main__ -   Epoch: 104 | Batch: 6600/10001 (66%) | G Loss: 2.633654 | C Loss: -0.447350\n",
      "06/29/2022 06:09:50 - INFO - __main__ -   Text: ['When combined with computer power the adults profit further.']\n",
      "06/29/2022 06:09:51 - INFO - __main__ -   Epoch: 104 | Batch: 7200/10001 (72%) | G Loss: 2.882072 | C Loss: -0.736662\n",
      "06/29/2022 06:09:51 - INFO - __main__ -   Text: ['I shall forgive you but the spirit will not die.']\n",
      "06/29/2022 06:09:52 - INFO - __main__ -   Epoch: 104 | Batch: 7800/10001 (78%) | G Loss: 2.398288 | C Loss: -0.587427\n",
      "06/29/2022 06:09:52 - INFO - __main__ -   Text: ['You can sometimes find cybersystem infections.']\n",
      "06/29/2022 06:09:53 - INFO - __main__ -   Epoch: 104 | Batch: 8400/10001 (84%) | G Loss: 2.323615 | C Loss: -0.641779\n",
      "06/29/2022 06:09:53 - INFO - __main__ -   Text: ['The metric is geometric.']\n",
      "06/29/2022 06:09:54 - INFO - __main__ -   Epoch: 104 | Batch: 9000/10001 (90%) | G Loss: 2.528890 | C Loss: -0.636782\n",
      "06/29/2022 06:09:54 - INFO - __main__ -   Text: [\"It's Brazilian hillnights in French.\"]\n",
      "06/29/2022 06:09:56 - INFO - __main__ -   Epoch: 104 | Batch: 9600/10001 (96%) | G Loss: 2.717599 | C Loss: -0.700544\n",
      "06/29/2022 06:09:56 - INFO - __main__ -   Text: ['The biggest selling magazine prediction category one year ago is Business Flora Insurance.\"']\n",
      "06/29/2022 06:09:56 - INFO - __main__ -   * (Train) Epoch: 104 | G Loss: 2.5730 | C Loss: -0.5592 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 06:10:06 - INFO - __main__ -   Bleu-2:0.202 | B-Bleu-2:0.246\n",
      "06/29/2022 06:10:06 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4482503396639673\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 105 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:16.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:13:31 - INFO - __main__ -   Epoch: 105 | Batch: 0/10000 (0%) | G Loss: 2.955868 | C Loss: -0.522742\n",
      "06/29/2022 06:13:31 - INFO - __main__ -   Text: ['Other India-based cams are slower then ura-phases.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.847\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:13:32 - INFO - __main__ -   Epoch: 105 | Batch: 600/10000 (6%) | G Loss: 3.244634 | C Loss: -0.538594\n",
      "06/29/2022 06:13:32 - INFO - __main__ -   Text: ['There need not be a mandate for professions; rather, one must have acquired the skill set.']\n",
      "06/29/2022 06:13:33 - INFO - __main__ -   Epoch: 105 | Batch: 1200/10000 (12%) | G Loss: 2.792749 | C Loss: -0.630691\n",
      "06/29/2022 06:13:33 - INFO - __main__ -   Text: ['They combine 4 k views and 20 views. <PAD>']\n",
      "06/29/2022 06:13:34 - INFO - __main__ -   Epoch: 105 | Batch: 1800/10000 (18%) | G Loss: 2.581661 | C Loss: -0.481250\n",
      "06/29/2022 06:13:34 - INFO - __main__ -   Text: ['workers may produce would.']\n",
      "06/29/2022 06:13:35 - INFO - __main__ -   Epoch: 105 | Batch: 2400/10000 (24%) | G Loss: 2.409317 | C Loss: -0.475563\n",
      "06/29/2022 06:13:35 - INFO - __main__ -   Text: ['Will Key owns the FBSG.']\n",
      "06/29/2022 06:13:36 - INFO - __main__ -   Epoch: 105 | Batch: 3000/10000 (30%) | G Loss: 2.724638 | C Loss: -0.418827\n",
      "06/29/2022 06:13:36 - INFO - __main__ -   Text: ['These are the real supernatural cases that I should be writing.']\n",
      "06/29/2022 06:13:37 - INFO - __main__ -   Epoch: 105 | Batch: 3600/10000 (36%) | G Loss: 2.881584 | C Loss: -0.678120\n",
      "06/29/2022 06:13:37 - INFO - __main__ -   Text: ['Intentional dominance polices rightward to estavism.']\n",
      "06/29/2022 06:13:38 - INFO - __main__ -   Epoch: 105 | Batch: 4200/10000 (42%) | G Loss: 2.821827 | C Loss: -0.646652\n",
      "06/29/2022 06:13:38 - INFO - __main__ -   Text: ['Although he has high-mindedness, he doesn\\'t show it.\"']\n",
      "06/29/2022 06:13:39 - INFO - __main__ -   Epoch: 105 | Batch: 4800/10000 (48%) | G Loss: 2.994452 | C Loss: -0.661030\n",
      "06/29/2022 06:13:40 - INFO - __main__ -   Text: ['In order to find status with their respective tribe.']\n",
      "06/29/2022 06:13:41 - INFO - __main__ -   Epoch: 105 | Batch: 5400/10000 (54%) | G Loss: 2.613816 | C Loss: -0.375160\n",
      "06/29/2022 06:13:41 - INFO - __main__ -   Text: ['This flavor: one can keep meat tasty while maintaining nonuniform caloric intake.']\n",
      "06/29/2022 06:13:42 - INFO - __main__ -   Epoch: 105 | Batch: 6000/10000 (60%) | G Loss: 2.914373 | C Loss: -0.773167\n",
      "06/29/2022 06:13:42 - INFO - __main__ -   Text: ['How hard is your test to get?']\n",
      "06/29/2022 06:13:43 - INFO - __main__ -   Epoch: 105 | Batch: 6600/10000 (66%) | G Loss: 2.787783 | C Loss: -0.356783\n",
      "06/29/2022 06:13:43 - INFO - __main__ -   Text: ['It is a hobby.']\n",
      "06/29/2022 06:13:44 - INFO - __main__ -   Epoch: 105 | Batch: 7200/10000 (72%) | G Loss: 2.674331 | C Loss: -0.549803\n",
      "06/29/2022 06:13:44 - INFO - __main__ -   Text: ['She is known both for being a Christian and a Muslim.']\n",
      "06/29/2022 06:13:45 - INFO - __main__ -   Epoch: 105 | Batch: 7800/10000 (78%) | G Loss: 2.868267 | C Loss: -0.715273\n",
      "06/29/2022 06:13:45 - INFO - __main__ -   Text: ['The Long Red Planet is a dream portal through which the narrator encounters the nearest planet.']\n",
      "06/29/2022 06:13:46 - INFO - __main__ -   Epoch: 105 | Batch: 8400/10000 (84%) | G Loss: 2.580794 | C Loss: -0.446873\n",
      "06/29/2022 06:13:46 - INFO - __main__ -   Text: ['He also considers himself a biker.']\n",
      "06/29/2022 06:13:47 - INFO - __main__ -   Epoch: 105 | Batch: 9000/10000 (90%) | G Loss: 2.664413 | C Loss: -0.665653\n",
      "06/29/2022 06:13:47 - INFO - __main__ -   Text: ['Root is obsessed with the plague, Bugs, which he describes as \"Daisy.\"']\n",
      "06/29/2022 06:13:48 - INFO - __main__ -   Epoch: 105 | Batch: 9600/10000 (96%) | G Loss: 2.868414 | C Loss: -0.658372\n",
      "06/29/2022 06:13:48 - INFO - __main__ -   Text: ['There is a well-known store called Sell Cap\".']\n",
      "06/29/2022 06:13:49 - INFO - __main__ -   * (Train) Epoch: 105 | G Loss: 2.7359 | C Loss: -0.5485 | Updates G: 52 | Updates C: 781\n",
      "06/29/2022 06:13:58 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.275\n",
      "06/29/2022 06:13:58 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4817418220922518\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 106 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:17:33 - INFO - __main__ -   Epoch: 106 | Batch: 0/10000 (0%) | G Loss: 3.004759 | C Loss: -0.379241\n",
      "06/29/2022 06:17:33 - INFO - __main__ -   Text: ['The score is highly accurate!\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.812\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:17:34 - INFO - __main__ -   Epoch: 106 | Batch: 600/10000 (6%) | G Loss: 2.526893 | C Loss: -0.410198\n",
      "06/29/2022 06:17:34 - INFO - __main__ -   Text: ['There can be one\" Normales twenty-one\".']\n",
      "06/29/2022 06:17:35 - INFO - __main__ -   Epoch: 106 | Batch: 1200/10000 (12%) | G Loss: 2.442875 | C Loss: -0.481996\n",
      "06/29/2022 06:17:35 - INFO - __main__ -   Text: [\"They don't want to swallow trees that go downward.\"]\n",
      "06/29/2022 06:17:36 - INFO - __main__ -   Epoch: 106 | Batch: 1800/10000 (18%) | G Loss: 2.819127 | C Loss: -0.602865\n",
      "06/29/2022 06:17:36 - INFO - __main__ -   Text: ['Trilogy is for evil.\"']\n",
      "06/29/2022 06:17:37 - INFO - __main__ -   Epoch: 106 | Batch: 2400/10000 (24%) | G Loss: 2.896338 | C Loss: -0.649137\n",
      "06/29/2022 06:17:37 - INFO - __main__ -   Text: [\"Rodriguez'd came to take a bad name.\"]\n",
      "06/29/2022 06:17:38 - INFO - __main__ -   Epoch: 106 | Batch: 3000/10000 (30%) | G Loss: 2.660771 | C Loss: -0.315203\n",
      "06/29/2022 06:17:38 - INFO - __main__ -   Text: ['The ATHt is profitable only if its marketshareaper munihides.']\n",
      "06/29/2022 06:17:39 - INFO - __main__ -   Epoch: 106 | Batch: 3600/10000 (36%) | G Loss: 2.608201 | C Loss: -0.537605\n",
      "06/29/2022 06:17:39 - INFO - __main__ -   Text: ['This is the firstKorean championship to be held during the year of 2006. <PAD> <BOS>']\n",
      "06/29/2022 06:17:40 - INFO - __main__ -   Epoch: 106 | Batch: 4200/10000 (42%) | G Loss: 2.913587 | C Loss: -0.356802\n",
      "06/29/2022 06:17:40 - INFO - __main__ -   Text: [\"Meat doesn't feed to cyclists or boats in the island.\"]\n",
      "06/29/2022 06:17:41 - INFO - __main__ -   Epoch: 106 | Batch: 4800/10000 (48%) | G Loss: 2.816620 | C Loss: -0.443115\n",
      "06/29/2022 06:17:41 - INFO - __main__ -   Text: ['Many songs from NME.']\n",
      "06/29/2022 06:17:42 - INFO - __main__ -   Epoch: 106 | Batch: 5400/10000 (54%) | G Loss: 2.769897 | C Loss: -0.555979\n",
      "06/29/2022 06:17:43 - INFO - __main__ -   Text: ['CuRush has it number one pollularitalybie o Man!']\n",
      "06/29/2022 06:17:44 - INFO - __main__ -   Epoch: 106 | Batch: 6000/10000 (60%) | G Loss: 2.697990 | C Loss: -0.583745\n",
      "06/29/2022 06:17:44 - INFO - __main__ -   Text: ['To consider that such man knows very well how to do it to a man.']\n",
      "06/29/2022 06:17:45 - INFO - __main__ -   Epoch: 106 | Batch: 6600/10000 (66%) | G Loss: 2.818036 | C Loss: -0.506555\n",
      "06/29/2022 06:17:45 - INFO - __main__ -   Text: ['Nutella is typically only used as a temperature gauge.']\n",
      "06/29/2022 06:17:46 - INFO - __main__ -   Epoch: 106 | Batch: 7200/10000 (72%) | G Loss: 2.973739 | C Loss: -0.568774\n",
      "06/29/2022 06:17:46 - INFO - __main__ -   Text: ['It is one of the most famous test questions in the game.']\n",
      "06/29/2022 06:17:47 - INFO - __main__ -   Epoch: 106 | Batch: 7800/10000 (78%) | G Loss: 2.911045 | C Loss: -0.768774\n",
      "06/29/2022 06:17:47 - INFO - __main__ -   Text: ['This is our task.\"']\n",
      "06/29/2022 06:17:48 - INFO - __main__ -   Epoch: 106 | Batch: 8400/10000 (84%) | G Loss: 2.806144 | C Loss: -0.498228\n",
      "06/29/2022 06:17:48 - INFO - __main__ -   Text: ['Macklemore burps it in\".']\n",
      "06/29/2022 06:17:49 - INFO - __main__ -   Epoch: 106 | Batch: 9000/10000 (90%) | G Loss: 2.830189 | C Loss: -0.420438\n",
      "06/29/2022 06:17:49 - INFO - __main__ -   Text: ['This counts certainly very servois.']\n",
      "06/29/2022 06:17:50 - INFO - __main__ -   Epoch: 106 | Batch: 9600/10000 (96%) | G Loss: 2.800596 | C Loss: -0.527427\n",
      "06/29/2022 06:17:50 - INFO - __main__ -   Text: ['Ships rely satellites and zero depth off )']\n",
      "06/29/2022 06:17:51 - INFO - __main__ -   * (Train) Epoch: 106 | G Loss: 2.7420 | C Loss: -0.5416 | Updates G: 49 | Updates C: 784\n",
      "06/29/2022 06:18:00 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.288\n",
      "06/29/2022 06:18:00 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4926830984782705\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 107 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:21:34 - INFO - __main__ -   Epoch: 107 | Batch: 0/10001 (0%) | G Loss: 2.775773 | C Loss: -0.508764\n",
      "06/29/2022 06:21:34 - INFO - __main__ -   Text: ['Pocket and I go there to learn stuff.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.487\n",
      "  Test Loss: 3.745\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:21:35 - INFO - __main__ -   Epoch: 107 | Batch: 600/10001 (6%) | G Loss: 2.841412 | C Loss: -0.704459\n",
      "06/29/2022 06:21:35 - INFO - __main__ -   Text: ['A auto-dial hardness pen.']\n",
      "06/29/2022 06:21:36 - INFO - __main__ -   Epoch: 107 | Batch: 1200/10001 (12%) | G Loss: 2.902730 | C Loss: -0.670287\n",
      "06/29/2022 06:21:36 - INFO - __main__ -   Text: ['The first step to master this scenario is to enter the World of Invention.']\n",
      "06/29/2022 06:21:37 - INFO - __main__ -   Epoch: 107 | Batch: 1800/10001 (18%) | G Loss: 2.764181 | C Loss: -0.680994\n",
      "06/29/2022 06:21:37 - INFO - __main__ -   Text: ['Pleased to see your name stuck in the Seven Fingers\".']\n",
      "06/29/2022 06:21:38 - INFO - __main__ -   Epoch: 107 | Batch: 2400/10001 (24%) | G Loss: 2.600453 | C Loss: -0.335726\n",
      "06/29/2022 06:21:38 - INFO - __main__ -   Text: ['The genre is cat food.']\n",
      "06/29/2022 06:21:39 - INFO - __main__ -   Epoch: 107 | Batch: 3000/10001 (30%) | G Loss: 2.942452 | C Loss: -0.758867\n",
      "06/29/2022 06:21:39 - INFO - __main__ -   Text: ['It is also studying online marketing.']\n",
      "06/29/2022 06:21:40 - INFO - __main__ -   Epoch: 107 | Batch: 3600/10001 (36%) | G Loss: 2.739258 | C Loss: -0.625124\n",
      "06/29/2022 06:21:41 - INFO - __main__ -   Text: ['Its average value is .']\n",
      "06/29/2022 06:21:41 - INFO - __main__ -   Epoch: 107 | Batch: 4200/10001 (42%) | G Loss: 2.387149 | C Loss: -0.489317\n",
      "06/29/2022 06:21:42 - INFO - __main__ -   Text: [\"It's so hip that he is happily gay.\"]\n",
      "06/29/2022 06:21:43 - INFO - __main__ -   Epoch: 107 | Batch: 4800/10001 (48%) | G Loss: 2.466591 | C Loss: -0.503933\n",
      "06/29/2022 06:21:43 - INFO - __main__ -   Text: ['\"Car!\".']\n",
      "06/29/2022 06:21:44 - INFO - __main__ -   Epoch: 107 | Batch: 5400/10001 (54%) | G Loss: 3.116495 | C Loss: -0.444192\n",
      "06/29/2022 06:21:44 - INFO - __main__ -   Text: ['\"okay yip\".']\n",
      "06/29/2022 06:21:45 - INFO - __main__ -   Epoch: 107 | Batch: 6000/10001 (60%) | G Loss: 2.878851 | C Loss: -0.354565\n",
      "06/29/2022 06:21:45 - INFO - __main__ -   Text: ['This causes geometry to diffractly supersede geometry.']\n",
      "06/29/2022 06:21:46 - INFO - __main__ -   Epoch: 107 | Batch: 6600/10001 (66%) | G Loss: 2.617809 | C Loss: -0.373332\n",
      "06/29/2022 06:21:46 - INFO - __main__ -   Text: [\"It's my favourite song.\"]\n",
      "06/29/2022 06:21:47 - INFO - __main__ -   Epoch: 107 | Batch: 7200/10001 (72%) | G Loss: 2.771546 | C Loss: -0.602088\n",
      "06/29/2022 06:21:47 - INFO - __main__ -   Text: ['The lamest compare noisily .']\n",
      "06/29/2022 06:21:48 - INFO - __main__ -   Epoch: 107 | Batch: 7800/10001 (78%) | G Loss: 2.690998 | C Loss: -0.561249\n",
      "06/29/2022 06:21:48 - INFO - __main__ -   Text: ['JD uses Emotile.']\n",
      "06/29/2022 06:21:49 - INFO - __main__ -   Epoch: 107 | Batch: 8400/10001 (84%) | G Loss: 3.012884 | C Loss: -0.944724\n",
      "06/29/2022 06:21:49 - INFO - __main__ -   Text: ['This second inactivation also occurs in the throat.']\n",
      "06/29/2022 06:21:50 - INFO - __main__ -   Epoch: 107 | Batch: 9000/10001 (90%) | G Loss: 2.656023 | C Loss: -0.552290\n",
      "06/29/2022 06:21:50 - INFO - __main__ -   Text: ['The formula is to be chosen especially because the world is farther away.']\n",
      "06/29/2022 06:21:51 - INFO - __main__ -   Epoch: 107 | Batch: 9600/10001 (96%) | G Loss: 2.544115 | C Loss: -0.504295\n",
      "06/29/2022 06:21:51 - INFO - __main__ -   Text: ['Already itmassed Euclidean.']\n",
      "06/29/2022 06:21:52 - INFO - __main__ -   * (Train) Epoch: 107 | G Loss: 2.6675 | C Loss: -0.5428 | Updates G: 44 | Updates C: 789\n",
      "06/29/2022 06:22:01 - INFO - __main__ -   Bleu-2:0.197 | B-Bleu-2:0.230\n",
      "06/29/2022 06:22:01 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4269737313404716\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 108 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:25:26 - INFO - __main__ -   Epoch: 108 | Batch: 0/10001 (0%) | G Loss: 2.723424 | C Loss: -0.632292\n",
      "06/29/2022 06:25:26 - INFO - __main__ -   Text: ['Manufacturing succeeds him.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.738\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:25:27 - INFO - __main__ -   Epoch: 108 | Batch: 600/10001 (6%) | G Loss: 2.791740 | C Loss: -0.700160\n",
      "06/29/2022 06:25:27 - INFO - __main__ -   Text: ['Pulsivity is the deciding factor.']\n",
      "06/29/2022 06:25:28 - INFO - __main__ -   Epoch: 108 | Batch: 1200/10001 (12%) | G Loss: 2.944952 | C Loss: -0.430785\n",
      "06/29/2022 06:25:28 - INFO - __main__ -   Text: ['It is a serial podcasting alternative to YouTube or IndieTV.']\n",
      "06/29/2022 06:25:29 - INFO - __main__ -   Epoch: 108 | Batch: 1800/10001 (18%) | G Loss: 3.100199 | C Loss: -0.579731\n",
      "06/29/2022 06:25:30 - INFO - __main__ -   Text: ['The term originated with SKLN where information may aid a general orientation course.']\n",
      "06/29/2022 06:25:31 - INFO - __main__ -   Epoch: 108 | Batch: 2400/10001 (24%) | G Loss: 2.302564 | C Loss: -0.535568\n",
      "06/29/2022 06:25:31 - INFO - __main__ -   Text: ['He༼u know what babies mean by that!']\n",
      "06/29/2022 06:25:32 - INFO - __main__ -   Epoch: 108 | Batch: 3000/10001 (30%) | G Loss: 2.326325 | C Loss: -0.341879\n",
      "06/29/2022 06:25:32 - INFO - __main__ -   Text: [\"The actor will ask nothing but what he's doing in order to justify the porniness in his life.\"]\n",
      "06/29/2022 06:25:33 - INFO - __main__ -   Epoch: 108 | Batch: 3600/10001 (36%) | G Loss: 2.941381 | C Loss: -0.417239\n",
      "06/29/2022 06:25:33 - INFO - __main__ -   Text: ['This is a scientific analogy that is not very parsimonious, with the Mohab butt going to body.']\n",
      "06/29/2022 06:25:34 - INFO - __main__ -   Epoch: 108 | Batch: 4200/10001 (42%) | G Loss: 2.717433 | C Loss: -0.443438\n",
      "06/29/2022 06:25:34 - INFO - __main__ -   Text: ['This is an excellent test to assess the adaption of e-books.']\n",
      "06/29/2022 06:25:35 - INFO - __main__ -   Epoch: 108 | Batch: 4800/10001 (48%) | G Loss: 2.722366 | C Loss: -0.466722\n",
      "06/29/2022 06:25:35 - INFO - __main__ -   Text: [\"You'll have a short cut.\"]\n",
      "06/29/2022 06:25:36 - INFO - __main__ -   Epoch: 108 | Batch: 5400/10001 (54%) | G Loss: 2.971333 | C Loss: -0.760806\n",
      "06/29/2022 06:25:36 - INFO - __main__ -   Text: ['It is about a lesbian broadcaster.']\n",
      "06/29/2022 06:25:37 - INFO - __main__ -   Epoch: 108 | Batch: 6000/10001 (60%) | G Loss: 2.714021 | C Loss: -0.595776\n",
      "06/29/2022 06:25:37 - INFO - __main__ -   Text: ['There is a conscience here.\"']\n",
      "06/29/2022 06:25:38 - INFO - __main__ -   Epoch: 108 | Batch: 6600/10001 (66%) | G Loss: 2.672509 | C Loss: -0.510726\n",
      "06/29/2022 06:25:38 - INFO - __main__ -   Text: ['They may be useful to a farm or could be discovered by a physicist.']\n",
      "06/29/2022 06:25:39 - INFO - __main__ -   Epoch: 108 | Batch: 7200/10001 (72%) | G Loss: 2.693465 | C Loss: -0.795799\n",
      "06/29/2022 06:25:39 - INFO - __main__ -   Text: ['Other first-order terms are being omitted.']\n",
      "06/29/2022 06:25:40 - INFO - __main__ -   Epoch: 108 | Batch: 7800/10001 (78%) | G Loss: 2.610790 | C Loss: -0.441771\n",
      "06/29/2022 06:25:41 - INFO - __main__ -   Text: ['\"Metamorphose!\".']\n",
      "06/29/2022 06:25:41 - INFO - __main__ -   Epoch: 108 | Batch: 8400/10001 (84%) | G Loss: 2.703696 | C Loss: -0.602408\n",
      "06/29/2022 06:25:42 - INFO - __main__ -   Text: ['The typical question for the Nodeakian is \"Will it be a publishing system?\"']\n",
      "06/29/2022 06:25:43 - INFO - __main__ -   Epoch: 108 | Batch: 9000/10001 (90%) | G Loss: 2.856854 | C Loss: -0.464276\n",
      "06/29/2022 06:25:43 - INFO - __main__ -   Text: ['Though both formal and informal schooling is also available.']\n",
      "06/29/2022 06:25:44 - INFO - __main__ -   Epoch: 108 | Batch: 9600/10001 (96%) | G Loss: 3.101348 | C Loss: -0.526052\n",
      "06/29/2022 06:25:44 - INFO - __main__ -   Text: ['Every wrestler with massive boos enables the bear, third in this category.']\n",
      "06/29/2022 06:25:44 - INFO - __main__ -   * (Train) Epoch: 108 | G Loss: 2.7679 | C Loss: -0.5430 | Updates G: 53 | Updates C: 780\n",
      "06/29/2022 06:25:54 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.273\n",
      "06/29/2022 06:25:54 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4704866253621808\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 109 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:00.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:18.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:29:29 - INFO - __main__ -   Epoch: 109 | Batch: 0/10001 (0%) | G Loss: 2.748689 | C Loss: -0.438275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.834\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:29:29 - INFO - __main__ -   Text: ['Similarly, Cosmo says she has no marketing ideas of why she puts how she dresses at all.']\n",
      "06/29/2022 06:29:30 - INFO - __main__ -   Epoch: 109 | Batch: 600/10001 (6%) | G Loss: 2.882361 | C Loss: -0.574212\n",
      "06/29/2022 06:29:30 - INFO - __main__ -   Text: ['The Internet is a affiliation for YouTube programmers.']\n",
      "06/29/2022 06:29:31 - INFO - __main__ -   Epoch: 109 | Batch: 1200/10001 (12%) | G Loss: 2.851241 | C Loss: -0.472801\n",
      "06/29/2022 06:29:31 - INFO - __main__ -   Text: ['If you can speak English a lot, here is a hard-hitting article.\"']\n",
      "06/29/2022 06:29:32 - INFO - __main__ -   Epoch: 109 | Batch: 1800/10001 (18%) | G Loss: 3.014309 | C Loss: -0.649471\n",
      "06/29/2022 06:29:32 - INFO - __main__ -   Text: ['As a kind of \"desertion.']\n",
      "06/29/2022 06:29:33 - INFO - __main__ -   Epoch: 109 | Batch: 2400/10001 (24%) | G Loss: 3.021297 | C Loss: -0.558190\n",
      "06/29/2022 06:29:33 - INFO - __main__ -   Text: ['Labs Interface picks a great company to get its JavaScript to automate JavaScript.']\n",
      "06/29/2022 06:29:34 - INFO - __main__ -   Epoch: 109 | Batch: 3000/10001 (30%) | G Loss: 2.513858 | C Loss: -0.630349\n",
      "06/29/2022 06:29:35 - INFO - __main__ -   Text: ['It is a Bishop to whom the King was allegedly elected.']\n",
      "06/29/2022 06:29:36 - INFO - __main__ -   Epoch: 109 | Batch: 3600/10001 (36%) | G Loss: 2.569688 | C Loss: -0.372342\n",
      "06/29/2022 06:29:36 - INFO - __main__ -   Text: [\"Puckiney is Myrtle's Pilot.\"]\n",
      "06/29/2022 06:29:37 - INFO - __main__ -   Epoch: 109 | Batch: 4200/10001 (42%) | G Loss: 2.809282 | C Loss: -0.560054\n",
      "06/29/2022 06:29:37 - INFO - __main__ -   Text: ['Santa and Mister Morgan are four other teenagers who attempt to kill zombies.']\n",
      "06/29/2022 06:29:38 - INFO - __main__ -   Epoch: 109 | Batch: 4800/10001 (48%) | G Loss: 3.044114 | C Loss: -0.475183\n",
      "06/29/2022 06:29:38 - INFO - __main__ -   Text: ['\"Red is the... Here\\'s the \"unseen.\"']\n",
      "06/29/2022 06:29:39 - INFO - __main__ -   Epoch: 109 | Batch: 5400/10001 (54%) | G Loss: 3.071754 | C Loss: -0.585950\n",
      "06/29/2022 06:29:39 - INFO - __main__ -   Text: ['This book is about an American school that has already enrolled 12 schools in Indonesia.']\n",
      "06/29/2022 06:29:40 - INFO - __main__ -   Epoch: 109 | Batch: 6000/10001 (60%) | G Loss: 2.740530 | C Loss: -0.534987\n",
      "06/29/2022 06:29:40 - INFO - __main__ -   Text: ['He works a scientific method.']\n",
      "06/29/2022 06:29:41 - INFO - __main__ -   Epoch: 109 | Batch: 6600/10001 (66%) | G Loss: 2.718453 | C Loss: -0.536772\n",
      "06/29/2022 06:29:41 - INFO - __main__ -   Text: ['Thus we can try:']\n",
      "06/29/2022 06:29:42 - INFO - __main__ -   Epoch: 109 | Batch: 7200/10001 (72%) | G Loss: 2.724373 | C Loss: -0.551082\n",
      "06/29/2022 06:29:42 - INFO - __main__ -   Text: ['Moroccan philosophy structures this fact as incurable.']\n",
      "06/29/2022 06:29:43 - INFO - __main__ -   Epoch: 109 | Batch: 7800/10001 (78%) | G Loss: 2.810212 | C Loss: -0.613275\n",
      "06/29/2022 06:29:43 - INFO - __main__ -   Text: ['One of the characters you might remember is a \"Karthi\".']\n",
      "06/29/2022 06:29:44 - INFO - __main__ -   Epoch: 109 | Batch: 8400/10001 (84%) | G Loss: 3.015505 | C Loss: -0.574606\n",
      "06/29/2022 06:29:44 - INFO - __main__ -   Text: ['He also has many wild ways that he uses to reach the First World.']\n",
      "06/29/2022 06:29:45 - INFO - __main__ -   Epoch: 109 | Batch: 9000/10001 (90%) | G Loss: 3.319021 | C Loss: -0.485039\n",
      "06/29/2022 06:29:45 - INFO - __main__ -   Text: ['The nature of ecstimulation can be studied in a lab.']\n",
      "06/29/2022 06:29:46 - INFO - __main__ -   Epoch: 109 | Batch: 9600/10001 (96%) | G Loss: 2.921299 | C Loss: -0.600331\n",
      "06/29/2022 06:29:47 - INFO - __main__ -   Text: ['Criminal cases, criminal school, read/write b: quote.']\n",
      "06/29/2022 06:29:47 - INFO - __main__ -   * (Train) Epoch: 109 | G Loss: 2.7673 | C Loss: -0.5368 | Updates G: 34 | Updates C: 799\n",
      "06/29/2022 06:29:56 - INFO - __main__ -   Bleu-2:0.213 | B-Bleu-2:0.242\n",
      "06/29/2022 06:29:56 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.455086093853764\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 110 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:33:28 - INFO - __main__ -   Epoch: 110 | Batch: 0/10001 (0%) | G Loss: 3.127879 | C Loss: -0.663192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.796\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:33:29 - INFO - __main__ -   Text: ['This is not to say that the birds are insatiable in life, they are just curious dogs.']\n",
      "06/29/2022 06:33:30 - INFO - __main__ -   Epoch: 110 | Batch: 600/10001 (6%) | G Loss: 3.008956 | C Loss: -0.547033\n",
      "06/29/2022 06:33:30 - INFO - __main__ -   Text: ['It is very dark and cool.\"']\n",
      "06/29/2022 06:33:31 - INFO - __main__ -   Epoch: 110 | Batch: 1200/10001 (12%) | G Loss: 2.917324 | C Loss: -0.771267\n",
      "06/29/2022 06:33:31 - INFO - __main__ -   Text: ['One dimension with no standard is that of the signifier is the water rate.']\n",
      "06/29/2022 06:33:32 - INFO - __main__ -   Epoch: 110 | Batch: 1800/10001 (18%) | G Loss: 2.781389 | C Loss: -0.523804\n",
      "06/29/2022 06:33:32 - INFO - __main__ -   Text: ['\"Utai kimirai\" means more intelligence\".']\n",
      "06/29/2022 06:33:33 - INFO - __main__ -   Epoch: 110 | Batch: 2400/10001 (24%) | G Loss: 3.130081 | C Loss: -0.382305\n",
      "06/29/2022 06:33:33 - INFO - __main__ -   Text: ['Father David asks.']\n",
      "06/29/2022 06:33:34 - INFO - __main__ -   Epoch: 110 | Batch: 3000/10001 (30%) | G Loss: 2.864086 | C Loss: -0.556930\n",
      "06/29/2022 06:33:34 - INFO - __main__ -   Text: ['She is much the second most common name in Slovenia.']\n",
      "06/29/2022 06:33:35 - INFO - __main__ -   Epoch: 110 | Batch: 3600/10001 (36%) | G Loss: 3.132053 | C Loss: -0.547169\n",
      "06/29/2022 06:33:35 - INFO - __main__ -   Text: [\"He doesn't listen.\"]\n",
      "06/29/2022 06:33:36 - INFO - __main__ -   Epoch: 110 | Batch: 4200/10001 (42%) | G Loss: 2.957829 | C Loss: -0.498056\n",
      "06/29/2022 06:33:36 - INFO - __main__ -   Text: ['Here are three methods of solving a primate problem.']\n",
      "06/29/2022 06:33:37 - INFO - __main__ -   Epoch: 110 | Batch: 4800/10001 (48%) | G Loss: 2.957944 | C Loss: -0.522765\n",
      "06/29/2022 06:33:37 - INFO - __main__ -   Text: [\"They are also recognised as favourites of certain hip hop group 'Stew.\"]\n",
      "06/29/2022 06:33:38 - INFO - __main__ -   Epoch: 110 | Batch: 5400/10001 (54%) | G Loss: 2.881026 | C Loss: -0.632857\n",
      "06/29/2022 06:33:38 - INFO - __main__ -   Text: ['The best one is ranked at 247 – highest percentage of repertoire.']\n",
      "06/29/2022 06:33:39 - INFO - __main__ -   Epoch: 110 | Batch: 6000/10001 (60%) | G Loss: 2.952162 | C Loss: -0.469909\n",
      "06/29/2022 06:33:39 - INFO - __main__ -   Text: [\"Copy that quote to me chick (i swear you're singin'.\"]\n",
      "06/29/2022 06:33:40 - INFO - __main__ -   Epoch: 110 | Batch: 6600/10001 (66%) | G Loss: 2.902213 | C Loss: -0.552148\n",
      "06/29/2022 06:33:41 - INFO - __main__ -   Text: ['It\\'s all good... and silly!\"']\n",
      "06/29/2022 06:33:42 - INFO - __main__ -   Epoch: 110 | Batch: 7200/10001 (72%) | G Loss: 3.180466 | C Loss: -0.574370\n",
      "06/29/2022 06:33:42 - INFO - __main__ -   Text: ['They have no lyrics.']\n",
      "06/29/2022 06:33:43 - INFO - __main__ -   Epoch: 110 | Batch: 7800/10001 (78%) | G Loss: 2.953503 | C Loss: -0.625020\n",
      "06/29/2022 06:33:43 - INFO - __main__ -   Text: ['Ethanol is a calculator and you can use the same method to get help.']\n",
      "06/29/2022 06:33:44 - INFO - __main__ -   Epoch: 110 | Batch: 8400/10001 (84%) | G Loss: 2.858316 | C Loss: -0.618388\n",
      "06/29/2022 06:33:44 - INFO - __main__ -   Text: ['This is streamed online so it can be isolated.']\n",
      "06/29/2022 06:33:45 - INFO - __main__ -   Epoch: 110 | Batch: 9000/10001 (90%) | G Loss: 3.039152 | C Loss: -0.717748\n",
      "06/29/2022 06:33:45 - INFO - __main__ -   Text: ['It is a patriot organization.']\n",
      "06/29/2022 06:33:46 - INFO - __main__ -   Epoch: 110 | Batch: 9600/10001 (96%) | G Loss: 2.768730 | C Loss: -0.499006\n",
      "06/29/2022 06:33:46 - INFO - __main__ -   Text: [\"They love their own status, but at don't dare to vote for the other party.\"]\n",
      "06/29/2022 06:33:47 - INFO - __main__ -   * (Train) Epoch: 110 | G Loss: 2.9262 | C Loss: -0.5370 | Updates G: 48 | Updates C: 785\n",
      "06/29/2022 06:33:56 - INFO - __main__ -   Bleu-2:0.205 | B-Bleu-2:0.240\n",
      "06/29/2022 06:33:56 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44474905232338124\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 111 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:37:40 - INFO - __main__ -   Epoch: 111 | Batch: 4800/10001 (48%) | G Loss: 2.777906 | C Loss: -0.574025\n",
      "06/29/2022 06:37:41 - INFO - __main__ -   Text: ['The test only offers a choice or some risk according to the student.']\n",
      "06/29/2022 06:37:42 - INFO - __main__ -   Epoch: 111 | Batch: 5400/10001 (54%) | G Loss: 3.128871 | C Loss: -0.621376\n",
      "06/29/2022 06:37:42 - INFO - __main__ -   Text: ['laboratory tests.']\n",
      "06/29/2022 06:37:43 - INFO - __main__ -   Epoch: 111 | Batch: 6000/10001 (60%) | G Loss: 2.892353 | C Loss: -0.599699\n",
      "06/29/2022 06:37:43 - INFO - __main__ -   Text: ['Metallism is one of the few methods with which a worker can find wearables.']\n",
      "06/29/2022 06:37:44 - INFO - __main__ -   Epoch: 111 | Batch: 6600/10001 (66%) | G Loss: 2.598894 | C Loss: -0.521891\n",
      "06/29/2022 06:37:44 - INFO - __main__ -   Text: [\"His Sunday Talk depends on kind of 'The Lending Guy' Rate-One.\"]\n",
      "06/29/2022 06:37:45 - INFO - __main__ -   Epoch: 111 | Batch: 7200/10001 (72%) | G Loss: 2.662956 | C Loss: -0.539289\n",
      "06/29/2022 06:37:45 - INFO - __main__ -   Text: ['Photographers view the capital as if they saw it from north\".']\n",
      "06/29/2022 06:37:46 - INFO - __main__ -   Epoch: 111 | Batch: 7800/10001 (78%) | G Loss: 2.856758 | C Loss: -0.569133\n",
      "06/29/2022 06:37:46 - INFO - __main__ -   Text: ['The celebrity form is famed magical power.']\n",
      "06/29/2022 06:37:47 - INFO - __main__ -   Epoch: 111 | Batch: 8400/10001 (84%) | G Loss: 2.774232 | C Loss: -0.459706\n",
      "06/29/2022 06:37:47 - INFO - __main__ -   Text: ['Climate Change Investigations & Disconnect.']\n",
      "06/29/2022 06:37:48 - INFO - __main__ -   Epoch: 111 | Batch: 9000/10001 (90%) | G Loss: 2.503333 | C Loss: -0.514583\n",
      "06/29/2022 06:37:48 - INFO - __main__ -   Text: ['It is often called a songwriter or chicken guy.']\n",
      "06/29/2022 06:37:49 - INFO - __main__ -   Epoch: 111 | Batch: 9600/10001 (96%) | G Loss: 2.892776 | C Loss: -0.464077\n",
      "06/29/2022 06:37:49 - INFO - __main__ -   Text: ['Studio films have lesson e about film and start n jokes in seroys.']\n",
      "06/29/2022 06:37:50 - INFO - __main__ -   * (Train) Epoch: 111 | G Loss: 2.7140 | C Loss: -0.5315 | Updates G: 36 | Updates C: 797\n",
      "06/29/2022 06:37:59 - INFO - __main__ -   Bleu-2:0.191 | B-Bleu-2:0.221\n",
      "06/29/2022 06:37:59 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41234660078613183\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 112 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:41:32 - INFO - __main__ -   Epoch: 112 | Batch: 0/10001 (0%) | G Loss: 2.732496 | C Loss: -0.596526\n",
      "06/29/2022 06:41:32 - INFO - __main__ -   Text: ['Conscious channel seeing right where you kneaculum.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.884\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:41:33 - INFO - __main__ -   Epoch: 112 | Batch: 600/10001 (6%) | G Loss: 2.641376 | C Loss: -0.638646\n",
      "06/29/2022 06:41:33 - INFO - __main__ -   Text: ['Peanut Buttercup is evil.']\n",
      "06/29/2022 06:41:34 - INFO - __main__ -   Epoch: 112 | Batch: 1200/10001 (12%) | G Loss: 2.655461 | C Loss: -0.340005\n",
      "06/29/2022 06:41:34 - INFO - __main__ -   Text: ['1 wins a 20% Sketches prize.']\n",
      "06/29/2022 06:41:35 - INFO - __main__ -   Epoch: 112 | Batch: 1800/10001 (18%) | G Loss: 2.987365 | C Loss: -0.549656\n",
      "06/29/2022 06:41:35 - INFO - __main__ -   Text: ['He does not hold a pro-Israel position.']\n",
      "06/29/2022 06:41:36 - INFO - __main__ -   Epoch: 112 | Batch: 2400/10001 (24%) | G Loss: 2.334194 | C Loss: -0.487385\n",
      "06/29/2022 06:41:36 - INFO - __main__ -   Text: ['She had no income in London and had no books.']\n",
      "06/29/2022 06:41:37 - INFO - __main__ -   Epoch: 112 | Batch: 3000/10001 (30%) | G Loss: 2.568518 | C Loss: -0.492797\n",
      "06/29/2022 06:41:37 - INFO - __main__ -   Text: ['Like Rome.']\n",
      "06/29/2022 06:41:38 - INFO - __main__ -   Epoch: 112 | Batch: 3600/10001 (36%) | G Loss: 2.724453 | C Loss: -0.566563\n",
      "06/29/2022 06:41:38 - INFO - __main__ -   Text: ['While some , are also The .']\n",
      "06/29/2022 06:41:39 - INFO - __main__ -   Epoch: 112 | Batch: 4200/10001 (42%) | G Loss: 2.920674 | C Loss: -0.548516\n",
      "06/29/2022 06:41:39 - INFO - __main__ -   Text: ['This idea is found in role-playing in the Western world.']\n",
      "06/29/2022 06:41:40 - INFO - __main__ -   Epoch: 112 | Batch: 4800/10001 (48%) | G Loss: 2.929468 | C Loss: -0.277757\n",
      "06/29/2022 06:41:40 - INFO - __main__ -   Text: ['Classically Teima dot is 000–000.']\n",
      "06/29/2022 06:41:41 - INFO - __main__ -   Epoch: 112 | Batch: 5400/10001 (54%) | G Loss: 2.635095 | C Loss: -0.637718\n",
      "06/29/2022 06:41:42 - INFO - __main__ -   Text: ['He also has an MBA from Southern University.']\n",
      "06/29/2022 06:41:43 - INFO - __main__ -   Epoch: 112 | Batch: 6000/10001 (60%) | G Loss: 2.511318 | C Loss: -0.418803\n",
      "06/29/2022 06:41:43 - INFO - __main__ -   Text: ['It is about flying monkeys in Hebrew.']\n",
      "06/29/2022 06:41:44 - INFO - __main__ -   Epoch: 112 | Batch: 6600/10001 (66%) | G Loss: 2.623311 | C Loss: -0.434160\n",
      "06/29/2022 06:41:44 - INFO - __main__ -   Text: ['People who have won the Great Lantern Prize often write poetry about The Gods.']\n",
      "06/29/2022 06:41:45 - INFO - __main__ -   Epoch: 112 | Batch: 7200/10001 (72%) | G Loss: 3.161235 | C Loss: -0.680522\n",
      "06/29/2022 06:41:45 - INFO - __main__ -   Text: ['Then it is possible to use cheap water.']\n",
      "06/29/2022 06:41:46 - INFO - __main__ -   Epoch: 112 | Batch: 7800/10001 (78%) | G Loss: 2.530504 | C Loss: -0.642756\n",
      "06/29/2022 06:41:46 - INFO - __main__ -   Text: ['Lorenz is overweight.']\n",
      "06/29/2022 06:41:47 - INFO - __main__ -   Epoch: 112 | Batch: 8400/10001 (84%) | G Loss: 3.000564 | C Loss: -0.646703\n",
      "06/29/2022 06:41:47 - INFO - __main__ -   Text: ['Yes I\\'m a calendar clock if I have them.\"']\n",
      "06/29/2022 06:41:48 - INFO - __main__ -   Epoch: 112 | Batch: 9000/10001 (90%) | G Loss: 2.864751 | C Loss: -0.530599\n",
      "06/29/2022 06:41:48 - INFO - __main__ -   Text: ['Hence everyone starts through this.']\n",
      "06/29/2022 06:41:49 - INFO - __main__ -   Epoch: 112 | Batch: 9600/10001 (96%) | G Loss: 2.983147 | C Loss: -0.537404\n",
      "06/29/2022 06:41:49 - INFO - __main__ -   Text: ['Less has a fee to acquire a business degree.']\n",
      "06/29/2022 06:41:50 - INFO - __main__ -   * (Train) Epoch: 112 | G Loss: 2.7655 | C Loss: -0.5300 | Updates G: 56 | Updates C: 777\n",
      "06/29/2022 06:41:59 - INFO - __main__ -   Bleu-2:0.191 | B-Bleu-2:0.271\n",
      "06/29/2022 06:41:59 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46174300313319316\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 113 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:45:33 - INFO - __main__ -   Epoch: 113 | Batch: 0/10001 (0%) | G Loss: 2.924703 | C Loss: -0.679778\n",
      "06/29/2022 06:45:33 - INFO - __main__ -   Text: ['The founder of Christianity was Kurt Vonnegut.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 3.892\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:45:34 - INFO - __main__ -   Epoch: 113 | Batch: 600/10001 (6%) | G Loss: 2.589621 | C Loss: -0.752975\n",
      "06/29/2022 06:45:34 - INFO - __main__ -   Text: ['His belief is that you should be sober.\"']\n",
      "06/29/2022 06:45:35 - INFO - __main__ -   Epoch: 113 | Batch: 1200/10001 (12%) | G Loss: 2.487520 | C Loss: -0.294718\n",
      "06/29/2022 06:45:35 - INFO - __main__ -   Text: ['The intro notes contains translations of the fluent English text.']\n",
      "06/29/2022 06:45:36 - INFO - __main__ -   Epoch: 113 | Batch: 1800/10001 (18%) | G Loss: 2.470397 | C Loss: -0.613472\n",
      "06/29/2022 06:45:36 - INFO - __main__ -   Text: ['Car is robbing a recycling port in an Arlington apartment.']\n",
      "06/29/2022 06:45:37 - INFO - __main__ -   Epoch: 113 | Batch: 2400/10001 (24%) | G Loss: 2.774956 | C Loss: -0.732576\n",
      "06/29/2022 06:45:37 - INFO - __main__ -   Text: ['He is interested in life in the present day and futures.']\n",
      "06/29/2022 06:45:38 - INFO - __main__ -   Epoch: 113 | Batch: 3000/10001 (30%) | G Loss: 2.947052 | C Loss: -0.658848\n",
      "06/29/2022 06:45:38 - INFO - __main__ -   Text: ['They do online processing for FEMA.']\n",
      "06/29/2022 06:45:39 - INFO - __main__ -   Epoch: 113 | Batch: 3600/10001 (36%) | G Loss: 2.767057 | C Loss: -0.442814\n",
      "06/29/2022 06:45:40 - INFO - __main__ -   Text: ['A wolf is just a world tempest.']\n",
      "06/29/2022 06:45:40 - INFO - __main__ -   Epoch: 113 | Batch: 4200/10001 (42%) | G Loss: 3.645762 | C Loss: -0.762112\n",
      "06/29/2022 06:45:41 - INFO - __main__ -   Text: [\"They are short for 'farming–farming for the benefit of humans' strategies.\"]\n",
      "06/29/2022 06:45:42 - INFO - __main__ -   Epoch: 113 | Batch: 4800/10001 (48%) | G Loss: 2.214119 | C Loss: -0.406783\n",
      "06/29/2022 06:45:42 - INFO - __main__ -   Text: ['The Forbes 1000 list of top universities.']\n",
      "06/29/2022 06:45:43 - INFO - __main__ -   Epoch: 113 | Batch: 5400/10001 (54%) | G Loss: 2.642657 | C Loss: -0.701160\n",
      "06/29/2022 06:45:43 - INFO - __main__ -   Text: ['So we are really passionate about today\\'s songs\".']\n",
      "06/29/2022 06:45:44 - INFO - __main__ -   Epoch: 113 | Batch: 6000/10001 (60%) | G Loss: 2.600998 | C Loss: -0.465264\n",
      "06/29/2022 06:45:44 - INFO - __main__ -   Text: ['Clarke\\'s mode for finding experience cards is \"make stairs.\"']\n",
      "06/29/2022 06:45:45 - INFO - __main__ -   Epoch: 113 | Batch: 6600/10001 (66%) | G Loss: 2.310344 | C Loss: -0.430489\n",
      "06/29/2022 06:45:45 - INFO - __main__ -   Text: ['They also look to churches because it is easy to know.\"']\n",
      "06/29/2022 06:45:46 - INFO - __main__ -   Epoch: 113 | Batch: 7200/10001 (72%) | G Loss: 3.386417 | C Loss: -0.536166\n",
      "06/29/2022 06:45:46 - INFO - __main__ -   Text: ['Rather, the Society Of Pain, this Rome of brain power.']\n",
      "06/29/2022 06:45:47 - INFO - __main__ -   Epoch: 113 | Batch: 7800/10001 (78%) | G Loss: 2.317983 | C Loss: -0.578391\n",
      "06/29/2022 06:45:47 - INFO - __main__ -   Text: ['The same is expressed by Vesakumar.']\n",
      "06/29/2022 06:45:48 - INFO - __main__ -   Epoch: 113 | Batch: 8400/10001 (84%) | G Loss: 2.065301 | C Loss: -0.544009\n",
      "06/29/2022 06:45:48 - INFO - __main__ -   Text: ['Beijing 64 is 114 degrees out.']\n",
      "06/29/2022 06:45:49 - INFO - __main__ -   Epoch: 113 | Batch: 9000/10001 (90%) | G Loss: 2.359160 | C Loss: -0.392121\n",
      "06/29/2022 06:45:49 - INFO - __main__ -   Text: ['Every time you praise someone, they always seem to me to be singing critical nonsense to their innate delight.']\n",
      "06/29/2022 06:45:50 - INFO - __main__ -   Epoch: 113 | Batch: 9600/10001 (96%) | G Loss: 2.465420 | C Loss: -0.341138\n",
      "06/29/2022 06:45:50 - INFO - __main__ -   Text: ['Steve Loundon writing.']\n",
      "06/29/2022 06:45:51 - INFO - __main__ -   * (Train) Epoch: 113 | G Loss: 2.6353 | C Loss: -0.5240 | Updates G: 57 | Updates C: 776\n",
      "06/29/2022 06:46:00 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.281\n",
      "06/29/2022 06:46:00 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4882023803216797\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 114 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:49:35 - INFO - __main__ -   Epoch: 114 | Batch: 0/10001 (0%) | G Loss: 3.086617 | C Loss: -0.508414\n",
      "06/29/2022 06:49:35 - INFO - __main__ -   Text: ['[Romans 3:8].\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.485\n",
      "  Test Loss: 3.959\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:49:36 - INFO - __main__ -   Epoch: 114 | Batch: 600/10001 (6%) | G Loss: 3.140165 | C Loss: -0.543037\n",
      "06/29/2022 06:49:36 - INFO - __main__ -   Text: ['If young people become infirm, they may be sceptical.']\n",
      "06/29/2022 06:49:37 - INFO - __main__ -   Epoch: 114 | Batch: 1200/10001 (12%) | G Loss: 2.776757 | C Loss: -0.596154\n",
      "06/29/2022 06:49:37 - INFO - __main__ -   Text: ['Bodega Coffee sells basic coffee to customers.']\n",
      "06/29/2022 06:49:38 - INFO - __main__ -   Epoch: 114 | Batch: 1800/10001 (18%) | G Loss: 2.635352 | C Loss: -0.566154\n",
      "06/29/2022 06:49:38 - INFO - __main__ -   Text: ['Psychologist Examining ninjas.']\n",
      "06/29/2022 06:49:39 - INFO - __main__ -   Epoch: 114 | Batch: 2400/10001 (24%) | G Loss: 2.813943 | C Loss: -0.524416\n",
      "06/29/2022 06:49:39 - INFO - __main__ -   Text: ['Indicornis compels a painful prostacy.']\n",
      "06/29/2022 06:49:40 - INFO - __main__ -   Epoch: 114 | Batch: 3000/10001 (30%) | G Loss: 2.581680 | C Loss: -0.479933\n",
      "06/29/2022 06:49:40 - INFO - __main__ -   Text: ['This store is very questionable!']\n",
      "06/29/2022 06:49:41 - INFO - __main__ -   Epoch: 114 | Batch: 3600/10001 (36%) | G Loss: 2.822048 | C Loss: -0.472581\n",
      "06/29/2022 06:49:41 - INFO - __main__ -   Text: ['But this drug was rendered useless in medical trials.']\n",
      "06/29/2022 06:49:42 - INFO - __main__ -   Epoch: 114 | Batch: 4200/10001 (42%) | G Loss: 3.045928 | C Loss: -0.539262\n",
      "06/29/2022 06:49:43 - INFO - __main__ -   Text: ['He is perfect in *next* way.']\n",
      "06/29/2022 06:49:44 - INFO - __main__ -   Epoch: 114 | Batch: 4800/10001 (48%) | G Loss: 3.056113 | C Loss: -0.353386\n",
      "06/29/2022 06:49:44 - INFO - __main__ -   Text: ['Indirectly, it route is congruent with correlation-gap theory.']\n",
      "06/29/2022 06:49:45 - INFO - __main__ -   Epoch: 114 | Batch: 5400/10001 (54%) | G Loss: 2.926809 | C Loss: -0.416700\n",
      "06/29/2022 06:49:45 - INFO - __main__ -   Text: ['\"The Army’s Catch-22.\"']\n",
      "06/29/2022 06:49:46 - INFO - __main__ -   Epoch: 114 | Batch: 6000/10001 (60%) | G Loss: 3.157084 | C Loss: -0.443336\n",
      "06/29/2022 06:49:46 - INFO - __main__ -   Text: ['Engineer can interact with others via specific commands.']\n",
      "06/29/2022 06:49:47 - INFO - __main__ -   Epoch: 114 | Batch: 6600/10001 (66%) | G Loss: 2.884501 | C Loss: -0.385980\n",
      "06/29/2022 06:49:47 - INFO - __main__ -   Text: ['They will teach you placebos.']\n",
      "06/29/2022 06:49:48 - INFO - __main__ -   Epoch: 114 | Batch: 7200/10001 (72%) | G Loss: 2.589625 | C Loss: -0.407527\n",
      "06/29/2022 06:49:48 - INFO - __main__ -   Text: ['Rock-Sneak� is a collection of songs that are written in modern Hindi.']\n",
      "06/29/2022 06:49:49 - INFO - __main__ -   Epoch: 114 | Batch: 7800/10001 (78%) | G Loss: 2.591551 | C Loss: -0.503470\n",
      "06/29/2022 06:49:49 - INFO - __main__ -   Text: ['CDs can be used at a university.']\n",
      "06/29/2022 06:49:50 - INFO - __main__ -   Epoch: 114 | Batch: 8400/10001 (84%) | G Loss: 2.781726 | C Loss: -0.518851\n",
      "06/29/2022 06:49:50 - INFO - __main__ -   Text: ['One winter morning, I will be standing in a strange position.']\n",
      "06/29/2022 06:49:51 - INFO - __main__ -   Epoch: 114 | Batch: 9000/10001 (90%) | G Loss: 2.866178 | C Loss: -0.385963\n",
      "06/29/2022 06:49:51 - INFO - __main__ -   Text: ['Tenant society has a higher threshold for determining who best supports a decision.']\n",
      "06/29/2022 06:49:52 - INFO - __main__ -   Epoch: 114 | Batch: 9600/10001 (96%) | G Loss: 2.859226 | C Loss: -0.421841\n",
      "06/29/2022 06:49:52 - INFO - __main__ -   Text: [\"For him it's more to play their dating sim from the movie 'I'm a princess'.\"]\n",
      "06/29/2022 06:49:53 - INFO - __main__ -   * (Train) Epoch: 114 | G Loss: 2.8337 | C Loss: -0.5237 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 06:50:02 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.230\n",
      "06/29/2022 06:50:02 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4279234530709517\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 115 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:53:30 - INFO - __main__ -   Epoch: 115 | Batch: 0/10001 (0%) | G Loss: 2.621793 | C Loss: -0.183442\n",
      "06/29/2022 06:53:30 - INFO - __main__ -   Text: ['Male brain to female brain.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.485\n",
      "  Test Loss: 3.977\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:53:31 - INFO - __main__ -   Epoch: 115 | Batch: 600/10001 (6%) | G Loss: 3.198106 | C Loss: -0.807142\n",
      "06/29/2022 06:53:31 - INFO - __main__ -   Text: ['A powerful anthem which other singers will take.']\n",
      "06/29/2022 06:53:32 - INFO - __main__ -   Epoch: 115 | Batch: 1200/10001 (12%) | G Loss: 2.949905 | C Loss: -0.925554\n",
      "06/29/2022 06:53:33 - INFO - __main__ -   Text: ['There is a dead man!']\n",
      "06/29/2022 06:53:33 - INFO - __main__ -   Epoch: 115 | Batch: 1800/10001 (18%) | G Loss: 1.933805 | C Loss: -0.557633\n",
      "06/29/2022 06:53:34 - INFO - __main__ -   Text: ['The course is able to focus on big ideas.']\n",
      "06/29/2022 06:53:35 - INFO - __main__ -   Epoch: 115 | Batch: 2400/10001 (24%) | G Loss: 2.374843 | C Loss: -0.560178\n",
      "06/29/2022 06:53:35 - INFO - __main__ -   Text: ['\"Stan League\" just breeds them.']\n",
      "06/29/2022 06:53:36 - INFO - __main__ -   Epoch: 115 | Batch: 3000/10001 (30%) | G Loss: 3.115304 | C Loss: -0.626841\n",
      "06/29/2022 06:53:36 - INFO - __main__ -   Text: ['The Los Angeles Science Photographer\\'s Name is \"Draco\".']\n",
      "06/29/2022 06:53:37 - INFO - __main__ -   Epoch: 115 | Batch: 3600/10001 (36%) | G Loss: 3.483902 | C Loss: -0.719146\n",
      "06/29/2022 06:53:37 - INFO - __main__ -   Text: ['Lucha Man is getting greedy at counting the the pounds to compete in the superbad game.']\n",
      "06/29/2022 06:53:38 - INFO - __main__ -   Epoch: 115 | Batch: 4200/10001 (42%) | G Loss: 2.276868 | C Loss: -0.475396\n",
      "06/29/2022 06:53:38 - INFO - __main__ -   Text: ['This is the title that many have said \"General Education\" \"Frankly.\"']\n",
      "06/29/2022 06:53:39 - INFO - __main__ -   Epoch: 115 | Batch: 4800/10001 (48%) | G Loss: 2.909630 | C Loss: -0.606290\n",
      "06/29/2022 06:53:39 - INFO - __main__ -   Text: ['The name refers to this tip that mobile phones is predictable on what is happening in co-share.']\n",
      "06/29/2022 06:53:40 - INFO - __main__ -   Epoch: 115 | Batch: 5400/10001 (54%) | G Loss: 3.329166 | C Loss: -0.576284\n",
      "06/29/2022 06:53:40 - INFO - __main__ -   Text: ['This is probably one of the internet subs.']\n",
      "06/29/2022 06:53:41 - INFO - __main__ -   Epoch: 115 | Batch: 6000/10001 (60%) | G Loss: 3.302548 | C Loss: -0.907483\n",
      "06/29/2022 06:53:41 - INFO - __main__ -   Text: [\"The hunters' names are Jin, Yu, and An.\"]\n",
      "06/29/2022 06:53:42 - INFO - __main__ -   Epoch: 115 | Batch: 6600/10001 (66%) | G Loss: 2.253475 | C Loss: -0.484409\n",
      "06/29/2022 06:53:42 - INFO - __main__ -   Text: ['The stanza of Anjali has the characteristic pinyin.']\n",
      "06/29/2022 06:53:43 - INFO - __main__ -   Epoch: 115 | Batch: 7200/10001 (72%) | G Loss: 2.563367 | C Loss: -0.598859\n",
      "06/29/2022 06:53:44 - INFO - __main__ -   Text: ['But if there is something bad going on, it is very simple.']\n",
      "06/29/2022 06:53:44 - INFO - __main__ -   Epoch: 115 | Batch: 7800/10001 (78%) | G Loss: 3.022451 | C Loss: -0.511077\n",
      "06/29/2022 06:53:45 - INFO - __main__ -   Text: ['In Australia LEND gets away with selling customers a \"distorted\" first name.']\n",
      "06/29/2022 06:53:46 - INFO - __main__ -   Epoch: 115 | Batch: 8400/10001 (84%) | G Loss: 2.918469 | C Loss: -0.561685\n",
      "06/29/2022 06:53:46 - INFO - __main__ -   Text: ['Having the chance to directly email Janis Devinski about Queenston Internet has been beyond my research.<br>']\n",
      "06/29/2022 06:53:47 - INFO - __main__ -   Epoch: 115 | Batch: 9000/10001 (90%) | G Loss: 2.912390 | C Loss: -0.538779\n",
      "06/29/2022 06:53:47 - INFO - __main__ -   Text: [\"Every day you can write a poem about a spice's price of labour.\"]\n",
      "06/29/2022 06:53:48 - INFO - __main__ -   Epoch: 115 | Batch: 9600/10001 (96%) | G Loss: 3.007246 | C Loss: -0.632330\n",
      "06/29/2022 06:53:48 - INFO - __main__ -   Text: ['This is the best dynamic method to optimize.']\n",
      "06/29/2022 06:53:49 - INFO - __main__ -   * (Train) Epoch: 115 | G Loss: 2.7252 | C Loss: -0.5430 | Updates G: 46 | Updates C: 787\n",
      "06/29/2022 06:53:58 - INFO - __main__ -   Bleu-2:0.202 | B-Bleu-2:0.257\n",
      "06/29/2022 06:53:58 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4584252264033729\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 116 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:57:29 - INFO - __main__ -   Epoch: 116 | Batch: 0/10001 (0%) | G Loss: 3.083071 | C Loss: -0.516259\n",
      "06/29/2022 06:57:29 - INFO - __main__ -   Text: ['When I am dreaming, it is more than that.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.487\n",
      "  Test Loss: 3.955\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 06:57:30 - INFO - __main__ -   Epoch: 116 | Batch: 600/10001 (6%) | G Loss: 3.146918 | C Loss: -0.664791\n",
      "06/29/2022 06:57:30 - INFO - __main__ -   Text: ['Prospective users must travel a bit too much to the center of the grid cupboard.']\n",
      "06/29/2022 06:57:31 - INFO - __main__ -   Epoch: 116 | Batch: 1200/10001 (12%) | G Loss: 3.066710 | C Loss: -0.726037\n",
      "06/29/2022 06:57:31 - INFO - __main__ -   Text: ['It is not much of an \"atheism.\"']\n",
      "06/29/2022 06:57:32 - INFO - __main__ -   Epoch: 116 | Batch: 1800/10001 (18%) | G Loss: 2.550985 | C Loss: -0.685839\n",
      "06/29/2022 06:57:32 - INFO - __main__ -   Text: ['A trading list will gather all tradios.\" <PAD>i.']\n",
      "06/29/2022 06:57:33 - INFO - __main__ -   Epoch: 116 | Batch: 2400/10001 (24%) | G Loss: 2.499861 | C Loss: -0.518350\n",
      "06/29/2022 06:57:33 - INFO - __main__ -   Text: ['Geodesk View.']\n",
      "06/29/2022 06:57:34 - INFO - __main__ -   Epoch: 116 | Batch: 3000/10001 (30%) | G Loss: 2.435815 | C Loss: -0.556449\n",
      "06/29/2022 06:57:34 - INFO - __main__ -   Text: ['is hoping to share it with fans as well.']\n",
      "06/29/2022 06:57:35 - INFO - __main__ -   Epoch: 116 | Batch: 3600/10001 (36%) | G Loss: 3.507384 | C Loss: -0.793132\n",
      "06/29/2022 06:57:35 - INFO - __main__ -   Text: ['Sadies Miley Jay produces something called generosity.']\n",
      "06/29/2022 06:57:36 - INFO - __main__ -   Epoch: 116 | Batch: 4200/10001 (42%) | G Loss: 3.593874 | C Loss: -0.537770\n",
      "06/29/2022 06:57:36 - INFO - __main__ -   Text: ['\"There\\'s a movie 100… \"']\n",
      "06/29/2022 06:57:37 - INFO - __main__ -   Epoch: 116 | Batch: 4800/10001 (48%) | G Loss: 3.388888 | C Loss: -0.631414\n",
      "06/29/2022 06:57:37 - INFO - __main__ -   Text: ['It tells you what each letter is indicating (*is))) Enogwiz provided unpagewiz.']\n",
      "06/29/2022 06:57:38 - INFO - __main__ -   Epoch: 116 | Batch: 5400/10001 (54%) | G Loss: 2.225960 | C Loss: -0.647942\n",
      "06/29/2022 06:57:38 - INFO - __main__ -   Text: ['It has many weekly readers.']\n",
      "06/29/2022 06:57:39 - INFO - __main__ -   Epoch: 116 | Batch: 6000/10001 (60%) | G Loss: 2.242127 | C Loss: -0.431594\n",
      "06/29/2022 06:57:39 - INFO - __main__ -   Text: ['\"i want to see birds\".']\n",
      "06/29/2022 06:57:40 - INFO - __main__ -   Epoch: 116 | Batch: 6600/10001 (66%) | G Loss: 3.261159 | C Loss: -0.365942\n",
      "06/29/2022 06:57:41 - INFO - __main__ -   Text: [\"That's most likely given your past practice.\"]\n",
      "06/29/2022 06:57:42 - INFO - __main__ -   Epoch: 116 | Batch: 7200/10001 (72%) | G Loss: 3.977298 | C Loss: -0.718735\n",
      "06/29/2022 06:57:42 - INFO - __main__ -   Text: ['This is a very good offer.']\n",
      "06/29/2022 06:57:43 - INFO - __main__ -   Epoch: 116 | Batch: 7800/10001 (78%) | G Loss: 3.219495 | C Loss: -0.560447\n",
      "06/29/2022 06:57:43 - INFO - __main__ -   Text: ['He also speaks on the Antiquities.']\n",
      "06/29/2022 06:57:44 - INFO - __main__ -   Epoch: 116 | Batch: 8400/10001 (84%) | G Loss: 2.763941 | C Loss: -0.463981\n",
      "06/29/2022 06:57:44 - INFO - __main__ -   Text: ['\"polynovel des frae Franciscanies.\"']\n",
      "06/29/2022 06:57:45 - INFO - __main__ -   Epoch: 116 | Batch: 9000/10001 (90%) | G Loss: 3.397609 | C Loss: -0.391988\n",
      "06/29/2022 06:57:45 - INFO - __main__ -   Text: ['Lovecraftian religion is evil.\"']\n",
      "06/29/2022 06:57:46 - INFO - __main__ -   Epoch: 116 | Batch: 9600/10001 (96%) | G Loss: 2.842208 | C Loss: -0.553030\n",
      "06/29/2022 06:57:46 - INFO - __main__ -   Text: [\"They don't have to advertise it.\"]\n",
      "06/29/2022 06:57:47 - INFO - __main__ -   * (Train) Epoch: 116 | G Loss: 2.7692 | C Loss: -0.5315 | Updates G: 50 | Updates C: 783\n",
      "06/29/2022 06:57:56 - INFO - __main__ -   Bleu-2:0.211 | B-Bleu-2:0.267\n",
      "06/29/2022 06:57:56 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_12.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4780378468296776\n",
      "Train file used is number 12\n",
      "../../yahoo/subdivided_large/train_12.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 117 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:00.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:01:30 - INFO - __main__ -   Epoch: 117 | Batch: 0/10001 (0%) | G Loss: 3.024122 | C Loss: -0.525800\n",
      "06/29/2022 07:01:31 - INFO - __main__ -   Text: ['This exposes us to weapons attack.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.482\n",
      "  Test Loss: 3.983\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:01:32 - INFO - __main__ -   Epoch: 117 | Batch: 600/10001 (6%) | G Loss: 1.974005 | C Loss: -0.462829\n",
      "06/29/2022 07:01:32 - INFO - __main__ -   Text: ['Twisters shall come out for me, under the pretense of forgiveness.']\n",
      "06/29/2022 07:01:33 - INFO - __main__ -   Epoch: 117 | Batch: 1200/10001 (12%) | G Loss: 2.543439 | C Loss: -0.498914\n",
      "06/29/2022 07:01:33 - INFO - __main__ -   Text: ['Another cause is an egalitarian with equality.']\n",
      "06/29/2022 07:01:34 - INFO - __main__ -   Epoch: 117 | Batch: 1800/10001 (18%) | G Loss: 2.841604 | C Loss: -0.406860\n",
      "06/29/2022 07:01:34 - INFO - __main__ -   Text: ['The swallowy comment \"Pork catman\" is an example of this, as captured by \"Exile of']\n",
      "06/29/2022 07:01:35 - INFO - __main__ -   Epoch: 117 | Batch: 2400/10001 (24%) | G Loss: 3.536912 | C Loss: -0.775093\n",
      "06/29/2022 07:01:35 - INFO - __main__ -   Text: ['The first of the human kingdoms consists of seven kingdoms.']\n",
      "06/29/2022 07:01:36 - INFO - __main__ -   Epoch: 117 | Batch: 3000/10001 (30%) | G Loss: 3.358142 | C Loss: -0.701923\n",
      "06/29/2022 07:01:36 - INFO - __main__ -   Text: ['There is no reason for him to stay in Italy.']\n",
      "06/29/2022 07:01:37 - INFO - __main__ -   Epoch: 117 | Batch: 3600/10001 (36%) | G Loss: 2.638800 | C Loss: -0.178321\n",
      "06/29/2022 07:01:37 - INFO - __main__ -   Text: ['The first step accepts you.\"']\n",
      "06/29/2022 07:01:38 - INFO - __main__ -   Epoch: 117 | Batch: 4200/10001 (42%) | G Loss: 2.822152 | C Loss: -0.733282\n",
      "06/29/2022 07:01:38 - INFO - __main__ -   Text: ['WDTS is ranked #1 on the planet.']\n",
      "06/29/2022 07:01:39 - INFO - __main__ -   Epoch: 117 | Batch: 4800/10001 (48%) | G Loss: 2.793711 | C Loss: -0.501052\n",
      "06/29/2022 07:01:39 - INFO - __main__ -   Text: ['While Zhegg is unsure of his motives, I would guess that he is a small man of mine.']\n",
      "06/29/2022 07:01:40 - INFO - __main__ -   Epoch: 117 | Batch: 5400/10001 (54%) | G Loss: 3.135931 | C Loss: -0.450745\n",
      "06/29/2022 07:01:40 - INFO - __main__ -   Text: ['The online magazine kind of uses \"MT.J.\"']\n",
      "06/29/2022 07:01:41 - INFO - __main__ -   Epoch: 117 | Batch: 6000/10001 (60%) | G Loss: 3.159836 | C Loss: -0.439517\n",
      "06/29/2022 07:01:42 - INFO - __main__ -   Text: ['Desire is easy to use and buzzars sideside.']\n",
      "06/29/2022 07:01:43 - INFO - __main__ -   Epoch: 117 | Batch: 6600/10001 (66%) | G Loss: 3.157167 | C Loss: -0.486326\n",
      "06/29/2022 07:01:43 - INFO - __main__ -   Text: ['Morphological labels can describe easier workers.']\n",
      "06/29/2022 07:01:44 - INFO - __main__ -   Epoch: 117 | Batch: 7200/10001 (72%) | G Loss: 2.708951 | C Loss: -0.437737\n",
      "06/29/2022 07:01:44 - INFO - __main__ -   Text: ['Fighting Budweiser!']\n",
      "06/29/2022 07:01:45 - INFO - __main__ -   Epoch: 117 | Batch: 7800/10001 (78%) | G Loss: 2.653609 | C Loss: -0.589041\n",
      "06/29/2022 07:01:45 - INFO - __main__ -   Text: ['In essence they are the same as the Death Up Here.']\n",
      "06/29/2022 07:01:46 - INFO - __main__ -   Epoch: 117 | Batch: 8400/10001 (84%) | G Loss: 3.098524 | C Loss: -0.498473\n",
      "06/29/2022 07:01:46 - INFO - __main__ -   Text: ['Promises you masturbate: The ropes is how old gear (camping) starts.']\n",
      "06/29/2022 07:01:47 - INFO - __main__ -   Epoch: 117 | Batch: 9000/10001 (90%) | G Loss: 3.310626 | C Loss: -0.416676\n",
      "06/29/2022 07:01:47 - INFO - __main__ -   Text: ['The crest of life warns those who do not read Nature. <PAD> Star Falls.']\n",
      "06/29/2022 07:01:48 - INFO - __main__ -   Epoch: 117 | Batch: 9600/10001 (96%) | G Loss: 3.459361 | C Loss: -0.571869\n",
      "06/29/2022 07:01:48 - INFO - __main__ -   Text: ['In addition to explaining the basketball games themselves, he describes this comedy as \"intellectual and military.\"']\n",
      "06/29/2022 07:01:49 - INFO - __main__ -   * (Train) Epoch: 117 | G Loss: 2.9050 | C Loss: -0.5300 | Updates G: 51 | Updates C: 782\n",
      "06/29/2022 07:01:58 - INFO - __main__ -   Bleu-2:0.197 | B-Bleu-2:0.274\n",
      "06/29/2022 07:01:58 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47038607466087745\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 118 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:05:26 - INFO - __main__ -   Epoch: 118 | Batch: 0/10001 (0%) | G Loss: 3.394581 | C Loss: -0.662685\n",
      "06/29/2022 07:05:27 - INFO - __main__ -   Text: ['To do this, DailyLife will also show you what you do.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.878\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:05:28 - INFO - __main__ -   Epoch: 118 | Batch: 600/10001 (6%) | G Loss: 2.454607 | C Loss: -0.391755\n",
      "06/29/2022 07:05:28 - INFO - __main__ -   Text: ['They reason from the effects of our interstellar processes.']\n",
      "06/29/2022 07:05:29 - INFO - __main__ -   Epoch: 118 | Batch: 1200/10001 (12%) | G Loss: 2.772085 | C Loss: -0.471072\n",
      "06/29/2022 07:05:29 - INFO - __main__ -   Text: ['She increases her gaze, so that she is bound to extreme endovian balls.']\n",
      "06/29/2022 07:05:30 - INFO - __main__ -   Epoch: 118 | Batch: 1800/10001 (18%) | G Loss: 3.506692 | C Loss: -0.618071\n",
      "06/29/2022 07:05:30 - INFO - __main__ -   Text: [\"Whether or not you pick cancer, you'll never be raped!\"]\n",
      "06/29/2022 07:05:31 - INFO - __main__ -   Epoch: 118 | Batch: 2400/10001 (24%) | G Loss: 2.521795 | C Loss: -0.317871\n",
      "06/29/2022 07:05:31 - INFO - __main__ -   Text: ['Examples include illustrated bags with printed bubbles.']\n",
      "06/29/2022 07:05:32 - INFO - __main__ -   Epoch: 118 | Batch: 3000/10001 (30%) | G Loss: 2.452607 | C Loss: -0.495784\n",
      "06/29/2022 07:05:32 - INFO - __main__ -   Text: ['\", and Cruel Feather.']\n",
      "06/29/2022 07:05:33 - INFO - __main__ -   Epoch: 118 | Batch: 3600/10001 (36%) | G Loss: 2.749524 | C Loss: -0.610323\n",
      "06/29/2022 07:05:33 - INFO - __main__ -   Text: ['Despite being feisty on social media, him is still lagging behind the tuk tuk discussion forums.']\n",
      "06/29/2022 07:05:34 - INFO - __main__ -   Epoch: 118 | Batch: 4200/10001 (42%) | G Loss: 2.938309 | C Loss: -0.548616\n",
      "06/29/2022 07:05:34 - INFO - __main__ -   Text: ['It is supported by a clerical preprocessor-cooler.']\n",
      "06/29/2022 07:05:35 - INFO - __main__ -   Epoch: 118 | Batch: 4800/10001 (48%) | G Loss: 2.701022 | C Loss: -0.610445\n",
      "06/29/2022 07:05:35 - INFO - __main__ -   Text: ['Applications of cloud are ongoing.\"']\n",
      "06/29/2022 07:05:36 - INFO - __main__ -   Epoch: 118 | Batch: 5400/10001 (54%) | G Loss: 2.875688 | C Loss: -0.580191\n",
      "06/29/2022 07:05:36 - INFO - __main__ -   Text: ['The Tyana end of this chain transports water to dune (Germany).']\n",
      "06/29/2022 07:05:37 - INFO - __main__ -   Epoch: 118 | Batch: 6000/10001 (60%) | G Loss: 2.920497 | C Loss: -0.464038\n",
      "06/29/2022 07:05:38 - INFO - __main__ -   Text: ['\"Your competition is free to choose between in- taxi * or without.']\n",
      "06/29/2022 07:05:39 - INFO - __main__ -   Epoch: 118 | Batch: 6600/10001 (66%) | G Loss: 3.226236 | C Loss: -0.532600\n",
      "06/29/2022 07:05:39 - INFO - __main__ -   Text: ['Masonic is Bombay.']\n",
      "06/29/2022 07:05:40 - INFO - __main__ -   Epoch: 118 | Batch: 7200/10001 (72%) | G Loss: 3.025942 | C Loss: -0.530686\n",
      "06/29/2022 07:05:40 - INFO - __main__ -   Text: ['The main purposes in making this survey is to compare the entry level (major).']\n",
      "06/29/2022 07:05:41 - INFO - __main__ -   Epoch: 118 | Batch: 7800/10001 (78%) | G Loss: 3.013375 | C Loss: -0.412786\n",
      "06/29/2022 07:05:41 - INFO - __main__ -   Text: ['The dark xenophobia of Russia is really in its infancy.\"']\n",
      "06/29/2022 07:05:42 - INFO - __main__ -   Epoch: 118 | Batch: 8400/10001 (84%) | G Loss: 3.159779 | C Loss: -0.525253\n",
      "06/29/2022 07:05:42 - INFO - __main__ -   Text: ['There is no song else to listen to.\"']\n",
      "06/29/2022 07:05:43 - INFO - __main__ -   Epoch: 118 | Batch: 9000/10001 (90%) | G Loss: 3.264995 | C Loss: -0.469037\n",
      "06/29/2022 07:05:43 - INFO - __main__ -   Text: [\"Sue Mera pretends her son is so weird because he's accessorizing everyone else's genitals.\"]\n",
      "06/29/2022 07:05:44 - INFO - __main__ -   Epoch: 118 | Batch: 9600/10001 (96%) | G Loss: 2.998438 | C Loss: -0.742858\n",
      "06/29/2022 07:05:44 - INFO - __main__ -   Text: ['\"Don\\'t fool me just yet!\".']\n",
      "06/29/2022 07:05:45 - INFO - __main__ -   * (Train) Epoch: 118 | G Loss: 2.8929 | C Loss: -0.5062 | Updates G: 50 | Updates C: 783\n",
      "06/29/2022 07:05:54 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.257\n",
      "06/29/2022 07:05:54 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_14.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45571651472610913\n",
      "Train file used is number 14\n",
      "../../yahoo/subdivided_large/train_14.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 119 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:09:22 - INFO - __main__ -   Epoch: 119 | Batch: 0/10001 (0%) | G Loss: 2.827098 | C Loss: -0.571961\n",
      "06/29/2022 07:09:22 - INFO - __main__ -   Text: ['small everything!']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.482\n",
      "  Test Loss: 3.978\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:09:23 - INFO - __main__ -   Epoch: 119 | Batch: 600/10001 (6%) | G Loss: 2.801996 | C Loss: -0.598665\n",
      "06/29/2022 07:09:23 - INFO - __main__ -   Text: ['He has a website which contains radios sold as black makers.']\n",
      "06/29/2022 07:09:24 - INFO - __main__ -   Epoch: 119 | Batch: 1200/10001 (12%) | G Loss: 3.030925 | C Loss: -0.593881\n",
      "06/29/2022 07:09:24 - INFO - __main__ -   Text: ['The return rate is less per frame than how much free energy that can be recycled.']\n",
      "06/29/2022 07:09:25 - INFO - __main__ -   Epoch: 119 | Batch: 1800/10001 (18%) | G Loss: 2.935403 | C Loss: -0.602428\n",
      "06/29/2022 07:09:25 - INFO - __main__ -   Text: ['He is called the poet.']\n",
      "06/29/2022 07:09:26 - INFO - __main__ -   Epoch: 119 | Batch: 2400/10001 (24%) | G Loss: 2.813180 | C Loss: -0.508764\n",
      "06/29/2022 07:09:26 - INFO - __main__ -   Text: ['Colodotus Eliadermore.']\n",
      "06/29/2022 07:09:27 - INFO - __main__ -   Epoch: 119 | Batch: 3000/10001 (30%) | G Loss: 3.157826 | C Loss: -0.463567\n",
      "06/29/2022 07:09:27 - INFO - __main__ -   Text: ['The song is called: From ANYWHERE!!!!']\n",
      "06/29/2022 07:09:28 - INFO - __main__ -   Epoch: 119 | Batch: 3600/10001 (36%) | G Loss: 3.489642 | C Loss: -0.607009\n",
      "06/29/2022 07:09:29 - INFO - __main__ -   Text: ['and \\'\"Ch3f\"\\'.']\n",
      "06/29/2022 07:09:29 - INFO - __main__ -   Epoch: 119 | Batch: 4200/10001 (42%) | G Loss: 3.352060 | C Loss: -0.562134\n",
      "06/29/2022 07:09:30 - INFO - __main__ -   Text: ['She was quick to learn that other girls would embarrass her but she was mostly modelling.']\n",
      "06/29/2022 07:09:31 - INFO - __main__ -   Epoch: 119 | Batch: 4800/10001 (48%) | G Loss: 2.475392 | C Loss: -0.479219\n",
      "06/29/2022 07:09:31 - INFO - __main__ -   Text: ['He is one can be an American, Native American, US.']\n",
      "06/29/2022 07:09:32 - INFO - __main__ -   Epoch: 119 | Batch: 5400/10001 (54%) | G Loss: 2.378230 | C Loss: -0.680984\n",
      "06/29/2022 07:09:32 - INFO - __main__ -   Text: ['The British Conservative Party is an independent party with a short life agenda.']\n",
      "06/29/2022 07:09:33 - INFO - __main__ -   Epoch: 119 | Batch: 6000/10001 (60%) | G Loss: 2.127572 | C Loss: -0.545207\n",
      "06/29/2022 07:09:33 - INFO - __main__ -   Text: ['Kvehga-nikya can be heard there.']\n",
      "06/29/2022 07:09:34 - INFO - __main__ -   Epoch: 119 | Batch: 6600/10001 (66%) | G Loss: 2.508978 | C Loss: -0.373051\n",
      "06/29/2022 07:09:34 - INFO - __main__ -   Text: ['It seems to be Sally.']\n",
      "06/29/2022 07:09:35 - INFO - __main__ -   Epoch: 119 | Batch: 7200/10001 (72%) | G Loss: 3.020146 | C Loss: -0.573169\n",
      "06/29/2022 07:09:35 - INFO - __main__ -   Text: ['That God gives us something great.\"']\n",
      "06/29/2022 07:09:36 - INFO - __main__ -   Epoch: 119 | Batch: 7800/10001 (78%) | G Loss: 3.145493 | C Loss: -0.618511\n",
      "06/29/2022 07:09:36 - INFO - __main__ -   Text: ['Above my pay scale: his!']\n",
      "06/29/2022 07:09:37 - INFO - __main__ -   Epoch: 119 | Batch: 8400/10001 (84%) | G Loss: 3.209315 | C Loss: -0.524308\n",
      "06/29/2022 07:09:37 - INFO - __main__ -   Text: ['The creators of the game attempt to create a perfect future self, a thousand answers to everyday social problems.']\n",
      "06/29/2022 07:09:38 - INFO - __main__ -   Epoch: 119 | Batch: 9000/10001 (90%) | G Loss: 3.061707 | C Loss: -0.432281\n",
      "06/29/2022 07:09:38 - INFO - __main__ -   Text: ['Although not a model test subject, she has existed for marriage engine which uses seed.']\n",
      "06/29/2022 07:09:39 - INFO - __main__ -   Epoch: 119 | Batch: 9600/10001 (96%) | G Loss: 2.923717 | C Loss: -0.552073\n",
      "06/29/2022 07:09:40 - INFO - __main__ -   Text: ['During the crumbling age Czech people may describe themselves as \"British.\"']\n",
      "06/29/2022 07:09:40 - INFO - __main__ -   * (Train) Epoch: 119 | G Loss: 2.8947 | C Loss: -0.5130 | Updates G: 35 | Updates C: 798\n",
      "06/29/2022 07:09:49 - INFO - __main__ -   Bleu-2:0.199 | B-Bleu-2:0.260\n",
      "06/29/2022 07:09:49 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45854206464415226\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 120 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:13:23 - INFO - __main__ -   Epoch: 120 | Batch: 0/10001 (0%) | G Loss: 2.940236 | C Loss: -0.410370\n",
      "06/29/2022 07:13:23 - INFO - __main__ -   Text: ['This particular creature requires a special non-judgemental educational exchange from another transmitter.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.896\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:13:24 - INFO - __main__ -   Epoch: 120 | Batch: 600/10001 (6%) | G Loss: 2.555694 | C Loss: -0.467491\n",
      "06/29/2022 07:13:24 - INFO - __main__ -   Text: ['This does explain why brown subjects seem to reject the idea of being different.']\n",
      "06/29/2022 07:13:25 - INFO - __main__ -   Epoch: 120 | Batch: 1200/10001 (12%) | G Loss: 2.881871 | C Loss: -0.574845\n",
      "06/29/2022 07:13:25 - INFO - __main__ -   Text: ['If you want to know what you want to do, just submit movies along with the song!\"']\n",
      "06/29/2022 07:13:26 - INFO - __main__ -   Epoch: 120 | Batch: 1800/10001 (18%) | G Loss: 2.817494 | C Loss: -0.571284\n",
      "06/29/2022 07:13:26 - INFO - __main__ -   Text: ['It is called the Civil War.\"']\n",
      "06/29/2022 07:13:27 - INFO - __main__ -   Epoch: 120 | Batch: 2400/10001 (24%) | G Loss: 3.170817 | C Loss: -0.635504\n",
      "06/29/2022 07:13:27 - INFO - __main__ -   Text: ['A direct approach can be applied to some fundamental issues.']\n",
      "06/29/2022 07:13:28 - INFO - __main__ -   Epoch: 120 | Batch: 3000/10001 (30%) | G Loss: 2.629879 | C Loss: -0.472632\n",
      "06/29/2022 07:13:28 - INFO - __main__ -   Text: ['It is not all-encompassing.']\n",
      "06/29/2022 07:13:29 - INFO - __main__ -   Epoch: 120 | Batch: 3600/10001 (36%) | G Loss: 3.012181 | C Loss: -0.428940\n",
      "06/29/2022 07:13:30 - INFO - __main__ -   Text: ['This test is also worth $350 for no trial unless it ends in victory and try!']\n",
      "06/29/2022 07:13:31 - INFO - __main__ -   Epoch: 120 | Batch: 4200/10001 (42%) | G Loss: 2.569208 | C Loss: -0.582460\n",
      "06/29/2022 07:13:31 - INFO - __main__ -   Text: ['There is no art thou mayest of my walk.\"']\n",
      "06/29/2022 07:13:32 - INFO - __main__ -   Epoch: 120 | Batch: 4800/10001 (48%) | G Loss: 2.359513 | C Loss: -0.622940\n",
      "06/29/2022 07:13:32 - INFO - __main__ -   Text: ['perception.']\n",
      "06/29/2022 07:13:33 - INFO - __main__ -   Epoch: 120 | Batch: 5400/10001 (54%) | G Loss: 2.373613 | C Loss: -0.402273\n",
      "06/29/2022 07:13:33 - INFO - __main__ -   Text: ['The bats are obviously kickball.']\n",
      "06/29/2022 07:13:34 - INFO - __main__ -   Epoch: 120 | Batch: 6000/10001 (60%) | G Loss: 2.439155 | C Loss: -0.677026\n",
      "06/29/2022 07:13:34 - INFO - __main__ -   Text: ['It employs a trustworthy personality rather than a fool.']\n",
      "06/29/2022 07:13:35 - INFO - __main__ -   Epoch: 120 | Batch: 6600/10001 (66%) | G Loss: 2.837154 | C Loss: -0.529197\n",
      "06/29/2022 07:13:35 - INFO - __main__ -   Text: ['You might notice some play on songs like \"iac\".']\n",
      "06/29/2022 07:13:36 - INFO - __main__ -   Epoch: 120 | Batch: 7200/10001 (72%) | G Loss: 2.814279 | C Loss: -0.420938\n",
      "06/29/2022 07:13:36 - INFO - __main__ -   Text: ['Everything in formula_11, h.']\n",
      "06/29/2022 07:13:37 - INFO - __main__ -   Epoch: 120 | Batch: 7800/10001 (78%) | G Loss: 3.222557 | C Loss: -0.583799\n",
      "06/29/2022 07:13:37 - INFO - __main__ -   Text: ['When he invented his idea, millions are born.']\n",
      "06/29/2022 07:13:38 - INFO - __main__ -   Epoch: 120 | Batch: 8400/10001 (84%) | G Loss: 2.759391 | C Loss: -0.515002\n",
      "06/29/2022 07:13:38 - INFO - __main__ -   Text: ['The end of Stanway means that driving cheaply is not on par with riding too.']\n",
      "06/29/2022 07:13:39 - INFO - __main__ -   Epoch: 120 | Batch: 9000/10001 (90%) | G Loss: 2.786110 | C Loss: -0.828194\n",
      "06/29/2022 07:13:39 - INFO - __main__ -   Text: ['Thus, happens to ask all these questions.']\n",
      "06/29/2022 07:13:40 - INFO - __main__ -   Epoch: 120 | Batch: 9600/10001 (96%) | G Loss: 2.303197 | C Loss: -0.405724\n",
      "06/29/2022 07:13:40 - INFO - __main__ -   Text: ['His son tugs his hair every day.\"']\n",
      "06/29/2022 07:13:41 - INFO - __main__ -   * (Train) Epoch: 120 | G Loss: 2.6847 | C Loss: -0.5124 | Updates G: 54 | Updates C: 779\n",
      "06/29/2022 07:13:50 - INFO - __main__ -   Bleu-2:0.184 | B-Bleu-2:0.230\n",
      "06/29/2022 07:13:50 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.414125103957648\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 121 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:17:16 - INFO - __main__ -   Epoch: 121 | Batch: 0/10001 (0%) | G Loss: 2.176973 | C Loss: -0.434110\n",
      "06/29/2022 07:17:16 - INFO - __main__ -   Text: [\"The previous Guard Commander's motto is the Imperial Guard.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.485\n",
      "  Test Loss: 3.911\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:17:17 - INFO - __main__ -   Epoch: 121 | Batch: 600/10001 (6%) | G Loss: 2.703609 | C Loss: -0.713198\n",
      "06/29/2022 07:17:17 - INFO - __main__ -   Text: ['They describe Hadza as \"symbolized by the agent of exclusion\".']\n",
      "06/29/2022 07:17:18 - INFO - __main__ -   Epoch: 121 | Batch: 1200/10001 (12%) | G Loss: 3.054591 | C Loss: -0.448885\n",
      "06/29/2022 07:17:18 - INFO - __main__ -   Text: ['Heidi is vegan.\"']\n",
      "06/29/2022 07:17:19 - INFO - __main__ -   Epoch: 121 | Batch: 1800/10001 (18%) | G Loss: 2.754624 | C Loss: -0.467519\n",
      "06/29/2022 07:17:19 - INFO - __main__ -   Text: ['They are passionate, highly independent and these many aspiring guys will be able to achieve a TEELTY.']\n",
      "06/29/2022 07:17:20 - INFO - __main__ -   Epoch: 121 | Batch: 2400/10001 (24%) | G Loss: 2.547794 | C Loss: -0.507469\n",
      "06/29/2022 07:17:20 - INFO - __main__ -   Text: [\"It's totally breathable.\"]\n",
      "06/29/2022 07:17:21 - INFO - __main__ -   Epoch: 121 | Batch: 3000/10001 (30%) | G Loss: 2.249761 | C Loss: -0.339532\n",
      "06/29/2022 07:17:22 - INFO - __main__ -   Text: ['Psychometrics most commonly may be:']\n",
      "06/29/2022 07:17:22 - INFO - __main__ -   Epoch: 121 | Batch: 3600/10001 (36%) | G Loss: 2.568158 | C Loss: -0.336215\n",
      "06/29/2022 07:17:23 - INFO - __main__ -   Text: ['Go ahead and create a cursor.']\n",
      "06/29/2022 07:17:24 - INFO - __main__ -   Epoch: 121 | Batch: 4200/10001 (42%) | G Loss: 2.953969 | C Loss: -0.528513\n",
      "06/29/2022 07:17:24 - INFO - __main__ -   Text: ['He has two synonyms for datosity: datfather.']\n",
      "06/29/2022 07:17:25 - INFO - __main__ -   Epoch: 121 | Batch: 4800/10001 (48%) | G Loss: 3.036858 | C Loss: -0.364440\n",
      "06/29/2022 07:17:25 - INFO - __main__ -   Text: ['The Guardians or Atomic Terror are indeed much less numerous.']\n",
      "06/29/2022 07:17:26 - INFO - __main__ -   Epoch: 121 | Batch: 5400/10001 (54%) | G Loss: 2.786130 | C Loss: -0.533373\n",
      "06/29/2022 07:17:26 - INFO - __main__ -   Text: ['Praveen has had a backwards feeling about the Indian market\".']\n",
      "06/29/2022 07:17:27 - INFO - __main__ -   Epoch: 121 | Batch: 6000/10001 (60%) | G Loss: 2.602403 | C Loss: -0.473983\n",
      "06/29/2022 07:17:27 - INFO - __main__ -   Text: ['There are no guarantees that the person will actually use the word \"will,\" as some people just don\\'t believe in']\n",
      "06/29/2022 07:17:28 - INFO - __main__ -   Epoch: 121 | Batch: 6600/10001 (66%) | G Loss: 2.699415 | C Loss: -0.484561\n",
      "06/29/2022 07:17:28 - INFO - __main__ -   Text: ['I don\\'t even consider myself a Jew.\"']\n",
      "06/29/2022 07:17:29 - INFO - __main__ -   Epoch: 121 | Batch: 7200/10001 (72%) | G Loss: 3.056877 | C Loss: -0.626065\n",
      "06/29/2022 07:17:29 - INFO - __main__ -   Text: ['Much does not know science: metaphysics.\"']\n",
      "06/29/2022 07:17:30 - INFO - __main__ -   Epoch: 121 | Batch: 7800/10001 (78%) | G Loss: 3.013015 | C Loss: -0.366912\n",
      "06/29/2022 07:17:30 - INFO - __main__ -   Text: ['The intention of this poet is to humiliate Aesarri.']\n",
      "06/29/2022 07:17:31 - INFO - __main__ -   Epoch: 121 | Batch: 8400/10001 (84%) | G Loss: 2.902982 | C Loss: -0.388794\n",
      "06/29/2022 07:17:31 - INFO - __main__ -   Text: ['Merry are we there for you?']\n",
      "06/29/2022 07:17:32 - INFO - __main__ -   Epoch: 121 | Batch: 9000/10001 (90%) | G Loss: 2.823119 | C Loss: -0.550781\n",
      "06/29/2022 07:17:32 - INFO - __main__ -   Text: ['Molly goes using the Garden of Eden.']\n",
      "06/29/2022 07:17:33 - INFO - __main__ -   Epoch: 121 | Batch: 9600/10001 (96%) | G Loss: 2.937828 | C Loss: -0.415529\n",
      "06/29/2022 07:17:33 - INFO - __main__ -   Text: ['Like almost all corsets males who grow great.']\n",
      "06/29/2022 07:17:34 - INFO - __main__ -   * (Train) Epoch: 121 | G Loss: 2.7276 | C Loss: -0.5057 | Updates G: 33 | Updates C: 800\n",
      "06/29/2022 07:17:43 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.233\n",
      "06/29/2022 07:17:43 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4327791441367098\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 122 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:21:12 - INFO - __main__ -   Epoch: 122 | Batch: 0/10001 (0%) | G Loss: 2.819754 | C Loss: -0.424319\n",
      "06/29/2022 07:21:12 - INFO - __main__ -   Text: ['These four tests do weigh a little.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.959\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:21:13 - INFO - __main__ -   Epoch: 122 | Batch: 600/10001 (6%) | G Loss: 2.667678 | C Loss: -0.431952\n",
      "06/29/2022 07:21:13 - INFO - __main__ -   Text: ['The Ant.']\n",
      "06/29/2022 07:21:14 - INFO - __main__ -   Epoch: 122 | Batch: 1200/10001 (12%) | G Loss: 2.758234 | C Loss: -0.420445\n",
      "06/29/2022 07:21:14 - INFO - __main__ -   Text: ['Some way to say how high I would know.']\n",
      "06/29/2022 07:21:15 - INFO - __main__ -   Epoch: 122 | Batch: 1800/10001 (18%) | G Loss: 3.056503 | C Loss: -0.757011\n",
      "06/29/2022 07:21:15 - INFO - __main__ -   Text: ['Blue is Essie and Doctor Beauf\".']\n",
      "06/29/2022 07:21:16 - INFO - __main__ -   Epoch: 122 | Batch: 2400/10001 (24%) | G Loss: 3.097905 | C Loss: -0.686902\n",
      "06/29/2022 07:21:16 - INFO - __main__ -   Text: ['But it is the same for everyone except for Asians.\"']\n",
      "06/29/2022 07:21:17 - INFO - __main__ -   Epoch: 122 | Batch: 3000/10001 (30%) | G Loss: 3.120712 | C Loss: -0.597588\n",
      "06/29/2022 07:21:17 - INFO - __main__ -   Text: ['A multidisciplinary critique.']\n",
      "06/29/2022 07:21:18 - INFO - __main__ -   Epoch: 122 | Batch: 3600/10001 (36%) | G Loss: 3.022562 | C Loss: -0.378711\n",
      "06/29/2022 07:21:18 - INFO - __main__ -   Text: ['McQuentin comes in very cranky, and The Hongian.']\n",
      "06/29/2022 07:21:19 - INFO - __main__ -   Epoch: 122 | Batch: 4200/10001 (42%) | G Loss: 2.750489 | C Loss: -0.406449\n",
      "06/29/2022 07:21:19 - INFO - __main__ -   Text: ['Ghujanneh is the first good server.']\n",
      "06/29/2022 07:21:20 - INFO - __main__ -   Epoch: 122 | Batch: 4800/10001 (48%) | G Loss: 2.532574 | C Loss: -0.477877\n",
      "06/29/2022 07:21:21 - INFO - __main__ -   Text: [\"I'm asking for '1945,' because that gives you something to talk about.\"]\n",
      "06/29/2022 07:21:22 - INFO - __main__ -   Epoch: 122 | Batch: 5400/10001 (54%) | G Loss: 3.079660 | C Loss: -0.528472\n",
      "06/29/2022 07:21:22 - INFO - __main__ -   Text: ['\"Yes, it\\'s life.\"']\n",
      "06/29/2022 07:21:23 - INFO - __main__ -   Epoch: 122 | Batch: 6000/10001 (60%) | G Loss: 3.080662 | C Loss: -0.429394\n",
      "06/29/2022 07:21:23 - INFO - __main__ -   Text: ['This hunger rating means that most megafauna inhabitants have very high hunger ratings.']\n",
      "06/29/2022 07:21:24 - INFO - __main__ -   Epoch: 122 | Batch: 6600/10001 (66%) | G Loss: 2.871317 | C Loss: -0.503973\n",
      "06/29/2022 07:21:24 - INFO - __main__ -   Text: ['They do not know about human rights.']\n",
      "06/29/2022 07:21:25 - INFO - __main__ -   Epoch: 122 | Batch: 7200/10001 (72%) | G Loss: 2.446376 | C Loss: -0.587048\n",
      "06/29/2022 07:21:25 - INFO - __main__ -   Text: ['The math is extremely well suited for CMS.']\n",
      "06/29/2022 07:21:26 - INFO - __main__ -   Epoch: 122 | Batch: 7800/10001 (78%) | G Loss: 2.542547 | C Loss: -0.548066\n",
      "06/29/2022 07:21:26 - INFO - __main__ -   Text: ['This sword slams into the blue sky to make you angry.\"']\n",
      "06/29/2022 07:21:27 - INFO - __main__ -   Epoch: 122 | Batch: 8400/10001 (84%) | G Loss: 2.963867 | C Loss: -0.442088\n",
      "06/29/2022 07:21:27 - INFO - __main__ -   Text: ['The virus affects the A3 themselves, so it may refer to `server server(s)` of this']\n",
      "06/29/2022 07:21:28 - INFO - __main__ -   Epoch: 122 | Batch: 9000/10001 (90%) | G Loss: 3.386590 | C Loss: -0.514645\n",
      "06/29/2022 07:21:28 - INFO - __main__ -   Text: ['Unfortunately, the joke is on shooting porn (which is often unavailable on mobile devices).']\n",
      "06/29/2022 07:21:29 - INFO - __main__ -   Epoch: 122 | Batch: 9600/10001 (96%) | G Loss: 2.676876 | C Loss: -0.515082\n",
      "06/29/2022 07:21:29 - INFO - __main__ -   Text: ['This will lead to two empty seconds given forever KRITI.']\n",
      "06/29/2022 07:21:30 - INFO - __main__ -   * (Train) Epoch: 122 | G Loss: 2.8087 | C Loss: -0.5135 | Updates G: 46 | Updates C: 787\n",
      "06/29/2022 07:21:39 - INFO - __main__ -   Bleu-2:0.195 | B-Bleu-2:0.263\n",
      "06/29/2022 07:21:39 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_18.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45748531346660604\n",
      "Train file used is number 18\n",
      "../../yahoo/subdivided_large/train_18.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 123 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:25:14 - INFO - __main__ -   Epoch: 123 | Batch: 0/10001 (0%) | G Loss: 2.958532 | C Loss: -0.757020\n",
      "06/29/2022 07:25:14 - INFO - __main__ -   Text: ['Commonly erroneously interpreted in court legal opinions.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.952\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:25:15 - INFO - __main__ -   Epoch: 123 | Batch: 600/10001 (6%) | G Loss: 2.795681 | C Loss: -0.435193\n",
      "06/29/2022 07:25:15 - INFO - __main__ -   Text: ['They include Diregional oveimpose lines.']\n",
      "06/29/2022 07:25:16 - INFO - __main__ -   Epoch: 123 | Batch: 1200/10001 (12%) | G Loss: 2.384470 | C Loss: -0.519529\n",
      "06/29/2022 07:25:16 - INFO - __main__ -   Text: [\"In Japan there are plenty of black and white T'. See Deep Throat's fantasies for profit.)\"]\n",
      "06/29/2022 07:25:17 - INFO - __main__ -   Epoch: 123 | Batch: 1800/10001 (18%) | G Loss: 2.502356 | C Loss: -0.508502\n",
      "06/29/2022 07:25:17 - INFO - __main__ -   Text: ['The UK Press contains both book and tablet versions - here is your thought on local geography.']\n",
      "06/29/2022 07:25:18 - INFO - __main__ -   Epoch: 123 | Batch: 2400/10001 (24%) | G Loss: 3.048577 | C Loss: -0.618863\n",
      "06/29/2022 07:25:18 - INFO - __main__ -   Text: ['The BIGBAD subscriber podcast is labelled as a podcast about R&B Albums.']\n",
      "06/29/2022 07:25:19 - INFO - __main__ -   Epoch: 123 | Batch: 3000/10001 (30%) | G Loss: 3.396815 | C Loss: -0.425020\n",
      "06/29/2022 07:25:19 - INFO - __main__ -   Text: ['The LHC APGB.']\n",
      "06/29/2022 07:25:20 - INFO - __main__ -   Epoch: 123 | Batch: 3600/10001 (36%) | G Loss: 3.275827 | C Loss: -0.484939\n",
      "06/29/2022 07:25:20 - INFO - __main__ -   Text: ['\"get it fastest\".']\n",
      "06/29/2022 07:25:21 - INFO - __main__ -   Epoch: 123 | Batch: 4200/10001 (42%) | G Loss: 2.899107 | C Loss: -0.305861\n",
      "06/29/2022 07:25:22 - INFO - __main__ -   Text: ['This makes tasting the sweet in the eye really exciting.\"']\n",
      "06/29/2022 07:25:22 - INFO - __main__ -   Epoch: 123 | Batch: 4800/10001 (48%) | G Loss: 2.879620 | C Loss: -0.432121\n",
      "06/29/2022 07:25:23 - INFO - __main__ -   Text: ['Slash is a shorthand for \"slew\".']\n",
      "06/29/2022 07:25:24 - INFO - __main__ -   Epoch: 123 | Batch: 5400/10001 (54%) | G Loss: 3.243903 | C Loss: -0.668892\n",
      "06/29/2022 07:25:24 - INFO - __main__ -   Text: ['Currently, it is a science or technology degree.']\n",
      "06/29/2022 07:25:25 - INFO - __main__ -   Epoch: 123 | Batch: 6000/10001 (60%) | G Loss: 2.831665 | C Loss: -0.591848\n",
      "06/29/2022 07:25:25 - INFO - __main__ -   Text: ['FRA/DFL comes on is it want just to use Rail?']\n",
      "06/29/2022 07:25:26 - INFO - __main__ -   Epoch: 123 | Batch: 6600/10001 (66%) | G Loss: 2.742184 | C Loss: -0.810209\n",
      "06/29/2022 07:25:26 - INFO - __main__ -   Text: ['These drawings guide you through the horror marketplace.']\n",
      "06/29/2022 07:25:27 - INFO - __main__ -   Epoch: 123 | Batch: 7200/10001 (72%) | G Loss: 2.622137 | C Loss: -0.629061\n",
      "06/29/2022 07:25:27 - INFO - __main__ -   Text: ['Vita mêrg !']\n",
      "06/29/2022 07:25:28 - INFO - __main__ -   Epoch: 123 | Batch: 7800/10001 (78%) | G Loss: 2.648373 | C Loss: -0.622311\n",
      "06/29/2022 07:25:28 - INFO - __main__ -   Text: ['I crazy\".']\n",
      "06/29/2022 07:25:29 - INFO - __main__ -   Epoch: 123 | Batch: 8400/10001 (84%) | G Loss: 2.708324 | C Loss: -0.504470\n",
      "06/29/2022 07:25:29 - INFO - __main__ -   Text: ['Researcher Skinner helps Harry C. Maxwell to evade jail.']\n",
      "06/29/2022 07:25:30 - INFO - __main__ -   Epoch: 123 | Batch: 9000/10001 (90%) | G Loss: 2.834773 | C Loss: -0.444236\n",
      "06/29/2022 07:25:30 - INFO - __main__ -   Text: ['Shaf Rabbitimb.\"']\n",
      "06/29/2022 07:25:31 - INFO - __main__ -   Epoch: 123 | Batch: 9600/10001 (96%) | G Loss: 3.051961 | C Loss: -0.558977\n",
      "06/29/2022 07:25:31 - INFO - __main__ -   Text: ['The author then reviews the qualified manuscripts listed on the following page.']\n",
      "06/29/2022 07:25:32 - INFO - __main__ -   * (Train) Epoch: 123 | G Loss: 2.8169 | C Loss: -0.5154 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 07:25:41 - INFO - __main__ -   Bleu-2:0.208 | B-Bleu-2:0.251\n",
      "06/29/2022 07:25:41 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4594506564366314\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 124 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:29:15 - INFO - __main__ -   Epoch: 124 | Batch: 0/10001 (0%) | G Loss: 3.052426 | C Loss: -0.516045\n",
      "06/29/2022 07:29:15 - INFO - __main__ -   Text: ['Her obsession is to find the sexiest woman on the street with the quickest score possible.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.958\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:29:16 - INFO - __main__ -   Epoch: 124 | Batch: 600/10001 (6%) | G Loss: 2.915079 | C Loss: -0.434579\n",
      "06/29/2022 07:29:16 - INFO - __main__ -   Text: ['Cycle64bot supports the conditional arithmetic here.']\n",
      "06/29/2022 07:29:17 - INFO - __main__ -   Epoch: 124 | Batch: 1200/10001 (12%) | G Loss: 2.581405 | C Loss: -0.443331\n",
      "06/29/2022 07:29:18 - INFO - __main__ -   Text: ['The player who have all time Trion.']\n",
      "06/29/2022 07:29:19 - INFO - __main__ -   Epoch: 124 | Batch: 1800/10001 (18%) | G Loss: 2.767510 | C Loss: -0.670465\n",
      "06/29/2022 07:29:19 - INFO - __main__ -   Text: ['The fathiism is small.']\n",
      "06/29/2022 07:29:20 - INFO - __main__ -   Epoch: 124 | Batch: 2400/10001 (24%) | G Loss: 2.218326 | C Loss: -0.255295\n",
      "06/29/2022 07:29:20 - INFO - __main__ -   Text: ['Merton has its own adventures.']\n",
      "06/29/2022 07:29:21 - INFO - __main__ -   Epoch: 124 | Batch: 3000/10001 (30%) | G Loss: 2.484274 | C Loss: -0.363702\n",
      "06/29/2022 07:29:21 - INFO - __main__ -   Text: [\"In discord, they aren't on the same hockey team as Chad.\"]\n",
      "06/29/2022 07:29:22 - INFO - __main__ -   Epoch: 124 | Batch: 3600/10001 (36%) | G Loss: 3.190995 | C Loss: -0.563933\n",
      "06/29/2022 07:29:22 - INFO - __main__ -   Text: [\"Marino's oratorics are also shared.\"]\n",
      "06/29/2022 07:29:23 - INFO - __main__ -   Epoch: 124 | Batch: 4200/10001 (42%) | G Loss: 3.770190 | C Loss: -0.772305\n",
      "06/29/2022 07:29:23 - INFO - __main__ -   Text: ['He says \"Well hey!\"']\n",
      "06/29/2022 07:29:24 - INFO - __main__ -   Epoch: 124 | Batch: 4800/10001 (48%) | G Loss: 3.531466 | C Loss: -0.569299\n",
      "06/29/2022 07:29:24 - INFO - __main__ -   Text: ['It is determinate\".']\n",
      "06/29/2022 07:29:25 - INFO - __main__ -   Epoch: 124 | Batch: 5400/10001 (54%) | G Loss: 3.394612 | C Loss: -1.024369\n",
      "06/29/2022 07:29:25 - INFO - __main__ -   Text: ['Plants can be planted before his time.\"']\n",
      "06/29/2022 07:29:26 - INFO - __main__ -   Epoch: 124 | Batch: 6000/10001 (60%) | G Loss: 2.725787 | C Loss: -0.268326\n",
      "06/29/2022 07:29:26 - INFO - __main__ -   Text: ['\"Ratives Ride\".']\n",
      "06/29/2022 07:29:27 - INFO - __main__ -   Epoch: 124 | Batch: 6600/10001 (66%) | G Loss: 2.546273 | C Loss: -0.406378\n",
      "06/29/2022 07:29:27 - INFO - __main__ -   Text: ['One way of creating film epistemology is to Google advent.']\n",
      "06/29/2022 07:29:28 - INFO - __main__ -   Epoch: 124 | Batch: 7200/10001 (72%) | G Loss: 2.337843 | C Loss: -0.421838\n",
      "06/29/2022 07:29:28 - INFO - __main__ -   Text: ['\"WHO shall rulestone?\"']\n",
      "06/29/2022 07:29:29 - INFO - __main__ -   Epoch: 124 | Batch: 7800/10001 (78%) | G Loss: 2.104166 | C Loss: -0.642160\n",
      "06/29/2022 07:29:29 - INFO - __main__ -   Text: ['Another thing I would ask is if this is exactly what I want to do!\"']\n",
      "06/29/2022 07:29:30 - INFO - __main__ -   Epoch: 124 | Batch: 8400/10001 (84%) | G Loss: 2.259617 | C Loss: -0.510680\n",
      "06/29/2022 07:29:30 - INFO - __main__ -   Text: ['What what scare bulls off.']\n",
      "06/29/2022 07:29:31 - INFO - __main__ -   Epoch: 124 | Batch: 9000/10001 (90%) | G Loss: 2.809189 | C Loss: -0.378186\n",
      "06/29/2022 07:29:31 - INFO - __main__ -   Text: ['Kahrs.\"']\n",
      "06/29/2022 07:29:32 - INFO - __main__ -   Epoch: 124 | Batch: 9600/10001 (96%) | G Loss: 3.163620 | C Loss: -0.670816\n",
      "06/29/2022 07:29:32 - INFO - __main__ -   Text: ['He is trying to do the right thing.\"']\n",
      "06/29/2022 07:29:33 - INFO - __main__ -   * (Train) Epoch: 124 | G Loss: 2.6307 | C Loss: -0.5343 | Updates G: 32 | Updates C: 801\n",
      "06/29/2022 07:29:42 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.222\n",
      "06/29/2022 07:29:42 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42618809255894285\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 125 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:33:14 - INFO - __main__ -   Epoch: 125 | Batch: 0/10001 (0%) | G Loss: 3.036473 | C Loss: -0.542054\n",
      "06/29/2022 07:33:14 - INFO - __main__ -   Text: ['But Kapostian transformational codeproperties and completeness.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.957\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:33:15 - INFO - __main__ -   Epoch: 125 | Batch: 600/10001 (6%) | G Loss: 2.968877 | C Loss: -0.460725\n",
      "06/29/2022 07:33:15 - INFO - __main__ -   Text: ['\"bing\".']\n",
      "06/29/2022 07:33:16 - INFO - __main__ -   Epoch: 125 | Batch: 1200/10001 (12%) | G Loss: 2.874475 | C Loss: -0.460446\n",
      "06/29/2022 07:33:16 - INFO - __main__ -   Text: ['If your campus can manage braking size.']\n",
      "06/29/2022 07:33:17 - INFO - __main__ -   Epoch: 125 | Batch: 1800/10001 (18%) | G Loss: 2.982973 | C Loss: -0.547695\n",
      "06/29/2022 07:33:17 - INFO - __main__ -   Text: ['Hhadash is also able to write Jash are not yet the same\".']\n",
      "06/29/2022 07:33:18 - INFO - __main__ -   Epoch: 125 | Batch: 2400/10001 (24%) | G Loss: 2.481101 | C Loss: -0.515766\n",
      "06/29/2022 07:33:18 - INFO - __main__ -   Text: ['Childs plays tips.\"']\n",
      "06/29/2022 07:33:19 - INFO - __main__ -   Epoch: 125 | Batch: 3000/10001 (30%) | G Loss: 2.988445 | C Loss: -0.582597\n",
      "06/29/2022 07:33:19 - INFO - __main__ -   Text: [\"That mascot's name was Ravenshawe.\"]\n",
      "06/29/2022 07:33:20 - INFO - __main__ -   Epoch: 125 | Batch: 3600/10001 (36%) | G Loss: 2.805639 | C Loss: -0.413404\n",
      "06/29/2022 07:33:20 - INFO - __main__ -   Text: ['A weak immune system also reduces survival rates.']\n",
      "06/29/2022 07:33:21 - INFO - __main__ -   Epoch: 125 | Batch: 4200/10001 (42%) | G Loss: 3.221029 | C Loss: -0.600446\n",
      "06/29/2022 07:33:21 - INFO - __main__ -   Text: [\"He's saying it every time he sees children falling for him.\"]\n",
      "06/29/2022 07:33:22 - INFO - __main__ -   Epoch: 125 | Batch: 4800/10001 (48%) | G Loss: 2.879507 | C Loss: -0.369552\n",
      "06/29/2022 07:33:22 - INFO - __main__ -   Text: ['I can guess what\\'s going on, but not supplies.\"']\n",
      "06/29/2022 07:33:23 - INFO - __main__ -   Epoch: 125 | Batch: 5400/10001 (54%) | G Loss: 2.577269 | C Loss: -0.301445\n",
      "06/29/2022 07:33:23 - INFO - __main__ -   Text: ['She must be listening to the students.']\n",
      "06/29/2022 07:33:24 - INFO - __main__ -   Epoch: 125 | Batch: 6000/10001 (60%) | G Loss: 2.341463 | C Loss: -0.853411\n",
      "06/29/2022 07:33:24 - INFO - __main__ -   Text: ['The Confederacy was considered the highest state in the Netherlands.']\n",
      "06/29/2022 07:33:25 - INFO - __main__ -   Epoch: 125 | Batch: 6600/10001 (66%) | G Loss: 2.408319 | C Loss: -0.660474\n",
      "06/29/2022 07:33:25 - INFO - __main__ -   Text: ['Studies concerning theology should be followed.']\n",
      "06/29/2022 07:33:26 - INFO - __main__ -   Epoch: 125 | Batch: 7200/10001 (72%) | G Loss: 2.432554 | C Loss: -0.490795\n",
      "06/29/2022 07:33:26 - INFO - __main__ -   Text: ['We shall not decide on the name until the ruler of many words is none.']\n",
      "06/29/2022 07:33:27 - INFO - __main__ -   Epoch: 125 | Batch: 7800/10001 (78%) | G Loss: 2.880903 | C Loss: -0.431300\n",
      "06/29/2022 07:33:27 - INFO - __main__ -   Text: ['§pnqu.\"']\n",
      "06/29/2022 07:33:28 - INFO - __main__ -   Epoch: 125 | Batch: 8400/10001 (84%) | G Loss: 2.813974 | C Loss: -0.439754\n",
      "06/29/2022 07:33:29 - INFO - __main__ -   Text: ['The road is blowing! <BOS> Makes fools on more ground.']\n",
      "06/29/2022 07:33:30 - INFO - __main__ -   Epoch: 125 | Batch: 9000/10001 (90%) | G Loss: 3.224037 | C Loss: -0.696067\n",
      "06/29/2022 07:33:30 - INFO - __main__ -   Text: ['He has a \"whooping, jingles\".']\n",
      "06/29/2022 07:33:31 - INFO - __main__ -   Epoch: 125 | Batch: 9600/10001 (96%) | G Loss: 2.739489 | C Loss: -0.483222\n",
      "06/29/2022 07:33:31 - INFO - __main__ -   Text: ['Prophetic reasoning often leads to speculation of causal causes.']\n",
      "06/29/2022 07:33:31 - INFO - __main__ -   * (Train) Epoch: 125 | G Loss: 2.7496 | C Loss: -0.5102 | Updates G: 38 | Updates C: 795\n",
      "06/29/2022 07:33:40 - INFO - __main__ -   Bleu-2:0.180 | B-Bleu-2:0.254\n",
      "06/29/2022 07:33:40 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43406739636060954\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 126 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:37:13 - INFO - __main__ -   Epoch: 126 | Batch: 0/10000 (0%) | G Loss: 2.785341 | C Loss: -0.506953\n",
      "06/29/2022 07:37:13 - INFO - __main__ -   Text: ['They are considered the fastest three to 25 km race (at the ocean course).']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.999\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:37:14 - INFO - __main__ -   Epoch: 126 | Batch: 600/10000 (6%) | G Loss: 2.976222 | C Loss: -0.597035\n",
      "06/29/2022 07:37:14 - INFO - __main__ -   Text: ['The scene is presented fast and his also trying to determine the path.']\n",
      "06/29/2022 07:37:15 - INFO - __main__ -   Epoch: 126 | Batch: 1200/10000 (12%) | G Loss: 3.126345 | C Loss: -0.557023\n",
      "06/29/2022 07:37:15 - INFO - __main__ -   Text: ['She\\'ll complain \\'Why don\\'t you get a curl?\\'\"']\n",
      "06/29/2022 07:37:16 - INFO - __main__ -   Epoch: 126 | Batch: 1800/10000 (18%) | G Loss: 2.550694 | C Loss: -0.393854\n",
      "06/29/2022 07:37:17 - INFO - __main__ -   Text: ['\"Weitard\" is co-author of an online dating guide.']\n",
      "06/29/2022 07:37:17 - INFO - __main__ -   Epoch: 126 | Batch: 2400/10000 (24%) | G Loss: 2.818436 | C Loss: -0.617755\n",
      "06/29/2022 07:37:18 - INFO - __main__ -   Text: ['The top list is bowling provers.']\n",
      "06/29/2022 07:37:19 - INFO - __main__ -   Epoch: 126 | Batch: 3000/10000 (30%) | G Loss: 2.846492 | C Loss: -0.452142\n",
      "06/29/2022 07:37:19 - INFO - __main__ -   Text: ['These competitions are run on the internet. <PAD> This competition has serious results.']\n",
      "06/29/2022 07:37:20 - INFO - __main__ -   Epoch: 126 | Batch: 3600/10000 (36%) | G Loss: 3.191217 | C Loss: -0.415227\n",
      "06/29/2022 07:37:20 - INFO - __main__ -   Text: ['He argues that the path of least resistance to this kind of major condition will be known as probabilistic.']\n",
      "06/29/2022 07:37:21 - INFO - __main__ -   Epoch: 126 | Batch: 4200/10000 (42%) | G Loss: 3.649649 | C Loss: -0.794844\n",
      "06/29/2022 07:37:21 - INFO - __main__ -   Text: ['All Pitt Actor plants turn the heads of ladies.']\n",
      "06/29/2022 07:37:22 - INFO - __main__ -   Epoch: 126 | Batch: 4800/10000 (48%) | G Loss: 3.231522 | C Loss: -0.692340\n",
      "06/29/2022 07:37:22 - INFO - __main__ -   Text: ['This refers to healing ailments it has cause someone.']\n",
      "06/29/2022 07:37:23 - INFO - __main__ -   Epoch: 126 | Batch: 5400/10000 (54%) | G Loss: 2.646683 | C Loss: -0.571403\n",
      "06/29/2022 07:37:23 - INFO - __main__ -   Text: ['She only loves things that make someone stupid.']\n",
      "06/29/2022 07:37:24 - INFO - __main__ -   Epoch: 126 | Batch: 6000/10000 (60%) | G Loss: 2.323871 | C Loss: -0.347508\n",
      "06/29/2022 07:37:24 - INFO - __main__ -   Text: ['One ought to know which hall is upside down, a sideshow.']\n",
      "06/29/2022 07:37:25 - INFO - __main__ -   Epoch: 126 | Batch: 6600/10000 (66%) | G Loss: 2.237329 | C Loss: -0.280771\n",
      "06/29/2022 07:37:25 - INFO - __main__ -   Text: ['They are often called the rake because the children are tippy.']\n",
      "06/29/2022 07:37:26 - INFO - __main__ -   Epoch: 126 | Batch: 7200/10000 (72%) | G Loss: 2.676582 | C Loss: -0.256551\n",
      "06/29/2022 07:37:26 - INFO - __main__ -   Text: [\"In 2020, Peach's goal is to become obese.\"]\n",
      "06/29/2022 07:37:27 - INFO - __main__ -   Epoch: 126 | Batch: 7800/10000 (78%) | G Loss: 2.481690 | C Loss: -0.518781\n",
      "06/29/2022 07:37:27 - INFO - __main__ -   Text: ['She will help you develop your santa around Jenny.']\n",
      "06/29/2022 07:37:28 - INFO - __main__ -   Epoch: 126 | Batch: 8400/10000 (84%) | G Loss: 2.529862 | C Loss: -0.643312\n",
      "06/29/2022 07:37:28 - INFO - __main__ -   Text: ['A number of notable monarchs.']\n",
      "06/29/2022 07:37:29 - INFO - __main__ -   Epoch: 126 | Batch: 9000/10000 (90%) | G Loss: 2.791496 | C Loss: -0.599895\n",
      "06/29/2022 07:37:29 - INFO - __main__ -   Text: ['CF is magic.']\n",
      "06/29/2022 07:37:30 - INFO - __main__ -   Epoch: 126 | Batch: 9600/10000 (96%) | G Loss: 3.074943 | C Loss: -0.494584\n",
      "06/29/2022 07:37:31 - INFO - __main__ -   Text: ['From the word \"parallel.\"']\n",
      "06/29/2022 07:37:31 - INFO - __main__ -   * (Train) Epoch: 126 | G Loss: 2.6743 | C Loss: -0.5193 | Updates G: 45 | Updates C: 788\n",
      "06/29/2022 07:37:40 - INFO - __main__ -   Bleu-2:0.191 | B-Bleu-2:0.243\n",
      "06/29/2022 07:37:40 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43399526535666455\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 127 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:41:07 - INFO - __main__ -   Epoch: 127 | Batch: 0/10000 (0%) | G Loss: 3.143519 | C Loss: -0.675175\n",
      "06/29/2022 07:41:07 - INFO - __main__ -   Text: [\"The NLRB's editorials are generally written by senior official.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.487\n",
      "  Test Loss: 4.065\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:41:08 - INFO - __main__ -   Epoch: 127 | Batch: 600/10000 (6%) | G Loss: 3.543211 | C Loss: -0.597450\n",
      "06/29/2022 07:41:08 - INFO - __main__ -   Text: ['This joke is hoping that if creators that use the video game are to have a screening thing.']\n",
      "06/29/2022 07:41:09 - INFO - __main__ -   Epoch: 127 | Batch: 1200/10000 (12%) | G Loss: 2.948704 | C Loss: -0.068482\n",
      "06/29/2022 07:41:09 - INFO - __main__ -   Text: [\"There's never any next way to get souvenirs from the racecourse, so I wanted to wear a crown on\"]\n",
      "06/29/2022 07:41:10 - INFO - __main__ -   Epoch: 127 | Batch: 1800/10000 (18%) | G Loss: 2.835631 | C Loss: -0.344660\n",
      "06/29/2022 07:41:11 - INFO - __main__ -   Text: ['The biggest incentive for me is hiking with my 39-year old sister and sister Maggie.']\n",
      "06/29/2022 07:41:12 - INFO - __main__ -   Epoch: 127 | Batch: 2400/10000 (24%) | G Loss: 2.793407 | C Loss: -0.465007\n",
      "06/29/2022 07:41:12 - INFO - __main__ -   Text: ['They use their ponies to provide his or her holiday shopping experience.']\n",
      "06/29/2022 07:41:13 - INFO - __main__ -   Epoch: 127 | Batch: 3000/10000 (30%) | G Loss: 2.740383 | C Loss: -0.587406\n",
      "06/29/2022 07:41:13 - INFO - __main__ -   Text: ['The game lets them get more ahead of themselves.\"']\n",
      "06/29/2022 07:41:14 - INFO - __main__ -   Epoch: 127 | Batch: 3600/10000 (36%) | G Loss: 2.560357 | C Loss: -0.451806\n",
      "06/29/2022 07:41:14 - INFO - __main__ -   Text: ['ThatTrollChannel is a . <BOS>Radio.']\n",
      "06/29/2022 07:41:15 - INFO - __main__ -   Epoch: 127 | Batch: 4200/10000 (42%) | G Loss: 2.649298 | C Loss: -0.422906\n",
      "06/29/2022 07:41:15 - INFO - __main__ -   Text: [\"I can't stop myself.\"]\n",
      "06/29/2022 07:41:16 - INFO - __main__ -   Epoch: 127 | Batch: 4800/10000 (48%) | G Loss: 2.720596 | C Loss: -0.413653\n",
      "06/29/2022 07:41:16 - INFO - __main__ -   Text: ['\", instructs us into gratitude.']\n",
      "06/29/2022 07:41:17 - INFO - __main__ -   Epoch: 127 | Batch: 5400/10000 (54%) | G Loss: 3.167435 | C Loss: -0.564463\n",
      "06/29/2022 07:41:17 - INFO - __main__ -   Text: ['Jewish understanding of God is not.']\n",
      "06/29/2022 07:41:18 - INFO - __main__ -   Epoch: 127 | Batch: 6000/10000 (60%) | G Loss: 3.136980 | C Loss: -0.327623\n",
      "06/29/2022 07:41:18 - INFO - __main__ -   Text: ['Saurya is sentient and impervious.']\n",
      "06/29/2022 07:41:19 - INFO - __main__ -   Epoch: 127 | Batch: 6600/10000 (66%) | G Loss: 3.066126 | C Loss: -0.466520\n",
      "06/29/2022 07:41:19 - INFO - __main__ -   Text: ['[\"stinks\").']\n",
      "06/29/2022 07:41:20 - INFO - __main__ -   Epoch: 127 | Batch: 7200/10000 (72%) | G Loss: 2.911361 | C Loss: -0.460712\n",
      "06/29/2022 07:41:20 - INFO - __main__ -   Text: ['He also tries to explain the duality of Lucidre.']\n",
      "06/29/2022 07:41:21 - INFO - __main__ -   Epoch: 127 | Batch: 7800/10000 (78%) | G Loss: 2.937403 | C Loss: -0.487912\n",
      "06/29/2022 07:41:21 - INFO - __main__ -   Text: ['The myth of Cthulhu is used to describe the world.']\n",
      "06/29/2022 07:41:22 - INFO - __main__ -   Epoch: 127 | Batch: 8400/10000 (84%) | G Loss: 2.784036 | C Loss: -0.310326\n",
      "06/29/2022 07:41:22 - INFO - __main__ -   Text: ['Service of UFOs.']\n",
      "06/29/2022 07:41:23 - INFO - __main__ -   Epoch: 127 | Batch: 9000/10000 (90%) | G Loss: 2.552046 | C Loss: -0.413445\n",
      "06/29/2022 07:41:23 - INFO - __main__ -   Text: ['It is only at 60% yield but or exactly']\n",
      "06/29/2022 07:41:24 - INFO - __main__ -   Epoch: 127 | Batch: 9600/10000 (96%) | G Loss: 2.905694 | C Loss: -0.502663\n",
      "06/29/2022 07:41:24 - INFO - __main__ -   Text: ['Thankfully, fairy tales are only the beginning of knowledge.\"']\n",
      "06/29/2022 07:41:25 - INFO - __main__ -   * (Train) Epoch: 127 | G Loss: 2.8024 | C Loss: -0.5120 | Updates G: 34 | Updates C: 799\n",
      "06/29/2022 07:41:34 - INFO - __main__ -   Bleu-2:0.195 | B-Bleu-2:0.243\n",
      "06/29/2022 07:41:34 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43881665218874294\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 128 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:45:08 - INFO - __main__ -   Epoch: 128 | Batch: 0/10001 (0%) | G Loss: 2.764747 | C Loss: -0.413266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 3.932\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:45:08 - INFO - __main__ -   Text: ['When a black body turns red, the pathway for pulling it into the oxidative hypersertitude.']\n",
      "06/29/2022 07:45:09 - INFO - __main__ -   Epoch: 128 | Batch: 600/10001 (6%) | G Loss: 2.865220 | C Loss: -0.439962\n",
      "06/29/2022 07:45:10 - INFO - __main__ -   Text: ['The concept of integration is off-putting to those with a sudden departure from the Christian.']\n",
      "06/29/2022 07:45:11 - INFO - __main__ -   Epoch: 128 | Batch: 1200/10001 (12%) | G Loss: 2.663165 | C Loss: -0.507472\n",
      "06/29/2022 07:45:11 - INFO - __main__ -   Text: ['Bert the Dots #� Mighty Pepper.']\n",
      "06/29/2022 07:45:12 - INFO - __main__ -   Epoch: 128 | Batch: 1800/10001 (18%) | G Loss: 2.754231 | C Loss: -0.358361\n",
      "06/29/2022 07:45:12 - INFO - __main__ -   Text: ['They seem to talk in rather western directions.']\n",
      "06/29/2022 07:45:13 - INFO - __main__ -   Epoch: 128 | Batch: 2400/10001 (24%) | G Loss: 3.161336 | C Loss: -0.519191\n",
      "06/29/2022 07:45:13 - INFO - __main__ -   Text: ['Furthermore, as a rule, that messages equals good.\"']\n",
      "06/29/2022 07:45:14 - INFO - __main__ -   Epoch: 128 | Batch: 3000/10001 (30%) | G Loss: 3.150998 | C Loss: -0.441963\n",
      "06/29/2022 07:45:14 - INFO - __main__ -   Text: ['What is fun is hearing about those programs.\"']\n",
      "06/29/2022 07:45:15 - INFO - __main__ -   Epoch: 128 | Batch: 3600/10001 (36%) | G Loss: 2.749846 | C Loss: -0.450524\n",
      "06/29/2022 07:45:15 - INFO - __main__ -   Text: ['Oilers are beautiful.']\n",
      "06/29/2022 07:45:16 - INFO - __main__ -   Epoch: 128 | Batch: 4200/10001 (42%) | G Loss: 2.717012 | C Loss: -0.508224\n",
      "06/29/2022 07:45:16 - INFO - __main__ -   Text: ['Medical measures are counterproductive.']\n",
      "06/29/2022 07:45:17 - INFO - __main__ -   Epoch: 128 | Batch: 4800/10001 (48%) | G Loss: 2.775033 | C Loss: -0.362275\n",
      "06/29/2022 07:45:17 - INFO - __main__ -   Text: ['If one wants, one can always get to know people and cultural changes.']\n",
      "06/29/2022 07:45:18 - INFO - __main__ -   Epoch: 128 | Batch: 5400/10001 (54%) | G Loss: 2.675003 | C Loss: -0.487337\n",
      "06/29/2022 07:45:18 - INFO - __main__ -   Text: ['It has weaker and more efficient habits than Dharma. <PAD> On this virtual <PAD>']\n",
      "06/29/2022 07:45:19 - INFO - __main__ -   Epoch: 128 | Batch: 6000/10001 (60%) | G Loss: 2.987008 | C Loss: -0.539744\n",
      "06/29/2022 07:45:19 - INFO - __main__ -   Text: ['He is not allowed to be sexually explicit with any male or female partner because of insecurity.']\n",
      "06/29/2022 07:45:20 - INFO - __main__ -   Epoch: 128 | Batch: 6600/10001 (66%) | G Loss: 2.548229 | C Loss: -0.511237\n",
      "06/29/2022 07:45:20 - INFO - __main__ -   Text: ['Something to play with!!']\n",
      "06/29/2022 07:45:21 - INFO - __main__ -   Epoch: 128 | Batch: 7200/10001 (72%) | G Loss: 2.780744 | C Loss: -0.594280\n",
      "06/29/2022 07:45:21 - INFO - __main__ -   Text: ['The vampire flies at high rate of physical contact with people.']\n",
      "06/29/2022 07:45:22 - INFO - __main__ -   Epoch: 128 | Batch: 7800/10001 (78%) | G Loss: 2.962760 | C Loss: -0.592620\n",
      "06/29/2022 07:45:22 - INFO - __main__ -   Text: ['It is also shown how much money you get when you eat.']\n",
      "06/29/2022 07:45:23 - INFO - __main__ -   Epoch: 128 | Batch: 8400/10001 (84%) | G Loss: 3.274070 | C Loss: -0.330545\n",
      "06/29/2022 07:45:24 - INFO - __main__ -   Text: ['A funny book is this!']\n",
      "06/29/2022 07:45:24 - INFO - __main__ -   Epoch: 128 | Batch: 9000/10001 (90%) | G Loss: 2.512226 | C Loss: -0.674849\n",
      "06/29/2022 07:45:25 - INFO - __main__ -   Text: ['\"<br>']\n",
      "06/29/2022 07:45:26 - INFO - __main__ -   Epoch: 128 | Batch: 9600/10001 (96%) | G Loss: 2.564780 | C Loss: -0.404139\n",
      "06/29/2022 07:45:26 - INFO - __main__ -   Text: ['They can be historians online only, separate from others.']\n",
      "06/29/2022 07:45:26 - INFO - __main__ -   * (Train) Epoch: 128 | G Loss: 2.7464 | C Loss: -0.5060 | Updates G: 56 | Updates C: 777\n",
      "06/29/2022 07:45:35 - INFO - __main__ -   Bleu-2:0.193 | B-Bleu-2:0.248\n",
      "06/29/2022 07:45:35 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4404974440175089\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 129 / 200 ========\n",
      "Training...\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:49:08 - INFO - __main__ -   Epoch: 129 | Batch: 0/10001 (0%) | G Loss: 2.778608 | C Loss: -0.481859\n",
      "06/29/2022 07:49:08 - INFO - __main__ -   Text: ['Military general is notable for his errors in the second sentence.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.939\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:49:09 - INFO - __main__ -   Epoch: 129 | Batch: 600/10001 (6%) | G Loss: 2.954777 | C Loss: -0.461004\n",
      "06/29/2022 07:49:09 - INFO - __main__ -   Text: ['In habitation, bats appear to be vicious (veiling).']\n",
      "06/29/2022 07:49:10 - INFO - __main__ -   Epoch: 129 | Batch: 1200/10001 (12%) | G Loss: 3.079321 | C Loss: -0.736327\n",
      "06/29/2022 07:49:10 - INFO - __main__ -   Text: ['It involves being socially inept.']\n",
      "06/29/2022 07:49:11 - INFO - __main__ -   Epoch: 129 | Batch: 1800/10001 (18%) | G Loss: 3.027420 | C Loss: -0.342911\n",
      "06/29/2022 07:49:11 - INFO - __main__ -   Text: ['Torino has learners of both English and Latin and blogs about them.']\n",
      "06/29/2022 07:49:12 - INFO - __main__ -   Epoch: 129 | Batch: 2400/10001 (24%) | G Loss: 2.938043 | C Loss: -0.538604\n",
      "06/29/2022 07:49:12 - INFO - __main__ -   Text: ['Therefore it has a rich and complex geographical landmass.']\n",
      "06/29/2022 07:49:13 - INFO - __main__ -   Epoch: 129 | Batch: 3000/10001 (30%) | G Loss: 2.625962 | C Loss: -0.378962\n",
      "06/29/2022 07:49:13 - INFO - __main__ -   Text: ['It is all basically happening on your laptop and is a plugin.']\n",
      "06/29/2022 07:49:14 - INFO - __main__ -   Epoch: 129 | Batch: 3600/10001 (36%) | G Loss: 2.592462 | C Loss: -0.472862\n",
      "06/29/2022 07:49:14 - INFO - __main__ -   Text: ['This means an easy victory.']\n",
      "06/29/2022 07:49:15 - INFO - __main__ -   Epoch: 129 | Batch: 4200/10001 (42%) | G Loss: 2.953978 | C Loss: -0.476688\n",
      "06/29/2022 07:49:16 - INFO - __main__ -   Text: ['It is an asshole.\"']\n",
      "06/29/2022 07:49:17 - INFO - __main__ -   Epoch: 129 | Batch: 4800/10001 (48%) | G Loss: 2.790072 | C Loss: -0.722480\n",
      "06/29/2022 07:49:17 - INFO - __main__ -   Text: ['\", thaii ela !']\n",
      "06/29/2022 07:49:18 - INFO - __main__ -   Epoch: 129 | Batch: 5400/10001 (54%) | G Loss: 2.288103 | C Loss: -0.436762\n",
      "06/29/2022 07:49:18 - INFO - __main__ -   Text: ['Also may refer to: Chinese lice (ignocious) and Pediclerii (blind).']\n",
      "06/29/2022 07:49:19 - INFO - __main__ -   Epoch: 129 | Batch: 6000/10001 (60%) | G Loss: 2.411787 | C Loss: -0.535921\n",
      "06/29/2022 07:49:19 - INFO - __main__ -   Text: ['It is a book of shame that more people are confused by this category.']\n",
      "06/29/2022 07:49:20 - INFO - __main__ -   Epoch: 129 | Batch: 6600/10001 (66%) | G Loss: 2.532974 | C Loss: -0.459010\n",
      "06/29/2022 07:49:20 - INFO - __main__ -   Text: ['However, Lestael has been chosen as the ninth president of A&E.']\n",
      "06/29/2022 07:49:21 - INFO - __main__ -   Epoch: 129 | Batch: 7200/10001 (72%) | G Loss: 2.641889 | C Loss: -0.766575\n",
      "06/29/2022 07:49:21 - INFO - __main__ -   Text: [\"It's like Forbidden!\"]\n",
      "06/29/2022 07:49:22 - INFO - __main__ -   Epoch: 129 | Batch: 7800/10001 (78%) | G Loss: 2.749704 | C Loss: -0.621848\n",
      "06/29/2022 07:49:22 - INFO - __main__ -   Text: ['The research section , which is related to a local conference, is still inactive.']\n",
      "06/29/2022 07:49:23 - INFO - __main__ -   Epoch: 129 | Batch: 8400/10001 (84%) | G Loss: 3.054171 | C Loss: -0.622876\n",
      "06/29/2022 07:49:23 - INFO - __main__ -   Text: ['rage is the power of perception.\"']\n",
      "06/29/2022 07:49:24 - INFO - __main__ -   Epoch: 129 | Batch: 9000/10001 (90%) | G Loss: 2.992817 | C Loss: -0.547301\n",
      "06/29/2022 07:49:24 - INFO - __main__ -   Text: [': Using a professional.\"']\n",
      "06/29/2022 07:49:25 - INFO - __main__ -   Epoch: 129 | Batch: 9600/10001 (96%) | G Loss: 2.602456 | C Loss: -0.397597\n",
      "06/29/2022 07:49:25 - INFO - __main__ -   Text: ['invest us there!\"']\n",
      "06/29/2022 07:49:26 - INFO - __main__ -   * (Train) Epoch: 129 | G Loss: 2.6392 | C Loss: -0.5018 | Updates G: 37 | Updates C: 796\n",
      "06/29/2022 07:49:35 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.248\n",
      "06/29/2022 07:49:35 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44881785676459496\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 130 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:53:05 - INFO - __main__ -   Epoch: 130 | Batch: 0/10001 (0%) | G Loss: 2.282820 | C Loss: -0.617352\n",
      "06/29/2022 07:53:05 - INFO - __main__ -   Text: ['UPDATE_NAME description Plugin *)']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 4.021\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:53:06 - INFO - __main__ -   Epoch: 130 | Batch: 600/10001 (6%) | G Loss: 2.702295 | C Loss: -0.576420\n",
      "06/29/2022 07:53:06 - INFO - __main__ -   Text: ['Pope Haslam has gone off script here too.\"']\n",
      "06/29/2022 07:53:07 - INFO - __main__ -   Epoch: 130 | Batch: 1200/10001 (12%) | G Loss: 3.250477 | C Loss: -0.757842\n",
      "06/29/2022 07:53:07 - INFO - __main__ -   Text: ['He has opted for an open-ended argumentative style.']\n",
      "06/29/2022 07:53:08 - INFO - __main__ -   Epoch: 130 | Batch: 1800/10001 (18%) | G Loss: 3.262165 | C Loss: -0.442003\n",
      "06/29/2022 07:53:08 - INFO - __main__ -   Text: ['He is sometimes painted as full of energy and rude, above his competitors.']\n",
      "06/29/2022 07:53:09 - INFO - __main__ -   Epoch: 130 | Batch: 2400/10001 (24%) | G Loss: 2.199903 | C Loss: -0.288676\n",
      "06/29/2022 07:53:09 - INFO - __main__ -   Text: ['\"higher\" μ medway Blues can be surprising.']\n",
      "06/29/2022 07:53:10 - INFO - __main__ -   Epoch: 130 | Batch: 3000/10001 (30%) | G Loss: 2.140829 | C Loss: -0.650663\n",
      "06/29/2022 07:53:10 - INFO - __main__ -   Text: ['She is the Leicester, but it is an entirely different town.']\n",
      "06/29/2022 07:53:11 - INFO - __main__ -   Epoch: 130 | Batch: 3600/10001 (36%) | G Loss: 3.048912 | C Loss: -0.505198\n",
      "06/29/2022 07:53:11 - INFO - __main__ -   Text: ['He says that he\\'s not afraid to help his devig\"hna\\' unless you tell him.']\n",
      "06/29/2022 07:53:12 - INFO - __main__ -   Epoch: 130 | Batch: 4200/10001 (42%) | G Loss: 2.143311 | C Loss: -0.392079\n",
      "06/29/2022 07:53:12 - INFO - __main__ -   Text: ['The stories are Guardian stories 73 and 83.']\n",
      "06/29/2022 07:53:13 - INFO - __main__ -   Epoch: 130 | Batch: 4800/10001 (48%) | G Loss: 2.054021 | C Loss: -0.332991\n",
      "06/29/2022 07:53:14 - INFO - __main__ -   Text: ['The socially minded send messenger to kill every mosquito.']\n",
      "06/29/2022 07:53:15 - INFO - __main__ -   Epoch: 130 | Batch: 5400/10001 (54%) | G Loss: 3.312856 | C Loss: -0.626449\n",
      "06/29/2022 07:53:15 - INFO - __main__ -   Text: ['Skin Deep Interface is therefore dangerous!!!!']\n",
      "06/29/2022 07:53:16 - INFO - __main__ -   Epoch: 130 | Batch: 6000/10001 (60%) | G Loss: 3.187149 | C Loss: -0.486239\n",
      "06/29/2022 07:53:16 - INFO - __main__ -   Text: [\"Because that's what conservation should be about.\"]\n",
      "06/29/2022 07:53:17 - INFO - __main__ -   Epoch: 130 | Batch: 6600/10001 (66%) | G Loss: 3.251304 | C Loss: -0.932136\n",
      "06/29/2022 07:53:17 - INFO - __main__ -   Text: ['Biology and synthetic solutions on seedwriting.']\n",
      "06/29/2022 07:53:18 - INFO - __main__ -   Epoch: 130 | Batch: 7200/10001 (72%) | G Loss: 2.869915 | C Loss: -0.500663\n",
      "06/29/2022 07:53:18 - INFO - __main__ -   Text: ['\"moheron\" / Kozum.']\n",
      "06/29/2022 07:53:19 - INFO - __main__ -   Epoch: 130 | Batch: 7800/10001 (78%) | G Loss: 2.537886 | C Loss: -0.582979\n",
      "06/29/2022 07:53:19 - INFO - __main__ -   Text: ['Bird is not one of those many who come on an hour-and-a-half journey.']\n",
      "06/29/2022 07:53:20 - INFO - __main__ -   Epoch: 130 | Batch: 8400/10001 (84%) | G Loss: 2.428294 | C Loss: -0.564422\n",
      "06/29/2022 07:53:20 - INFO - __main__ -   Text: [\"Only two princesses are recognised as prince: (somewhat like London where they're called)\"]\n",
      "06/29/2022 07:53:21 - INFO - __main__ -   Epoch: 130 | Batch: 9000/10001 (90%) | G Loss: 2.065284 | C Loss: -0.508130\n",
      "06/29/2022 07:53:21 - INFO - __main__ -   Text: ['Prior to pregnancy, black males are considered unlikely to consent.']\n",
      "06/29/2022 07:53:22 - INFO - __main__ -   Epoch: 130 | Batch: 9600/10001 (96%) | G Loss: 2.544772 | C Loss: -0.534489\n",
      "06/29/2022 07:53:22 - INFO - __main__ -   Text: ['Students should know basic geometry’s main purpose.']\n",
      "06/29/2022 07:53:23 - INFO - __main__ -   * (Train) Epoch: 130 | G Loss: 2.5552 | C Loss: -0.5271 | Updates G: 48 | Updates C: 785\n",
      "06/29/2022 07:53:32 - INFO - __main__ -   Bleu-2:0.191 | B-Bleu-2:0.238\n",
      "06/29/2022 07:53:32 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4292615036616061\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 131 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:57:05 - INFO - __main__ -   Epoch: 131 | Batch: 0/10001 (0%) | G Loss: 2.798783 | C Loss: -0.354377\n",
      "06/29/2022 07:57:05 - INFO - __main__ -   Text: ['Jenny McCarthy is unsure of what may be meant by college.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.994\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 07:57:06 - INFO - __main__ -   Epoch: 131 | Batch: 600/10001 (6%) | G Loss: 2.237329 | C Loss: -0.355795\n",
      "06/29/2022 07:57:06 - INFO - __main__ -   Text: ['The quiz is easy to enter, though most can be found in other school places.']\n",
      "06/29/2022 07:57:07 - INFO - __main__ -   Epoch: 131 | Batch: 1200/10001 (12%) | G Loss: 4.465978 | C Loss: -0.735735\n",
      "06/29/2022 07:57:08 - INFO - __main__ -   Text: ['This seven-year-old boy is the son of \"Kapav na Bamchai\".']\n",
      "06/29/2022 07:57:09 - INFO - __main__ -   Epoch: 131 | Batch: 1800/10001 (18%) | G Loss: 3.775050 | C Loss: -0.401281\n",
      "06/29/2022 07:57:09 - INFO - __main__ -   Text: ['Vladeware.']\n",
      "06/29/2022 07:57:10 - INFO - __main__ -   Epoch: 131 | Batch: 2400/10001 (24%) | G Loss: 2.053113 | C Loss: -0.303699\n",
      "06/29/2022 07:57:10 - INFO - __main__ -   Text: ['Nanospacer network offers a js business model.']\n",
      "06/29/2022 07:57:11 - INFO - __main__ -   Epoch: 131 | Batch: 3000/10001 (30%) | G Loss: 2.645891 | C Loss: -0.300540\n",
      "06/29/2022 07:57:11 - INFO - __main__ -   Text: ['The sequence of events is invisible to nasties and other monitored authors.']\n",
      "06/29/2022 07:57:12 - INFO - __main__ -   Epoch: 131 | Batch: 3600/10001 (36%) | G Loss: 3.678998 | C Loss: -0.337100\n",
      "06/29/2022 07:57:12 - INFO - __main__ -   Text: ['\"The Complete Guide to Dungeons & Dragons\".']\n",
      "06/29/2022 07:57:13 - INFO - __main__ -   Epoch: 131 | Batch: 4200/10001 (42%) | G Loss: 3.229676 | C Loss: -0.931863\n",
      "06/29/2022 07:57:13 - INFO - __main__ -   Text: ['The grrrrrrrrrr special!']\n",
      "06/29/2022 07:57:14 - INFO - __main__ -   Epoch: 131 | Batch: 4800/10001 (48%) | G Loss: 2.523694 | C Loss: -0.171041\n",
      "06/29/2022 07:57:14 - INFO - __main__ -   Text: ['\"taming feathers\".']\n",
      "06/29/2022 07:57:15 - INFO - __main__ -   Epoch: 131 | Batch: 5400/10001 (54%) | G Loss: 1.131935 | C Loss: -0.309092\n",
      "06/29/2022 07:57:15 - INFO - __main__ -   Text: ['Often people know that Vonbil is not a baby, and favorite food.']\n",
      "06/29/2022 07:57:16 - INFO - __main__ -   Epoch: 131 | Batch: 6000/10001 (60%) | G Loss: 2.132550 | C Loss: -0.391499\n",
      "06/29/2022 07:57:16 - INFO - __main__ -   Text: ['The fight is would I win this fight?']\n",
      "06/29/2022 07:57:17 - INFO - __main__ -   Epoch: 131 | Batch: 6600/10001 (66%) | G Loss: 2.933722 | C Loss: -0.558722\n",
      "06/29/2022 07:57:17 - INFO - __main__ -   Text: ['Information from both nations may be available.']\n",
      "06/29/2022 07:57:18 - INFO - __main__ -   Epoch: 131 | Batch: 7200/10001 (72%) | G Loss: 2.906745 | C Loss: -0.864272\n",
      "06/29/2022 07:57:18 - INFO - __main__ -   Text: [\"The next test of a driver's character is whether he has any sense of morality.\"]\n",
      "06/29/2022 07:57:19 - INFO - __main__ -   Epoch: 131 | Batch: 7800/10001 (78%) | G Loss: 1.745342 | C Loss: -0.251470\n",
      "06/29/2022 07:57:20 - INFO - __main__ -   Text: ['It is the mandate for each branch of the Checklists.']\n",
      "06/29/2022 07:57:21 - INFO - __main__ -   Epoch: 131 | Batch: 8400/10001 (84%) | G Loss: 3.011826 | C Loss: -0.442450\n",
      "06/29/2022 07:57:21 - INFO - __main__ -   Text: ['Sling Varnits are wimpy in their own right.']\n",
      "06/29/2022 07:57:22 - INFO - __main__ -   Epoch: 131 | Batch: 9000/10001 (90%) | G Loss: 2.964130 | C Loss: -0.112594\n",
      "06/29/2022 07:57:22 - INFO - __main__ -   Text: ['“When drinking water comes from above the surface”.']\n",
      "06/29/2022 07:57:23 - INFO - __main__ -   Epoch: 131 | Batch: 9600/10001 (96%) | G Loss: 2.494225 | C Loss: -0.418511\n",
      "06/29/2022 07:57:23 - INFO - __main__ -   Text: ['Two legs may go a bit further.']\n",
      "06/29/2022 07:57:23 - INFO - __main__ -   * (Train) Epoch: 131 | G Loss: 2.4950 | C Loss: -0.5485 | Updates G: 51 | Updates C: 782\n",
      "06/29/2022 07:57:33 - INFO - __main__ -   Bleu-2:0.208 | B-Bleu-2:0.229\n",
      "06/29/2022 07:57:33 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43692645283873155\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 132 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:00:59 - INFO - __main__ -   Epoch: 132 | Batch: 0/10001 (0%) | G Loss: 2.437242 | C Loss: -0.466119\n",
      "06/29/2022 08:01:00 - INFO - __main__ -   Text: ['She gives birth to unborn babies.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.971\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:01:00 - INFO - __main__ -   Epoch: 132 | Batch: 600/10001 (6%) | G Loss: 3.334970 | C Loss: -0.781504\n",
      "06/29/2022 08:01:01 - INFO - __main__ -   Text: [\"It is the fictional original trilogy of children's names.\"]\n",
      "06/29/2022 08:01:02 - INFO - __main__ -   Epoch: 132 | Batch: 1200/10001 (12%) | G Loss: 2.896212 | C Loss: -0.367960\n",
      "06/29/2022 08:01:02 - INFO - __main__ -   Text: ['Consider a parliamentary decision: Do I have to move the -1 prospect to the -0.']\n",
      "06/29/2022 08:01:03 - INFO - __main__ -   Epoch: 132 | Batch: 1800/10001 (18%) | G Loss: 2.976321 | C Loss: -0.474398\n",
      "06/29/2022 08:01:03 - INFO - __main__ -   Text: ['Then, knowledge can really cut edge according to which businesses the college is planning to compete for.']\n",
      "06/29/2022 08:01:04 - INFO - __main__ -   Epoch: 132 | Batch: 2400/10001 (24%) | G Loss: 2.428774 | C Loss: -0.280481\n",
      "06/29/2022 08:01:04 - INFO - __main__ -   Text: ['\"The attitude gets people thinking of me.\"']\n",
      "06/29/2022 08:01:05 - INFO - __main__ -   Epoch: 132 | Batch: 3000/10001 (30%) | G Loss: 2.597927 | C Loss: -0.568089\n",
      "06/29/2022 08:01:05 - INFO - __main__ -   Text: ['Regions within nanometer molecules oxygen.']\n",
      "06/29/2022 08:01:06 - INFO - __main__ -   Epoch: 132 | Batch: 3600/10001 (36%) | G Loss: 2.926031 | C Loss: -0.646769\n",
      "06/29/2022 08:01:06 - INFO - __main__ -   Text: ['\"Get My Tickets\" is a kind of second-hand experience search engine.']\n",
      "06/29/2022 08:01:07 - INFO - __main__ -   Epoch: 132 | Batch: 4200/10001 (42%) | G Loss: 3.153271 | C Loss: -0.442876\n",
      "06/29/2022 08:01:07 - INFO - __main__ -   Text: [\"A girl seems to think he's the thief, who wants to his wife.\"]\n",
      "06/29/2022 08:01:08 - INFO - __main__ -   Epoch: 132 | Batch: 4800/10001 (48%) | G Loss: 2.492634 | C Loss: -0.619137\n",
      "06/29/2022 08:01:08 - INFO - __main__ -   Text: ['Nomehraldo say Nomehra kurta cat).']\n",
      "06/29/2022 08:01:09 - INFO - __main__ -   Epoch: 132 | Batch: 5400/10001 (54%) | G Loss: 2.151532 | C Loss: -0.484133\n",
      "06/29/2022 08:01:10 - INFO - __main__ -   Text: ['The modification of the acidic metabolism of Europa: is a cancer.']\n",
      "06/29/2022 08:01:11 - INFO - __main__ -   Epoch: 132 | Batch: 6000/10001 (60%) | G Loss: 2.572107 | C Loss: -0.360205\n",
      "06/29/2022 08:01:11 - INFO - __main__ -   Text: ['The video.']\n",
      "06/29/2022 08:01:12 - INFO - __main__ -   Epoch: 132 | Batch: 6600/10001 (66%) | G Loss: 3.162905 | C Loss: -0.539833\n",
      "06/29/2022 08:01:12 - INFO - __main__ -   Text: ['It is similar to the Welsh.']\n",
      "06/29/2022 08:01:13 - INFO - __main__ -   Epoch: 132 | Batch: 7200/10001 (72%) | G Loss: 3.326976 | C Loss: -0.432007\n",
      "06/29/2022 08:01:13 - INFO - __main__ -   Text: ['According to Gosling, \"he may sell to satisfy his appetite.']\n",
      "06/29/2022 08:01:14 - INFO - __main__ -   Epoch: 132 | Batch: 7800/10001 (78%) | G Loss: 2.650187 | C Loss: -0.400609\n",
      "06/29/2022 08:01:14 - INFO - __main__ -   Text: ['When we don\\'t have energy to do something, what should I do?\".']\n",
      "06/29/2022 08:01:15 - INFO - __main__ -   Epoch: 132 | Batch: 8400/10001 (84%) | G Loss: 2.161212 | C Loss: -0.392385\n",
      "06/29/2022 08:01:15 - INFO - __main__ -   Text: ['18.']\n",
      "06/29/2022 08:01:16 - INFO - __main__ -   Epoch: 132 | Batch: 9000/10001 (90%) | G Loss: 1.790841 | C Loss: -0.478161\n",
      "06/29/2022 08:01:16 - INFO - __main__ -   Text: ['The elaboration and construction of the concept of spiritual law requires an understanding of the implications.']\n",
      "06/29/2022 08:01:17 - INFO - __main__ -   Epoch: 132 | Batch: 9600/10001 (96%) | G Loss: 2.383995 | C Loss: -0.538150\n",
      "06/29/2022 08:01:17 - INFO - __main__ -   Text: ['They can also be named Pooah.']\n",
      "06/29/2022 08:01:18 - INFO - __main__ -   * (Train) Epoch: 132 | G Loss: 2.6105 | C Loss: -0.4890 | Updates G: 52 | Updates C: 781\n",
      "06/29/2022 08:01:27 - INFO - __main__ -   Bleu-2:0.193 | B-Bleu-2:0.239\n",
      "06/29/2022 08:01:27 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43180238959563444\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 133 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:04:58 - INFO - __main__ -   Epoch: 133 | Batch: 0/10001 (0%) | G Loss: 2.780558 | C Loss: -0.565809\n",
      "06/29/2022 08:04:58 - INFO - __main__ -   Text: [\"Tauha's only wife is Barthalu .\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.980\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:04:59 - INFO - __main__ -   Epoch: 133 | Batch: 600/10001 (6%) | G Loss: 3.134491 | C Loss: -0.745384\n",
      "06/29/2022 08:04:59 - INFO - __main__ -   Text: ['tozamine spider is currently mine.']\n",
      "06/29/2022 08:05:00 - INFO - __main__ -   Epoch: 133 | Batch: 1200/10001 (12%) | G Loss: 2.969381 | C Loss: -0.515787\n",
      "06/29/2022 08:05:00 - INFO - __main__ -   Text: ['This is a guide to chapters on magic and skill or combinations.']\n",
      "06/29/2022 08:05:01 - INFO - __main__ -   Epoch: 133 | Batch: 1800/10001 (18%) | G Loss: 2.518542 | C Loss: -0.277955\n",
      "06/29/2022 08:05:01 - INFO - __main__ -   Text: ['it should easily define topodoc.']\n",
      "06/29/2022 08:05:02 - INFO - __main__ -   Epoch: 133 | Batch: 2400/10001 (24%) | G Loss: 2.276466 | C Loss: -0.434168\n",
      "06/29/2022 08:05:02 - INFO - __main__ -   Text: ['Plan DT Dual L\\'Oil\".']\n",
      "06/29/2022 08:05:03 - INFO - __main__ -   Epoch: 133 | Batch: 3000/10001 (30%) | G Loss: 2.512940 | C Loss: -0.372915\n",
      "06/29/2022 08:05:03 - INFO - __main__ -   Text: ['Having gonads makes these flowers bright.']\n",
      "06/29/2022 08:05:04 - INFO - __main__ -   Epoch: 133 | Batch: 3600/10001 (36%) | G Loss: 2.741964 | C Loss: -0.636795\n",
      "06/29/2022 08:05:04 - INFO - __main__ -   Text: ['There are other tribes associated with this coral called the Mythoes.']\n",
      "06/29/2022 08:05:05 - INFO - __main__ -   Epoch: 133 | Batch: 4200/10001 (42%) | G Loss: 2.671644 | C Loss: -0.912757\n",
      "06/29/2022 08:05:05 - INFO - __main__ -   Text: ['they are a cosmopolitan and Bohemian type.']\n",
      "06/29/2022 08:05:06 - INFO - __main__ -   Epoch: 133 | Batch: 4800/10001 (48%) | G Loss: 2.343172 | C Loss: -0.397050\n",
      "06/29/2022 08:05:07 - INFO - __main__ -   Text: ['It\\'s on air.\"']\n",
      "06/29/2022 08:05:08 - INFO - __main__ -   Epoch: 133 | Batch: 5400/10001 (54%) | G Loss: 2.064997 | C Loss: -0.372332\n",
      "06/29/2022 08:05:08 - INFO - __main__ -   Text: ['It is really 20ish and yet ya have me right there!\"']\n",
      "06/29/2022 08:05:09 - INFO - __main__ -   Epoch: 133 | Batch: 6000/10001 (60%) | G Loss: 2.693200 | C Loss: -0.640101\n",
      "06/29/2022 08:05:09 - INFO - __main__ -   Text: ['It displays Tunisian typing information such as foot strokes.']\n",
      "06/29/2022 08:05:10 - INFO - __main__ -   Epoch: 133 | Batch: 6600/10001 (66%) | G Loss: 3.088812 | C Loss: -0.460366\n",
      "06/29/2022 08:05:10 - INFO - __main__ -   Text: ['Caution is good too for honey.']\n",
      "06/29/2022 08:05:11 - INFO - __main__ -   Epoch: 133 | Batch: 7200/10001 (72%) | G Loss: 3.062073 | C Loss: -0.420795\n",
      "06/29/2022 08:05:11 - INFO - __main__ -   Text: ['\"the school...\"']\n",
      "06/29/2022 08:05:12 - INFO - __main__ -   Epoch: 133 | Batch: 7800/10001 (78%) | G Loss: 2.730773 | C Loss: -0.494676\n",
      "06/29/2022 08:05:12 - INFO - __main__ -   Text: ['\"Fiend Noël!\"']\n",
      "06/29/2022 08:05:13 - INFO - __main__ -   Epoch: 133 | Batch: 8400/10001 (84%) | G Loss: 2.562664 | C Loss: -0.506919\n",
      "06/29/2022 08:05:13 - INFO - __main__ -   Text: ['The set is imagined to be Bile sexuality.']\n",
      "06/29/2022 08:05:14 - INFO - __main__ -   Epoch: 133 | Batch: 9000/10001 (90%) | G Loss: 2.595472 | C Loss: -0.302635\n",
      "06/29/2022 08:05:14 - INFO - __main__ -   Text: ['Their tendency is to assume that everyone else will not have access to guns.']\n",
      "06/29/2022 08:05:15 - INFO - __main__ -   Epoch: 133 | Batch: 9600/10001 (96%) | G Loss: 2.856132 | C Loss: -0.371235\n",
      "06/29/2022 08:05:15 - INFO - __main__ -   Text: ['It is somewhat unique to its culture.']\n",
      "06/29/2022 08:05:16 - INFO - __main__ -   * (Train) Epoch: 133 | G Loss: 2.5963 | C Loss: -0.4995 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 08:05:25 - INFO - __main__ -   Bleu-2:0.201 | B-Bleu-2:0.266\n",
      "06/29/2022 08:05:25 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46735804617981325\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 134 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:24.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:00.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:18.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:09:01 - INFO - __main__ -   Epoch: 134 | Batch: 0/10001 (0%) | G Loss: 2.511956 | C Loss: -0.802013\n",
      "06/29/2022 08:09:01 - INFO - __main__ -   Text: ['However, infatuation, not saying it, is the source of its madness.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.871\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:09:02 - INFO - __main__ -   Epoch: 134 | Batch: 600/10001 (6%) | G Loss: 2.281526 | C Loss: -0.829117\n",
      "06/29/2022 08:09:02 - INFO - __main__ -   Text: ['\"Falsification\".']\n",
      "06/29/2022 08:09:03 - INFO - __main__ -   Epoch: 134 | Batch: 1200/10001 (12%) | G Loss: 1.762343 | C Loss: -0.269145\n",
      "06/29/2022 08:09:03 - INFO - __main__ -   Text: ['Like a remote squeaker, his heart changes.']\n",
      "06/29/2022 08:09:04 - INFO - __main__ -   Epoch: 134 | Batch: 1800/10001 (18%) | G Loss: 2.101239 | C Loss: -0.539936\n",
      "06/29/2022 08:09:04 - INFO - __main__ -   Text: ['You expect to see bright!']\n",
      "06/29/2022 08:09:05 - INFO - __main__ -   Epoch: 134 | Batch: 2400/10001 (24%) | G Loss: 2.346246 | C Loss: -0.201206\n",
      "06/29/2022 08:09:05 - INFO - __main__ -   Text: ['In maths there are no scopes on Lois Off\".']\n",
      "06/29/2022 08:09:06 - INFO - __main__ -   Epoch: 134 | Batch: 3000/10001 (30%) | G Loss: 3.317813 | C Loss: -0.446970\n",
      "06/29/2022 08:09:06 - INFO - __main__ -   Text: ['A higher level of heart-like communication is known as magical message.']\n",
      "06/29/2022 08:09:07 - INFO - __main__ -   Epoch: 134 | Batch: 3600/10001 (36%) | G Loss: 2.959230 | C Loss: -0.528007\n",
      "06/29/2022 08:09:08 - INFO - __main__ -   Text: ['Prior to being blind, Sherman is a reporter for the \"New York Times.\"']\n",
      "06/29/2022 08:09:09 - INFO - __main__ -   Epoch: 134 | Batch: 4200/10001 (42%) | G Loss: 2.644885 | C Loss: -0.465445\n",
      "06/29/2022 08:09:09 - INFO - __main__ -   Text: ['Mathematically \"Umatry\" is exactly the equivalent of \"moe\".']\n",
      "06/29/2022 08:09:10 - INFO - __main__ -   Epoch: 134 | Batch: 4800/10001 (48%) | G Loss: 2.294437 | C Loss: -0.513454\n",
      "06/29/2022 08:09:10 - INFO - __main__ -   Text: ['Prevention isn\\'t a lack of policy but attempts to cure disease.\"']\n",
      "06/29/2022 08:09:11 - INFO - __main__ -   Epoch: 134 | Batch: 5400/10001 (54%) | G Loss: 2.343481 | C Loss: -0.445245\n",
      "06/29/2022 08:09:11 - INFO - __main__ -   Text: ['For example, Yasog.\"']\n",
      "06/29/2022 08:09:12 - INFO - __main__ -   Epoch: 134 | Batch: 6000/10001 (60%) | G Loss: 3.073768 | C Loss: -0.610662\n",
      "06/29/2022 08:09:12 - INFO - __main__ -   Text: ['Michie takes a toxin to describe humans.']\n",
      "06/29/2022 08:09:13 - INFO - __main__ -   Epoch: 134 | Batch: 6600/10001 (66%) | G Loss: 3.292195 | C Loss: -0.473340\n",
      "06/29/2022 08:09:13 - INFO - __main__ -   Text: ['The sensation of seeing his neighbor crying tears down!']\n",
      "06/29/2022 08:09:14 - INFO - __main__ -   Epoch: 134 | Batch: 7200/10001 (72%) | G Loss: 3.034830 | C Loss: -1.151446\n",
      "06/29/2022 08:09:14 - INFO - __main__ -   Text: ['\"Triple Cache X\" allows youths to skip school.']\n",
      "06/29/2022 08:09:15 - INFO - __main__ -   Epoch: 134 | Batch: 7800/10001 (78%) | G Loss: 2.450955 | C Loss: -0.202010\n",
      "06/29/2022 08:09:15 - INFO - __main__ -   Text: ['An ideal battle sitting bottle for pearlogi.']\n",
      "06/29/2022 08:09:16 - INFO - __main__ -   Epoch: 134 | Batch: 8400/10001 (84%) | G Loss: 2.158466 | C Loss: -0.446797\n",
      "06/29/2022 08:09:16 - INFO - __main__ -   Text: ['I. Gat.']\n",
      "06/29/2022 08:09:17 - INFO - __main__ -   Epoch: 134 | Batch: 9000/10001 (90%) | G Loss: 2.305437 | C Loss: -0.544141\n",
      "06/29/2022 08:09:17 - INFO - __main__ -   Text: ['Even Nuehoffen!']\n",
      "06/29/2022 08:09:18 - INFO - __main__ -   Epoch: 134 | Batch: 9600/10001 (96%) | G Loss: 2.970349 | C Loss: -0.719174\n",
      "06/29/2022 08:09:18 - INFO - __main__ -   Text: ['2 fun treatment.']\n",
      "06/29/2022 08:09:19 - INFO - __main__ -   * (Train) Epoch: 134 | G Loss: 2.5494 | C Loss: -0.4923 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 08:09:28 - INFO - __main__ -   Bleu-2:0.212 | B-Bleu-2:0.267\n",
      "06/29/2022 08:09:28 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4790191804357342\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 135 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:12:58 - INFO - __main__ -   Epoch: 135 | Batch: 0/10001 (0%) | G Loss: 2.925004 | C Loss: -0.483476\n",
      "06/29/2022 08:12:58 - INFO - __main__ -   Text: ['If people are equal, then we have 5.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.856\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:12:59 - INFO - __main__ -   Epoch: 135 | Batch: 600/10001 (6%) | G Loss: 2.926847 | C Loss: -0.442030\n",
      "06/29/2022 08:12:59 - INFO - __main__ -   Text: ['It\\'s all you have to do!\"']\n",
      "06/29/2022 08:13:00 - INFO - __main__ -   Epoch: 135 | Batch: 1200/10001 (12%) | G Loss: 2.889041 | C Loss: -0.462694\n",
      "06/29/2022 08:13:00 - INFO - __main__ -   Text: ['Most prospective strength test participants would be able to learn to read.']\n",
      "06/29/2022 08:13:01 - INFO - __main__ -   Epoch: 135 | Batch: 1800/10001 (18%) | G Loss: 2.686608 | C Loss: -0.491910\n",
      "06/29/2022 08:13:02 - INFO - __main__ -   Text: ['She is known as the unexpected legacy of Ike.']\n",
      "06/29/2022 08:13:03 - INFO - __main__ -   Epoch: 135 | Batch: 2400/10001 (24%) | G Loss: 2.396010 | C Loss: -0.456859\n",
      "06/29/2022 08:13:03 - INFO - __main__ -   Text: ['There is a whole of the kind of society.']\n",
      "06/29/2022 08:13:04 - INFO - __main__ -   Epoch: 135 | Batch: 3000/10001 (30%) | G Loss: 2.413791 | C Loss: -0.542327\n",
      "06/29/2022 08:13:04 - INFO - __main__ -   Text: [\"He's not afraid of his own stuff.\"]\n",
      "06/29/2022 08:13:05 - INFO - __main__ -   Epoch: 135 | Batch: 3600/10001 (36%) | G Loss: 2.617988 | C Loss: -0.460922\n",
      "06/29/2022 08:13:05 - INFO - __main__ -   Text: ['This is different from the professional health insurance deduction and the way ICDs are calculated.']\n",
      "06/29/2022 08:13:06 - INFO - __main__ -   Epoch: 135 | Batch: 4200/10001 (42%) | G Loss: 2.420305 | C Loss: -0.296327\n",
      "06/29/2022 08:13:06 - INFO - __main__ -   Text: ['stresses it which is no matter.\"']\n",
      "06/29/2022 08:13:07 - INFO - __main__ -   Epoch: 135 | Batch: 4800/10001 (48%) | G Loss: 2.682297 | C Loss: -0.185708\n",
      "06/29/2022 08:13:07 - INFO - __main__ -   Text: ['CBTC asks things of fear and usually fails to show why.']\n",
      "06/29/2022 08:13:08 - INFO - __main__ -   Epoch: 135 | Batch: 5400/10001 (54%) | G Loss: 3.191528 | C Loss: -0.603009\n",
      "06/29/2022 08:13:08 - INFO - __main__ -   Text: ['Obey all norms and behave like a professional.']\n",
      "06/29/2022 08:13:09 - INFO - __main__ -   Epoch: 135 | Batch: 6000/10001 (60%) | G Loss: 3.096977 | C Loss: -0.473845\n",
      "06/29/2022 08:13:09 - INFO - __main__ -   Text: ['ó. <PAD>\"']\n",
      "06/29/2022 08:13:10 - INFO - __main__ -   Epoch: 135 | Batch: 6600/10001 (66%) | G Loss: 2.616278 | C Loss: -0.547741\n",
      "06/29/2022 08:13:10 - INFO - __main__ -   Text: ['This is called wayis, or something\".']\n",
      "06/29/2022 08:13:11 - INFO - __main__ -   Epoch: 135 | Batch: 7200/10001 (72%) | G Loss: 2.042107 | C Loss: -0.423690\n",
      "06/29/2022 08:13:11 - INFO - __main__ -   Text: ['It is an International Radio talk show!']\n",
      "06/29/2022 08:13:12 - INFO - __main__ -   Epoch: 135 | Batch: 7800/10001 (78%) | G Loss: 2.118576 | C Loss: -0.495696\n",
      "06/29/2022 08:13:12 - INFO - __main__ -   Text: ['Since \\'\\'you don\\'t have to wear a baseball cap at bowling games, you can just play.\"']\n",
      "06/29/2022 08:13:13 - INFO - __main__ -   Epoch: 135 | Batch: 8400/10001 (84%) | G Loss: 2.930189 | C Loss: -0.787939\n",
      "06/29/2022 08:13:13 - INFO - __main__ -   Text: ['Ten years old, they are afraid.']\n",
      "06/29/2022 08:13:14 - INFO - __main__ -   Epoch: 135 | Batch: 9000/10001 (90%) | G Loss: 2.940851 | C Loss: -0.729626\n",
      "06/29/2022 08:13:15 - INFO - __main__ -   Text: ['Both Mumblebee and Elon G. have previously studied and written about science.']\n",
      "06/29/2022 08:13:16 - INFO - __main__ -   Epoch: 135 | Batch: 9600/10001 (96%) | G Loss: 3.088301 | C Loss: -0.322003\n",
      "06/29/2022 08:13:16 - INFO - __main__ -   Text: ['\"Are You Experienced?\" <PAD> House of Cards!']\n",
      "06/29/2022 08:13:16 - INFO - __main__ -   * (Train) Epoch: 135 | G Loss: 2.6708 | C Loss: -0.4999 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 08:13:25 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.266\n",
      "06/29/2022 08:13:25 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4646982824882415\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 136 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:16:59 - INFO - __main__ -   Epoch: 136 | Batch: 0/10001 (0%) | G Loss: 3.117966 | C Loss: -0.418038\n",
      "06/29/2022 08:16:59 - INFO - __main__ -   Text: ['It is necessary to conjure fire from heaven.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.512\n",
      "  Test Loss: 3.852\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:17:00 - INFO - __main__ -   Epoch: 136 | Batch: 600/10001 (6%) | G Loss: 2.947293 | C Loss: -0.441540\n",
      "06/29/2022 08:17:00 - INFO - __main__ -   Text: ['It also lists \"Venus . . A clojure blaséword\" as one of the most']\n",
      "06/29/2022 08:17:01 - INFO - __main__ -   Epoch: 136 | Batch: 1200/10001 (12%) | G Loss: 2.685987 | C Loss: -0.412501\n",
      "06/29/2022 08:17:01 - INFO - __main__ -   Text: ['It mocks capitalism and has no purpose.\"']\n",
      "06/29/2022 08:17:02 - INFO - __main__ -   Epoch: 136 | Batch: 1800/10001 (18%) | G Loss: 2.504456 | C Loss: -0.282512\n",
      "06/29/2022 08:17:02 - INFO - __main__ -   Text: ['Ben for example will never win the knitting contest and windles could have some difficulty in wining the stone.']\n",
      "06/29/2022 08:17:03 - INFO - __main__ -   Epoch: 136 | Batch: 2400/10001 (24%) | G Loss: 2.982604 | C Loss: -0.528974\n",
      "06/29/2022 08:17:04 - INFO - __main__ -   Text: ['\"I\\'m trying to make resources easy to get.']\n",
      "06/29/2022 08:17:05 - INFO - __main__ -   Epoch: 136 | Batch: 3000/10001 (30%) | G Loss: 2.679349 | C Loss: -0.535474\n",
      "06/29/2022 08:17:05 - INFO - __main__ -   Text: ['This bridge is created with Our Hands Upon Our Faith.']\n",
      "06/29/2022 08:17:06 - INFO - __main__ -   Epoch: 136 | Batch: 3600/10001 (36%) | G Loss: 2.309467 | C Loss: -0.349540\n",
      "06/29/2022 08:17:06 - INFO - __main__ -   Text: ['In the running is Chinese sports car world champion Raymond Su.']\n",
      "06/29/2022 08:17:07 - INFO - __main__ -   Epoch: 136 | Batch: 4200/10001 (42%) | G Loss: 2.773840 | C Loss: -0.477782\n",
      "06/29/2022 08:17:07 - INFO - __main__ -   Text: ['On the other hand, it is the greatest catastrophe yet felt on this planet.']\n",
      "06/29/2022 08:17:08 - INFO - __main__ -   Epoch: 136 | Batch: 4800/10001 (48%) | G Loss: 3.213961 | C Loss: -0.770427\n",
      "06/29/2022 08:17:08 - INFO - __main__ -   Text: ['There is a separatist culture living in Kenya.']\n",
      "06/29/2022 08:17:09 - INFO - __main__ -   Epoch: 136 | Batch: 5400/10001 (54%) | G Loss: 3.156877 | C Loss: -0.541889\n",
      "06/29/2022 08:17:09 - INFO - __main__ -   Text: ['This would help the owners of the money to find it.']\n",
      "06/29/2022 08:17:10 - INFO - __main__ -   Epoch: 136 | Batch: 6000/10001 (60%) | G Loss: 2.560388 | C Loss: -0.547555\n",
      "06/29/2022 08:17:10 - INFO - __main__ -   Text: ['satiricians call it profitable\".']\n",
      "06/29/2022 08:17:11 - INFO - __main__ -   Epoch: 136 | Batch: 6600/10001 (66%) | G Loss: 2.497109 | C Loss: -0.512867\n",
      "06/29/2022 08:17:11 - INFO - __main__ -   Text: ['They are working out the theory and procedures of mental health research.']\n",
      "06/29/2022 08:17:12 - INFO - __main__ -   Epoch: 136 | Batch: 7200/10001 (72%) | G Loss: 2.682709 | C Loss: -0.503187\n",
      "06/29/2022 08:17:12 - INFO - __main__ -   Text: ['Group philosophies are the common values of many British societies.']\n",
      "06/29/2022 08:17:13 - INFO - __main__ -   Epoch: 136 | Batch: 7800/10001 (78%) | G Loss: 3.155383 | C Loss: -0.499333\n",
      "06/29/2022 08:17:13 - INFO - __main__ -   Text: ['As well as being a social experience, it is also a birthday card.']\n",
      "06/29/2022 08:17:14 - INFO - __main__ -   Epoch: 136 | Batch: 8400/10001 (84%) | G Loss: 3.097620 | C Loss: -0.744723\n",
      "06/29/2022 08:17:15 - INFO - __main__ -   Text: ['The letter recommends that Charles take the fight to the corporate groups in college.']\n",
      "06/29/2022 08:17:16 - INFO - __main__ -   Epoch: 136 | Batch: 9000/10001 (90%) | G Loss: 2.617366 | C Loss: -0.401491\n",
      "06/29/2022 08:17:16 - INFO - __main__ -   Text: ['If extinction in the equilibrium increases \"number of reptiles per moleum\" and full-borders.']\n",
      "06/29/2022 08:17:17 - INFO - __main__ -   Epoch: 136 | Batch: 9600/10001 (96%) | G Loss: 2.562868 | C Loss: -0.452642\n",
      "06/29/2022 08:17:17 - INFO - __main__ -   Text: ['If access to knowledge locally declines and mass leaves needed, the technology magnifies.']\n",
      "06/29/2022 08:17:17 - INFO - __main__ -   * (Train) Epoch: 136 | G Loss: 2.7227 | C Loss: -0.4947 | Updates G: 53 | Updates C: 780\n",
      "06/29/2022 08:17:27 - INFO - __main__ -   Bleu-2:0.211 | B-Bleu-2:0.245\n",
      "06/29/2022 08:17:27 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45612982019534665\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 137 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:20:54 - INFO - __main__ -   Epoch: 137 | Batch: 0/10001 (0%) | G Loss: 2.658368 | C Loss: -0.790068\n",
      "06/29/2022 08:20:54 - INFO - __main__ -   Text: ['I think that interest of the page may even be linked back to [my blog].']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.010\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:20:55 - INFO - __main__ -   Epoch: 137 | Batch: 600/10001 (6%) | G Loss: 2.431082 | C Loss: -0.531864\n",
      "06/29/2022 08:20:55 - INFO - __main__ -   Text: ['Kopardenians work on a wafer bond for a handful of minutes.']\n",
      "06/29/2022 08:20:56 - INFO - __main__ -   Epoch: 137 | Batch: 1200/10001 (12%) | G Loss: 2.559804 | C Loss: -0.669430\n",
      "06/29/2022 08:20:56 - INFO - __main__ -   Text: ['\", \"Getski\" \"\"\\'S\" .']\n",
      "06/29/2022 08:20:57 - INFO - __main__ -   Epoch: 137 | Batch: 1800/10001 (18%) | G Loss: 2.946828 | C Loss: -0.573694\n",
      "06/29/2022 08:20:57 - INFO - __main__ -   Text: ['Antonio may eventually lose it to Frisian Airways instead Prize still is also not guaranteed.']\n",
      "06/29/2022 08:20:58 - INFO - __main__ -   Epoch: 137 | Batch: 2400/10001 (24%) | G Loss: 3.172964 | C Loss: -0.502091\n",
      "06/29/2022 08:20:59 - INFO - __main__ -   Text: ['Even a ray for gym !']\n",
      "06/29/2022 08:21:00 - INFO - __main__ -   Epoch: 137 | Batch: 3000/10001 (30%) | G Loss: 3.261311 | C Loss: -0.536067\n",
      "06/29/2022 08:21:00 - INFO - __main__ -   Text: [\"Finn's an oddball.\"]\n",
      "06/29/2022 08:21:01 - INFO - __main__ -   Epoch: 137 | Batch: 3600/10001 (36%) | G Loss: 3.278057 | C Loss: -0.638659\n",
      "06/29/2022 08:21:01 - INFO - __main__ -   Text: ['Application should be given to scripter or the suntanm.']\n",
      "06/29/2022 08:21:02 - INFO - __main__ -   Epoch: 137 | Batch: 4200/10001 (42%) | G Loss: 2.629610 | C Loss: -0.511643\n",
      "06/29/2022 08:21:02 - INFO - __main__ -   Text: ['R. .']\n",
      "06/29/2022 08:21:03 - INFO - __main__ -   Epoch: 137 | Batch: 4800/10001 (48%) | G Loss: 2.222226 | C Loss: -0.221169\n",
      "06/29/2022 08:21:03 - INFO - __main__ -   Text: ['It tells the story of a guy who reads all that the internet.']\n",
      "06/29/2022 08:21:04 - INFO - __main__ -   Epoch: 137 | Batch: 5400/10001 (54%) | G Loss: 2.174039 | C Loss: -0.384088\n",
      "06/29/2022 08:21:04 - INFO - __main__ -   Text: ['He can say, \"Anybody who ever climbs the ladder gets the same wrong.\"']\n",
      "06/29/2022 08:21:05 - INFO - __main__ -   Epoch: 137 | Batch: 6000/10001 (60%) | G Loss: 2.967130 | C Loss: -0.562260\n",
      "06/29/2022 08:21:05 - INFO - __main__ -   Text: ['\"If I\\'m going to be honest, that\\'s what I want.\"']\n",
      "06/29/2022 08:21:06 - INFO - __main__ -   Epoch: 137 | Batch: 6600/10001 (66%) | G Loss: 3.130452 | C Loss: -0.614633\n",
      "06/29/2022 08:21:06 - INFO - __main__ -   Text: ['The fourth person to win the Tag Team Challenge is USA Basketball.']\n",
      "06/29/2022 08:21:07 - INFO - __main__ -   Epoch: 137 | Batch: 7200/10001 (72%) | G Loss: 3.301669 | C Loss: -0.536898\n",
      "06/29/2022 08:21:07 - INFO - __main__ -   Text: ['It\\'s fruitless to say so.\"']\n",
      "06/29/2022 08:21:08 - INFO - __main__ -   Epoch: 137 | Batch: 7800/10001 (78%) | G Loss: 2.805660 | C Loss: -0.349126\n",
      "06/29/2022 08:21:08 - INFO - __main__ -   Text: [\"Aimeridge's Classic above all else is the ultimate XML tool.\"]\n",
      "06/29/2022 08:21:09 - INFO - __main__ -   Epoch: 137 | Batch: 8400/10001 (84%) | G Loss: 2.942106 | C Loss: -0.503075\n",
      "06/29/2022 08:21:09 - INFO - __main__ -   Text: ['']\n",
      "06/29/2022 08:21:10 - INFO - __main__ -   Epoch: 137 | Batch: 9000/10001 (90%) | G Loss: 2.662176 | C Loss: -0.536154\n",
      "06/29/2022 08:21:10 - INFO - __main__ -   Text: ['It is also occasionally reviewed on iMovie.Tim Happy.\"']\n",
      "06/29/2022 08:21:11 - INFO - __main__ -   Epoch: 137 | Batch: 9600/10001 (96%) | G Loss: 2.410551 | C Loss: -0.634255\n",
      "06/29/2022 08:21:12 - INFO - __main__ -   Text: ['If the candidate keeps down the sport, voter high vote.\"']\n",
      "06/29/2022 08:21:12 - INFO - __main__ -   * (Train) Epoch: 137 | G Loss: 2.6815 | C Loss: -0.5048 | Updates G: 42 | Updates C: 791\n",
      "06/29/2022 08:21:21 - INFO - __main__ -   Bleu-2:0.181 | B-Bleu-2:0.219\n",
      "06/29/2022 08:21:21 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_12.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39942772881231714\n",
      "Train file used is number 12\n",
      "../../yahoo/subdivided_large/train_12.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 138 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:24:49 - INFO - __main__ -   Epoch: 138 | Batch: 0/10001 (0%) | G Loss: 2.509542 | C Loss: -0.672602\n",
      "06/29/2022 08:24:49 - INFO - __main__ -   Text: ['It is generally backwards to distinguish such a person from a followier.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.976\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:24:50 - INFO - __main__ -   Epoch: 138 | Batch: 600/10001 (6%) | G Loss: 2.502042 | C Loss: -0.267910\n",
      "06/29/2022 08:24:50 - INFO - __main__ -   Text: ['Nothing bad is going on here but you\\'ve got to show them how to do business\".']\n",
      "06/29/2022 08:24:51 - INFO - __main__ -   Epoch: 138 | Batch: 1200/10001 (12%) | G Loss: 2.942123 | C Loss: -0.487492\n",
      "06/29/2022 08:24:51 - INFO - __main__ -   Text: ['Guitar is often talked about the song being about him.']\n",
      "06/29/2022 08:24:52 - INFO - __main__ -   Epoch: 138 | Batch: 1800/10001 (18%) | G Loss: 3.019348 | C Loss: -0.632358\n",
      "06/29/2022 08:24:52 - INFO - __main__ -   Text: ['Winding guidelines are specific to winding.']\n",
      "06/29/2022 08:24:53 - INFO - __main__ -   Epoch: 138 | Batch: 2400/10001 (24%) | G Loss: 3.053391 | C Loss: -0.750207\n",
      "06/29/2022 08:24:53 - INFO - __main__ -   Text: ['This means that a fifth of even the most odious or degenerated traveler will never be found.']\n",
      "06/29/2022 08:24:54 - INFO - __main__ -   Epoch: 138 | Batch: 3000/10001 (30%) | G Loss: 2.186666 | C Loss: -0.447869\n",
      "06/29/2022 08:24:55 - INFO - __main__ -   Text: ['Level 3 rushing bombers are almost too fast.']\n",
      "06/29/2022 08:24:56 - INFO - __main__ -   Epoch: 138 | Batch: 3600/10001 (36%) | G Loss: 3.248621 | C Loss: -0.680160\n",
      "06/29/2022 08:24:56 - INFO - __main__ -   Text: [\"He doesn't stand for followers initially, but goes on taking them to national.\"]\n",
      "06/29/2022 08:24:57 - INFO - __main__ -   Epoch: 138 | Batch: 4200/10001 (42%) | G Loss: 3.481217 | C Loss: -0.800230\n",
      "06/29/2022 08:24:57 - INFO - __main__ -   Text: ['is his cliché story for those drawn to comedy at the start of reality TV.']\n",
      "06/29/2022 08:24:58 - INFO - __main__ -   Epoch: 138 | Batch: 4800/10001 (48%) | G Loss: 3.061698 | C Loss: -0.572492\n",
      "06/29/2022 08:24:58 - INFO - __main__ -   Text: ['In modern days, Death To Fight is described as \"... Madness Through War.\"']\n",
      "06/29/2022 08:24:59 - INFO - __main__ -   Epoch: 138 | Batch: 5400/10001 (54%) | G Loss: 2.236081 | C Loss: -0.417031\n",
      "06/29/2022 08:24:59 - INFO - __main__ -   Text: ['If Nin,\" Brown said, \"he\\'s honest.\"']\n",
      "06/29/2022 08:25:00 - INFO - __main__ -   Epoch: 138 | Batch: 6000/10001 (60%) | G Loss: 1.858299 | C Loss: -0.614338\n",
      "06/29/2022 08:25:00 - INFO - __main__ -   Text: ['The South by South Show is about cricket match The CW Annihilated 6.']\n",
      "06/29/2022 08:25:01 - INFO - __main__ -   Epoch: 138 | Batch: 6600/10001 (66%) | G Loss: 2.817038 | C Loss: -0.889237\n",
      "06/29/2022 08:25:01 - INFO - __main__ -   Text: ['It has received several prestigious awards such as The Husband Game and Degree to Help Men <PAD>s.']\n",
      "06/29/2022 08:25:02 - INFO - __main__ -   Epoch: 138 | Batch: 7200/10001 (72%) | G Loss: 3.494611 | C Loss: -1.066358\n",
      "06/29/2022 08:25:02 - INFO - __main__ -   Text: ['It has another chapter called \", that captures Japanese sales.']\n",
      "06/29/2022 08:25:03 - INFO - __main__ -   Epoch: 138 | Batch: 7800/10001 (78%) | G Loss: 2.459539 | C Loss: -0.305213\n",
      "06/29/2022 08:25:03 - INFO - __main__ -   Text: ['Its cultural existence seems to be brutally mocked by people from Vancouver.']\n",
      "06/29/2022 08:25:04 - INFO - __main__ -   Epoch: 138 | Batch: 8400/10001 (84%) | G Loss: 2.146240 | C Loss: -0.301214\n",
      "06/29/2022 08:25:05 - INFO - __main__ -   Text: ['Studies indicate that men of reproductive age have at least part in the invasion of female genitalia.']\n",
      "06/29/2022 08:25:06 - INFO - __main__ -   Epoch: 138 | Batch: 9000/10001 (90%) | G Loss: 2.596511 | C Loss: -0.455898\n",
      "06/29/2022 08:25:06 - INFO - __main__ -   Text: ['The coder.']\n",
      "06/29/2022 08:25:07 - INFO - __main__ -   Epoch: 138 | Batch: 9600/10001 (96%) | G Loss: 3.312029 | C Loss: -0.618632\n",
      "06/29/2022 08:25:07 - INFO - __main__ -   Text: [\"As exotic as it sounds, Canning's laboratory is still in it.\"]\n",
      "06/29/2022 08:25:07 - INFO - __main__ -   * (Train) Epoch: 138 | G Loss: 2.6170 | C Loss: -0.5063 | Updates G: 58 | Updates C: 775\n",
      "06/29/2022 08:25:16 - INFO - __main__ -   Bleu-2:0.206 | B-Bleu-2:0.249\n",
      "06/29/2022 08:25:16 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45494428971995693\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 139 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:28:49 - INFO - __main__ -   Epoch: 139 | Batch: 0/10001 (0%) | G Loss: 3.532138 | C Loss: -0.230785\n",
      "06/29/2022 08:28:49 - INFO - __main__ -   Text: ['Their mission is to find early modern terrorists.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 4.028\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:28:50 - INFO - __main__ -   Epoch: 139 | Batch: 600/10001 (6%) | G Loss: 2.893330 | C Loss: -0.521597\n",
      "06/29/2022 08:28:50 - INFO - __main__ -   Text: ['\"Get Food Shots\" is the easiest way to get a buy .']\n",
      "06/29/2022 08:28:51 - INFO - __main__ -   Epoch: 139 | Batch: 1200/10001 (12%) | G Loss: 2.432249 | C Loss: -0.960300\n",
      "06/29/2022 08:28:51 - INFO - __main__ -   Text: ['Pretty much any nice person or outdoors man can be called Cool!']\n",
      "06/29/2022 08:28:52 - INFO - __main__ -   Epoch: 139 | Batch: 1800/10001 (18%) | G Loss: 2.040080 | C Loss: -0.237943\n",
      "06/29/2022 08:28:53 - INFO - __main__ -   Text: [\"or maybe it's a reflection of our humanity.\"]\n",
      "06/29/2022 08:28:54 - INFO - __main__ -   Epoch: 139 | Batch: 2400/10001 (24%) | G Loss: 2.185259 | C Loss: -0.369541\n",
      "06/29/2022 08:28:54 - INFO - __main__ -   Text: ['This person who puts out a streaming video doesn\\'t know where to start.\"']\n",
      "06/29/2022 08:28:55 - INFO - __main__ -   Epoch: 139 | Batch: 3000/10001 (30%) | G Loss: 2.381103 | C Loss: -0.350595\n",
      "06/29/2022 08:28:55 - INFO - __main__ -   Text: ['The plant is classified as Model.']\n",
      "06/29/2022 08:28:56 - INFO - __main__ -   Epoch: 139 | Batch: 3600/10001 (36%) | G Loss: 2.778174 | C Loss: -0.539873\n",
      "06/29/2022 08:28:56 - INFO - __main__ -   Text: ['Maybe the best way to decide whether something is hot or cold.']\n",
      "06/29/2022 08:28:57 - INFO - __main__ -   Epoch: 139 | Batch: 4200/10001 (42%) | G Loss: 3.095581 | C Loss: -0.402108\n",
      "06/29/2022 08:28:57 - INFO - __main__ -   Text: ['Holden fills with petrol and drinks it every time a competitor ends results.']\n",
      "06/29/2022 08:28:58 - INFO - __main__ -   Epoch: 139 | Batch: 4800/10001 (48%) | G Loss: 3.062682 | C Loss: -0.495711\n",
      "06/29/2022 08:28:58 - INFO - __main__ -   Text: ['I have books.\"']\n",
      "06/29/2022 08:28:59 - INFO - __main__ -   Epoch: 139 | Batch: 5400/10001 (54%) | G Loss: 2.674946 | C Loss: -0.542756\n",
      "06/29/2022 08:28:59 - INFO - __main__ -   Text: ['It is mentioned every year in the following world order: Brabak (India).']\n",
      "06/29/2022 08:29:00 - INFO - __main__ -   Epoch: 139 | Batch: 6000/10001 (60%) | G Loss: 2.758989 | C Loss: -0.579064\n",
      "06/29/2022 08:29:00 - INFO - __main__ -   Text: ['Pippens have more power.\"']\n",
      "06/29/2022 08:29:01 - INFO - __main__ -   Epoch: 139 | Batch: 6600/10001 (66%) | G Loss: 2.557126 | C Loss: -0.465388\n",
      "06/29/2022 08:29:01 - INFO - __main__ -   Text: ['It is an aqua shield that catches waterfalls and other Idiot drinking storms.']\n",
      "06/29/2022 08:29:02 - INFO - __main__ -   Epoch: 139 | Batch: 7200/10001 (72%) | G Loss: 2.554300 | C Loss: -0.476645\n",
      "06/29/2022 08:29:02 - INFO - __main__ -   Text: ['Eyewitness Nick Greenwood.']\n",
      "06/29/2022 08:29:03 - INFO - __main__ -   Epoch: 139 | Batch: 7800/10001 (78%) | G Loss: 2.988428 | C Loss: -0.342114\n",
      "06/29/2022 08:29:03 - INFO - __main__ -   Text: [\"Like how darkness lives, it feels like a parent's duty to title a child.\"]\n",
      "06/29/2022 08:29:04 - INFO - __main__ -   Epoch: 139 | Batch: 8400/10001 (84%) | G Loss: 2.620993 | C Loss: -0.621375\n",
      "06/29/2022 08:29:04 - INFO - __main__ -   Text: ['Dried herbs shall be consumed often with diabetes.']\n",
      "06/29/2022 08:29:05 - INFO - __main__ -   Epoch: 139 | Batch: 9000/10001 (90%) | G Loss: 2.668858 | C Loss: -0.560521\n",
      "06/29/2022 08:29:06 - INFO - __main__ -   Text: ['The Fitrian method of playing is like \"almost dying\", I\\'m guessing.']\n",
      "06/29/2022 08:29:07 - INFO - __main__ -   Epoch: 139 | Batch: 9600/10001 (96%) | G Loss: 2.663818 | C Loss: -0.487992\n",
      "06/29/2022 08:29:07 - INFO - __main__ -   Text: ['The surrealism and mysticism their creators have envied that nature.']\n",
      "06/29/2022 08:29:07 - INFO - __main__ -   * (Train) Epoch: 139 | G Loss: 2.6577 | C Loss: -0.4879 | Updates G: 46 | Updates C: 787\n",
      "06/29/2022 08:29:16 - INFO - __main__ -   Bleu-2:0.192 | B-Bleu-2:0.240\n",
      "06/29/2022 08:29:16 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_14.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4319699201235797\n",
      "Train file used is number 14\n",
      "../../yahoo/subdivided_large/train_14.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 140 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:32:48 - INFO - __main__ -   Epoch: 140 | Batch: 0/10001 (0%) | G Loss: 2.965145 | C Loss: -0.524018\n",
      "06/29/2022 08:32:48 - INFO - __main__ -   Text: ['Robin Money thesis is actually a tax.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.963\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:32:49 - INFO - __main__ -   Epoch: 140 | Batch: 600/10001 (6%) | G Loss: 3.536763 | C Loss: -0.583445\n",
      "06/29/2022 08:32:49 - INFO - __main__ -   Text: ['\"LibertyCons (LCTV :).\"']\n",
      "06/29/2022 08:32:50 - INFO - __main__ -   Epoch: 140 | Batch: 1200/10001 (12%) | G Loss: 3.095428 | C Loss: -0.699108\n",
      "06/29/2022 08:32:50 - INFO - __main__ -   Text: ['Between prekkjacicz.']\n",
      "06/29/2022 08:32:51 - INFO - __main__ -   Epoch: 140 | Batch: 1800/10001 (18%) | G Loss: 2.447706 | C Loss: -0.412427\n",
      "06/29/2022 08:32:51 - INFO - __main__ -   Text: ['Type nominally variable-sized, of course is route writing.']\n",
      "06/29/2022 08:32:52 - INFO - __main__ -   Epoch: 140 | Batch: 2400/10001 (24%) | G Loss: 2.188501 | C Loss: -0.377026\n",
      "06/29/2022 08:32:52 - INFO - __main__ -   Text: ['This mode is opposed to knowledge itself, but can also inform philosophical thought.']\n",
      "06/29/2022 08:32:53 - INFO - __main__ -   Epoch: 140 | Batch: 3000/10001 (30%) | G Loss: 2.955894 | C Loss: -0.485487\n",
      "06/29/2022 08:32:54 - INFO - __main__ -   Text: ['His politics are all scattered and open right from the heart.']\n",
      "06/29/2022 08:32:55 - INFO - __main__ -   Epoch: 140 | Batch: 3600/10001 (36%) | G Loss: 3.455414 | C Loss: -0.666522\n",
      "06/29/2022 08:32:55 - INFO - __main__ -   Text: ['Zen is a trip through social understanding.']\n",
      "06/29/2022 08:32:56 - INFO - __main__ -   Epoch: 140 | Batch: 4200/10001 (42%) | G Loss: 3.121148 | C Loss: -0.271945\n",
      "06/29/2022 08:32:56 - INFO - __main__ -   Text: ['\"Peeking at the Tree from out the womb.\"']\n",
      "06/29/2022 08:32:57 - INFO - __main__ -   Epoch: 140 | Batch: 4800/10001 (48%) | G Loss: 2.728035 | C Loss: -0.611934\n",
      "06/29/2022 08:32:57 - INFO - __main__ -   Text: ['It now repeats the time shown above from ~spr.']\n",
      "06/29/2022 08:32:58 - INFO - __main__ -   Epoch: 140 | Batch: 5400/10001 (54%) | G Loss: 2.630948 | C Loss: -0.569606\n",
      "06/29/2022 08:32:58 - INFO - __main__ -   Text: ['An inquisitive consultant is concerned with tragic consequences of his disobedience.']\n",
      "06/29/2022 08:32:59 - INFO - __main__ -   Epoch: 140 | Batch: 6000/10001 (60%) | G Loss: 2.431614 | C Loss: -0.431787\n",
      "06/29/2022 08:32:59 - INFO - __main__ -   Text: ['Rainbow Bludgeon 0).']\n",
      "06/29/2022 08:33:00 - INFO - __main__ -   Epoch: 140 | Batch: 6600/10001 (66%) | G Loss: 2.340879 | C Loss: -0.498270\n",
      "06/29/2022 08:33:00 - INFO - __main__ -   Text: [\"A disease can affect a woman's health.\"]\n",
      "06/29/2022 08:33:01 - INFO - __main__ -   Epoch: 140 | Batch: 7200/10001 (72%) | G Loss: 2.748600 | C Loss: -0.418820\n",
      "06/29/2022 08:33:01 - INFO - __main__ -   Text: ['Fact check it is!']\n",
      "06/29/2022 08:33:02 - INFO - __main__ -   Epoch: 140 | Batch: 7800/10001 (78%) | G Loss: 3.024948 | C Loss: -0.462658\n",
      "06/29/2022 08:33:02 - INFO - __main__ -   Text: ['Able to be a pony talker is heresy.']\n",
      "06/29/2022 08:33:03 - INFO - __main__ -   Epoch: 140 | Batch: 8400/10001 (84%) | G Loss: 2.745975 | C Loss: -0.429437\n",
      "06/29/2022 08:33:03 - INFO - __main__ -   Text: ['\"His pride is over a gunfight with Northern Europe\".']\n",
      "06/29/2022 08:33:04 - INFO - __main__ -   Epoch: 140 | Batch: 9000/10001 (90%) | G Loss: 2.650142 | C Loss: -0.467161\n",
      "06/29/2022 08:33:04 - INFO - __main__ -   Text: ['She is really afraid of doing things that are unfamiliar to people in public.']\n",
      "06/29/2022 08:33:05 - INFO - __main__ -   Epoch: 140 | Batch: 9600/10001 (96%) | G Loss: 2.996827 | C Loss: -0.642484\n",
      "06/29/2022 08:33:05 - INFO - __main__ -   Text: ['The sources are listed below.']\n",
      "06/29/2022 08:33:06 - INFO - __main__ -   * (Train) Epoch: 140 | G Loss: 2.7302 | C Loss: -0.4837 | Updates G: 43 | Updates C: 790\n",
      "06/29/2022 08:33:15 - INFO - __main__ -   Bleu-2:0.196 | B-Bleu-2:0.253\n",
      "06/29/2022 08:33:15 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44878187633363126\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 141 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:36:45 - INFO - __main__ -   Epoch: 141 | Batch: 0/10001 (0%) | G Loss: 2.896787 | C Loss: -0.536526\n",
      "06/29/2022 08:36:45 - INFO - __main__ -   Text: ['They are basically the opposite neater than ordinary.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.914\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:36:46 - INFO - __main__ -   Epoch: 141 | Batch: 600/10001 (6%) | G Loss: 2.640823 | C Loss: -0.477554\n",
      "06/29/2022 08:36:46 - INFO - __main__ -   Text: ['Her hobbies are Ampaches and Magic.']\n",
      "06/29/2022 08:36:47 - INFO - __main__ -   Epoch: 141 | Batch: 1200/10001 (12%) | G Loss: 2.719639 | C Loss: -0.471297\n",
      "06/29/2022 08:36:48 - INFO - __main__ -   Text: ['\"AGU-Ires mushrooms\" can detect incoming 1,000 foot projectiles.']\n",
      "06/29/2022 08:36:49 - INFO - __main__ -   Epoch: 141 | Batch: 1800/10001 (18%) | G Loss: 2.862560 | C Loss: -0.554616\n",
      "06/29/2022 08:36:49 - INFO - __main__ -   Text: ['Dolce is interested in the meaning\", \"casio .']\n",
      "06/29/2022 08:36:50 - INFO - __main__ -   Epoch: 141 | Batch: 2400/10001 (24%) | G Loss: 2.648039 | C Loss: -0.259362\n",
      "06/29/2022 08:36:50 - INFO - __main__ -   Text: ['IRS rules have same-sex marriage.']\n",
      "06/29/2022 08:36:51 - INFO - __main__ -   Epoch: 141 | Batch: 3000/10001 (30%) | G Loss: 2.689205 | C Loss: -0.485395\n",
      "06/29/2022 08:36:51 - INFO - __main__ -   Text: ['Backings (including Aussie']\n",
      "06/29/2022 08:36:52 - INFO - __main__ -   Epoch: 141 | Batch: 3600/10001 (36%) | G Loss: 2.972909 | C Loss: -0.609840\n",
      "06/29/2022 08:36:52 - INFO - __main__ -   Text: ['He is described as having a fairly comfortable head.']\n",
      "06/29/2022 08:36:53 - INFO - __main__ -   Epoch: 141 | Batch: 4200/10001 (42%) | G Loss: 3.104859 | C Loss: -0.505089\n",
      "06/29/2022 08:36:53 - INFO - __main__ -   Text: ['There are a few rumours here that Abigail Saratham is also on the team.']\n",
      "06/29/2022 08:36:54 - INFO - __main__ -   Epoch: 141 | Batch: 4800/10001 (48%) | G Loss: 3.097398 | C Loss: -0.460428\n",
      "06/29/2022 08:36:54 - INFO - __main__ -   Text: ['In June 2007 he has also been a popular \"Museum News\".']\n",
      "06/29/2022 08:36:55 - INFO - __main__ -   Epoch: 141 | Batch: 5400/10001 (54%) | G Loss: 2.978702 | C Loss: -0.537562\n",
      "06/29/2022 08:36:55 - INFO - __main__ -   Text: ['Alto-tuned driveguns.']\n",
      "06/29/2022 08:36:56 - INFO - __main__ -   Epoch: 141 | Batch: 6000/10001 (60%) | G Loss: 2.714004 | C Loss: -0.336697\n",
      "06/29/2022 08:36:56 - INFO - __main__ -   Text: ['He goes with me and says \"Christina\".']\n",
      "06/29/2022 08:36:57 - INFO - __main__ -   Epoch: 141 | Batch: 6600/10001 (66%) | G Loss: 3.233393 | C Loss: -0.537638\n",
      "06/29/2022 08:36:57 - INFO - __main__ -   Text: ['The #1 spot to listen to is \"Periscope.\"']\n",
      "06/29/2022 08:36:58 - INFO - __main__ -   Epoch: 141 | Batch: 7200/10001 (72%) | G Loss: 2.603687 | C Loss: -0.492523\n",
      "06/29/2022 08:36:58 - INFO - __main__ -   Text: ['The most obvious question in a presidential debate is \"\"\".']\n",
      "06/29/2022 08:36:59 - INFO - __main__ -   Epoch: 141 | Batch: 7800/10001 (78%) | G Loss: 2.796523 | C Loss: -0.448283\n",
      "06/29/2022 08:37:00 - INFO - __main__ -   Text: ['Arna can only be changed by offering mists\".']\n",
      "06/29/2022 08:37:01 - INFO - __main__ -   Epoch: 141 | Batch: 8400/10001 (84%) | G Loss: 2.640065 | C Loss: -1.015144\n",
      "06/29/2022 08:37:01 - INFO - __main__ -   Text: ['In answer boy no___.\"']\n",
      "06/29/2022 08:37:02 - INFO - __main__ -   Epoch: 141 | Batch: 9000/10001 (90%) | G Loss: 2.451215 | C Loss: -0.491054\n",
      "06/29/2022 08:37:02 - INFO - __main__ -   Text: ['It just has a very good grass score.']\n",
      "06/29/2022 08:37:03 - INFO - __main__ -   Epoch: 141 | Batch: 9600/10001 (96%) | G Loss: 2.646828 | C Loss: -0.496764\n",
      "06/29/2022 08:37:03 - INFO - __main__ -   Text: ['Digital Systems Production teaches with StringPad.']\n",
      "06/29/2022 08:37:03 - INFO - __main__ -   * (Train) Epoch: 141 | G Loss: 2.7649 | C Loss: -0.4926 | Updates G: 35 | Updates C: 798\n",
      "06/29/2022 08:37:12 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.245\n",
      "06/29/2022 08:37:12 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44498995522354945\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 142 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:15.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:31.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:47.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:04.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:21\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:40:33 - INFO - __main__ -   Epoch: 142 | Batch: 0/10001 (0%) | G Loss: 2.604622 | C Loss: -0.568121\n",
      "06/29/2022 08:40:34 - INFO - __main__ -   Text: ['Frankly, people arguing this are old school.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.914\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:40:35 - INFO - __main__ -   Epoch: 142 | Batch: 600/10001 (6%) | G Loss: 2.764355 | C Loss: -0.443845\n",
      "06/29/2022 08:40:35 - INFO - __main__ -   Text: ['This is probably number one on the list.']\n",
      "06/29/2022 08:40:36 - INFO - __main__ -   Epoch: 142 | Batch: 1200/10001 (12%) | G Loss: 3.063039 | C Loss: -0.458516\n",
      "06/29/2022 08:40:36 - INFO - __main__ -   Text: ['This might be:']\n",
      "06/29/2022 08:40:37 - INFO - __main__ -   Epoch: 142 | Batch: 1800/10001 (18%) | G Loss: 2.952513 | C Loss: -0.469279\n",
      "06/29/2022 08:40:37 - INFO - __main__ -   Text: ['Baender Ranger has a regular alberting beam.']\n",
      "06/29/2022 08:40:38 - INFO - __main__ -   Epoch: 142 | Batch: 2400/10001 (24%) | G Loss: 2.945171 | C Loss: -0.563613\n",
      "06/29/2022 08:40:38 - INFO - __main__ -   Text: ['Empire can be very very different than it is found in other television.']\n",
      "06/29/2022 08:40:39 - INFO - __main__ -   Epoch: 142 | Batch: 3000/10001 (30%) | G Loss: 2.819536 | C Loss: -0.511263\n",
      "06/29/2022 08:40:39 - INFO - __main__ -   Text: ['Will I not be able to take Lobock?']\n",
      "06/29/2022 08:40:40 - INFO - __main__ -   Epoch: 142 | Batch: 3600/10001 (36%) | G Loss: 2.820681 | C Loss: -0.508954\n",
      "06/29/2022 08:40:40 - INFO - __main__ -   Text: ['This concept has implications in drugology.\"']\n",
      "06/29/2022 08:40:41 - INFO - __main__ -   Epoch: 142 | Batch: 4200/10001 (42%) | G Loss: 2.747952 | C Loss: -0.605609\n",
      "06/29/2022 08:40:41 - INFO - __main__ -   Text: ['Comic Supplies make up a significant portion of all the robbers.']\n",
      "06/29/2022 08:40:42 - INFO - __main__ -   Epoch: 142 | Batch: 4800/10001 (48%) | G Loss: 2.791236 | C Loss: -0.787972\n",
      "06/29/2022 08:40:42 - INFO - __main__ -   Text: ['It was his lastÂ show!']\n",
      "06/29/2022 08:40:43 - INFO - __main__ -   Epoch: 142 | Batch: 5400/10001 (54%) | G Loss: 2.383543 | C Loss: -0.412877\n",
      "06/29/2022 08:40:43 - INFO - __main__ -   Text: ['He faces an election as a commander.']\n",
      "06/29/2022 08:40:44 - INFO - __main__ -   Epoch: 142 | Batch: 6000/10001 (60%) | G Loss: 2.380774 | C Loss: -0.392616\n",
      "06/29/2022 08:40:44 - INFO - __main__ -   Text: [\"He uses 'you' a lot.'\"]\n",
      "06/29/2022 08:40:45 - INFO - __main__ -   Epoch: 142 | Batch: 6600/10001 (66%) | G Loss: 2.521838 | C Loss: -0.652667\n",
      "06/29/2022 08:40:45 - INFO - __main__ -   Text: ['Batsuit!\".']\n",
      "06/29/2022 08:40:46 - INFO - __main__ -   Epoch: 142 | Batch: 7200/10001 (72%) | G Loss: 3.353503 | C Loss: -0.479169\n",
      "06/29/2022 08:40:46 - INFO - __main__ -   Text: ['This is true of many high school students: These are the people who want to be a girl.']\n",
      "06/29/2022 08:40:47 - INFO - __main__ -   Epoch: 142 | Batch: 7800/10001 (78%) | G Loss: 3.577364 | C Loss: -0.611356\n",
      "06/29/2022 08:40:47 - INFO - __main__ -   Text: ['It is always not with convenience.\"\"']\n",
      "06/29/2022 08:40:48 - INFO - __main__ -   Epoch: 142 | Batch: 8400/10001 (84%) | G Loss: 3.620896 | C Loss: -0.439389\n",
      "06/29/2022 08:40:49 - INFO - __main__ -   Text: ['It is connecting the KCON aka Atlantadic.']\n",
      "06/29/2022 08:40:50 - INFO - __main__ -   Epoch: 142 | Batch: 9000/10001 (90%) | G Loss: 2.443227 | C Loss: -0.452762\n",
      "06/29/2022 08:40:50 - INFO - __main__ -   Text: ['it is well known that he occasionally fartes highly the mother of all dogs.']\n",
      "06/29/2022 08:40:51 - INFO - __main__ -   Epoch: 142 | Batch: 9600/10001 (96%) | G Loss: 2.362083 | C Loss: -0.445622\n",
      "06/29/2022 08:40:51 - INFO - __main__ -   Text: ['A single cell hormone does not produce an elongated growth hormone.']\n",
      "06/29/2022 08:40:51 - INFO - __main__ -   * (Train) Epoch: 142 | G Loss: 2.7914 | C Loss: -0.4930 | Updates G: 41 | Updates C: 792\n",
      "06/29/2022 08:41:00 - INFO - __main__ -   Bleu-2:0.197 | B-Bleu-2:0.228\n",
      "06/29/2022 08:41:00 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4253057668601468\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 143 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:12.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:30.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:48.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:06.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:42.\n",
      "  Batch   100  of    120.    Elapsed: 0:03:00.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:18.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:48:29 - INFO - __main__ -   Epoch: 144 | Batch: 0/10001 (0%) | G Loss: 3.102794 | C Loss: -0.480521\n",
      "06/29/2022 08:48:29 - INFO - __main__ -   Text: ['At the end, \"however I want to stand, I will.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.981\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:48:30 - INFO - __main__ -   Epoch: 144 | Batch: 600/10001 (6%) | G Loss: 2.833158 | C Loss: -0.581584\n",
      "06/29/2022 08:48:30 - INFO - __main__ -   Text: ['Covert pins may refer to:']\n",
      "06/29/2022 08:48:31 - INFO - __main__ -   Epoch: 144 | Batch: 1200/10001 (12%) | G Loss: 2.232267 | C Loss: -0.597651\n",
      "06/29/2022 08:48:31 - INFO - __main__ -   Text: ['There are some concerns that domestic pressures will hurt Ukip if they could win elections across Europe.']\n",
      "06/29/2022 08:48:32 - INFO - __main__ -   Epoch: 144 | Batch: 1800/10001 (18%) | G Loss: 2.088247 | C Loss: -0.347766\n",
      "06/29/2022 08:48:32 - INFO - __main__ -   Text: ['Finally he gets 4: Premium Master.']\n",
      "06/29/2022 08:48:33 - INFO - __main__ -   Epoch: 144 | Batch: 2400/10001 (24%) | G Loss: 2.466227 | C Loss: -0.418551\n",
      "06/29/2022 08:48:33 - INFO - __main__ -   Text: ['A world inhabited by armies.']\n",
      "06/29/2022 08:48:34 - INFO - __main__ -   Epoch: 144 | Batch: 3000/10001 (30%) | G Loss: 2.813759 | C Loss: -0.566141\n",
      "06/29/2022 08:48:34 - INFO - __main__ -   Text: ['Safety training is another standard AICF recommendation that dates from 1981.']\n",
      "06/29/2022 08:48:35 - INFO - __main__ -   Epoch: 144 | Batch: 3600/10001 (36%) | G Loss: 2.851954 | C Loss: -0.500512\n",
      "06/29/2022 08:48:35 - INFO - __main__ -   Text: ['Heavenly Kind is a Sin Shelter.']\n",
      "06/29/2022 08:48:36 - INFO - __main__ -   Epoch: 144 | Batch: 4200/10001 (42%) | G Loss: 2.704133 | C Loss: -0.382443\n",
      "06/29/2022 08:48:36 - INFO - __main__ -   Text: ['\"You just can\\'t blow them off\".']\n",
      "06/29/2022 08:48:37 - INFO - __main__ -   Epoch: 144 | Batch: 4800/10001 (48%) | G Loss: 2.366611 | C Loss: -0.478667\n",
      "06/29/2022 08:48:37 - INFO - __main__ -   Text: ['A mathematician will always have a very brief description before issuing a single theorem.']\n",
      "06/29/2022 08:48:38 - INFO - __main__ -   Epoch: 144 | Batch: 5400/10001 (54%) | G Loss: 2.529815 | C Loss: -0.644663\n",
      "06/29/2022 08:48:38 - INFO - __main__ -   Text: ['This is a variation on gravity.']\n",
      "06/29/2022 08:48:39 - INFO - __main__ -   Epoch: 144 | Batch: 6000/10001 (60%) | G Loss: 3.109037 | C Loss: -0.324163\n",
      "06/29/2022 08:48:39 - INFO - __main__ -   Text: ['Like low fatter creatures, the tubes.']\n",
      "06/29/2022 08:48:40 - INFO - __main__ -   Epoch: 144 | Batch: 6600/10001 (66%) | G Loss: 3.298089 | C Loss: -0.565228\n",
      "06/29/2022 08:48:41 - INFO - __main__ -   Text: ['\"Julian\" lemma number 99.']\n",
      "06/29/2022 08:48:42 - INFO - __main__ -   Epoch: 144 | Batch: 7200/10001 (72%) | G Loss: 2.733157 | C Loss: -0.612289\n",
      "06/29/2022 08:48:42 - INFO - __main__ -   Text: ['Not much Java.']\n",
      "06/29/2022 08:48:43 - INFO - __main__ -   Epoch: 144 | Batch: 7800/10001 (78%) | G Loss: 2.629292 | C Loss: -0.302639\n",
      "06/29/2022 08:48:43 - INFO - __main__ -   Text: ['This text!\"']\n",
      "06/29/2022 08:48:44 - INFO - __main__ -   Epoch: 144 | Batch: 8400/10001 (84%) | G Loss: 2.299822 | C Loss: -0.282317\n",
      "06/29/2022 08:48:44 - INFO - __main__ -   Text: ['He may hate me if I hate him.\"']\n",
      "06/29/2022 08:48:45 - INFO - __main__ -   Epoch: 144 | Batch: 9000/10001 (90%) | G Loss: 1.817061 | C Loss: -0.419680\n",
      "06/29/2022 08:48:45 - INFO - __main__ -   Text: ['They are simply trying to kill humans\".']\n",
      "06/29/2022 08:48:46 - INFO - __main__ -   Epoch: 144 | Batch: 9600/10001 (96%) | G Loss: 2.754692 | C Loss: -0.552605\n",
      "06/29/2022 08:48:46 - INFO - __main__ -   Text: ['The one is opened; nevertheless, we can!']\n",
      "06/29/2022 08:48:46 - INFO - __main__ -   * (Train) Epoch: 144 | G Loss: 2.5432 | C Loss: -0.4825 | Updates G: 46 | Updates C: 787\n",
      "06/29/2022 08:48:56 - INFO - __main__ -   Bleu-2:0.189 | B-Bleu-2:0.228\n",
      "06/29/2022 08:48:56 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41650797685726126\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 145 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:52:21 - INFO - __main__ -   Epoch: 145 | Batch: 0/10001 (0%) | G Loss: 3.130046 | C Loss: -0.558232\n",
      "06/29/2022 08:52:21 - INFO - __main__ -   Text: ['Athletes can take advantage of an application fee trail to meet source codes.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.993\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:52:22 - INFO - __main__ -   Epoch: 145 | Batch: 600/10001 (6%) | G Loss: 3.682949 | C Loss: -0.522544\n",
      "06/29/2022 08:52:22 - INFO - __main__ -   Text: ['Another source says everything is legal under the California law.']\n",
      "06/29/2022 08:52:23 - INFO - __main__ -   Epoch: 145 | Batch: 1200/10001 (12%) | G Loss: 3.257909 | C Loss: -0.246452\n",
      "06/29/2022 08:52:23 - INFO - __main__ -   Text: ['However, dannuri that somebody is floating upside down.']\n",
      "06/29/2022 08:52:24 - INFO - __main__ -   Epoch: 145 | Batch: 1800/10001 (18%) | G Loss: 2.675632 | C Loss: -0.420471\n",
      "06/29/2022 08:52:24 - INFO - __main__ -   Text: [\"A good comparison is through an episode of the television show 'Swairing'.\"]\n",
      "06/29/2022 08:52:25 - INFO - __main__ -   Epoch: 145 | Batch: 2400/10001 (24%) | G Loss: 2.373932 | C Loss: -0.887740\n",
      "06/29/2022 08:52:26 - INFO - __main__ -   Text: ['He is Leader and the only sensible Wolf.']\n",
      "06/29/2022 08:52:27 - INFO - __main__ -   Epoch: 145 | Batch: 3000/10001 (30%) | G Loss: 2.267912 | C Loss: -0.534406\n",
      "06/29/2022 08:52:27 - INFO - __main__ -   Text: ['This may be seen as anti-Q out of contradiction with what Keynesian classes imply.']\n",
      "06/29/2022 08:52:28 - INFO - __main__ -   Epoch: 145 | Batch: 3600/10001 (36%) | G Loss: 2.587019 | C Loss: -0.500337\n",
      "06/29/2022 08:52:28 - INFO - __main__ -   Text: ['Very little knowledge, I don\\'t know how to answer that question.\"']\n",
      "06/29/2022 08:52:29 - INFO - __main__ -   Epoch: 145 | Batch: 4200/10001 (42%) | G Loss: 3.242216 | C Loss: -0.758831\n",
      "06/29/2022 08:52:29 - INFO - __main__ -   Text: ['The area is awash in coal in the highest quality coal.']\n",
      "06/29/2022 08:52:30 - INFO - __main__ -   Epoch: 145 | Batch: 4800/10001 (48%) | G Loss: 2.970751 | C Loss: -0.336278\n",
      "06/29/2022 08:52:30 - INFO - __main__ -   Text: ['Mediabot ValueWP Mock Apple Edition.']\n",
      "06/29/2022 08:52:31 - INFO - __main__ -   Epoch: 145 | Batch: 5400/10001 (54%) | G Loss: 2.986106 | C Loss: -0.638097\n",
      "06/29/2022 08:52:31 - INFO - __main__ -   Text: ['Snowball is an annoying figure\" ...']\n",
      "06/29/2022 08:52:32 - INFO - __main__ -   Epoch: 145 | Batch: 6000/10001 (60%) | G Loss: 2.620727 | C Loss: -0.496824\n",
      "06/29/2022 08:52:32 - INFO - __main__ -   Text: ['The channel subscribers are shocked as 45% and 50% definitely recommend \"Cal Free News\".']\n",
      "06/29/2022 08:52:33 - INFO - __main__ -   Epoch: 145 | Batch: 6600/10001 (66%) | G Loss: 2.440572 | C Loss: -0.397557\n",
      "06/29/2022 08:52:33 - INFO - __main__ -   Text: ['Special happens to be Private The Horse Private is a natural 1 lift distance runner.']\n",
      "06/29/2022 08:52:34 - INFO - __main__ -   Epoch: 145 | Batch: 7200/10001 (72%) | G Loss: 2.680971 | C Loss: -0.658037\n",
      "06/29/2022 08:52:34 - INFO - __main__ -   Text: [\"He battles John Belmont's brothers on the Ohno Power Rangers.\"]\n",
      "06/29/2022 08:52:35 - INFO - __main__ -   Epoch: 145 | Batch: 7800/10001 (78%) | G Loss: 2.839766 | C Loss: -0.507531\n",
      "06/29/2022 08:52:35 - INFO - __main__ -   Text: ['That is something sublime to them.']\n",
      "06/29/2022 08:52:36 - INFO - __main__ -   Epoch: 145 | Batch: 8400/10001 (84%) | G Loss: 2.672729 | C Loss: -0.621969\n",
      "06/29/2022 08:52:36 - INFO - __main__ -   Text: ['They also have a great sense of humor.']\n",
      "06/29/2022 08:52:37 - INFO - __main__ -   Epoch: 145 | Batch: 9000/10001 (90%) | G Loss: 2.800252 | C Loss: -0.477408\n",
      "06/29/2022 08:52:38 - INFO - __main__ -   Text: ['In addition, Awasan has the ability to subscribe to music via MIDI.']\n",
      "06/29/2022 08:52:39 - INFO - __main__ -   Epoch: 145 | Batch: 9600/10001 (96%) | G Loss: 3.218577 | C Loss: -0.652107\n",
      "06/29/2022 08:52:39 - INFO - __main__ -   Text: ['Defining the name normally refers to a small group of fish.']\n",
      "06/29/2022 08:52:39 - INFO - __main__ -   * (Train) Epoch: 145 | G Loss: 2.7673 | C Loss: -0.4988 | Updates G: 37 | Updates C: 796\n",
      "06/29/2022 08:52:48 - INFO - __main__ -   Bleu-2:0.181 | B-Bleu-2:0.223\n",
      "06/29/2022 08:52:48 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40375584886276555\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 146 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:56:17 - INFO - __main__ -   Epoch: 146 | Batch: 0/10001 (0%) | G Loss: 3.146280 | C Loss: -0.471172\n",
      "06/29/2022 08:56:17 - INFO - __main__ -   Text: ['It is usually Tsipras speak with a neutral accent.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 4.044\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 08:56:18 - INFO - __main__ -   Epoch: 146 | Batch: 600/10001 (6%) | G Loss: 2.830910 | C Loss: -0.465713\n",
      "06/29/2022 08:56:18 - INFO - __main__ -   Text: ['This might be the last time that the American popular classic, \"Billy\\'s law is real law.\"']\n",
      "06/29/2022 08:56:19 - INFO - __main__ -   Epoch: 146 | Batch: 1200/10001 (12%) | G Loss: 3.209009 | C Loss: -0.421016\n",
      "06/29/2022 08:56:19 - INFO - __main__ -   Text: ['\"Are you dating me? <BOS>?! <PAD>!\"']\n",
      "06/29/2022 08:56:20 - INFO - __main__ -   Epoch: 146 | Batch: 1800/10001 (18%) | G Loss: 2.953377 | C Loss: -0.536888\n",
      "06/29/2022 08:56:20 - INFO - __main__ -   Text: ['They have a few books published by the editors of this magazine.']\n",
      "06/29/2022 08:56:21 - INFO - __main__ -   Epoch: 146 | Batch: 2400/10001 (24%) | G Loss: 2.568226 | C Loss: -0.576330\n",
      "06/29/2022 08:56:21 - INFO - __main__ -   Text: ['For more information refer: It is ALSO run by Adafruit. <PAD>.']\n",
      "06/29/2022 08:56:22 - INFO - __main__ -   Epoch: 146 | Batch: 3000/10001 (30%) | G Loss: 2.449390 | C Loss: -0.439931\n",
      "06/29/2022 08:56:22 - INFO - __main__ -   Text: ['per 100×\".']\n",
      "06/29/2022 08:56:23 - INFO - __main__ -   Epoch: 146 | Batch: 3600/10001 (36%) | G Loss: 2.411370 | C Loss: -0.481815\n",
      "06/29/2022 08:56:23 - INFO - __main__ -   Text: ['Finally, Edwin can swallow fire.']\n",
      "06/29/2022 08:56:24 - INFO - __main__ -   Epoch: 146 | Batch: 4200/10001 (42%) | G Loss: 2.595188 | C Loss: -0.334444\n",
      "06/29/2022 08:56:24 - INFO - __main__ -   Text: ['This lotblock implies the test score of \"number.\"']\n",
      "06/29/2022 08:56:25 - INFO - __main__ -   Epoch: 146 | Batch: 4800/10001 (48%) | G Loss: 3.468536 | C Loss: -0.693799\n",
      "06/29/2022 08:56:25 - INFO - __main__ -   Text: ['In theory, SETI could solve this problem.']\n",
      "06/29/2022 08:56:26 - INFO - __main__ -   Epoch: 146 | Batch: 5400/10001 (54%) | G Loss: 3.752001 | C Loss: -0.943722\n",
      "06/29/2022 08:56:26 - INFO - __main__ -   Text: ['All Naguls should emphasize scientific development.']\n",
      "06/29/2022 08:56:27 - INFO - __main__ -   Epoch: 146 | Batch: 6000/10001 (60%) | G Loss: 3.267507 | C Loss: -0.253628\n",
      "06/29/2022 08:56:28 - INFO - __main__ -   Text: ['\"A dance that stops everyone from thinking there\\'s a dancing rule.\"']\n",
      "06/29/2022 08:56:29 - INFO - __main__ -   Epoch: 146 | Batch: 6600/10001 (66%) | G Loss: 2.867215 | C Loss: -0.339809\n",
      "06/29/2022 08:56:29 - INFO - __main__ -   Text: ['Working Projects in Information Science.']\n",
      "06/29/2022 08:56:30 - INFO - __main__ -   Epoch: 146 | Batch: 7200/10001 (72%) | G Loss: 2.685567 | C Loss: -0.350604\n",
      "06/29/2022 08:56:30 - INFO - __main__ -   Text: ['His father tells him that he needs to be with Ricky.']\n",
      "06/29/2022 08:56:31 - INFO - __main__ -   Epoch: 146 | Batch: 7800/10001 (78%) | G Loss: 2.178244 | C Loss: -0.537907\n",
      "06/29/2022 08:56:31 - INFO - __main__ -   Text: ['She excels at her job and both men and women have been known to get drunk.']\n",
      "06/29/2022 08:56:32 - INFO - __main__ -   Epoch: 146 | Batch: 8400/10001 (84%) | G Loss: 2.306297 | C Loss: -0.520359\n",
      "06/29/2022 08:56:32 - INFO - __main__ -   Text: ['There can be several Rabbits laden.']\n",
      "06/29/2022 08:56:33 - INFO - __main__ -   Epoch: 146 | Batch: 9000/10001 (90%) | G Loss: 2.350657 | C Loss: -0.307165\n",
      "06/29/2022 08:56:33 - INFO - __main__ -   Text: ['Catholics agree in his traits.']\n",
      "06/29/2022 08:56:34 - INFO - __main__ -   Epoch: 146 | Batch: 9600/10001 (96%) | G Loss: 2.619134 | C Loss: -0.668245\n",
      "06/29/2022 08:56:34 - INFO - __main__ -   Text: ['Next to the lemen it looks like a funfair.']\n",
      "06/29/2022 08:56:35 - INFO - __main__ -   * (Train) Epoch: 146 | G Loss: 2.7084 | C Loss: -0.4911 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 08:56:44 - INFO - __main__ -   Bleu-2:0.213 | B-Bleu-2:0.242\n",
      "06/29/2022 08:56:44 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4546148650502667\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 147 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:00:11 - INFO - __main__ -   Epoch: 147 | Batch: 0/10000 (0%) | G Loss: 2.935694 | C Loss: -0.542389\n",
      "06/29/2022 09:00:11 - INFO - __main__ -   Text: ['It\\'s a perfect game to show your love for life,\" he \"cadgets.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 4.043\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:00:12 - INFO - __main__ -   Epoch: 147 | Batch: 600/10000 (6%) | G Loss: 2.895068 | C Loss: -0.391548\n",
      "06/29/2022 09:00:12 - INFO - __main__ -   Text: ['This quest does not mean that it has to always be buffeted by Yugoslavia.']\n",
      "06/29/2022 09:00:13 - INFO - __main__ -   Epoch: 147 | Batch: 1200/10000 (12%) | G Loss: 3.119377 | C Loss: -0.371197\n",
      "06/29/2022 09:00:13 - INFO - __main__ -   Text: ['Foresightful grunts, pared and boisterous.']\n",
      "06/29/2022 09:00:14 - INFO - __main__ -   Epoch: 147 | Batch: 1800/10000 (18%) | G Loss: 3.274349 | C Loss: -0.507718\n",
      "06/29/2022 09:00:14 - INFO - __main__ -   Text: ['Governors of materials and ideas demonstrate how influential matter is.']\n",
      "06/29/2022 09:00:15 - INFO - __main__ -   Epoch: 147 | Batch: 2400/10000 (24%) | G Loss: 2.880863 | C Loss: -0.385934\n",
      "06/29/2022 09:00:16 - INFO - __main__ -   Text: ['Even this ghost town has a very strong sweet tooth.']\n",
      "06/29/2022 09:00:16 - INFO - __main__ -   Epoch: 147 | Batch: 3000/10000 (30%) | G Loss: 2.081609 | C Loss: -0.522924\n",
      "06/29/2022 09:00:17 - INFO - __main__ -   Text: ['Valerie enters her dream world as an shortstop who is less of a writer.']\n",
      "06/29/2022 09:00:18 - INFO - __main__ -   Epoch: 147 | Batch: 3600/10000 (36%) | G Loss: 2.470151 | C Loss: -0.537304\n",
      "06/29/2022 09:00:18 - INFO - __main__ -   Text: ['This Guy assumes that non-American citizens dislike Oa.']\n",
      "06/29/2022 09:00:19 - INFO - __main__ -   Epoch: 147 | Batch: 4200/10000 (42%) | G Loss: 3.012628 | C Loss: -0.425465\n",
      "06/29/2022 09:00:19 - INFO - __main__ -   Text: ['Upon being told that you cannot not violate this rule, there is nothing wrong with it.']\n",
      "06/29/2022 09:00:20 - INFO - __main__ -   Epoch: 147 | Batch: 4800/10000 (48%) | G Loss: 3.335812 | C Loss: -0.432728\n",
      "06/29/2022 09:00:20 - INFO - __main__ -   Text: ['When describing the baroque, it should be mentioned that it is the grammatical the Baroque.']\n",
      "06/29/2022 09:00:21 - INFO - __main__ -   Epoch: 147 | Batch: 5400/10000 (54%) | G Loss: 2.624482 | C Loss: -0.819742\n",
      "06/29/2022 09:00:21 - INFO - __main__ -   Text: ['It\\'s called \"Meet The Guys\".']\n",
      "06/29/2022 09:00:22 - INFO - __main__ -   Epoch: 147 | Batch: 6000/10000 (60%) | G Loss: 2.679510 | C Loss: -0.534030\n",
      "06/29/2022 09:00:22 - INFO - __main__ -   Text: ['Unlike other animals.']\n",
      "06/29/2022 09:00:23 - INFO - __main__ -   Epoch: 147 | Batch: 6600/10000 (66%) | G Loss: 2.496347 | C Loss: -0.285356\n",
      "06/29/2022 09:00:23 - INFO - __main__ -   Text: ['Gadioks have been used all along.']\n",
      "06/29/2022 09:00:24 - INFO - __main__ -   Epoch: 147 | Batch: 7200/10000 (72%) | G Loss: 2.948740 | C Loss: -0.518499\n",
      "06/29/2022 09:00:24 - INFO - __main__ -   Text: ['They may inhabit many other terrestrial planets.']\n",
      "06/29/2022 09:00:25 - INFO - __main__ -   Epoch: 147 | Batch: 7800/10000 (78%) | G Loss: 3.020169 | C Loss: -0.657033\n",
      "06/29/2022 09:00:25 - INFO - __main__ -   Text: [\"It's really becoming one of my fears, seeing there are fake ads on Vietnam.\"]\n",
      "06/29/2022 09:00:26 - INFO - __main__ -   Epoch: 147 | Batch: 8400/10000 (84%) | G Loss: 2.563401 | C Loss: -0.178284\n",
      "06/29/2022 09:00:26 - INFO - __main__ -   Text: ['The course is reported every month.']\n",
      "06/29/2022 09:00:27 - INFO - __main__ -   Epoch: 147 | Batch: 9000/10000 (90%) | G Loss: 2.441650 | C Loss: -0.295356\n",
      "06/29/2022 09:00:28 - INFO - __main__ -   Text: ['However, Chi feels pulled towards me for his big girl character.']\n",
      "06/29/2022 09:00:29 - INFO - __main__ -   Epoch: 147 | Batch: 9600/10000 (96%) | G Loss: 2.464175 | C Loss: -0.445420\n",
      "06/29/2022 09:00:29 - INFO - __main__ -   Text: ['Cow may know he is the mole.']\n",
      "06/29/2022 09:00:29 - INFO - __main__ -   * (Train) Epoch: 147 | G Loss: 2.6689 | C Loss: -0.4775 | Updates G: 42 | Updates C: 791\n",
      "06/29/2022 09:00:38 - INFO - __main__ -   Bleu-2:0.199 | B-Bleu-2:0.235\n",
      "06/29/2022 09:00:38 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43351996308648694\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 148 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:04:03 - INFO - __main__ -   Epoch: 148 | Batch: 0/10000 (0%) | G Loss: 2.623587 | C Loss: -0.539604\n",
      "06/29/2022 09:04:03 - INFO - __main__ -   Text: [\"You probably shouldn't speak to this.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.981\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:04:04 - INFO - __main__ -   Epoch: 148 | Batch: 600/10000 (6%) | G Loss: 3.132479 | C Loss: -0.633448\n",
      "06/29/2022 09:04:04 - INFO - __main__ -   Text: ['She follows her dad to a park and engages in some \"man fricking\".']\n",
      "06/29/2022 09:04:05 - INFO - __main__ -   Epoch: 148 | Batch: 1200/10000 (12%) | G Loss: 3.024654 | C Loss: -0.512592\n",
      "06/29/2022 09:04:05 - INFO - __main__ -   Text: ['There are two ways of doing this sort of thing too.']\n",
      "06/29/2022 09:04:06 - INFO - __main__ -   Epoch: 148 | Batch: 1800/10000 (18%) | G Loss: 3.140566 | C Loss: -0.540648\n",
      "06/29/2022 09:04:06 - INFO - __main__ -   Text: ['It can write all that about, for instance.']\n",
      "06/29/2022 09:04:07 - INFO - __main__ -   Epoch: 148 | Batch: 2400/10000 (24%) | G Loss: 2.513792 | C Loss: -0.403358\n",
      "06/29/2022 09:04:07 - INFO - __main__ -   Text: ['The basic investigations of the Safety and Maintenance of Circulars.']\n",
      "06/29/2022 09:04:08 - INFO - __main__ -   Epoch: 148 | Batch: 3000/10000 (30%) | G Loss: 2.527283 | C Loss: -0.534904\n",
      "06/29/2022 09:04:08 - INFO - __main__ -   Text: ['Learn more about interacting with Boars and Babies.']\n",
      "06/29/2022 09:04:09 - INFO - __main__ -   Epoch: 148 | Batch: 3600/10000 (36%) | G Loss: 2.836198 | C Loss: -0.334916\n",
      "06/29/2022 09:04:09 - INFO - __main__ -   Text: ['Complacent yet beautiful.']\n",
      "06/29/2022 09:04:10 - INFO - __main__ -   Epoch: 148 | Batch: 4200/10000 (42%) | G Loss: 3.115671 | C Loss: -0.556048\n",
      "06/29/2022 09:04:10 - INFO - __main__ -   Text: ['Some authors claim there are many equal.']\n",
      "06/29/2022 09:04:11 - INFO - __main__ -   Epoch: 148 | Batch: 4800/10000 (48%) | G Loss: 3.416273 | C Loss: -0.641331\n",
      "06/29/2022 09:04:12 - INFO - __main__ -   Text: [\"The theme here is just how much instant money Haunt benefit what's happening.\"]\n",
      "06/29/2022 09:04:13 - INFO - __main__ -   Epoch: 148 | Batch: 5400/10000 (54%) | G Loss: 2.857145 | C Loss: -0.348517\n",
      "06/29/2022 09:04:13 - INFO - __main__ -   Text: ['AA has very catchy lyrics.']\n",
      "06/29/2022 09:04:14 - INFO - __main__ -   Epoch: 148 | Batch: 6000/10000 (60%) | G Loss: 2.943189 | C Loss: -0.458837\n",
      "06/29/2022 09:04:14 - INFO - __main__ -   Text: ['The challenge for this country is the ultimate \"winner-take-all.\"']\n",
      "06/29/2022 09:04:15 - INFO - __main__ -   Epoch: 148 | Batch: 6600/10000 (66%) | G Loss: 2.954510 | C Loss: -0.515311\n",
      "06/29/2022 09:04:15 - INFO - __main__ -   Text: ['Nohm seems to have a rebel nature.']\n",
      "06/29/2022 09:04:16 - INFO - __main__ -   Epoch: 148 | Batch: 7200/10000 (72%) | G Loss: 2.975384 | C Loss: -0.571135\n",
      "06/29/2022 09:04:16 - INFO - __main__ -   Text: ['\"Scape!']\n",
      "06/29/2022 09:04:17 - INFO - __main__ -   Epoch: 148 | Batch: 7800/10000 (78%) | G Loss: 2.645054 | C Loss: -0.452557\n",
      "06/29/2022 09:04:17 - INFO - __main__ -   Text: ['There are a lot of molasses matches.']\n",
      "06/29/2022 09:04:18 - INFO - __main__ -   Epoch: 148 | Batch: 8400/10000 (84%) | G Loss: 2.774468 | C Loss: -0.654617\n",
      "06/29/2022 09:04:18 - INFO - __main__ -   Text: ['The room behind the door always turns to gravitational force.']\n",
      "06/29/2022 09:04:19 - INFO - __main__ -   Epoch: 148 | Batch: 9000/10000 (90%) | G Loss: 3.108760 | C Loss: -0.225973\n",
      "06/29/2022 09:04:19 - INFO - __main__ -   Text: ['Then I will just give them no rusks.']\n",
      "06/29/2022 09:04:20 - INFO - __main__ -   Epoch: 148 | Batch: 9600/10000 (96%) | G Loss: 3.435873 | C Loss: -0.688893\n",
      "06/29/2022 09:04:20 - INFO - __main__ -   Text: [\"Because of that they gain more you don't get your money.\"]\n",
      "06/29/2022 09:04:21 - INFO - __main__ -   * (Train) Epoch: 148 | G Loss: 2.8558 | C Loss: -0.4948 | Updates G: 51 | Updates C: 782\n",
      "06/29/2022 09:04:30 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.242\n",
      "06/29/2022 09:04:30 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4416484783482597\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 149 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:08:02 - INFO - __main__ -   Epoch: 149 | Batch: 0/10001 (0%) | G Loss: 2.995269 | C Loss: -0.451322\n",
      "06/29/2022 09:08:02 - INFO - __main__ -   Text: ['Man got off to a good writing career.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.485\n",
      "  Test Loss: 4.071\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:08:03 - INFO - __main__ -   Epoch: 149 | Batch: 600/10001 (6%) | G Loss: 2.808601 | C Loss: -0.573371\n",
      "06/29/2022 09:08:03 - INFO - __main__ -   Text: ['\"The Ultimate test is looking at all possible paths to perfect speed.']\n",
      "06/29/2022 09:08:04 - INFO - __main__ -   Epoch: 149 | Batch: 1200/10001 (12%) | G Loss: 2.388188 | C Loss: -0.367394\n",
      "06/29/2022 09:08:04 - INFO - __main__ -   Text: ['A semiquature of the Greek defense of Europe.']\n",
      "06/29/2022 09:08:05 - INFO - __main__ -   Epoch: 149 | Batch: 1800/10001 (18%) | G Loss: 2.722353 | C Loss: -0.460463\n",
      "06/29/2022 09:08:05 - INFO - __main__ -   Text: ['She is still being blamed on whoever steals that money.']\n",
      "06/29/2022 09:08:06 - INFO - __main__ -   Epoch: 149 | Batch: 2400/10001 (24%) | G Loss: 2.790204 | C Loss: -0.544734\n",
      "06/29/2022 09:08:06 - INFO - __main__ -   Text: ['The Counterman forces.']\n",
      "06/29/2022 09:08:07 - INFO - __main__ -   Epoch: 149 | Batch: 3000/10001 (30%) | G Loss: 3.020282 | C Loss: -0.402255\n",
      "06/29/2022 09:08:07 - INFO - __main__ -   Text: ['Writing the code for \"Ragshank\", or a Zoot Task.']\n",
      "06/29/2022 09:08:08 - INFO - __main__ -   Epoch: 149 | Batch: 3600/10001 (36%) | G Loss: 3.395301 | C Loss: -0.475495\n",
      "06/29/2022 09:08:08 - INFO - __main__ -   Text: ['He can think of any witch who hasn\\'t bought the war bell.\"']\n",
      "06/29/2022 09:08:09 - INFO - __main__ -   Epoch: 149 | Batch: 4200/10001 (42%) | G Loss: 3.257734 | C Loss: -0.544851\n",
      "06/29/2022 09:08:09 - INFO - __main__ -   Text: ['The song refers to situations in which we feel pain.\"']\n",
      "06/29/2022 09:08:10 - INFO - __main__ -   Epoch: 149 | Batch: 4800/10001 (48%) | G Loss: 2.783892 | C Loss: -0.433552\n",
      "06/29/2022 09:08:10 - INFO - __main__ -   Text: ['The Beat Up!']\n",
      "06/29/2022 09:08:11 - INFO - __main__ -   Epoch: 149 | Batch: 5400/10001 (54%) | G Loss: 2.441411 | C Loss: -0.238053\n",
      "06/29/2022 09:08:11 - INFO - __main__ -   Text: ['The Welti is the Fushinet.']\n",
      "06/29/2022 09:08:12 - INFO - __main__ -   Epoch: 149 | Batch: 6000/10001 (60%) | G Loss: 2.450286 | C Loss: -0.483040\n",
      "06/29/2022 09:08:12 - INFO - __main__ -   Text: ['Baroc = neuturl.']\n",
      "06/29/2022 09:08:13 - INFO - __main__ -   Epoch: 149 | Batch: 6600/10001 (66%) | G Loss: 2.828818 | C Loss: -0.472804\n",
      "06/29/2022 09:08:14 - INFO - __main__ -   Text: ['\\u0b81மੁ']\n",
      "06/29/2022 09:08:15 - INFO - __main__ -   Epoch: 149 | Batch: 7200/10001 (72%) | G Loss: 2.759667 | C Loss: -0.485164\n",
      "06/29/2022 09:08:15 - INFO - __main__ -   Text: ['After a preliminary investigation the film co-investigates or states that an episode was planned.']\n",
      "06/29/2022 09:08:16 - INFO - __main__ -   Epoch: 149 | Batch: 7800/10001 (78%) | G Loss: 2.977962 | C Loss: -0.423573\n",
      "06/29/2022 09:08:16 - INFO - __main__ -   Text: ['They can take me back.']\n",
      "06/29/2022 09:08:17 - INFO - __main__ -   Epoch: 149 | Batch: 8400/10001 (84%) | G Loss: 3.010950 | C Loss: -0.507651\n",
      "06/29/2022 09:08:17 - INFO - __main__ -   Text: ['Impossible is the universe of unreal.']\n",
      "06/29/2022 09:08:18 - INFO - __main__ -   Epoch: 149 | Batch: 9000/10001 (90%) | G Loss: 2.850084 | C Loss: -0.423543\n",
      "06/29/2022 09:08:18 - INFO - __main__ -   Text: ['The reason for this is that there are some criteria for this aural therapy.']\n",
      "06/29/2022 09:08:19 - INFO - __main__ -   Epoch: 149 | Batch: 9600/10001 (96%) | G Loss: 2.982662 | C Loss: -0.509128\n",
      "06/29/2022 09:08:19 - INFO - __main__ -   Text: ['Means strictly of oneself.\"']\n",
      "06/29/2022 09:08:20 - INFO - __main__ -   * (Train) Epoch: 149 | G Loss: 2.8150 | C Loss: -0.4695 | Updates G: 36 | Updates C: 797\n",
      "06/29/2022 09:08:29 - INFO - __main__ -   Bleu-2:0.203 | B-Bleu-2:0.241\n",
      "06/29/2022 09:08:29 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444748306674228\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 150 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:11:55 - INFO - __main__ -   Epoch: 150 | Batch: 0/10001 (0%) | G Loss: 2.893089 | C Loss: -0.520230\n",
      "06/29/2022 09:11:55 - INFO - __main__ -   Text: ['One may say case-by-case thehingo related.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 3.891\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:11:56 - INFO - __main__ -   Epoch: 150 | Batch: 600/10001 (6%) | G Loss: 2.970191 | C Loss: -0.535475\n",
      "06/29/2022 09:11:56 - INFO - __main__ -   Text: ['They may not get religious.']\n",
      "06/29/2022 09:11:57 - INFO - __main__ -   Epoch: 150 | Batch: 1200/10001 (12%) | G Loss: 3.104515 | C Loss: -0.406734\n",
      "06/29/2022 09:11:58 - INFO - __main__ -   Text: ['The worst of all is cheating on math tests... These humanses are a source of shame to both the lazy and']\n",
      "06/29/2022 09:11:59 - INFO - __main__ -   Epoch: 150 | Batch: 1800/10001 (18%) | G Loss: 2.987309 | C Loss: -0.354007\n",
      "06/29/2022 09:11:59 - INFO - __main__ -   Text: ['Croruses with his homosexuals because \"the government knows nothing.\"']\n",
      "06/29/2022 09:12:00 - INFO - __main__ -   Epoch: 150 | Batch: 2400/10001 (24%) | G Loss: 2.712579 | C Loss: -0.390085\n",
      "06/29/2022 09:12:00 - INFO - __main__ -   Text: ['It starts as a defense of the overweene in note 1 edit.']\n",
      "06/29/2022 09:12:01 - INFO - __main__ -   Epoch: 150 | Batch: 3000/10001 (30%) | G Loss: 2.774749 | C Loss: -0.545355\n",
      "06/29/2022 09:12:01 - INFO - __main__ -   Text: ['This implies, if the fleet lands somewhere, it will have yet other way to later mission the planet.']\n",
      "06/29/2022 09:12:02 - INFO - __main__ -   Epoch: 150 | Batch: 3600/10001 (36%) | G Loss: 2.327323 | C Loss: -0.204751\n",
      "06/29/2022 09:12:02 - INFO - __main__ -   Text: ['Each episode can include: each episode of a web series or study course.']\n",
      "06/29/2022 09:12:03 - INFO - __main__ -   Epoch: 150 | Batch: 4200/10001 (42%) | G Loss: 3.012327 | C Loss: -0.531816\n",
      "06/29/2022 09:12:03 - INFO - __main__ -   Text: ['the eyes because it contains myrrh.\"']\n",
      "06/29/2022 09:12:04 - INFO - __main__ -   Epoch: 150 | Batch: 4800/10001 (48%) | G Loss: 3.390873 | C Loss: -0.493643\n",
      "06/29/2022 09:12:04 - INFO - __main__ -   Text: ['The prizes for contestants are prizes recommended every time someone tries to visit.']\n",
      "06/29/2022 09:12:05 - INFO - __main__ -   Epoch: 150 | Batch: 5400/10001 (54%) | G Loss: 2.856955 | C Loss: -0.460940\n",
      "06/29/2022 09:12:05 - INFO - __main__ -   Text: ['The common denominator is \"geeking.\"']\n",
      "06/29/2022 09:12:06 - INFO - __main__ -   Epoch: 150 | Batch: 6000/10001 (60%) | G Loss: 2.754188 | C Loss: -0.316272\n",
      "06/29/2022 09:12:06 - INFO - __main__ -   Text: ['The baskerisation trend is in Argentina winning another available tag.']\n",
      "06/29/2022 09:12:07 - INFO - __main__ -   Epoch: 150 | Batch: 6600/10001 (66%) | G Loss: 2.669529 | C Loss: -0.297928\n",
      "06/29/2022 09:12:07 - INFO - __main__ -   Text: ['\"Chease My Reduction!\"']\n",
      "06/29/2022 09:12:08 - INFO - __main__ -   Epoch: 150 | Batch: 7200/10001 (72%) | G Loss: 2.826510 | C Loss: -0.473368\n",
      "06/29/2022 09:12:09 - INFO - __main__ -   Text: ['The video can also be heard sale times on school radio stations for non-explained reasons.']\n",
      "06/29/2022 09:12:10 - INFO - __main__ -   Epoch: 150 | Batch: 7800/10001 (78%) | G Loss: 2.680061 | C Loss: -0.528793\n",
      "06/29/2022 09:12:10 - INFO - __main__ -   Text: ['In mainly countries, đas!\"']\n",
      "06/29/2022 09:12:11 - INFO - __main__ -   Epoch: 150 | Batch: 8400/10001 (84%) | G Loss: 2.978165 | C Loss: -0.358942\n",
      "06/29/2022 09:12:11 - INFO - __main__ -   Text: ['You can\\'t fool me.\"']\n",
      "06/29/2022 09:12:12 - INFO - __main__ -   Epoch: 150 | Batch: 9000/10001 (90%) | G Loss: 2.862348 | C Loss: -0.344588\n",
      "06/29/2022 09:12:12 - INFO - __main__ -   Text: ['Bonnie and Switch Logo and Jason Jacques']\n",
      "06/29/2022 09:12:13 - INFO - __main__ -   Epoch: 150 | Batch: 9600/10001 (96%) | G Loss: 2.714736 | C Loss: -0.323386\n",
      "06/29/2022 09:12:13 - INFO - __main__ -   Text: ['It first mishaps me that this is probably an ill-advised first impression.\"']\n",
      "06/29/2022 09:12:13 - INFO - __main__ -   * (Train) Epoch: 150 | G Loss: 2.8216 | C Loss: -0.4798 | Updates G: 51 | Updates C: 782\n",
      "06/29/2022 09:12:23 - INFO - __main__ -   Bleu-2:0.206 | B-Bleu-2:0.265\n",
      "06/29/2022 09:12:23 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.470602114304121\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 151 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:15:48 - INFO - __main__ -   Epoch: 151 | Batch: 0/10001 (0%) | G Loss: 2.689848 | C Loss: -0.346770\n",
      "06/29/2022 09:15:48 - INFO - __main__ -   Text: ['Often relegated to Super B policy for Josie.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.013\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:15:49 - INFO - __main__ -   Epoch: 151 | Batch: 600/10001 (6%) | G Loss: 2.688063 | C Loss: -0.333924\n",
      "06/29/2022 09:15:50 - INFO - __main__ -   Text: ['Wicked Hat will use peek mode and require manual creation.']\n",
      "06/29/2022 09:15:50 - INFO - __main__ -   Epoch: 151 | Batch: 1200/10001 (12%) | G Loss: 3.270631 | C Loss: -0.513731\n",
      "06/29/2022 09:15:51 - INFO - __main__ -   Text: ['The textbook contains a special presentation of basic topics.']\n",
      "06/29/2022 09:15:52 - INFO - __main__ -   Epoch: 151 | Batch: 1800/10001 (18%) | G Loss: 3.660615 | C Loss: -0.376175\n",
      "06/29/2022 09:15:52 - INFO - __main__ -   Text: ['Monies school the Parliament.']\n",
      "06/29/2022 09:15:53 - INFO - __main__ -   Epoch: 151 | Batch: 2400/10001 (24%) | G Loss: 2.632983 | C Loss: -0.330405\n",
      "06/29/2022 09:15:53 - INFO - __main__ -   Text: ['He tips readers on theories of state security.']\n",
      "06/29/2022 09:15:54 - INFO - __main__ -   Epoch: 151 | Batch: 3000/10001 (30%) | G Loss: 2.552417 | C Loss: -0.689402\n",
      "06/29/2022 09:15:54 - INFO - __main__ -   Text: ['Model 3 is put to rigorous use.']\n",
      "06/29/2022 09:15:55 - INFO - __main__ -   Epoch: 151 | Batch: 3600/10001 (36%) | G Loss: 2.300614 | C Loss: -0.303437\n",
      "06/29/2022 09:15:55 - INFO - __main__ -   Text: ['Baby is a great target for teens.']\n",
      "06/29/2022 09:15:56 - INFO - __main__ -   Epoch: 151 | Batch: 4200/10001 (42%) | G Loss: 2.737196 | C Loss: -0.511476\n",
      "06/29/2022 09:15:56 - INFO - __main__ -   Text: [\"There's only one that transcends the subject.\"]\n",
      "06/29/2022 09:15:57 - INFO - __main__ -   Epoch: 151 | Batch: 4800/10001 (48%) | G Loss: 3.444514 | C Loss: -0.726623\n",
      "06/29/2022 09:15:57 - INFO - __main__ -   Text: ['The sentence states VCI condemns this man to be hanged.']\n",
      "06/29/2022 09:15:58 - INFO - __main__ -   Epoch: 151 | Batch: 5400/10001 (54%) | G Loss: 3.434493 | C Loss: -0.222466\n",
      "06/29/2022 09:15:58 - INFO - __main__ -   Text: ['Both cyclical and nonvector are the requiredfood.']\n",
      "06/29/2022 09:15:59 - INFO - __main__ -   Epoch: 151 | Batch: 6000/10001 (60%) | G Loss: 3.041660 | C Loss: -0.446260\n",
      "06/29/2022 09:15:59 - INFO - __main__ -   Text: ['It is a very like track in the seven-hour race.']\n",
      "06/29/2022 09:16:00 - INFO - __main__ -   Epoch: 151 | Batch: 6600/10001 (66%) | G Loss: 2.843454 | C Loss: -0.394132\n",
      "06/29/2022 09:16:00 - INFO - __main__ -   Text: ['I want to deal with people that think differently.']\n",
      "06/29/2022 09:16:01 - INFO - __main__ -   Epoch: 151 | Batch: 7200/10001 (72%) | G Loss: 2.611546 | C Loss: -0.251118\n",
      "06/29/2022 09:16:01 - INFO - __main__ -   Text: ['The Korean king said: Make lips a mirror.']\n",
      "06/29/2022 09:16:02 - INFO - __main__ -   Epoch: 151 | Batch: 7800/10001 (78%) | G Loss: 2.630510 | C Loss: -0.413470\n",
      "06/29/2022 09:16:02 - INFO - __main__ -   Text: [\"Relationships are one of engineering's keys to success.\"]\n",
      "06/29/2022 09:16:03 - INFO - __main__ -   Epoch: 151 | Batch: 8400/10001 (84%) | G Loss: 2.723182 | C Loss: -0.606522\n",
      "06/29/2022 09:16:03 - INFO - __main__ -   Text: ['( lit.']\n",
      "06/29/2022 09:16:04 - INFO - __main__ -   Epoch: 151 | Batch: 9000/10001 (90%) | G Loss: 2.774122 | C Loss: -0.280349\n",
      "06/29/2022 09:16:05 - INFO - __main__ -   Text: ['Within a country has already left India.']\n",
      "06/29/2022 09:16:05 - INFO - __main__ -   Epoch: 151 | Batch: 9600/10001 (96%) | G Loss: 2.954189 | C Loss: -0.482238\n",
      "06/29/2022 09:16:06 - INFO - __main__ -   Text: ['A duality might be called \"Jump\".']\n",
      "06/29/2022 09:16:06 - INFO - __main__ -   * (Train) Epoch: 151 | G Loss: 2.8161 | C Loss: -0.4706 | Updates G: 42 | Updates C: 791\n",
      "06/29/2022 09:16:15 - INFO - __main__ -   Bleu-2:0.189 | B-Bleu-2:0.244\n",
      "06/29/2022 09:16:15 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43211602436491486\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 152 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:19:43 - INFO - __main__ -   Epoch: 152 | Batch: 0/10001 (0%) | G Loss: 2.907586 | C Loss: -0.459765\n",
      "06/29/2022 09:19:43 - INFO - __main__ -   Text: ['The experiment is used for modeling metal balance for silicon derivatives.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.997\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:19:44 - INFO - __main__ -   Epoch: 152 | Batch: 600/10001 (6%) | G Loss: 2.808620 | C Loss: -0.425145\n",
      "06/29/2022 09:19:45 - INFO - __main__ -   Text: ['If \"dha pow\" is green, there is a blue blast.']\n",
      "06/29/2022 09:19:45 - INFO - __main__ -   Epoch: 152 | Batch: 1200/10001 (12%) | G Loss: 2.899404 | C Loss: -0.535854\n",
      "06/29/2022 09:19:46 - INFO - __main__ -   Text: ['In contrast, South Africa is far from closed on distance.']\n",
      "06/29/2022 09:19:47 - INFO - __main__ -   Epoch: 152 | Batch: 1800/10001 (18%) | G Loss: 3.036691 | C Loss: -0.351573\n",
      "06/29/2022 09:19:47 - INFO - __main__ -   Text: ['Supplementation is online testing.']\n",
      "06/29/2022 09:19:48 - INFO - __main__ -   Epoch: 152 | Batch: 2400/10001 (24%) | G Loss: 3.592863 | C Loss: -0.509317\n",
      "06/29/2022 09:19:48 - INFO - __main__ -   Text: ['She does receive occasional dukes in bars, but she loves being an independent.']\n",
      "06/29/2022 09:19:49 - INFO - __main__ -   Epoch: 152 | Batch: 3000/10001 (30%) | G Loss: 3.113809 | C Loss: -0.345953\n",
      "06/29/2022 09:19:49 - INFO - __main__ -   Text: ['He is the only self-help author.']\n",
      "06/29/2022 09:19:50 - INFO - __main__ -   Epoch: 152 | Batch: 3600/10001 (36%) | G Loss: 2.466384 | C Loss: -0.533276\n",
      "06/29/2022 09:19:50 - INFO - __main__ -   Text: ['It is Olympic.']\n",
      "06/29/2022 09:19:51 - INFO - __main__ -   Epoch: 152 | Batch: 4200/10001 (42%) | G Loss: 2.754686 | C Loss: -0.542424\n",
      "06/29/2022 09:19:51 - INFO - __main__ -   Text: ['She is not guilty, but merely accused of sex abuse.']\n",
      "06/29/2022 09:19:52 - INFO - __main__ -   Epoch: 152 | Batch: 4800/10001 (48%) | G Loss: 3.188503 | C Loss: -0.902019\n",
      "06/29/2022 09:19:52 - INFO - __main__ -   Text: ['🙌#nyp...']\n",
      "06/29/2022 09:19:53 - INFO - __main__ -   Epoch: 152 | Batch: 5400/10001 (54%) | G Loss: 2.943036 | C Loss: -0.464098\n",
      "06/29/2022 09:19:53 - INFO - __main__ -   Text: ['Steven then realizes they have two sons and proposes that they are both duct-taped.']\n",
      "06/29/2022 09:19:54 - INFO - __main__ -   Epoch: 152 | Batch: 6000/10001 (60%) | G Loss: 2.896543 | C Loss: -0.489098\n",
      "06/29/2022 09:19:54 - INFO - __main__ -   Text: ['I try to be innovative\".']\n",
      "06/29/2022 09:19:55 - INFO - __main__ -   Epoch: 152 | Batch: 6600/10001 (66%) | G Loss: 3.380758 | C Loss: -0.531557\n",
      "06/29/2022 09:19:55 - INFO - __main__ -   Text: ['Roll is no-tude \"Meet the merchants on routes to Persia\".']\n",
      "06/29/2022 09:19:56 - INFO - __main__ -   Epoch: 152 | Batch: 7200/10001 (72%) | G Loss: 3.236721 | C Loss: -0.614429\n",
      "06/29/2022 09:19:56 - INFO - __main__ -   Text: [\"Nitrospuke doesn't care which way it goes.\"]\n",
      "06/29/2022 09:19:57 - INFO - __main__ -   Epoch: 152 | Batch: 7800/10001 (78%) | G Loss: 2.584238 | C Loss: -0.372146\n",
      "06/29/2022 09:19:57 - INFO - __main__ -   Text: ['In greater accomplishment, like an Einstein is.']\n",
      "06/29/2022 09:19:58 - INFO - __main__ -   Epoch: 152 | Batch: 8400/10001 (84%) | G Loss: 2.445904 | C Loss: -0.416152\n",
      "06/29/2022 09:19:59 - INFO - __main__ -   Text: ['These jumpers may be pinned or straightened out from above.']\n",
      "06/29/2022 09:20:00 - INFO - __main__ -   Epoch: 152 | Batch: 9000/10001 (90%) | G Loss: 2.757207 | C Loss: -0.428242\n",
      "06/29/2022 09:20:00 - INFO - __main__ -   Text: ['Historically, it means that in a certain sense, something supernatural should be involved.']\n",
      "06/29/2022 09:20:01 - INFO - __main__ -   Epoch: 152 | Batch: 9600/10001 (96%) | G Loss: 3.349723 | C Loss: -0.753990\n",
      "06/29/2022 09:20:01 - INFO - __main__ -   Text: ['Few minutes gradually make me feel happiest; this theory explains how I\\'m also fast.\"']\n",
      "06/29/2022 09:20:02 - INFO - __main__ -   * (Train) Epoch: 152 | G Loss: 2.8884 | C Loss: -0.4822 | Updates G: 52 | Updates C: 781\n",
      "06/29/2022 09:20:11 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.256\n",
      "06/29/2022 09:20:11 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.462813975247127\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 153 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:41.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:59.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:17.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:23:45 - INFO - __main__ -   Epoch: 153 | Batch: 0/10001 (0%) | G Loss: 2.986078 | C Loss: -0.265305\n",
      "06/29/2022 09:23:45 - INFO - __main__ -   Text: ['Stilwell describes him as a \"HID experience guru.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.965\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:23:46 - INFO - __main__ -   Epoch: 153 | Batch: 600/10001 (6%) | G Loss: 2.800144 | C Loss: -0.353396\n",
      "06/29/2022 09:23:46 - INFO - __main__ -   Text: ['Wiories are vulnerable to locator locator distress.']\n",
      "06/29/2022 09:23:47 - INFO - __main__ -   Epoch: 153 | Batch: 1200/10001 (12%) | G Loss: 2.759026 | C Loss: -0.437415\n",
      "06/29/2022 09:23:47 - INFO - __main__ -   Text: ['Xinhua NASA']\n",
      "06/29/2022 09:23:48 - INFO - __main__ -   Epoch: 153 | Batch: 1800/10001 (18%) | G Loss: 2.846682 | C Loss: -0.352735\n",
      "06/29/2022 09:23:49 - INFO - __main__ -   Text: ['It therefore requires an accelerated market.\"']\n",
      "06/29/2022 09:23:50 - INFO - __main__ -   Epoch: 153 | Batch: 2400/10001 (24%) | G Loss: 2.793423 | C Loss: -0.422326\n",
      "06/29/2022 09:23:50 - INFO - __main__ -   Text: ['They are friends with art.']\n",
      "06/29/2022 09:23:51 - INFO - __main__ -   Epoch: 153 | Batch: 3000/10001 (30%) | G Loss: 3.427581 | C Loss: -0.513391\n",
      "06/29/2022 09:23:51 - INFO - __main__ -   Text: ['I prefer it than other modems.']\n",
      "06/29/2022 09:23:52 - INFO - __main__ -   Epoch: 153 | Batch: 3600/10001 (36%) | G Loss: 3.674158 | C Loss: -0.587657\n",
      "06/29/2022 09:23:52 - INFO - __main__ -   Text: ['If you walk on a HMB (movie warning system) there is a lot more risk that you are approaching a']\n",
      "06/29/2022 09:23:53 - INFO - __main__ -   Epoch: 153 | Batch: 4200/10001 (42%) | G Loss: 3.233746 | C Loss: -0.359778\n",
      "06/29/2022 09:23:53 - INFO - __main__ -   Text: ['Since only males derive access to the plot of eye colour, terms used in these styles.']\n",
      "06/29/2022 09:23:54 - INFO - __main__ -   Epoch: 153 | Batch: 4800/10001 (48%) | G Loss: 2.855181 | C Loss: -0.494751\n",
      "06/29/2022 09:23:54 - INFO - __main__ -   Text: ['Drifting or dicing may also occur.']\n",
      "06/29/2022 09:23:55 - INFO - __main__ -   Epoch: 153 | Batch: 5400/10001 (54%) | G Loss: 1.689914 | C Loss: -0.287075\n",
      "06/29/2022 09:23:55 - INFO - __main__ -   Text: ['The arrow is great, but yet there are no get-downs.\"']\n",
      "06/29/2022 09:23:56 - INFO - __main__ -   Epoch: 153 | Batch: 6000/10001 (60%) | G Loss: 1.800621 | C Loss: -0.485330\n",
      "06/29/2022 09:23:56 - INFO - __main__ -   Text: ['\"Cell phone\" is a book that may hold conversation.']\n",
      "06/29/2022 09:23:57 - INFO - __main__ -   Epoch: 153 | Batch: 6600/10001 (66%) | G Loss: 2.404045 | C Loss: -0.407958\n",
      "06/29/2022 09:23:57 - INFO - __main__ -   Text: ['When there is sedentary prestige some amateurs even support.']\n",
      "06/29/2022 09:23:58 - INFO - __main__ -   Epoch: 153 | Batch: 7200/10001 (72%) | G Loss: 2.612280 | C Loss: -0.387056\n",
      "06/29/2022 09:23:58 - INFO - __main__ -   Text: ['Reeffag, reeformus is not without its critics.']\n",
      "06/29/2022 09:23:59 - INFO - __main__ -   Epoch: 153 | Batch: 7800/10001 (78%) | G Loss: 3.131269 | C Loss: -0.346597\n",
      "06/29/2022 09:24:00 - INFO - __main__ -   Text: ['Everyone knows the worst person is the banker.\"']\n",
      "06/29/2022 09:24:01 - INFO - __main__ -   Epoch: 153 | Batch: 8400/10001 (84%) | G Loss: 3.771628 | C Loss: -0.653713\n",
      "06/29/2022 09:24:01 - INFO - __main__ -   Text: ['Access to this narrow spectrum requires remote data.']\n",
      "06/29/2022 09:24:02 - INFO - __main__ -   Epoch: 153 | Batch: 9000/10001 (90%) | G Loss: 2.954863 | C Loss: -0.384301\n",
      "06/29/2022 09:24:02 - INFO - __main__ -   Text: ['An argument to take over traffic is that it ought to be a threat to everyone.']\n",
      "06/29/2022 09:24:03 - INFO - __main__ -   Epoch: 153 | Batch: 9600/10001 (96%) | G Loss: 2.262846 | C Loss: -0.372990\n",
      "06/29/2022 09:24:03 - INFO - __main__ -   Text: ['Leach therefore warns governments against the threat of Arab states joining the war.']\n",
      "06/29/2022 09:24:04 - INFO - __main__ -   * (Train) Epoch: 153 | G Loss: 2.7337 | C Loss: -0.4795 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 09:24:13 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.287\n",
      "06/29/2022 09:24:13 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49419164879106037\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 154 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:27:45 - INFO - __main__ -   Epoch: 154 | Batch: 0/10001 (0%) | G Loss: 2.514237 | C Loss: -0.301267\n",
      "06/29/2022 09:27:45 - INFO - __main__ -   Text: ['\"Cinderella\" – is not very many people.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.978\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:27:46 - INFO - __main__ -   Epoch: 154 | Batch: 600/10001 (6%) | G Loss: 2.689288 | C Loss: -0.544160\n",
      "06/29/2022 09:27:46 - INFO - __main__ -   Text: ['\"liar Vishnu\").']\n",
      "06/29/2022 09:27:47 - INFO - __main__ -   Epoch: 154 | Batch: 1200/10001 (12%) | G Loss: 2.767196 | C Loss: -0.387340\n",
      "06/29/2022 09:27:47 - INFO - __main__ -   Text: ['Treespark and cancer.']\n",
      "06/29/2022 09:27:48 - INFO - __main__ -   Epoch: 154 | Batch: 1800/10001 (18%) | G Loss: 3.348909 | C Loss: -0.498824\n",
      "06/29/2022 09:27:48 - INFO - __main__ -   Text: ['It is a conversation I love.\"']\n",
      "06/29/2022 09:27:49 - INFO - __main__ -   Epoch: 154 | Batch: 2400/10001 (24%) | G Loss: 3.397454 | C Loss: -0.863589\n",
      "06/29/2022 09:27:49 - INFO - __main__ -   Text: ['He is supposedly accused of stealing money from the Detroit Lions.']\n",
      "06/29/2022 09:27:50 - INFO - __main__ -   Epoch: 154 | Batch: 3000/10001 (30%) | G Loss: 2.790024 | C Loss: -0.439399\n",
      "06/29/2022 09:27:50 - INFO - __main__ -   Text: [\"That's why we develop broad eyes.\"]\n",
      "06/29/2022 09:27:51 - INFO - __main__ -   Epoch: 154 | Batch: 3600/10001 (36%) | G Loss: 2.819203 | C Loss: -0.439081\n",
      "06/29/2022 09:27:51 - INFO - __main__ -   Text: ['Dean can not speak for her — not even fellow Manchester residents — but her girlfriend.']\n",
      "06/29/2022 09:27:52 - INFO - __main__ -   Epoch: 154 | Batch: 4200/10001 (42%) | G Loss: 2.797326 | C Loss: -0.541645\n",
      "06/29/2022 09:27:53 - INFO - __main__ -   Text: ['Episodes about dating are therefore usually published in \"sexy culture\" websites.']\n",
      "06/29/2022 09:27:54 - INFO - __main__ -   Epoch: 154 | Batch: 4800/10001 (48%) | G Loss: 3.127993 | C Loss: -0.568151\n",
      "06/29/2022 09:27:54 - INFO - __main__ -   Text: ['This pin causes Willpower to laugh at Beyoncé.']\n",
      "06/29/2022 09:27:55 - INFO - __main__ -   Epoch: 154 | Batch: 5400/10001 (54%) | G Loss: 2.747752 | C Loss: -0.392278\n",
      "06/29/2022 09:27:55 - INFO - __main__ -   Text: ['Only after learning that the ritual is wrong is I to begin to suspect I am eating healthier.']\n",
      "06/29/2022 09:27:56 - INFO - __main__ -   Epoch: 154 | Batch: 6000/10001 (60%) | G Loss: 3.066393 | C Loss: -0.470556\n",
      "06/29/2022 09:27:56 - INFO - __main__ -   Text: ['Bodily is open to being married to a woman.']\n",
      "06/29/2022 09:27:57 - INFO - __main__ -   Epoch: 154 | Batch: 6600/10001 (66%) | G Loss: 3.206397 | C Loss: -0.264420\n",
      "06/29/2022 09:27:57 - INFO - __main__ -   Text: ['Some say failure is due to lack of experience.']\n",
      "06/29/2022 09:27:58 - INFO - __main__ -   Epoch: 154 | Batch: 7200/10001 (72%) | G Loss: 2.558770 | C Loss: -0.527420\n",
      "06/29/2022 09:27:58 - INFO - __main__ -   Text: ['Quality choose mostly Wright Toys.']\n",
      "06/29/2022 09:27:59 - INFO - __main__ -   Epoch: 154 | Batch: 7800/10001 (78%) | G Loss: 2.737039 | C Loss: -0.459659\n",
      "06/29/2022 09:27:59 - INFO - __main__ -   Text: ['Her most popular honor is the Differential Scrabble.']\n",
      "06/29/2022 09:28:00 - INFO - __main__ -   Epoch: 154 | Batch: 8400/10001 (84%) | G Loss: 3.244346 | C Loss: -0.690564\n",
      "06/29/2022 09:28:00 - INFO - __main__ -   Text: [\"Mark: You're an greatest hitter?\"]\n",
      "06/29/2022 09:28:01 - INFO - __main__ -   Epoch: 154 | Batch: 9000/10001 (90%) | G Loss: 2.925325 | C Loss: -0.548527\n",
      "06/29/2022 09:28:01 - INFO - __main__ -   Text: ['film camera upholstery sell you trikes for money.\"']\n",
      "06/29/2022 09:28:02 - INFO - __main__ -   Epoch: 154 | Batch: 9600/10001 (96%) | G Loss: 3.016166 | C Loss: -0.558646\n",
      "06/29/2022 09:28:02 - INFO - __main__ -   Text: ['Although the size of functions of the immunostructure is well defined, it is more difficult to distinguish certain types.']\n",
      "06/29/2022 09:28:03 - INFO - __main__ -   * (Train) Epoch: 154 | G Loss: 2.8575 | C Loss: -0.4627 | Updates G: 58 | Updates C: 775\n",
      "06/29/2022 09:28:12 - INFO - __main__ -   Bleu-2:0.195 | B-Bleu-2:0.231\n",
      "06/29/2022 09:28:12 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42601315425274566\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 155 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:54.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:31:44 - INFO - __main__ -   Epoch: 155 | Batch: 0/10001 (0%) | G Loss: 2.859208 | C Loss: -0.384327\n",
      "06/29/2022 09:31:44 - INFO - __main__ -   Text: ['This site is published in the UK and as a companion site.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 4.004\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:31:45 - INFO - __main__ -   Epoch: 155 | Batch: 600/10001 (6%) | G Loss: 2.570035 | C Loss: -0.467628\n",
      "06/29/2022 09:31:45 - INFO - __main__ -   Text: ['The girls , he thinks, will be a doctor.']\n",
      "06/29/2022 09:31:46 - INFO - __main__ -   Epoch: 155 | Batch: 1200/10001 (12%) | G Loss: 2.951284 | C Loss: -0.364856\n",
      "06/29/2022 09:31:47 - INFO - __main__ -   Text: ['Along with this he says, in this world, Devil is shopping, singing!\"']\n",
      "06/29/2022 09:31:48 - INFO - __main__ -   Epoch: 155 | Batch: 1800/10001 (18%) | G Loss: 3.454164 | C Loss: -0.714583\n",
      "06/29/2022 09:31:48 - INFO - __main__ -   Text: ['Chilean server implementation in help to improve machines.']\n",
      "06/29/2022 09:31:49 - INFO - __main__ -   Epoch: 155 | Batch: 2400/10001 (24%) | G Loss: 3.279985 | C Loss: -0.477703\n",
      "06/29/2022 09:31:49 - INFO - __main__ -   Text: ['them in dream\".']\n",
      "06/29/2022 09:31:50 - INFO - __main__ -   Epoch: 155 | Batch: 3000/10001 (30%) | G Loss: 2.625237 | C Loss: -0.361402\n",
      "06/29/2022 09:31:50 - INFO - __main__ -   Text: ['This is the matter of the idea that is called meditation.']\n",
      "06/29/2022 09:31:51 - INFO - __main__ -   Epoch: 155 | Batch: 3600/10001 (36%) | G Loss: 2.531118 | C Loss: -0.389356\n",
      "06/29/2022 09:31:51 - INFO - __main__ -   Text: ['Other studies suggest that the disease may be related to desert acacia trees.']\n",
      "06/29/2022 09:31:52 - INFO - __main__ -   Epoch: 155 | Batch: 4200/10001 (42%) | G Loss: 2.668581 | C Loss: -0.264946\n",
      "06/29/2022 09:31:52 - INFO - __main__ -   Text: ['Yeah, that\\'s sir.\"']\n",
      "06/29/2022 09:31:53 - INFO - __main__ -   Epoch: 155 | Batch: 4800/10001 (48%) | G Loss: 2.433745 | C Loss: -0.201176\n",
      "06/29/2022 09:31:53 - INFO - __main__ -   Text: ['Management aptu should be focused on app test.']\n",
      "06/29/2022 09:31:54 - INFO - __main__ -   Epoch: 155 | Batch: 5400/10001 (54%) | G Loss: 3.395708 | C Loss: -0.472923\n",
      "06/29/2022 09:31:54 - INFO - __main__ -   Text: ['It allows students to quickly write a data science paper without any worries.']\n",
      "06/29/2022 09:31:55 - INFO - __main__ -   Epoch: 155 | Batch: 6000/10001 (60%) | G Loss: 2.768344 | C Loss: -0.281533\n",
      "06/29/2022 09:31:55 - INFO - __main__ -   Text: ['He is capable of taking higher decisions\".']\n",
      "06/29/2022 09:31:56 - INFO - __main__ -   Epoch: 155 | Batch: 6600/10001 (66%) | G Loss: 2.842142 | C Loss: -0.431197\n",
      "06/29/2022 09:31:56 - INFO - __main__ -   Text: ['Vacuum is an audio simulator that monitors your outgoing conversation.']\n",
      "06/29/2022 09:31:57 - INFO - __main__ -   Epoch: 155 | Batch: 7200/10001 (72%) | G Loss: 2.709765 | C Loss: -0.911576\n",
      "06/29/2022 09:31:57 - INFO - __main__ -   Text: ['Synthesis is not scaled down.']\n",
      "06/29/2022 09:31:58 - INFO - __main__ -   Epoch: 155 | Batch: 7800/10001 (78%) | G Loss: 2.348664 | C Loss: -0.242397\n",
      "06/29/2022 09:31:59 - INFO - __main__ -   Text: ['Coding difficulty is correlated to emotionally motivated work.']\n",
      "06/29/2022 09:31:59 - INFO - __main__ -   Epoch: 155 | Batch: 8400/10001 (84%) | G Loss: 2.225653 | C Loss: -0.352121\n",
      "06/29/2022 09:32:00 - INFO - __main__ -   Text: [\"How does any of this version of 'Silver Bullet?'\"]\n",
      "06/29/2022 09:32:01 - INFO - __main__ -   Epoch: 155 | Batch: 9000/10001 (90%) | G Loss: 2.684767 | C Loss: -0.459035\n",
      "06/29/2022 09:32:01 - INFO - __main__ -   Text: ['Scientists know that within one cubic metre gravity is lubricated.']\n",
      "06/29/2022 09:32:02 - INFO - __main__ -   Epoch: 155 | Batch: 9600/10001 (96%) | G Loss: 3.209927 | C Loss: -0.342692\n",
      "06/29/2022 09:32:02 - INFO - __main__ -   Text: ['There are many reasons why this is a process.']\n",
      "06/29/2022 09:32:02 - INFO - __main__ -   * (Train) Epoch: 155 | G Loss: 2.7685 | C Loss: -0.4751 | Updates G: 45 | Updates C: 788\n",
      "06/29/2022 09:32:12 - INFO - __main__ -   Bleu-2:0.199 | B-Bleu-2:0.249\n",
      "06/29/2022 09:32:12 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44806504144362\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 156 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:35:42 - INFO - __main__ -   Epoch: 156 | Batch: 0/10001 (0%) | G Loss: 3.289222 | C Loss: -0.586132\n",
      "06/29/2022 09:35:43 - INFO - __main__ -   Text: ['Kelpie Strong!\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.954\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:35:44 - INFO - __main__ -   Epoch: 156 | Batch: 600/10001 (6%) | G Loss: 3.138017 | C Loss: -0.645815\n",
      "06/29/2022 09:35:44 - INFO - __main__ -   Text: [\"From Carbon'.\"]\n",
      "06/29/2022 09:35:45 - INFO - __main__ -   Epoch: 156 | Batch: 1200/10001 (12%) | G Loss: 3.071774 | C Loss: -0.214318\n",
      "06/29/2022 09:35:45 - INFO - __main__ -   Text: ['Sister also relies on other women to text messages to her.']\n",
      "06/29/2022 09:35:46 - INFO - __main__ -   Epoch: 156 | Batch: 1800/10001 (18%) | G Loss: 2.862657 | C Loss: -0.443918\n",
      "06/29/2022 09:35:46 - INFO - __main__ -   Text: ['The external notation is infinite here .']\n",
      "06/29/2022 09:35:47 - INFO - __main__ -   Epoch: 156 | Batch: 2400/10001 (24%) | G Loss: 2.917641 | C Loss: -0.478022\n",
      "06/29/2022 09:35:47 - INFO - __main__ -   Text: ['His name is For The People.']\n",
      "06/29/2022 09:35:48 - INFO - __main__ -   Epoch: 156 | Batch: 3000/10001 (30%) | G Loss: 2.704072 | C Loss: -0.656362\n",
      "06/29/2022 09:35:48 - INFO - __main__ -   Text: ['The Crow people believe that their word is biblical.']\n",
      "06/29/2022 09:35:49 - INFO - __main__ -   Epoch: 156 | Batch: 3600/10001 (36%) | G Loss: 2.717742 | C Loss: -0.320007\n",
      "06/29/2022 09:35:49 - INFO - __main__ -   Text: ['Lunch is a ghost powered by Donald Duck.']\n",
      "06/29/2022 09:35:50 - INFO - __main__ -   Epoch: 156 | Batch: 4200/10001 (42%) | G Loss: 3.020729 | C Loss: -0.511667\n",
      "06/29/2022 09:35:50 - INFO - __main__ -   Text: ['Although not inbred, her Favorite People are Blacks.']\n",
      "06/29/2022 09:35:51 - INFO - __main__ -   Epoch: 156 | Batch: 4800/10001 (48%) | G Loss: 3.566819 | C Loss: -0.622647\n",
      "06/29/2022 09:35:51 - INFO - __main__ -   Text: [\"He's a 6th grade student at Richmond High School.\"]\n",
      "06/29/2022 09:35:52 - INFO - __main__ -   Epoch: 156 | Batch: 5400/10001 (54%) | G Loss: 3.204434 | C Loss: -0.431237\n",
      "06/29/2022 09:35:52 - INFO - __main__ -   Text: ['This enhances the feelings and buried history of childhood.']\n",
      "06/29/2022 09:35:53 - INFO - __main__ -   Epoch: 156 | Batch: 6000/10001 (60%) | G Loss: 3.319263 | C Loss: -0.456174\n",
      "06/29/2022 09:35:53 - INFO - __main__ -   Text: ['There are 250 national champions.']\n",
      "06/29/2022 09:35:54 - INFO - __main__ -   Epoch: 156 | Batch: 6600/10001 (66%) | G Loss: 2.657386 | C Loss: -0.548446\n",
      "06/29/2022 09:35:54 - INFO - __main__ -   Text: ['Cumulative necessarily is \"caude I\"\" etc.']\n",
      "06/29/2022 09:35:55 - INFO - __main__ -   Epoch: 156 | Batch: 7200/10001 (72%) | G Loss: 2.518963 | C Loss: -0.524940\n",
      "06/29/2022 09:35:55 - INFO - __main__ -   Text: ['Rediscovering Yellow is not limited to technology patents, thanks to laws and government research.']\n",
      "06/29/2022 09:35:56 - INFO - __main__ -   Epoch: 156 | Batch: 7800/10001 (78%) | G Loss: 2.593885 | C Loss: -0.437249\n",
      "06/29/2022 09:35:57 - INFO - __main__ -   Text: ['Intriguingly, the Midnight Six is one of the five holiday tricks.']\n",
      "06/29/2022 09:35:58 - INFO - __main__ -   Epoch: 156 | Batch: 8400/10001 (84%) | G Loss: 2.723790 | C Loss: -0.369572\n",
      "06/29/2022 09:35:58 - INFO - __main__ -   Text: ['They should not be stoned so they are made to feel unreachable with no reason beyond self-interest.\"']\n",
      "06/29/2022 09:35:59 - INFO - __main__ -   Epoch: 156 | Batch: 9000/10001 (90%) | G Loss: 3.083456 | C Loss: -0.535254\n",
      "06/29/2022 09:35:59 - INFO - __main__ -   Text: ['In fact the pro-lifers hate us !']\n",
      "06/29/2022 09:36:00 - INFO - __main__ -   Epoch: 156 | Batch: 9600/10001 (96%) | G Loss: 2.875651 | C Loss: -0.428881\n",
      "06/29/2022 09:36:00 - INFO - __main__ -   Text: ['It is an ancient text of the Roman Empire.']\n",
      "06/29/2022 09:36:01 - INFO - __main__ -   * (Train) Epoch: 156 | G Loss: 2.8502 | C Loss: -0.4761 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 09:36:10 - INFO - __main__ -   Bleu-2:0.197 | B-Bleu-2:0.267\n",
      "06/29/2022 09:36:10 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4644476344720818\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 157 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:39:39 - INFO - __main__ -   Epoch: 157 | Batch: 0/10001 (0%) | G Loss: 2.759887 | C Loss: -0.425250\n",
      "06/29/2022 09:39:39 - INFO - __main__ -   Text: ['It may be viable to make synthetic drugs.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 4.048\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:39:40 - INFO - __main__ -   Epoch: 157 | Batch: 600/10001 (6%) | G Loss: 2.847754 | C Loss: -0.333610\n",
      "06/29/2022 09:39:40 - INFO - __main__ -   Text: ['These are also anti-freedom theories (see here).']\n",
      "06/29/2022 09:39:41 - INFO - __main__ -   Epoch: 157 | Batch: 1200/10001 (12%) | G Loss: 3.239448 | C Loss: -0.220604\n",
      "06/29/2022 09:39:41 - INFO - __main__ -   Text: ['Ocelot describes himself as a \"Unitarian.\"']\n",
      "06/29/2022 09:39:42 - INFO - __main__ -   Epoch: 157 | Batch: 1800/10001 (18%) | G Loss: 3.270614 | C Loss: -0.460741\n",
      "06/29/2022 09:39:42 - INFO - __main__ -   Text: ['Margaret Adams is an American fictional agent as well as a traveler in Africa.']\n",
      "06/29/2022 09:39:43 - INFO - __main__ -   Epoch: 157 | Batch: 2400/10001 (24%) | G Loss: 2.742373 | C Loss: -0.310716\n",
      "06/29/2022 09:39:43 - INFO - __main__ -   Text: ['Bubble spangles has a soluble cholesterol which thus pumps out more aromatic.']\n",
      "06/29/2022 09:39:44 - INFO - __main__ -   Epoch: 157 | Batch: 3000/10001 (30%) | G Loss: 2.487590 | C Loss: -0.371194\n",
      "06/29/2022 09:39:44 - INFO - __main__ -   Text: ['At 168.51 notes card today moonshot serious cricket is coming.']\n",
      "06/29/2022 09:39:45 - INFO - __main__ -   Epoch: 157 | Batch: 3600/10001 (36%) | G Loss: 2.321126 | C Loss: -0.487542\n",
      "06/29/2022 09:39:45 - INFO - __main__ -   Text: ['Neoginism is not the same as gravitational contraction anyway.']\n",
      "06/29/2022 09:39:46 - INFO - __main__ -   Epoch: 157 | Batch: 4200/10001 (42%) | G Loss: 2.694116 | C Loss: -0.391910\n",
      "06/29/2022 09:39:46 - INFO - __main__ -   Text: ['Each fragment is trying to understand one another.']\n",
      "06/29/2022 09:39:47 - INFO - __main__ -   Epoch: 157 | Batch: 4800/10001 (48%) | G Loss: 2.844621 | C Loss: -0.787340\n",
      "06/29/2022 09:39:48 - INFO - __main__ -   Text: ['The bird will say, \"I just saw the eye bug.\"']\n",
      "06/29/2022 09:39:49 - INFO - __main__ -   Epoch: 157 | Batch: 5400/10001 (54%) | G Loss: 2.869453 | C Loss: -0.635234\n",
      "06/29/2022 09:39:49 - INFO - __main__ -   Text: ['In Greece, he spends his childhood as a trained amateur boxer who commends himself as the \"go-to sport']\n",
      "06/29/2022 09:39:50 - INFO - __main__ -   Epoch: 157 | Batch: 6000/10001 (60%) | G Loss: 2.920408 | C Loss: -0.409573\n",
      "06/29/2022 09:39:50 - INFO - __main__ -   Text: ['The song ends with \"Yuri.\"']\n",
      "06/29/2022 09:39:51 - INFO - __main__ -   Epoch: 157 | Batch: 6600/10001 (66%) | G Loss: 2.726821 | C Loss: -0.649371\n",
      "06/29/2022 09:39:51 - INFO - __main__ -   Text: ['A band-bucket hitter can be severely tainted with the word .']\n",
      "06/29/2022 09:39:52 - INFO - __main__ -   Epoch: 157 | Batch: 7200/10001 (72%) | G Loss: 2.656595 | C Loss: -0.459146\n",
      "06/29/2022 09:39:52 - INFO - __main__ -   Text: [\"Shortly after Larry's built a website on Google, I blame him for abducting me.\"]\n",
      "06/29/2022 09:39:53 - INFO - __main__ -   Epoch: 157 | Batch: 7800/10001 (78%) | G Loss: 2.699283 | C Loss: -0.457175\n",
      "06/29/2022 09:39:53 - INFO - __main__ -   Text: ['In other words, pancakes are a good palette for digestive health!']\n",
      "06/29/2022 09:39:54 - INFO - __main__ -   Epoch: 157 | Batch: 8400/10001 (84%) | G Loss: 2.820216 | C Loss: -0.512332\n",
      "06/29/2022 09:39:54 - INFO - __main__ -   Text: ['He is an intelligent compulsive author who knows the best ways to draw.']\n",
      "06/29/2022 09:39:55 - INFO - __main__ -   Epoch: 157 | Batch: 9000/10001 (90%) | G Loss: 2.913332 | C Loss: -0.423180\n",
      "06/29/2022 09:39:55 - INFO - __main__ -   Text: ['Return then to its point.\"']\n",
      "06/29/2022 09:39:56 - INFO - __main__ -   Epoch: 157 | Batch: 9600/10001 (96%) | G Loss: 3.024201 | C Loss: -0.654892\n",
      "06/29/2022 09:39:56 - INFO - __main__ -   Text: ['Russell and Zebediah are among the robbers.']\n",
      "06/29/2022 09:39:57 - INFO - __main__ -   * (Train) Epoch: 157 | G Loss: 2.7621 | C Loss: -0.4675 | Updates G: 41 | Updates C: 792\n",
      "06/29/2022 09:40:06 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.242\n",
      "06/29/2022 09:40:06 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4461777517391754\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 158 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:43:38 - INFO - __main__ -   Epoch: 158 | Batch: 0/10001 (0%) | G Loss: 2.980602 | C Loss: -0.603756\n",
      "06/29/2022 09:43:38 - INFO - __main__ -   Text: ['Other notable figures include John Jay.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 4.078\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:43:39 - INFO - __main__ -   Epoch: 158 | Batch: 600/10001 (6%) | G Loss: 2.860651 | C Loss: -0.381392\n",
      "06/29/2022 09:43:39 - INFO - __main__ -   Text: ['Already, Billy wants to stop dating.']\n",
      "06/29/2022 09:43:40 - INFO - __main__ -   Epoch: 158 | Batch: 1200/10001 (12%) | G Loss: 2.863957 | C Loss: -0.670991\n",
      "06/29/2022 09:43:40 - INFO - __main__ -   Text: ['Holy Power Level 4!']\n",
      "06/29/2022 09:43:41 - INFO - __main__ -   Epoch: 158 | Batch: 1800/10001 (18%) | G Loss: 2.804867 | C Loss: -0.617492\n",
      "06/29/2022 09:43:41 - INFO - __main__ -   Text: ['Matt itself expresses humor at the worst times, and is thinking of making kayaking.']\n",
      "06/29/2022 09:43:42 - INFO - __main__ -   Epoch: 158 | Batch: 2400/10001 (24%) | G Loss: 2.764601 | C Loss: -0.439620\n",
      "06/29/2022 09:43:43 - INFO - __main__ -   Text: ['Visibility teams treat Lee as if he, the press, and the media.']\n",
      "06/29/2022 09:43:44 - INFO - __main__ -   Epoch: 158 | Batch: 3000/10001 (30%) | G Loss: 2.766215 | C Loss: -0.315294\n",
      "06/29/2022 09:43:44 - INFO - __main__ -   Text: ['Most jammers are only capable of reasoning in terms its genotype.']\n",
      "06/29/2022 09:43:45 - INFO - __main__ -   Epoch: 158 | Batch: 3600/10001 (36%) | G Loss: 3.022779 | C Loss: -0.488449\n",
      "06/29/2022 09:43:45 - INFO - __main__ -   Text: ['\"Dynamite\".']\n",
      "06/29/2022 09:43:46 - INFO - __main__ -   Epoch: 158 | Batch: 4200/10001 (42%) | G Loss: 3.107898 | C Loss: -0.537258\n",
      "06/29/2022 09:43:46 - INFO - __main__ -   Text: ['Mapo hierarchises its classification.']\n",
      "06/29/2022 09:43:47 - INFO - __main__ -   Epoch: 158 | Batch: 4800/10001 (48%) | G Loss: 3.569874 | C Loss: -0.694984\n",
      "06/29/2022 09:43:47 - INFO - __main__ -   Text: [\"Some people are entitled to speak, they don't pretend or whatnot.\"]\n",
      "06/29/2022 09:43:48 - INFO - __main__ -   Epoch: 158 | Batch: 5400/10001 (54%) | G Loss: 3.512528 | C Loss: -0.440453\n",
      "06/29/2022 09:43:48 - INFO - __main__ -   Text: ['Vijay is reacting against the idea of inherent power.']\n",
      "06/29/2022 09:43:49 - INFO - __main__ -   Epoch: 158 | Batch: 6000/10001 (60%) | G Loss: 3.293511 | C Loss: -0.570603\n",
      "06/29/2022 09:43:49 - INFO - __main__ -   Text: [\"The program's official target time is on January 9 a.s.\"]\n",
      "06/29/2022 09:43:50 - INFO - __main__ -   Epoch: 158 | Batch: 6600/10001 (66%) | G Loss: 2.982522 | C Loss: -0.443722\n",
      "06/29/2022 09:43:50 - INFO - __main__ -   Text: ['This is bad for you.']\n",
      "06/29/2022 09:43:51 - INFO - __main__ -   Epoch: 158 | Batch: 7200/10001 (72%) | G Loss: 2.781255 | C Loss: -0.274516\n",
      "06/29/2022 09:43:51 - INFO - __main__ -   Text: ['Sneaks them out but I guess it is a bomb.']\n",
      "06/29/2022 09:43:52 - INFO - __main__ -   Epoch: 158 | Batch: 7800/10001 (78%) | G Loss: 2.446413 | C Loss: -0.479205\n",
      "06/29/2022 09:43:52 - INFO - __main__ -   Text: ['The Underground Traveler #153.']\n",
      "06/29/2022 09:43:53 - INFO - __main__ -   Epoch: 158 | Batch: 8400/10001 (84%) | G Loss: 2.902915 | C Loss: -0.413555\n",
      "06/29/2022 09:43:53 - INFO - __main__ -   Text: ['In theory at least, it seems to end up being a gay man.\"']\n",
      "06/29/2022 09:43:54 - INFO - __main__ -   Epoch: 158 | Batch: 9000/10001 (90%) | G Loss: 2.744067 | C Loss: -0.618665\n",
      "06/29/2022 09:43:54 - INFO - __main__ -   Text: ['The music chorus repeats exactly half of the lyric.']\n",
      "06/29/2022 09:43:55 - INFO - __main__ -   Epoch: 158 | Batch: 9600/10001 (96%) | G Loss: 2.675983 | C Loss: -0.281444\n",
      "06/29/2022 09:43:56 - INFO - __main__ -   Text: ['\"Brian Goldsmith\" claims it.']\n",
      "06/29/2022 09:43:56 - INFO - __main__ -   * (Train) Epoch: 158 | G Loss: 2.8364 | C Loss: -0.4553 | Updates G: 36 | Updates C: 797\n",
      "06/29/2022 09:44:05 - INFO - __main__ -   Bleu-2:0.216 | B-Bleu-2:0.249\n",
      "06/29/2022 09:44:05 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_12.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46560327799972645\n",
      "Train file used is number 12\n",
      "../../yahoo/subdivided_large/train_12.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 159 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:40.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:57.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:14.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:30.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:46.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:02.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:18\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:47:24 - INFO - __main__ -   Epoch: 159 | Batch: 0/10001 (0%) | G Loss: 2.769810 | C Loss: -0.453651\n",
      "06/29/2022 09:47:24 - INFO - __main__ -   Text: ['The most common application is calculation.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 4.017\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:47:25 - INFO - __main__ -   Epoch: 159 | Batch: 600/10001 (6%) | G Loss: 3.013135 | C Loss: -0.515383\n",
      "06/29/2022 09:47:25 - INFO - __main__ -   Text: ['The name is simple for anyone who feels like trying super high-level science.']\n",
      "06/29/2022 09:47:26 - INFO - __main__ -   Epoch: 159 | Batch: 1200/10001 (12%) | G Loss: 3.363106 | C Loss: -0.507393\n",
      "06/29/2022 09:47:26 - INFO - __main__ -   Text: ['Maggie is an evil person, and Helen is disturbed.']\n",
      "06/29/2022 09:47:27 - INFO - __main__ -   Epoch: 159 | Batch: 1800/10001 (18%) | G Loss: 3.613801 | C Loss: -0.576690\n",
      "06/29/2022 09:47:28 - INFO - __main__ -   Text: ['Newman uses racism to find out what German parents do sometimes.']\n",
      "06/29/2022 09:47:29 - INFO - __main__ -   Epoch: 159 | Batch: 2400/10001 (24%) | G Loss: 3.305161 | C Loss: -0.398046\n",
      "06/29/2022 09:47:29 - INFO - __main__ -   Text: ['As for the mass transit network, the military might be interested.']\n",
      "06/29/2022 09:47:30 - INFO - __main__ -   Epoch: 159 | Batch: 3000/10001 (30%) | G Loss: 2.711920 | C Loss: -0.411564\n",
      "06/29/2022 09:47:30 - INFO - __main__ -   Text: [\"It's all for Saturn.\"]\n",
      "06/29/2022 09:47:31 - INFO - __main__ -   Epoch: 159 | Batch: 3600/10001 (36%) | G Loss: 2.328667 | C Loss: -0.444419\n",
      "06/29/2022 09:47:31 - INFO - __main__ -   Text: ['\"Shadow Lord!\"']\n",
      "06/29/2022 09:47:32 - INFO - __main__ -   Epoch: 159 | Batch: 4200/10001 (42%) | G Loss: 2.506011 | C Loss: -0.547091\n",
      "06/29/2022 09:47:32 - INFO - __main__ -   Text: ['This secret method of religion is called.']\n",
      "06/29/2022 09:47:33 - INFO - __main__ -   Epoch: 159 | Batch: 4800/10001 (48%) | G Loss: 2.890139 | C Loss: -0.634512\n",
      "06/29/2022 09:47:33 - INFO - __main__ -   Text: ['This institution is focused upon \"musical instruction for students and faculty alike.\"']\n",
      "06/29/2022 09:47:34 - INFO - __main__ -   Epoch: 159 | Batch: 5400/10001 (54%) | G Loss: 3.206494 | C Loss: -0.464736\n",
      "06/29/2022 09:47:34 - INFO - __main__ -   Text: ['Firstly, you will not know that soothsayer.\"']\n",
      "06/29/2022 09:47:35 - INFO - __main__ -   Epoch: 159 | Batch: 6000/10001 (60%) | G Loss: 3.381242 | C Loss: -0.460128\n",
      "06/29/2022 09:47:35 - INFO - __main__ -   Text: ['Things you might say or help is a job interview.']\n",
      "06/29/2022 09:47:36 - INFO - __main__ -   Epoch: 159 | Batch: 6600/10001 (66%) | G Loss: 3.121508 | C Loss: -0.469071\n",
      "06/29/2022 09:47:36 - INFO - __main__ -   Text: ['Unstable outside the ship.']\n",
      "06/29/2022 09:47:37 - INFO - __main__ -   Epoch: 159 | Batch: 7200/10001 (72%) | G Loss: 3.005301 | C Loss: -0.541573\n",
      "06/29/2022 09:47:37 - INFO - __main__ -   Text: ['Olympic swimming is a risky habit because most mortals swim for less than an hour.']\n",
      "06/29/2022 09:47:38 - INFO - __main__ -   Epoch: 159 | Batch: 7800/10001 (78%) | G Loss: 2.879153 | C Loss: -0.365578\n",
      "06/29/2022 09:47:38 - INFO - __main__ -   Text: ['A genderless man is considered frivolous.']\n",
      "06/29/2022 09:47:39 - INFO - __main__ -   Epoch: 159 | Batch: 8400/10001 (84%) | G Loss: 2.786695 | C Loss: -0.434497\n",
      "06/29/2022 09:47:39 - INFO - __main__ -   Text: ['At public discussion, it is possible to discuss the process of conjuring.']\n",
      "06/29/2022 09:47:40 - INFO - __main__ -   Epoch: 159 | Batch: 9000/10001 (90%) | G Loss: 2.904670 | C Loss: -0.316332\n",
      "06/29/2022 09:47:41 - INFO - __main__ -   Text: ['Science has learned to bury ants by swimming through sand throughout the day.']\n",
      "06/29/2022 09:47:42 - INFO - __main__ -   Epoch: 159 | Batch: 9600/10001 (96%) | G Loss: 2.728327 | C Loss: -0.314307\n",
      "06/29/2022 09:47:42 - INFO - __main__ -   Text: ['If this poem can consume you, you could borrow Shakespeare\".']\n",
      "06/29/2022 09:47:42 - INFO - __main__ -   * (Train) Epoch: 159 | G Loss: 2.8785 | C Loss: -0.4579 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 09:47:51 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.244\n",
      "06/29/2022 09:47:51 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44775511544185376\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 160 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:51:16 - INFO - __main__ -   Epoch: 160 | Batch: 0/10001 (0%) | G Loss: 2.579393 | C Loss: -0.378593\n",
      "06/29/2022 09:51:16 - INFO - __main__ -   Text: ['\"plat\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.510\n",
      "  Test Loss: 3.944\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:51:17 - INFO - __main__ -   Epoch: 160 | Batch: 600/10001 (6%) | G Loss: 2.772052 | C Loss: -0.450491\n",
      "06/29/2022 09:51:17 - INFO - __main__ -   Text: ['Some fighters consider themselves to be superheroes.']\n",
      "06/29/2022 09:51:18 - INFO - __main__ -   Epoch: 160 | Batch: 1200/10001 (12%) | G Loss: 2.930008 | C Loss: -0.625263\n",
      "06/29/2022 09:51:18 - INFO - __main__ -   Text: ['Datocyphya super Treatment.']\n",
      "06/29/2022 09:51:19 - INFO - __main__ -   Epoch: 160 | Batch: 1800/10001 (18%) | G Loss: 2.804099 | C Loss: -0.374135\n",
      "06/29/2022 09:51:19 - INFO - __main__ -   Text: ['To do that in this town, we all fervently follow.\"']\n",
      "06/29/2022 09:51:20 - INFO - __main__ -   Epoch: 160 | Batch: 2400/10001 (24%) | G Loss: 3.444529 | C Loss: -0.588879\n",
      "06/29/2022 09:51:21 - INFO - __main__ -   Text: ['I have friends in Afghanistan who are all right, but they are totally against any idea they might have.']\n",
      "06/29/2022 09:51:21 - INFO - __main__ -   Epoch: 160 | Batch: 3000/10001 (30%) | G Loss: 3.368123 | C Loss: -0.508512\n",
      "06/29/2022 09:51:22 - INFO - __main__ -   Text: ['Her agency is hard as hell to achieve, but glorifies it.']\n",
      "06/29/2022 09:51:23 - INFO - __main__ -   Epoch: 160 | Batch: 3600/10001 (36%) | G Loss: 3.052436 | C Loss: -0.524354\n",
      "06/29/2022 09:51:23 - INFO - __main__ -   Text: ['This is a dead call to the birds.']\n",
      "06/29/2022 09:51:24 - INFO - __main__ -   Epoch: 160 | Batch: 4200/10001 (42%) | G Loss: 2.984854 | C Loss: -0.584820\n",
      "06/29/2022 09:51:24 - INFO - __main__ -   Text: ['This makes soma sound when we ride.\"\"']\n",
      "06/29/2022 09:51:25 - INFO - __main__ -   Epoch: 160 | Batch: 4800/10001 (48%) | G Loss: 2.908818 | C Loss: -0.501588\n",
      "06/29/2022 09:51:25 - INFO - __main__ -   Text: ['LL.']\n",
      "06/29/2022 09:51:26 - INFO - __main__ -   Epoch: 160 | Batch: 5400/10001 (54%) | G Loss: 2.601871 | C Loss: -0.347968\n",
      "06/29/2022 09:51:26 - INFO - __main__ -   Text: [\"bushie's dislike of kade ends up being more mutual.\"]\n",
      "06/29/2022 09:51:27 - INFO - __main__ -   Epoch: 160 | Batch: 6000/10001 (60%) | G Loss: 2.517810 | C Loss: -0.368698\n",
      "06/29/2022 09:51:27 - INFO - __main__ -   Text: ['They care about this more.']\n",
      "06/29/2022 09:51:28 - INFO - __main__ -   Epoch: 160 | Batch: 6600/10001 (66%) | G Loss: 3.158923 | C Loss: -0.421572\n",
      "06/29/2022 09:51:28 - INFO - __main__ -   Text: [\"I'm like a scattered shopping card reader, short of a post office.\"]\n",
      "06/29/2022 09:51:29 - INFO - __main__ -   Epoch: 160 | Batch: 7200/10001 (72%) | G Loss: 4.046523 | C Loss: -0.775780\n",
      "06/29/2022 09:51:29 - INFO - __main__ -   Text: ['By contrast, a few other tablets which can track cloud pollutant emissions.']\n",
      "06/29/2022 09:51:30 - INFO - __main__ -   Epoch: 160 | Batch: 7800/10001 (78%) | G Loss: 3.886094 | C Loss: -0.487922\n",
      "06/29/2022 09:51:30 - INFO - __main__ -   Text: ['From your point of view, Bond does not favour me.\"']\n",
      "06/29/2022 09:51:31 - INFO - __main__ -   Epoch: 160 | Batch: 8400/10001 (84%) | G Loss: 3.414492 | C Loss: -0.412214\n",
      "06/29/2022 09:51:31 - INFO - __main__ -   Text: ['The Fromnowatian 190 follows.']\n",
      "06/29/2022 09:51:32 - INFO - __main__ -   Epoch: 160 | Batch: 9000/10001 (90%) | G Loss: 2.917022 | C Loss: -0.440250\n",
      "06/29/2022 09:51:32 - INFO - __main__ -   Text: ['It is the thought to ride a horse that scares me.\"']\n",
      "06/29/2022 09:51:33 - INFO - __main__ -   Epoch: 160 | Batch: 9600/10001 (96%) | G Loss: 2.757212 | C Loss: -0.338278\n",
      "06/29/2022 09:51:34 - INFO - __main__ -   Text: ['The Sun is the star, the Diamond is the deflection mechanism.']\n",
      "06/29/2022 09:51:34 - INFO - __main__ -   * (Train) Epoch: 160 | G Loss: 2.8696 | C Loss: -0.4758 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 09:51:43 - INFO - __main__ -   Bleu-2:0.186 | B-Bleu-2:0.255\n",
      "06/29/2022 09:51:43 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_14.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4404988343299987\n",
      "Train file used is number 14\n",
      "../../yahoo/subdivided_large/train_14.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 161 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:36.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:55:16 - INFO - __main__ -   Epoch: 161 | Batch: 0/10001 (0%) | G Loss: 3.095680 | C Loss: -0.505191\n",
      "06/29/2022 09:55:16 - INFO - __main__ -   Text: ['\", \"的»\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 4.017\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:55:17 - INFO - __main__ -   Epoch: 161 | Batch: 600/10001 (6%) | G Loss: 2.664298 | C Loss: -0.502837\n",
      "06/29/2022 09:55:17 - INFO - __main__ -   Text: ['The project manual is npm node verb with .']\n",
      "06/29/2022 09:55:18 - INFO - __main__ -   Epoch: 161 | Batch: 1200/10001 (12%) | G Loss: 2.475726 | C Loss: -0.424489\n",
      "06/29/2022 09:55:18 - INFO - __main__ -   Text: ['Working economy is an employment problem and like other countries doing nothing such as.']\n",
      "06/29/2022 09:55:19 - INFO - __main__ -   Epoch: 161 | Batch: 1800/10001 (18%) | G Loss: 2.757132 | C Loss: -0.462709\n",
      "06/29/2022 09:55:19 - INFO - __main__ -   Text: ['Clausen denies this and says the proper name is Waggonerst.']\n",
      "06/29/2022 09:55:20 - INFO - __main__ -   Epoch: 161 | Batch: 2400/10001 (24%) | G Loss: 2.727562 | C Loss: -0.398858\n",
      "06/29/2022 09:55:20 - INFO - __main__ -   Text: ['Custom 16-bit 10MHz reflections or full-width Fourier transformers.']\n",
      "06/29/2022 09:55:21 - INFO - __main__ -   Epoch: 161 | Batch: 3000/10001 (30%) | G Loss: 2.944142 | C Loss: -0.440474\n",
      "06/29/2022 09:55:21 - INFO - __main__ -   Text: ['This is the way sport normally works.\"']\n",
      "06/29/2022 09:55:22 - INFO - __main__ -   Epoch: 161 | Batch: 3600/10001 (36%) | G Loss: 3.230671 | C Loss: -0.410082\n",
      "06/29/2022 09:55:22 - INFO - __main__ -   Text: ['Dave Cocks PC blackjack game...']\n",
      "06/29/2022 09:55:23 - INFO - __main__ -   Epoch: 161 | Batch: 4200/10001 (42%) | G Loss: 3.165061 | C Loss: -0.367556\n",
      "06/29/2022 09:55:23 - INFO - __main__ -   Text: ['Visitors can choose \"Wolfaar Beenreren Dart\" as the reference.']\n",
      "06/29/2022 09:55:24 - INFO - __main__ -   Epoch: 161 | Batch: 4800/10001 (48%) | G Loss: 3.011113 | C Loss: -0.523935\n",
      "06/29/2022 09:55:24 - INFO - __main__ -   Text: ['This is a dual-fuel marketplace as it permits high-volume oil travel from outside.']\n",
      "06/29/2022 09:55:25 - INFO - __main__ -   Epoch: 161 | Batch: 5400/10001 (54%) | G Loss: 2.594592 | C Loss: -0.387218\n",
      "06/29/2022 09:55:26 - INFO - __main__ -   Text: ['And yet it takes care of utility.']\n",
      "06/29/2022 09:55:27 - INFO - __main__ -   Epoch: 161 | Batch: 6000/10001 (60%) | G Loss: 2.494523 | C Loss: -0.374569\n",
      "06/29/2022 09:55:27 - INFO - __main__ -   Text: ['A comic book named \"Queen-Popping Paper Killer\".']\n",
      "06/29/2022 09:55:28 - INFO - __main__ -   Epoch: 161 | Batch: 6600/10001 (66%) | G Loss: 2.529619 | C Loss: -0.441974\n",
      "06/29/2022 09:55:28 - INFO - __main__ -   Text: ['It is prevalent.']\n",
      "06/29/2022 09:55:29 - INFO - __main__ -   Epoch: 161 | Batch: 7200/10001 (72%) | G Loss: 2.633079 | C Loss: -0.540627\n",
      "06/29/2022 09:55:29 - INFO - __main__ -   Text: ['he sees no benefit.\"']\n",
      "06/29/2022 09:55:30 - INFO - __main__ -   Epoch: 161 | Batch: 7800/10001 (78%) | G Loss: 2.803132 | C Loss: -0.526551\n",
      "06/29/2022 09:55:30 - INFO - __main__ -   Text: ['There may be a variety of Hindu beliefs.']\n",
      "06/29/2022 09:55:31 - INFO - __main__ -   Epoch: 161 | Batch: 8400/10001 (84%) | G Loss: 2.771720 | C Loss: -0.330374\n",
      "06/29/2022 09:55:31 - INFO - __main__ -   Text: ['The game gets better and better every time.']\n",
      "06/29/2022 09:55:32 - INFO - __main__ -   Epoch: 161 | Batch: 9000/10001 (90%) | G Loss: 2.935650 | C Loss: -0.405504\n",
      "06/29/2022 09:55:32 - INFO - __main__ -   Text: ['Orfe flyer is mugger.']\n",
      "06/29/2022 09:55:33 - INFO - __main__ -   Epoch: 161 | Batch: 9600/10001 (96%) | G Loss: 3.370637 | C Loss: -0.452586\n",
      "06/29/2022 09:55:33 - INFO - __main__ -   Text: [\"It's when Gordon discover a bomb plot and a comedy track.\"]\n",
      "06/29/2022 09:55:34 - INFO - __main__ -   * (Train) Epoch: 161 | G Loss: 2.8358 | C Loss: -0.4664 | Updates G: 33 | Updates C: 800\n",
      "06/29/2022 09:55:43 - INFO - __main__ -   Bleu-2:0.206 | B-Bleu-2:0.272\n",
      "06/29/2022 09:55:43 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47818721809629827\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 162 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:59:12 - INFO - __main__ -   Epoch: 162 | Batch: 0/10001 (0%) | G Loss: 3.192788 | C Loss: -0.348475\n",
      "06/29/2022 09:59:12 - INFO - __main__ -   Text: ['The fearful can respond by sucking on the food.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.071\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 09:59:13 - INFO - __main__ -   Epoch: 162 | Batch: 600/10001 (6%) | G Loss: 2.683100 | C Loss: -0.252208\n",
      "06/29/2022 09:59:13 - INFO - __main__ -   Text: ['\"I love to read with (some) women.\"']\n",
      "06/29/2022 09:59:14 - INFO - __main__ -   Epoch: 162 | Batch: 1200/10001 (12%) | G Loss: 2.622493 | C Loss: -0.556374\n",
      "06/29/2022 09:59:15 - INFO - __main__ -   Text: ['Some hills have dwarfish pale aree. <PAD> Almost like an English witticant.']\n",
      "06/29/2022 09:59:15 - INFO - __main__ -   Epoch: 162 | Batch: 1800/10001 (18%) | G Loss: 2.850721 | C Loss: -0.434892\n",
      "06/29/2022 09:59:16 - INFO - __main__ -   Text: ['SP and SP principles guide several different types of sports.']\n",
      "06/29/2022 09:59:17 - INFO - __main__ -   Epoch: 162 | Batch: 2400/10001 (24%) | G Loss: 2.928957 | C Loss: -0.476334\n",
      "06/29/2022 09:59:17 - INFO - __main__ -   Text: ['Rabbi is half-speech.\"']\n",
      "06/29/2022 09:59:18 - INFO - __main__ -   Epoch: 162 | Batch: 3000/10001 (30%) | G Loss: 2.846962 | C Loss: -0.081788\n",
      "06/29/2022 09:59:18 - INFO - __main__ -   Text: ['His sense of humor is impossible.']\n",
      "06/29/2022 09:59:19 - INFO - __main__ -   Epoch: 162 | Batch: 3600/10001 (36%) | G Loss: 3.535216 | C Loss: -0.526372\n",
      "06/29/2022 09:59:19 - INFO - __main__ -   Text: ['Since WSL does not allow for insider quotes, analysts may be extrapolated as WordRank.']\n",
      "06/29/2022 09:59:20 - INFO - __main__ -   Epoch: 162 | Batch: 4200/10001 (42%) | G Loss: 2.415978 | C Loss: -0.482336\n",
      "06/29/2022 09:59:20 - INFO - __main__ -   Text: ['Besides, the ruling authority of a sovereign.\"']\n",
      "06/29/2022 09:59:21 - INFO - __main__ -   Epoch: 162 | Batch: 4800/10001 (48%) | G Loss: 2.163605 | C Loss: -0.387779\n",
      "06/29/2022 09:59:21 - INFO - __main__ -   Text: ['I encourage a general treatise about microworship.']\n",
      "06/29/2022 09:59:22 - INFO - __main__ -   Epoch: 162 | Batch: 5400/10001 (54%) | G Loss: 2.868891 | C Loss: -0.457911\n",
      "06/29/2022 09:59:22 - INFO - __main__ -   Text: ['It can sometimes be hard to find someone who doesn\\'t enjoy it.\"']\n",
      "06/29/2022 09:59:23 - INFO - __main__ -   Epoch: 162 | Batch: 6000/10001 (60%) | G Loss: 3.380616 | C Loss: -0.383516\n",
      "06/29/2022 09:59:23 - INFO - __main__ -   Text: ['There are not any single change in the ways of time.\"']\n",
      "06/29/2022 09:59:24 - INFO - __main__ -   Epoch: 162 | Batch: 6600/10001 (66%) | G Loss: 3.489552 | C Loss: -0.510803\n",
      "06/29/2022 09:59:24 - INFO - __main__ -   Text: [\"He'll guess the rate of rainfall in the night.\"]\n",
      "06/29/2022 09:59:25 - INFO - __main__ -   Epoch: 162 | Batch: 7200/10001 (72%) | G Loss: 3.242854 | C Loss: -0.410135\n",
      "06/29/2022 09:59:25 - INFO - __main__ -   Text: ['in this XSI approach.']\n",
      "06/29/2022 09:59:26 - INFO - __main__ -   Epoch: 162 | Batch: 7800/10001 (78%) | G Loss: 3.053247 | C Loss: -0.670947\n",
      "06/29/2022 09:59:26 - INFO - __main__ -   Text: ['In addition to being LGBT, Georgetown has \"covered\" LGBT teenagers.']\n",
      "06/29/2022 09:59:27 - INFO - __main__ -   Epoch: 162 | Batch: 8400/10001 (84%) | G Loss: 2.860934 | C Loss: -0.430530\n",
      "06/29/2022 09:59:28 - INFO - __main__ -   Text: ['He is famous for having a students classmate.']\n",
      "06/29/2022 09:59:28 - INFO - __main__ -   Epoch: 162 | Batch: 9000/10001 (90%) | G Loss: 2.689128 | C Loss: -0.474702\n",
      "06/29/2022 09:59:29 - INFO - __main__ -   Text: ['This boy will make it popular.']\n",
      "06/29/2022 09:59:30 - INFO - __main__ -   Epoch: 162 | Batch: 9600/10001 (96%) | G Loss: 2.566979 | C Loss: -0.404365\n",
      "06/29/2022 09:59:30 - INFO - __main__ -   Text: ['They can tinker it up and induct it.']\n",
      "06/29/2022 09:59:30 - INFO - __main__ -   * (Train) Epoch: 162 | G Loss: 2.8036 | C Loss: -0.4527 | Updates G: 45 | Updates C: 788\n",
      "06/29/2022 09:59:39 - INFO - __main__ -   Bleu-2:0.208 | B-Bleu-2:0.265\n",
      "06/29/2022 09:59:39 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4730921657343128\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 163 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:03:05 - INFO - __main__ -   Epoch: 163 | Batch: 0/10001 (0%) | G Loss: 2.823113 | C Loss: -0.371648\n",
      "06/29/2022 10:03:05 - INFO - __main__ -   Text: [\"Strategic warfare has always been the state of affairs of Osborne's country.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 3.977\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:03:06 - INFO - __main__ -   Epoch: 163 | Batch: 600/10001 (6%) | G Loss: 3.165551 | C Loss: -0.387002\n",
      "06/29/2022 10:03:06 - INFO - __main__ -   Text: [\"Simpson's been pleased to learn of the strange ratfolk living in this world.\"]\n",
      "06/29/2022 10:03:07 - INFO - __main__ -   Epoch: 163 | Batch: 1200/10001 (12%) | G Loss: 3.389200 | C Loss: -0.478439\n",
      "06/29/2022 10:03:07 - INFO - __main__ -   Text: ['All ingredientsmith software - either real or invented by Cliepen.']\n",
      "06/29/2022 10:03:08 - INFO - __main__ -   Epoch: 163 | Batch: 1800/10001 (18%) | G Loss: 2.684715 | C Loss: -0.283016\n",
      "06/29/2022 10:03:08 - INFO - __main__ -   Text: ['external lyrics%craw\".']\n",
      "06/29/2022 10:03:09 - INFO - __main__ -   Epoch: 163 | Batch: 2400/10001 (24%) | G Loss: 2.753768 | C Loss: -0.708394\n",
      "06/29/2022 10:03:09 - INFO - __main__ -   Text: ['Usually, it is expected.']\n",
      "06/29/2022 10:03:10 - INFO - __main__ -   Epoch: 163 | Batch: 3000/10001 (30%) | G Loss: 2.481183 | C Loss: -0.413844\n",
      "06/29/2022 10:03:10 - INFO - __main__ -   Text: ['Ducis may be a leftist, as you see.']\n",
      "06/29/2022 10:03:11 - INFO - __main__ -   Epoch: 163 | Batch: 3600/10001 (36%) | G Loss: 2.597035 | C Loss: -0.453912\n",
      "06/29/2022 10:03:11 - INFO - __main__ -   Text: ['Solomon is the Royal fruit of geotypes.']\n",
      "06/29/2022 10:03:12 - INFO - __main__ -   Epoch: 163 | Batch: 4200/10001 (42%) | G Loss: 2.684993 | C Loss: -0.321412\n",
      "06/29/2022 10:03:12 - INFO - __main__ -   Text: ['They use direct motion to trick the plant workers into being fools.']\n",
      "06/29/2022 10:03:13 - INFO - __main__ -   Epoch: 163 | Batch: 4800/10001 (48%) | G Loss: 3.196721 | C Loss: -0.470408\n",
      "06/29/2022 10:03:13 - INFO - __main__ -   Text: ['mongrel responsible.']\n",
      "06/29/2022 10:03:14 - INFO - __main__ -   Epoch: 163 | Batch: 5400/10001 (54%) | G Loss: 3.620703 | C Loss: -0.627166\n",
      "06/29/2022 10:03:15 - INFO - __main__ -   Text: ['This is the story of Tudors great Dad Fortunatley.']\n",
      "06/29/2022 10:03:16 - INFO - __main__ -   Epoch: 163 | Batch: 6000/10001 (60%) | G Loss: 3.639431 | C Loss: -0.635178\n",
      "06/29/2022 10:03:16 - INFO - __main__ -   Text: ['He does not care that the word \"First\" is used in a commercial, or that \"It tastes hip\".']\n",
      "06/29/2022 10:03:17 - INFO - __main__ -   Epoch: 163 | Batch: 6600/10001 (66%) | G Loss: 3.038460 | C Loss: -0.406593\n",
      "06/29/2022 10:03:17 - INFO - __main__ -   Text: ['The future is to become faster and faster at detecting and knowing when something is dangerous.']\n",
      "06/29/2022 10:03:18 - INFO - __main__ -   Epoch: 163 | Batch: 7200/10001 (72%) | G Loss: 2.884552 | C Loss: -0.465328\n",
      "06/29/2022 10:03:18 - INFO - __main__ -   Text: ['When he is on the left you like a: in this case.']\n",
      "06/29/2022 10:03:19 - INFO - __main__ -   Epoch: 163 | Batch: 7800/10001 (78%) | G Loss: 2.666863 | C Loss: -0.396680\n",
      "06/29/2022 10:03:19 - INFO - __main__ -   Text: ['Cavendish leaves secrete cleaning agents.']\n",
      "06/29/2022 10:03:20 - INFO - __main__ -   Epoch: 163 | Batch: 8400/10001 (84%) | G Loss: 2.652030 | C Loss: -0.428680\n",
      "06/29/2022 10:03:20 - INFO - __main__ -   Text: [\"He has it in his mouth, he calls this 'tape of life'.\"]\n",
      "06/29/2022 10:03:21 - INFO - __main__ -   Epoch: 163 | Batch: 9000/10001 (90%) | G Loss: 2.678879 | C Loss: -0.249299\n",
      "06/29/2022 10:03:21 - INFO - __main__ -   Text: ['Average KKAP-andal Superman is a wheelchair wizard with a big brain!']\n",
      "06/29/2022 10:03:22 - INFO - __main__ -   Epoch: 163 | Batch: 9600/10001 (96%) | G Loss: 2.601640 | C Loss: -0.313431\n",
      "06/29/2022 10:03:22 - INFO - __main__ -   Text: ['Even if all three are in favour of a play on the channel.']\n",
      "06/29/2022 10:03:23 - INFO - __main__ -   * (Train) Epoch: 163 | G Loss: 2.8464 | C Loss: -0.4683 | Updates G: 41 | Updates C: 792\n",
      "06/29/2022 10:03:32 - INFO - __main__ -   Bleu-2:0.213 | B-Bleu-2:0.260\n",
      "06/29/2022 10:03:32 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47310529658633765\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 164 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:07:00 - INFO - __main__ -   Epoch: 164 | Batch: 0/10001 (0%) | G Loss: 2.772121 | C Loss: -0.490526\n",
      "06/29/2022 10:07:00 - INFO - __main__ -   Text: ['At number of bars a selected episode is published!']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 3.985\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:07:01 - INFO - __main__ -   Epoch: 164 | Batch: 600/10001 (6%) | G Loss: 3.441788 | C Loss: -0.369204\n",
      "06/29/2022 10:07:01 - INFO - __main__ -   Text: [\"Today's rating is 'sockery'.\"]\n",
      "06/29/2022 10:07:02 - INFO - __main__ -   Epoch: 164 | Batch: 1200/10001 (12%) | G Loss: 3.647903 | C Loss: -0.644599\n",
      "06/29/2022 10:07:02 - INFO - __main__ -   Text: ['Guy Gossett is another outlaw.']\n",
      "06/29/2022 10:07:03 - INFO - __main__ -   Epoch: 164 | Batch: 1800/10001 (18%) | G Loss: 2.834246 | C Loss: -0.693649\n",
      "06/29/2022 10:07:03 - INFO - __main__ -   Text: ['Shut Up is then tended to be a 5-star album?']\n",
      "06/29/2022 10:07:04 - INFO - __main__ -   Epoch: 164 | Batch: 2400/10001 (24%) | G Loss: 2.226541 | C Loss: -0.161181\n",
      "06/29/2022 10:07:05 - INFO - __main__ -   Text: ['The principle of Kerps is to use the IORAS.']\n",
      "06/29/2022 10:07:05 - INFO - __main__ -   Epoch: 164 | Batch: 3000/10001 (30%) | G Loss: 2.541725 | C Loss: -0.600170\n",
      "06/29/2022 10:07:06 - INFO - __main__ -   Text: ['There is no tradition of hiring such bootstrapping as there before.']\n",
      "06/29/2022 10:07:07 - INFO - __main__ -   Epoch: 164 | Batch: 3600/10001 (36%) | G Loss: 2.992584 | C Loss: -0.516353\n",
      "06/29/2022 10:07:07 - INFO - __main__ -   Text: ['The moon orbit is 0.1215944.']\n",
      "06/29/2022 10:07:08 - INFO - __main__ -   Epoch: 164 | Batch: 4200/10001 (42%) | G Loss: 3.147169 | C Loss: -0.484499\n",
      "06/29/2022 10:07:08 - INFO - __main__ -   Text: ['Fundive lenses for blocking and other objects.']\n",
      "06/29/2022 10:07:09 - INFO - __main__ -   Epoch: 164 | Batch: 4800/10001 (48%) | G Loss: 3.431796 | C Loss: -0.570985\n",
      "06/29/2022 10:07:09 - INFO - __main__ -   Text: ['\"net-titanium\" is hard.']\n",
      "06/29/2022 10:07:10 - INFO - __main__ -   Epoch: 164 | Batch: 5400/10001 (54%) | G Loss: 3.351168 | C Loss: -0.438335\n",
      "06/29/2022 10:07:10 - INFO - __main__ -   Text: ['Despite being a celebrity, Chopler has no affection from his students.']\n",
      "06/29/2022 10:07:11 - INFO - __main__ -   Epoch: 164 | Batch: 6000/10001 (60%) | G Loss: 2.816880 | C Loss: -0.419485\n",
      "06/29/2022 10:07:11 - INFO - __main__ -   Text: ['They have claimed to be immune to HIV , HIV/AIDS and AIDS-like symptoms.']\n",
      "06/29/2022 10:07:12 - INFO - __main__ -   Epoch: 164 | Batch: 6600/10001 (66%) | G Loss: 2.717665 | C Loss: -0.396389\n",
      "06/29/2022 10:07:12 - INFO - __main__ -   Text: ['Hermetically, she can find steady water or water from urine.']\n",
      "06/29/2022 10:07:13 - INFO - __main__ -   Epoch: 164 | Batch: 7200/10001 (72%) | G Loss: 3.073232 | C Loss: -0.474225\n",
      "06/29/2022 10:07:13 - INFO - __main__ -   Text: ['In this drug, I am far from a pale brown.\"']\n",
      "06/29/2022 10:07:14 - INFO - __main__ -   Epoch: 164 | Batch: 7800/10001 (78%) | G Loss: 2.704181 | C Loss: -0.370994\n",
      "06/29/2022 10:07:14 - INFO - __main__ -   Text: ['The name \"»maon sitz Iht gem\\'» refers to its source.']\n",
      "06/29/2022 10:07:15 - INFO - __main__ -   Epoch: 164 | Batch: 8400/10001 (84%) | G Loss: 2.386103 | C Loss: -0.325518\n",
      "06/29/2022 10:07:16 - INFO - __main__ -   Text: ['The green jam is one advantage to kale.']\n",
      "06/29/2022 10:07:17 - INFO - __main__ -   Epoch: 164 | Batch: 9000/10001 (90%) | G Loss: 2.423079 | C Loss: -0.423855\n",
      "06/29/2022 10:07:17 - INFO - __main__ -   Text: ['\", again signals the opposite.']\n",
      "06/29/2022 10:07:18 - INFO - __main__ -   Epoch: 164 | Batch: 9600/10001 (96%) | G Loss: 2.389542 | C Loss: -0.378060\n",
      "06/29/2022 10:07:18 - INFO - __main__ -   Text: ['Universities are also interested.']\n",
      "06/29/2022 10:07:18 - INFO - __main__ -   * (Train) Epoch: 164 | G Loss: 2.8080 | C Loss: -0.4623 | Updates G: 42 | Updates C: 791\n",
      "06/29/2022 10:07:27 - INFO - __main__ -   Bleu-2:0.216 | B-Bleu-2:0.259\n",
      "06/29/2022 10:07:27 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_18.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47514511840657037\n",
      "Train file used is number 18\n",
      "../../yahoo/subdivided_large/train_18.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 165 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:16.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:33.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:50.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:10:51 - INFO - __main__ -   Epoch: 165 | Batch: 0/10001 (0%) | G Loss: 2.635324 | C Loss: -0.473614\n",
      "06/29/2022 10:10:52 - INFO - __main__ -   Text: ['Toriko can do anything he wants, just like Japan.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.071\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:10:53 - INFO - __main__ -   Epoch: 165 | Batch: 600/10001 (6%) | G Loss: 3.801701 | C Loss: -0.642054\n",
      "06/29/2022 10:10:53 - INFO - __main__ -   Text: ['Lovecraft symbolizes legitimate anti-nuclear strategy.']\n",
      "06/29/2022 10:10:54 - INFO - __main__ -   Epoch: 165 | Batch: 1200/10001 (12%) | G Loss: 3.986962 | C Loss: -0.443702\n",
      "06/29/2022 10:10:54 - INFO - __main__ -   Text: ['It is called \"Sunary\" (because Earth is like a grinding bullet).']\n",
      "06/29/2022 10:10:55 - INFO - __main__ -   Epoch: 165 | Batch: 1800/10001 (18%) | G Loss: 4.012055 | C Loss: -0.492030\n",
      "06/29/2022 10:10:55 - INFO - __main__ -   Text: ['It could also be some time in Africa.']\n",
      "06/29/2022 10:10:56 - INFO - __main__ -   Epoch: 165 | Batch: 2400/10001 (24%) | G Loss: 3.753688 | C Loss: -0.545454\n",
      "06/29/2022 10:10:56 - INFO - __main__ -   Text: ['\"Journeys are a journey.']\n",
      "06/29/2022 10:10:57 - INFO - __main__ -   Epoch: 165 | Batch: 3000/10001 (30%) | G Loss: 2.914600 | C Loss: -0.607327\n",
      "06/29/2022 10:10:57 - INFO - __main__ -   Text: ['AREND(->null).']\n",
      "06/29/2022 10:10:58 - INFO - __main__ -   Epoch: 165 | Batch: 3600/10001 (36%) | G Loss: 2.237103 | C Loss: -0.390476\n",
      "06/29/2022 10:10:58 - INFO - __main__ -   Text: ['Dilmostor stores the lowest-cost public Digital Electronics.']\n",
      "06/29/2022 10:10:59 - INFO - __main__ -   Epoch: 165 | Batch: 4200/10001 (42%) | G Loss: 2.166662 | C Loss: -0.617988\n",
      "06/29/2022 10:10:59 - INFO - __main__ -   Text: ['When they arrive at home, Finn comes down from the sea somewhere\".']\n",
      "06/29/2022 10:11:00 - INFO - __main__ -   Epoch: 165 | Batch: 4800/10001 (48%) | G Loss: 2.531204 | C Loss: -0.489944\n",
      "06/29/2022 10:11:00 - INFO - __main__ -   Text: ['Brochner does indeed use Blackberry.']\n",
      "06/29/2022 10:11:01 - INFO - __main__ -   Epoch: 165 | Batch: 5400/10001 (54%) | G Loss: 2.953097 | C Loss: -0.428570\n",
      "06/29/2022 10:11:01 - INFO - __main__ -   Text: ['Always assume sequential processing.']\n",
      "06/29/2022 10:11:02 - INFO - __main__ -   Epoch: 165 | Batch: 6000/10001 (60%) | G Loss: 3.414189 | C Loss: -0.529924\n",
      "06/29/2022 10:11:02 - INFO - __main__ -   Text: [\"Several authors call it 'Wildogi' from the whole book.\"]\n",
      "06/29/2022 10:11:03 - INFO - __main__ -   Epoch: 165 | Batch: 6600/10001 (66%) | G Loss: 3.162633 | C Loss: -0.484657\n",
      "06/29/2022 10:11:04 - INFO - __main__ -   Text: ['ද\\u0db2ඣ\\u0dbf’ \"There is no harm.\"']\n",
      "06/29/2022 10:11:05 - INFO - __main__ -   Epoch: 165 | Batch: 7200/10001 (72%) | G Loss: 2.875793 | C Loss: -0.386674\n",
      "06/29/2022 10:11:05 - INFO - __main__ -   Text: ['She can also spit blood for breath.']\n",
      "06/29/2022 10:11:06 - INFO - __main__ -   Epoch: 165 | Batch: 7800/10001 (78%) | G Loss: 3.230789 | C Loss: -0.712131\n",
      "06/29/2022 10:11:06 - INFO - __main__ -   Text: ['It\\'s a Swimmer laterie.\"']\n",
      "06/29/2022 10:11:07 - INFO - __main__ -   Epoch: 165 | Batch: 8400/10001 (84%) | G Loss: 2.594118 | C Loss: -0.646205\n",
      "06/29/2022 10:11:07 - INFO - __main__ -   Text: ['This content is available to localhosters Facebook.']\n",
      "06/29/2022 10:11:08 - INFO - __main__ -   Epoch: 165 | Batch: 9000/10001 (90%) | G Loss: 2.435506 | C Loss: -0.412629\n",
      "06/29/2022 10:11:08 - INFO - __main__ -   Text: [\"More often, it is measured against the player as 'knowledgeable'.\"]\n",
      "06/29/2022 10:11:09 - INFO - __main__ -   Epoch: 165 | Batch: 9600/10001 (96%) | G Loss: 2.419291 | C Loss: -0.368129\n",
      "06/29/2022 10:11:09 - INFO - __main__ -   Text: ['Talk Talk about seeing Dashie Raygun look like a god!']\n",
      "06/29/2022 10:11:10 - INFO - __main__ -   * (Train) Epoch: 165 | G Loss: 2.8203 | C Loss: -0.4690 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 10:11:19 - INFO - __main__ -   Bleu-2:0.209 | B-Bleu-2:0.259\n",
      "06/29/2022 10:11:19 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46725937154754144\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 166 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:23.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:58.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:16.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:14:52 - INFO - __main__ -   Epoch: 166 | Batch: 0/10001 (0%) | G Loss: 3.004802 | C Loss: -0.411896\n",
      "06/29/2022 10:14:52 - INFO - __main__ -   Text: ['He is fascinated by everything, and becoming stronger rather that gaining a little.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 4.102\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:14:53 - INFO - __main__ -   Epoch: 166 | Batch: 600/10001 (6%) | G Loss: 3.556744 | C Loss: -0.511934\n",
      "06/29/2022 10:14:53 - INFO - __main__ -   Text: [\"Some legal terminology you should consider if you're not a Bad Ass Steve.\"]\n",
      "06/29/2022 10:14:54 - INFO - __main__ -   Epoch: 166 | Batch: 1200/10001 (12%) | G Loss: 3.510881 | C Loss: -0.561155\n",
      "06/29/2022 10:14:54 - INFO - __main__ -   Text: ['Scooter is a self-teaching course for small aliens.']\n",
      "06/29/2022 10:14:55 - INFO - __main__ -   Epoch: 166 | Batch: 1800/10001 (18%) | G Loss: 2.660801 | C Loss: -0.389981\n",
      "06/29/2022 10:14:55 - INFO - __main__ -   Text: ['Rampath argues that it\\'s in the ale\".']\n",
      "06/29/2022 10:14:56 - INFO - __main__ -   Epoch: 166 | Batch: 2400/10001 (24%) | G Loss: 2.205212 | C Loss: -0.477586\n",
      "06/29/2022 10:14:56 - INFO - __main__ -   Text: ['In fact, some people name Bob after him.']\n",
      "06/29/2022 10:14:57 - INFO - __main__ -   Epoch: 166 | Batch: 3000/10001 (30%) | G Loss: 2.558546 | C Loss: -0.420518\n",
      "06/29/2022 10:14:57 - INFO - __main__ -   Text: ['A only acceptable narrative?']\n",
      "06/29/2022 10:14:58 - INFO - __main__ -   Epoch: 166 | Batch: 3600/10001 (36%) | G Loss: 3.135070 | C Loss: -0.446596\n",
      "06/29/2022 10:14:58 - INFO - __main__ -   Text: ['The video components are: head hits combo interludes, reversal of card combos.']\n",
      "06/29/2022 10:14:59 - INFO - __main__ -   Epoch: 166 | Batch: 4200/10001 (42%) | G Loss: 3.432821 | C Loss: -0.523092\n",
      "06/29/2022 10:14:59 - INFO - __main__ -   Text: ['It can swim!']\n",
      "06/29/2022 10:15:00 - INFO - __main__ -   Epoch: 166 | Batch: 4800/10001 (48%) | G Loss: 3.362710 | C Loss: -0.557361\n",
      "06/29/2022 10:15:00 - INFO - __main__ -   Text: ['In order to stop you it has to be a joke.']\n",
      "06/29/2022 10:15:01 - INFO - __main__ -   Epoch: 166 | Batch: 5400/10001 (54%) | G Loss: 2.910162 | C Loss: -0.378890\n",
      "06/29/2022 10:15:01 - INFO - __main__ -   Text: [\"English isn't a priority for me.\"]\n",
      "06/29/2022 10:15:02 - INFO - __main__ -   Epoch: 166 | Batch: 6000/10001 (60%) | G Loss: 2.900208 | C Loss: -0.440502\n",
      "06/29/2022 10:15:03 - INFO - __main__ -   Text: ['Her favorite form of sleeping prevents paralysis.']\n",
      "06/29/2022 10:15:04 - INFO - __main__ -   Epoch: 166 | Batch: 6600/10001 (66%) | G Loss: 2.982321 | C Loss: -0.534688\n",
      "06/29/2022 10:15:04 - INFO - __main__ -   Text: ['A military study of the Web is ready to stop today.\"']\n",
      "06/29/2022 10:15:05 - INFO - __main__ -   Epoch: 166 | Batch: 7200/10001 (72%) | G Loss: 2.335079 | C Loss: -0.175167\n",
      "06/29/2022 10:15:05 - INFO - __main__ -   Text: ['Kids Is a Big Black Hole.']\n",
      "06/29/2022 10:15:06 - INFO - __main__ -   Epoch: 166 | Batch: 7800/10001 (78%) | G Loss: 2.853136 | C Loss: -0.572180\n",
      "06/29/2022 10:15:06 - INFO - __main__ -   Text: [\"He uses this 'religious' as an excuse.\"]\n",
      "06/29/2022 10:15:07 - INFO - __main__ -   Epoch: 166 | Batch: 8400/10001 (84%) | G Loss: 3.075963 | C Loss: -0.360567\n",
      "06/29/2022 10:15:07 - INFO - __main__ -   Text: [\"For example, someone who doesn't work for a horse will have to sew horse trainers or hobend drivers.\"]\n",
      "06/29/2022 10:15:08 - INFO - __main__ -   Epoch: 166 | Batch: 9000/10001 (90%) | G Loss: 2.734310 | C Loss: -0.414491\n",
      "06/29/2022 10:15:08 - INFO - __main__ -   Text: ['The Great Potential is most likely to be uncertain.']\n",
      "06/29/2022 10:15:09 - INFO - __main__ -   Epoch: 166 | Batch: 9600/10001 (96%) | G Loss: 2.610522 | C Loss: -0.557833\n",
      "06/29/2022 10:15:09 - INFO - __main__ -   Text: ['A similar fertilizing message might even be \"freeze up.\"']\n",
      "06/29/2022 10:15:10 - INFO - __main__ -   * (Train) Epoch: 166 | G Loss: 2.7642 | C Loss: -0.4634 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 10:15:18 - INFO - __main__ -   Bleu-2:0.194 | B-Bleu-2:0.233\n",
      "06/29/2022 10:15:18 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4274540438949805\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 167 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:18:45 - INFO - __main__ -   Epoch: 167 | Batch: 0/10001 (0%) | G Loss: 2.791815 | C Loss: -0.492535\n",
      "06/29/2022 10:18:45 - INFO - __main__ -   Text: ['At the solar system E is just called the sigmoid.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.100\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:18:46 - INFO - __main__ -   Epoch: 167 | Batch: 600/10001 (6%) | G Loss: 2.825033 | C Loss: -0.410720\n",
      "06/29/2022 10:18:46 - INFO - __main__ -   Text: ['A wolf is attacking here.']\n",
      "06/29/2022 10:18:47 - INFO - __main__ -   Epoch: 167 | Batch: 1200/10001 (12%) | G Loss: 3.569683 | C Loss: -0.608753\n",
      "06/29/2022 10:18:47 - INFO - __main__ -   Text: ['The kicker is that seizures are sometimes claimed not to be caused by confusion but by ignorance.']\n",
      "06/29/2022 10:18:48 - INFO - __main__ -   Epoch: 167 | Batch: 1800/10001 (18%) | G Loss: 3.566101 | C Loss: -0.243172\n",
      "06/29/2022 10:18:48 - INFO - __main__ -   Text: ['This tool is extremely helpful for beginners.']\n",
      "06/29/2022 10:18:49 - INFO - __main__ -   Epoch: 167 | Batch: 2400/10001 (24%) | G Loss: 3.474781 | C Loss: -0.581329\n",
      "06/29/2022 10:18:49 - INFO - __main__ -   Text: ['This is only Peach (creative lifestyle).\"']\n",
      "06/29/2022 10:18:50 - INFO - __main__ -   Epoch: 167 | Batch: 3000/10001 (30%) | G Loss: 2.659564 | C Loss: -0.416732\n",
      "06/29/2022 10:18:50 - INFO - __main__ -   Text: ['It is hard to achieve superimposed global agreements with countries.']\n",
      "06/29/2022 10:18:51 - INFO - __main__ -   Epoch: 167 | Batch: 3600/10001 (36%) | G Loss: 2.592653 | C Loss: -0.412305\n",
      "06/29/2022 10:18:51 - INFO - __main__ -   Text: ['Simple is good; honest is bad.\"']\n",
      "06/29/2022 10:18:52 - INFO - __main__ -   Epoch: 167 | Batch: 4200/10001 (42%) | G Loss: 2.726878 | C Loss: -0.505488\n",
      "06/29/2022 10:18:53 - INFO - __main__ -   Text: ['Also, any magic pill can be used as an adjective in conjunction with child curse.']\n",
      "06/29/2022 10:18:53 - INFO - __main__ -   Epoch: 167 | Batch: 4800/10001 (48%) | G Loss: 2.918972 | C Loss: -0.603078\n",
      "06/29/2022 10:18:54 - INFO - __main__ -   Text: ['They want to know that humans are like, multiple times stronger than the \"lesbians\".']\n",
      "06/29/2022 10:18:55 - INFO - __main__ -   Epoch: 167 | Batch: 5400/10001 (54%) | G Loss: 3.135113 | C Loss: -0.473145\n",
      "06/29/2022 10:18:55 - INFO - __main__ -   Text: ['Where the First Spring is Coming!']\n",
      "06/29/2022 10:18:56 - INFO - __main__ -   Epoch: 167 | Batch: 6000/10001 (60%) | G Loss: 2.978348 | C Loss: -0.369636\n",
      "06/29/2022 10:18:56 - INFO - __main__ -   Text: ['Friends are evil.\"']\n",
      "06/29/2022 10:18:57 - INFO - __main__ -   Epoch: 167 | Batch: 6600/10001 (66%) | G Loss: 3.299784 | C Loss: -0.587933\n",
      "06/29/2022 10:18:57 - INFO - __main__ -   Text: ['<Bashki>\"); They can be called <Bashki> by all-good <PAD> people.']\n",
      "06/29/2022 10:18:58 - INFO - __main__ -   Epoch: 167 | Batch: 7200/10001 (72%) | G Loss: 3.179020 | C Loss: -0.352757\n",
      "06/29/2022 10:18:58 - INFO - __main__ -   Text: ['The Achaike biodiversity depends on the \"Karak\" relationship.']\n",
      "06/29/2022 10:18:59 - INFO - __main__ -   Epoch: 167 | Batch: 7800/10001 (78%) | G Loss: 3.575203 | C Loss: -0.341873\n",
      "06/29/2022 10:18:59 - INFO - __main__ -   Text: ['What do we call that saying?\"']\n",
      "06/29/2022 10:19:00 - INFO - __main__ -   Epoch: 167 | Batch: 8400/10001 (84%) | G Loss: 3.283011 | C Loss: -0.861314\n",
      "06/29/2022 10:19:00 - INFO - __main__ -   Text: ['However, she has no dependency: she must be able to transcend growth hormone levels.']\n",
      "06/29/2022 10:19:01 - INFO - __main__ -   Epoch: 167 | Batch: 9000/10001 (90%) | G Loss: 2.998109 | C Loss: -0.609404\n",
      "06/29/2022 10:19:01 - INFO - __main__ -   Text: ['Like a past reading of any awards that has been submitted to the school.\"']\n",
      "06/29/2022 10:19:02 - INFO - __main__ -   Epoch: 167 | Batch: 9600/10001 (96%) | G Loss: 2.010078 | C Loss: -0.373494\n",
      "06/29/2022 10:19:02 - INFO - __main__ -   Text: ['But then he isn\\'t competent in a double threat plan.\"']\n",
      "06/29/2022 10:19:03 - INFO - __main__ -   * (Train) Epoch: 167 | G Loss: 2.8269 | C Loss: -0.4730 | Updates G: 45 | Updates C: 788\n",
      "06/29/2022 10:19:12 - INFO - __main__ -   Bleu-2:0.199 | B-Bleu-2:0.228\n",
      "06/29/2022 10:19:12 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4265846158964566\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 168 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:40.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:56.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:14.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:29.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:46.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:03.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:18\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:22:31 - INFO - __main__ -   Epoch: 168 | Batch: 0/10000 (0%) | G Loss: 1.739202 | C Loss: -0.392580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 4.099\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:22:31 - INFO - __main__ -   Text: ['Lieberman is more than likely to oppose abortion, because morally in keeping with his commitments to his conservative base.']\n",
      "06/29/2022 10:22:32 - INFO - __main__ -   Epoch: 168 | Batch: 600/10000 (6%) | G Loss: 3.516130 | C Loss: -0.693851\n",
      "06/29/2022 10:22:32 - INFO - __main__ -   Text: [\"23 . <PAD> Thinking that some light will strike back to the Sun, predicts that early in man's evolution.\"]\n",
      "06/29/2022 10:22:33 - INFO - __main__ -   Epoch: 168 | Batch: 1200/10000 (12%) | G Loss: 3.038285 | C Loss: -0.342007\n",
      "06/29/2022 10:22:33 - INFO - __main__ -   Text: ['Then, Jesse Freckle\\'s \"Give Me Your Cheese\" slogan.']\n",
      "06/29/2022 10:22:34 - INFO - __main__ -   Epoch: 168 | Batch: 1800/10000 (18%) | G Loss: 2.148671 | C Loss: -0.536530\n",
      "06/29/2022 10:22:35 - INFO - __main__ -   Text: ['Hindi stream-communication defines \"khla network for telephony\".']\n",
      "06/29/2022 10:22:36 - INFO - __main__ -   Epoch: 168 | Batch: 2400/10000 (24%) | G Loss: 3.159356 | C Loss: -0.482768\n",
      "06/29/2022 10:22:36 - INFO - __main__ -   Text: ['The phrase: \"\"I perceive \"p.3ast\". <PAD> Examples: \"P.71 soul.\"']\n",
      "06/29/2022 10:22:37 - INFO - __main__ -   Epoch: 168 | Batch: 3000/10000 (30%) | G Loss: 3.526072 | C Loss: -0.449932\n",
      "06/29/2022 10:22:37 - INFO - __main__ -   Text: ['\"Tip\" suggests rubbing off from your mouth.']\n",
      "06/29/2022 10:22:38 - INFO - __main__ -   Epoch: 168 | Batch: 3600/10000 (36%) | G Loss: 2.469154 | C Loss: -0.470532\n",
      "06/29/2022 10:22:38 - INFO - __main__ -   Text: ['These are best known for being the largest material on the tundra.']\n",
      "06/29/2022 10:22:39 - INFO - __main__ -   Epoch: 168 | Batch: 4200/10000 (42%) | G Loss: 3.015229 | C Loss: -0.688825\n",
      "06/29/2022 10:22:39 - INFO - __main__ -   Text: ['In college, Psychology begins doing experiments all over the world.']\n",
      "06/29/2022 10:22:40 - INFO - __main__ -   Epoch: 168 | Batch: 4800/10000 (48%) | G Loss: 3.297130 | C Loss: -0.558231\n",
      "06/29/2022 10:22:40 - INFO - __main__ -   Text: ['Unidirectional Union Terminal is absorbed by basic mail.']\n",
      "06/29/2022 10:22:41 - INFO - __main__ -   Epoch: 168 | Batch: 5400/10000 (54%) | G Loss: 3.106928 | C Loss: -0.638001\n",
      "06/29/2022 10:22:41 - INFO - __main__ -   Text: ['Here is a mediocre and wide flick to a short benttail companion.']\n",
      "06/29/2022 10:22:42 - INFO - __main__ -   Epoch: 168 | Batch: 6000/10000 (60%) | G Loss: 2.466287 | C Loss: -0.427725\n",
      "06/29/2022 10:22:42 - INFO - __main__ -   Text: ['Later (if they let it be established \"you may become possessed by snakes\").']\n",
      "06/29/2022 10:22:43 - INFO - __main__ -   Epoch: 168 | Batch: 6600/10000 (66%) | G Loss: 2.374418 | C Loss: -0.585951\n",
      "06/29/2022 10:22:43 - INFO - __main__ -   Text: ['The issue for candidates who are making different decisions is about awarding it first rank.']\n",
      "06/29/2022 10:22:44 - INFO - __main__ -   Epoch: 168 | Batch: 7200/10000 (72%) | G Loss: 2.514730 | C Loss: -0.239013\n",
      "06/29/2022 10:22:45 - INFO - __main__ -   Text: ['The author readily admits to being a successful lawyer.']\n",
      "06/29/2022 10:22:45 - INFO - __main__ -   Epoch: 168 | Batch: 7800/10000 (78%) | G Loss: 2.800463 | C Loss: -0.326731\n",
      "06/29/2022 10:22:46 - INFO - __main__ -   Text: ['This secrethra gangestion hormone can cure breast cancer.']\n",
      "06/29/2022 10:22:47 - INFO - __main__ -   Epoch: 168 | Batch: 8400/10000 (84%) | G Loss: 2.871303 | C Loss: -0.562099\n",
      "06/29/2022 10:22:47 - INFO - __main__ -   Text: ['I think that it is important to hopefully see people realise that what you just heard is FUD.']\n",
      "06/29/2022 10:22:48 - INFO - __main__ -   Epoch: 168 | Batch: 9000/10000 (90%) | G Loss: 2.569487 | C Loss: -0.308981\n",
      "06/29/2022 10:22:48 - INFO - __main__ -   Text: ['Students across the world are reportedly lobbying the government to get ahead.']\n",
      "06/29/2022 10:22:49 - INFO - __main__ -   Epoch: 168 | Batch: 9600/10000 (96%) | G Loss: 2.954653 | C Loss: -0.484081\n",
      "06/29/2022 10:22:49 - INFO - __main__ -   Text: ['If someone doesn\\'t stand to blame you for making them laugh, they are not truly hanging themselves.\"']\n",
      "06/29/2022 10:22:50 - INFO - __main__ -   * (Train) Epoch: 168 | G Loss: 2.7356 | C Loss: -0.4490 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 10:22:59 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.262\n",
      "06/29/2022 10:22:59 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4689502113780276\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 169 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:26:29 - INFO - __main__ -   Epoch: 169 | Batch: 0/10000 (0%) | G Loss: 3.315182 | C Loss: -0.608541\n",
      "06/29/2022 10:26:29 - INFO - __main__ -   Text: ['Then I can finish all the dishes.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.057\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:26:30 - INFO - __main__ -   Epoch: 169 | Batch: 600/10000 (6%) | G Loss: 3.346055 | C Loss: -0.362845\n",
      "06/29/2022 10:26:30 - INFO - __main__ -   Text: ['it is unsigned.']\n",
      "06/29/2022 10:26:31 - INFO - __main__ -   Epoch: 169 | Batch: 1200/10000 (12%) | G Loss: 3.161962 | C Loss: -0.429900\n",
      "06/29/2022 10:26:31 - INFO - __main__ -   Text: ['Note: despite this particular being word-efficient there is no Optimism']\n",
      "06/29/2022 10:26:32 - INFO - __main__ -   Epoch: 169 | Batch: 1800/10000 (18%) | G Loss: 2.819059 | C Loss: -0.101609\n",
      "06/29/2022 10:26:32 - INFO - __main__ -   Text: ['This acid -and-ultimate is the feeding of juice.']\n",
      "06/29/2022 10:26:33 - INFO - __main__ -   Epoch: 169 | Batch: 2400/10000 (24%) | G Loss: 2.618932 | C Loss: -0.699223\n",
      "06/29/2022 10:26:33 - INFO - __main__ -   Text: ['To eat aetils \"tis psychological\".']\n",
      "06/29/2022 10:26:34 - INFO - __main__ -   Epoch: 169 | Batch: 3000/10000 (30%) | G Loss: 2.660190 | C Loss: -0.370513\n",
      "06/29/2022 10:26:34 - INFO - __main__ -   Text: ['Others know how to play dice but will not tell no one.']\n",
      "06/29/2022 10:26:35 - INFO - __main__ -   Epoch: 169 | Batch: 3600/10000 (36%) | G Loss: 3.120904 | C Loss: -0.614013\n",
      "06/29/2022 10:26:36 - INFO - __main__ -   Text: ['If we can scale (more precisely) it will be reached.']\n",
      "06/29/2022 10:26:36 - INFO - __main__ -   Epoch: 169 | Batch: 4200/10000 (42%) | G Loss: 3.421194 | C Loss: -0.598517\n",
      "06/29/2022 10:26:37 - INFO - __main__ -   Text: ['Atm much answering affords the inverse way.']\n",
      "06/29/2022 10:26:38 - INFO - __main__ -   Epoch: 169 | Batch: 4800/10000 (48%) | G Loss: 3.449971 | C Loss: -0.512032\n",
      "06/29/2022 10:26:38 - INFO - __main__ -   Text: ['Instead, Bond was born with a remarkable sense of confidence.']\n",
      "06/29/2022 10:26:39 - INFO - __main__ -   Epoch: 169 | Batch: 5400/10000 (54%) | G Loss: 3.100678 | C Loss: -0.338472\n",
      "06/29/2022 10:26:39 - INFO - __main__ -   Text: ['God made a dull scream when she came knocking on my door.']\n",
      "06/29/2022 10:26:40 - INFO - __main__ -   Epoch: 169 | Batch: 6000/10000 (60%) | G Loss: 3.109155 | C Loss: -0.479278\n",
      "06/29/2022 10:26:40 - INFO - __main__ -   Text: ['Xue Whitecap fan is used for knives.']\n",
      "06/29/2022 10:26:41 - INFO - __main__ -   Epoch: 169 | Batch: 6600/10000 (66%) | G Loss: 3.135688 | C Loss: -0.530605\n",
      "06/29/2022 10:26:41 - INFO - __main__ -   Text: ['Steriloids kill the ravens.']\n",
      "06/29/2022 10:26:42 - INFO - __main__ -   Epoch: 169 | Batch: 7200/10000 (72%) | G Loss: 2.573530 | C Loss: -0.365576\n",
      "06/29/2022 10:26:42 - INFO - __main__ -   Text: [\"auto-charged may be better than gas-powered: It doesn't quagmire pocket car.\"]\n",
      "06/29/2022 10:26:43 - INFO - __main__ -   Epoch: 169 | Batch: 7800/10000 (78%) | G Loss: 2.627151 | C Loss: -0.239495\n",
      "06/29/2022 10:26:43 - INFO - __main__ -   Text: ['Grazing is optional for posture.']\n",
      "06/29/2022 10:26:44 - INFO - __main__ -   Epoch: 169 | Batch: 8400/10000 (84%) | G Loss: 3.591072 | C Loss: -0.508782\n",
      "06/29/2022 10:26:44 - INFO - __main__ -   Text: ['It is considered practicable for one fecundity to be equal to a hundred.']\n",
      "06/29/2022 10:26:45 - INFO - __main__ -   Epoch: 169 | Batch: 9000/10000 (90%) | G Loss: 3.042351 | C Loss: -0.359054\n",
      "06/29/2022 10:26:45 - INFO - __main__ -   Text: ['Bacon is the ruler of the South.']\n",
      "06/29/2022 10:26:46 - INFO - __main__ -   Epoch: 169 | Batch: 9600/10000 (96%) | G Loss: 2.549460 | C Loss: -0.242107\n",
      "06/29/2022 10:26:46 - INFO - __main__ -   Text: ['The next link is the English alphabet, which means \"Signen.\"']\n",
      "06/29/2022 10:26:47 - INFO - __main__ -   * (Train) Epoch: 169 | G Loss: 2.8849 | C Loss: -0.4576 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 10:26:56 - INFO - __main__ -   Bleu-2:0.211 | B-Bleu-2:0.230\n",
      "06/29/2022 10:26:56 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4411825703267952\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 170 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:49.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:04.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:22.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:39.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:55.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:12.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:28.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:44.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:01.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:15\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:30:12 - INFO - __main__ -   Epoch: 170 | Batch: 0/10001 (0%) | G Loss: 2.469854 | C Loss: -0.382127\n",
      "06/29/2022 10:30:12 - INFO - __main__ -   Text: ['It always has money bio-technically.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 3.966\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:30:13 - INFO - __main__ -   Epoch: 170 | Batch: 600/10001 (6%) | G Loss: 3.160789 | C Loss: -0.262051\n",
      "06/29/2022 10:30:13 - INFO - __main__ -   Text: ['Quite typical.']\n",
      "06/29/2022 10:30:14 - INFO - __main__ -   Epoch: 170 | Batch: 1200/10001 (12%) | G Loss: 3.563413 | C Loss: -0.721632\n",
      "06/29/2022 10:30:14 - INFO - __main__ -   Text: ['This election is a referendum on Israel or the financial asymmetry between Britain and the US.']\n",
      "06/29/2022 10:30:15 - INFO - __main__ -   Epoch: 170 | Batch: 1800/10001 (18%) | G Loss: 2.922401 | C Loss: -0.150809\n",
      "06/29/2022 10:30:15 - INFO - __main__ -   Text: ['The next time you can look at your profile, see how much you have gained.']\n",
      "06/29/2022 10:30:16 - INFO - __main__ -   Epoch: 170 | Batch: 2400/10001 (24%) | G Loss: 2.569641 | C Loss: -0.419618\n",
      "06/29/2022 10:30:16 - INFO - __main__ -   Text: ['They will be enrolled in five U.S.']\n",
      "06/29/2022 10:30:17 - INFO - __main__ -   Epoch: 170 | Batch: 3000/10001 (30%) | G Loss: 3.010756 | C Loss: -0.611670\n",
      "06/29/2022 10:30:17 - INFO - __main__ -   Text: ['Cas is a \"pseudonym for a greater ethical ideal person.\"']\n",
      "06/29/2022 10:30:18 - INFO - __main__ -   Epoch: 170 | Batch: 3600/10001 (36%) | G Loss: 2.905884 | C Loss: -0.486425\n",
      "06/29/2022 10:30:19 - INFO - __main__ -   Text: ['More information and lots of choosing this sports brand.']\n",
      "06/29/2022 10:30:19 - INFO - __main__ -   Epoch: 170 | Batch: 4200/10001 (42%) | G Loss: 2.624523 | C Loss: -0.445832\n",
      "06/29/2022 10:30:20 - INFO - __main__ -   Text: ['It is a highly skilled process if one need to learn completely.']\n",
      "06/29/2022 10:30:21 - INFO - __main__ -   Epoch: 170 | Batch: 4800/10001 (48%) | G Loss: 2.300481 | C Loss: -0.362498\n",
      "06/29/2022 10:30:21 - INFO - __main__ -   Text: ['Not even though alcohol might be seen as dangerous in Main Street countries, it appears to be health freight.']\n",
      "06/29/2022 10:30:22 - INFO - __main__ -   Epoch: 170 | Batch: 5400/10001 (54%) | G Loss: 3.187505 | C Loss: -0.396896\n",
      "06/29/2022 10:30:22 - INFO - __main__ -   Text: [\"One of my favourite fiddle tricks is 'hurt.'\"]\n",
      "06/29/2022 10:30:23 - INFO - __main__ -   Epoch: 170 | Batch: 6000/10001 (60%) | G Loss: 4.001996 | C Loss: -0.517885\n",
      "06/29/2022 10:30:23 - INFO - __main__ -   Text: ['The \"dairy circle\" is the bafflingly brilliant plan.']\n",
      "06/29/2022 10:30:24 - INFO - __main__ -   Epoch: 170 | Batch: 6600/10001 (66%) | G Loss: 3.523108 | C Loss: -0.602117\n",
      "06/29/2022 10:30:24 - INFO - __main__ -   Text: ['Copworth could easily his one true fathoms when he keeps the English Speaker sahs.']\n",
      "06/29/2022 10:30:25 - INFO - __main__ -   Epoch: 170 | Batch: 7200/10001 (72%) | G Loss: 2.770674 | C Loss: -0.476003\n",
      "06/29/2022 10:30:25 - INFO - __main__ -   Text: ['Science & Science Week.']\n",
      "06/29/2022 10:30:26 - INFO - __main__ -   Epoch: 170 | Batch: 7800/10001 (78%) | G Loss: 2.399039 | C Loss: -0.365111\n",
      "06/29/2022 10:30:26 - INFO - __main__ -   Text: ['\"I am a teardrop\".']\n",
      "06/29/2022 10:30:27 - INFO - __main__ -   Epoch: 170 | Batch: 8400/10001 (84%) | G Loss: 2.652039 | C Loss: -0.315745\n",
      "06/29/2022 10:30:27 - INFO - __main__ -   Text: [\"The connection is permitted by BTX's own freight transfer fees.\"]\n",
      "06/29/2022 10:30:28 - INFO - __main__ -   Epoch: 170 | Batch: 9000/10001 (90%) | G Loss: 2.721664 | C Loss: -0.442151\n",
      "06/29/2022 10:30:28 - INFO - __main__ -   Text: ['As usual with Øaírds.']\n",
      "06/29/2022 10:30:29 - INFO - __main__ -   Epoch: 170 | Batch: 9600/10001 (96%) | G Loss: 2.839441 | C Loss: -0.556278\n",
      "06/29/2022 10:30:29 - INFO - __main__ -   Text: ['Zolets can be found at the lodge for reducing noise pollution.']\n",
      "06/29/2022 10:30:30 - INFO - __main__ -   * (Train) Epoch: 170 | G Loss: 2.7976 | C Loss: -0.4564 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 10:30:39 - INFO - __main__ -   Bleu-2:0.213 | B-Bleu-2:0.250\n",
      "06/29/2022 10:30:39 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4628702451084383\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 171 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:34:05 - INFO - __main__ -   Epoch: 171 | Batch: 0/10001 (0%) | G Loss: 3.197183 | C Loss: -0.458808\n",
      "06/29/2022 10:34:05 - INFO - __main__ -   Text: ['Another note of caution is \"tolerated\" by this constituency.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.510\n",
      "  Test Loss: 3.865\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:34:06 - INFO - __main__ -   Epoch: 171 | Batch: 600/10001 (6%) | G Loss: 3.498925 | C Loss: -0.649229\n",
      "06/29/2022 10:34:06 - INFO - __main__ -   Text: ['Two acts of dancing called \"joing\" often do not always work together.']\n",
      "06/29/2022 10:34:07 - INFO - __main__ -   Epoch: 171 | Batch: 1200/10001 (12%) | G Loss: 3.408538 | C Loss: -0.446038\n",
      "06/29/2022 10:34:07 - INFO - __main__ -   Text: ['One betting method that shows a greater potential for growth and currency.']\n",
      "06/29/2022 10:34:08 - INFO - __main__ -   Epoch: 171 | Batch: 1800/10001 (18%) | G Loss: 2.945882 | C Loss: -0.445639\n",
      "06/29/2022 10:34:08 - INFO - __main__ -   Text: ['Automated navigation is something very unique.']\n",
      "06/29/2022 10:34:09 - INFO - __main__ -   Epoch: 171 | Batch: 2400/10001 (24%) | G Loss: 3.060771 | C Loss: -0.297205\n",
      "06/29/2022 10:34:09 - INFO - __main__ -   Text: ['\"TuneUp!\" <PAD> tremendous playability and performance.']\n",
      "06/29/2022 10:34:10 - INFO - __main__ -   Epoch: 171 | Batch: 3000/10001 (30%) | G Loss: 3.027310 | C Loss: -0.465121\n",
      "06/29/2022 10:34:10 - INFO - __main__ -   Text: ['Eventually learning defines what counts.']\n",
      "06/29/2022 10:34:11 - INFO - __main__ -   Epoch: 171 | Batch: 3600/10001 (36%) | G Loss: 2.633557 | C Loss: -0.337670\n",
      "06/29/2022 10:34:11 - INFO - __main__ -   Text: ['I like this mixup a lot.\"']\n",
      "06/29/2022 10:34:12 - INFO - __main__ -   Epoch: 171 | Batch: 4200/10001 (42%) | G Loss: 2.907455 | C Loss: -0.438555\n",
      "06/29/2022 10:34:12 - INFO - __main__ -   Text: ['A Telepathy Response Problem is on the horizon.']\n",
      "06/29/2022 10:34:13 - INFO - __main__ -   Epoch: 171 | Batch: 4800/10001 (48%) | G Loss: 3.036008 | C Loss: -0.410827\n",
      "06/29/2022 10:34:14 - INFO - __main__ -   Text: ['By using object fallacies it claims that PureInt extends Chi. <BOS> is faster than loop calculus.']\n",
      "06/29/2022 10:34:14 - INFO - __main__ -   Epoch: 171 | Batch: 5400/10001 (54%) | G Loss: 2.959405 | C Loss: -0.294856\n",
      "06/29/2022 10:34:15 - INFO - __main__ -   Text: ['Normal expression suggests that the interpretation is the following: <PAD>Quant.']\n",
      "06/29/2022 10:34:16 - INFO - __main__ -   Epoch: 171 | Batch: 6000/10001 (60%) | G Loss: 3.067679 | C Loss: -0.521025\n",
      "06/29/2022 10:34:16 - INFO - __main__ -   Text: ['\"cure\".']\n",
      "06/29/2022 10:34:17 - INFO - __main__ -   Epoch: 171 | Batch: 6600/10001 (66%) | G Loss: 3.292627 | C Loss: -0.524463\n",
      "06/29/2022 10:34:17 - INFO - __main__ -   Text: ['Apparently, Mother Pratap... http://www.falsediscover.com .']\n",
      "06/29/2022 10:34:18 - INFO - __main__ -   Epoch: 171 | Batch: 7200/10001 (72%) | G Loss: 2.739189 | C Loss: -0.732636\n",
      "06/29/2022 10:34:18 - INFO - __main__ -   Text: ['Jack also believes that he is bisexual.']\n",
      "06/29/2022 10:34:19 - INFO - __main__ -   Epoch: 171 | Batch: 7800/10001 (78%) | G Loss: 2.381582 | C Loss: -0.353337\n",
      "06/29/2022 10:34:19 - INFO - __main__ -   Text: ['Inhabitant.']\n",
      "06/29/2022 10:34:20 - INFO - __main__ -   Epoch: 171 | Batch: 8400/10001 (84%) | G Loss: 2.997436 | C Loss: -0.324955\n",
      "06/29/2022 10:34:20 - INFO - __main__ -   Text: ['It is called \"funnel calculus\".']\n",
      "06/29/2022 10:34:21 - INFO - __main__ -   Epoch: 171 | Batch: 9000/10001 (90%) | G Loss: 3.554478 | C Loss: -0.317951\n",
      "06/29/2022 10:34:21 - INFO - __main__ -   Text: ['Horror is Fun!']\n",
      "06/29/2022 10:34:22 - INFO - __main__ -   Epoch: 171 | Batch: 9600/10001 (96%) | G Loss: 3.265701 | C Loss: -0.478837\n",
      "06/29/2022 10:34:22 - INFO - __main__ -   Text: ['My nose\\'s \\'ooh\\' my brain!\"']\n",
      "06/29/2022 10:34:23 - INFO - __main__ -   * (Train) Epoch: 171 | G Loss: 2.9551 | C Loss: -0.4581 | Updates G: 36 | Updates C: 797\n",
      "06/29/2022 10:34:32 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.243\n",
      "06/29/2022 10:34:32 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4430059702382102\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 172 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:38:00 - INFO - __main__ -   Epoch: 172 | Batch: 0/10001 (0%) | G Loss: 2.684323 | C Loss: -0.353833\n",
      "06/29/2022 10:38:00 - INFO - __main__ -   Text: ['methane (talking spoon crazy).']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.510\n",
      "  Test Loss: 3.915\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:38:01 - INFO - __main__ -   Epoch: 172 | Batch: 600/10001 (6%) | G Loss: 3.216095 | C Loss: -0.501558\n",
      "06/29/2022 10:38:02 - INFO - __main__ -   Text: ['Rice asks the reader to imagine a nuclear bomb.']\n",
      "06/29/2022 10:38:03 - INFO - __main__ -   Epoch: 172 | Batch: 1200/10001 (12%) | G Loss: 3.212989 | C Loss: -0.460067\n",
      "06/29/2022 10:38:03 - INFO - __main__ -   Text: ['Although many researchers think of Mathematics as a STEM field, or at least functionally similar.']\n",
      "06/29/2022 10:38:04 - INFO - __main__ -   Epoch: 172 | Batch: 1800/10001 (18%) | G Loss: 2.915758 | C Loss: -0.443014\n",
      "06/29/2022 10:38:04 - INFO - __main__ -   Text: ['Damaskianis or stciusus.']\n",
      "06/29/2022 10:38:05 - INFO - __main__ -   Epoch: 172 | Batch: 2400/10001 (24%) | G Loss: 2.854864 | C Loss: -0.510678\n",
      "06/29/2022 10:38:05 - INFO - __main__ -   Text: ['Cardinal Pellegrini wants to say that Cire is an \"ot.\"']\n",
      "06/29/2022 10:38:06 - INFO - __main__ -   Epoch: 172 | Batch: 3000/10001 (30%) | G Loss: 2.950928 | C Loss: -0.432772\n",
      "06/29/2022 10:38:06 - INFO - __main__ -   Text: ['In one breed, a small amount of moisture can leak back to the body.']\n",
      "06/29/2022 10:38:07 - INFO - __main__ -   Epoch: 172 | Batch: 3600/10001 (36%) | G Loss: 3.601401 | C Loss: -0.354688\n",
      "06/29/2022 10:38:07 - INFO - __main__ -   Text: ['Barette is said to have been the \"unbeloved isle\".']\n",
      "06/29/2022 10:38:08 - INFO - __main__ -   Epoch: 172 | Batch: 4200/10001 (42%) | G Loss: 3.356109 | C Loss: -0.076874\n",
      "06/29/2022 10:38:08 - INFO - __main__ -   Text: ['This will set it free and free to you.\"']\n",
      "06/29/2022 10:38:09 - INFO - __main__ -   Epoch: 172 | Batch: 4800/10001 (48%) | G Loss: 3.302150 | C Loss: -0.843878\n",
      "06/29/2022 10:38:09 - INFO - __main__ -   Text: ['Auchen comes to our table.']\n",
      "06/29/2022 10:38:10 - INFO - __main__ -   Epoch: 172 | Batch: 5400/10001 (54%) | G Loss: 2.645049 | C Loss: -0.481877\n",
      "06/29/2022 10:38:10 - INFO - __main__ -   Text: ['Unfortunately there are no freebies contests that IBCTS tries to defeat.']\n",
      "06/29/2022 10:38:11 - INFO - __main__ -   Epoch: 172 | Batch: 6000/10001 (60%) | G Loss: 2.231293 | C Loss: -0.448761\n",
      "06/29/2022 10:38:11 - INFO - __main__ -   Text: ['\", you can also see movie version.']\n",
      "06/29/2022 10:38:12 - INFO - __main__ -   Epoch: 172 | Batch: 6600/10001 (66%) | G Loss: 3.100427 | C Loss: -0.396451\n",
      "06/29/2022 10:38:12 - INFO - __main__ -   Text: ['Spoilers should be difficult.']\n",
      "06/29/2022 10:38:13 - INFO - __main__ -   Epoch: 172 | Batch: 7200/10001 (72%) | G Loss: 3.651386 | C Loss: -0.326740\n",
      "06/29/2022 10:38:14 - INFO - __main__ -   Text: ['It is a science of how we fellowship.']\n",
      "06/29/2022 10:38:14 - INFO - __main__ -   Epoch: 172 | Batch: 7800/10001 (78%) | G Loss: 3.584123 | C Loss: -0.520189\n",
      "06/29/2022 10:38:15 - INFO - __main__ -   Text: ['The song ends so fast that may or may not my heart.']\n",
      "06/29/2022 10:38:16 - INFO - __main__ -   Epoch: 172 | Batch: 8400/10001 (84%) | G Loss: 3.400892 | C Loss: -0.509616\n",
      "06/29/2022 10:38:16 - INFO - __main__ -   Text: ['In addition, Rabbi Chak mathematically wrote that the West must be made more like a unit of descent.']\n",
      "06/29/2022 10:38:17 - INFO - __main__ -   Epoch: 172 | Batch: 9000/10001 (90%) | G Loss: 2.660784 | C Loss: -0.437459\n",
      "06/29/2022 10:38:17 - INFO - __main__ -   Text: ['FM show about guys.']\n",
      "06/29/2022 10:38:18 - INFO - __main__ -   Epoch: 172 | Batch: 9600/10001 (96%) | G Loss: 3.028710 | C Loss: -0.447347\n",
      "06/29/2022 10:38:18 - INFO - __main__ -   Text: ['It looks like Dickson is going to build his own terminal.']\n",
      "06/29/2022 10:38:19 - INFO - __main__ -   * (Train) Epoch: 172 | G Loss: 2.9171 | C Loss: -0.4524 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 10:38:28 - INFO - __main__ -   Bleu-2:0.206 | B-Bleu-2:0.236\n",
      "06/29/2022 10:38:28 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4427545372924151\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 173 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:41:54 - INFO - __main__ -   Epoch: 173 | Batch: 0/10001 (0%) | G Loss: 2.965757 | C Loss: -0.467789\n",
      "06/29/2022 10:41:54 - INFO - __main__ -   Text: ['Often, the person may choose to speak with silence, or be involved in sages.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 3.908\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:41:55 - INFO - __main__ -   Epoch: 173 | Batch: 600/10001 (6%) | G Loss: 3.267873 | C Loss: -0.487129\n",
      "06/29/2022 10:41:55 - INFO - __main__ -   Text: ['It is stated that the ruler of Crooked Head is Wad.']\n",
      "06/29/2022 10:41:56 - INFO - __main__ -   Epoch: 173 | Batch: 1200/10001 (12%) | G Loss: 3.240479 | C Loss: -0.416634\n",
      "06/29/2022 10:41:56 - INFO - __main__ -   Text: ['Margaret Moonshine is the music tag for Austin Texans.']\n",
      "06/29/2022 10:41:57 - INFO - __main__ -   Epoch: 173 | Batch: 1800/10001 (18%) | G Loss: 3.037039 | C Loss: -0.320191\n",
      "06/29/2022 10:41:57 - INFO - __main__ -   Text: ['According to \"Capitalron-hoists\".']\n",
      "06/29/2022 10:41:58 - INFO - __main__ -   Epoch: 173 | Batch: 2400/10001 (24%) | G Loss: 3.041608 | C Loss: -0.690490\n",
      "06/29/2022 10:41:58 - INFO - __main__ -   Text: ['The potential difficulties to the Prime Minister show.']\n",
      "06/29/2022 10:41:59 - INFO - __main__ -   Epoch: 173 | Batch: 3000/10001 (30%) | G Loss: 2.907452 | C Loss: -0.424906\n",
      "06/29/2022 10:41:59 - INFO - __main__ -   Text: ['Wanting to get hit is a trick.\"']\n",
      "06/29/2022 10:42:00 - INFO - __main__ -   Epoch: 173 | Batch: 3600/10001 (36%) | G Loss: 3.083710 | C Loss: -0.483453\n",
      "06/29/2022 10:42:00 - INFO - __main__ -   Text: ['It\\'s the worst fight that\\'s ever happened in America.\"']\n",
      "06/29/2022 10:42:01 - INFO - __main__ -   Epoch: 173 | Batch: 4200/10001 (42%) | G Loss: 3.049089 | C Loss: -0.428396\n",
      "06/29/2022 10:42:01 - INFO - __main__ -   Text: ['gives a URL.']\n",
      "06/29/2022 10:42:02 - INFO - __main__ -   Epoch: 173 | Batch: 4800/10001 (48%) | G Loss: 3.089899 | C Loss: -0.348933\n",
      "06/29/2022 10:42:02 - INFO - __main__ -   Text: ['It is typically all over the central and Eastern US.']\n",
      "06/29/2022 10:42:03 - INFO - __main__ -   Epoch: 173 | Batch: 5400/10001 (54%) | G Loss: 3.472717 | C Loss: -0.604518\n",
      "06/29/2022 10:42:03 - INFO - __main__ -   Text: ['Many varieties of saliva are in drought.']\n",
      "06/29/2022 10:42:04 - INFO - __main__ -   Epoch: 173 | Batch: 6000/10001 (60%) | G Loss: 3.363973 | C Loss: -0.522484\n",
      "06/29/2022 10:42:04 - INFO - __main__ -   Text: ['She tells her how to be a black girl instead of a fat girl.']\n",
      "06/29/2022 10:42:05 - INFO - __main__ -   Epoch: 173 | Batch: 6600/10001 (66%) | G Loss: 3.043339 | C Loss: -0.637326\n",
      "06/29/2022 10:42:06 - INFO - __main__ -   Text: ['There are some tragic consequences for those countries economically.']\n",
      "06/29/2022 10:42:07 - INFO - __main__ -   Epoch: 173 | Batch: 7200/10001 (72%) | G Loss: 2.670887 | C Loss: -0.416402\n",
      "06/29/2022 10:42:07 - INFO - __main__ -   Text: ['It would be the first time a man in 61 years puts an end to the race.']\n",
      "06/29/2022 10:42:08 - INFO - __main__ -   Epoch: 173 | Batch: 7800/10001 (78%) | G Loss: 2.959551 | C Loss: -0.277041\n",
      "06/29/2022 10:42:08 - INFO - __main__ -   Text: ['']\n",
      "06/29/2022 10:42:09 - INFO - __main__ -   Epoch: 173 | Batch: 8400/10001 (84%) | G Loss: 3.170610 | C Loss: -0.451454\n",
      "06/29/2022 10:42:09 - INFO - __main__ -   Text: [\"Marzipates shouldn't compete too well the way they do in films.\"]\n",
      "06/29/2022 10:42:10 - INFO - __main__ -   Epoch: 173 | Batch: 9000/10001 (90%) | G Loss: 3.177523 | C Loss: -0.454461\n",
      "06/29/2022 10:42:10 - INFO - __main__ -   Text: ['\"No harassment, no harm\" is present.']\n",
      "06/29/2022 10:42:11 - INFO - __main__ -   Epoch: 173 | Batch: 9600/10001 (96%) | G Loss: 3.264502 | C Loss: -0.447467\n",
      "06/29/2022 10:42:11 - INFO - __main__ -   Text: ['Often the thoughts are appropriate if an apprentice undertakes a certain form.']\n",
      "06/29/2022 10:42:12 - INFO - __main__ -   * (Train) Epoch: 173 | G Loss: 3.0764 | C Loss: -0.4547 | Updates G: 37 | Updates C: 796\n",
      "06/29/2022 10:42:21 - INFO - __main__ -   Bleu-2:0.206 | B-Bleu-2:0.251\n",
      "06/29/2022 10:42:21 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45711317596534007\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 174 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:45:49 - INFO - __main__ -   Epoch: 174 | Batch: 0/10001 (0%) | G Loss: 3.214912 | C Loss: -0.426914\n",
      "06/29/2022 10:45:49 - INFO - __main__ -   Text: ['Jiun must make love to us though.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 4.034\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:45:50 - INFO - __main__ -   Epoch: 174 | Batch: 600/10001 (6%) | G Loss: 3.110417 | C Loss: -0.486022\n",
      "06/29/2022 10:45:50 - INFO - __main__ -   Text: ['As long as my death ratio is 1 (...) then I die.\"']\n",
      "06/29/2022 10:45:51 - INFO - __main__ -   Epoch: 174 | Batch: 1200/10001 (12%) | G Loss: 3.451251 | C Loss: -0.449281\n",
      "06/29/2022 10:45:51 - INFO - __main__ -   Text: ['Or a chocolate drink!']\n",
      "06/29/2022 10:45:52 - INFO - __main__ -   Epoch: 174 | Batch: 1800/10001 (18%) | G Loss: 3.602188 | C Loss: -0.415982\n",
      "06/29/2022 10:45:53 - INFO - __main__ -   Text: ['There is no mainland Ph.D.']\n",
      "06/29/2022 10:45:54 - INFO - __main__ -   Epoch: 174 | Batch: 2400/10001 (24%) | G Loss: 3.496394 | C Loss: -0.233195\n",
      "06/29/2022 10:45:54 - INFO - __main__ -   Text: ['To make an Ûmmyer there are two sides.']\n",
      "06/29/2022 10:45:55 - INFO - __main__ -   Epoch: 174 | Batch: 3000/10001 (30%) | G Loss: 3.163660 | C Loss: -0.403780\n",
      "06/29/2022 10:45:55 - INFO - __main__ -   Text: ['This is also true when the kitten sneezes and bleed.']\n",
      "06/29/2022 10:45:56 - INFO - __main__ -   Epoch: 174 | Batch: 3600/10001 (36%) | G Loss: 2.518812 | C Loss: -0.457281\n",
      "06/29/2022 10:45:56 - INFO - __main__ -   Text: ['Sour apple is safe from the fumes from oil oil drainage with degrees Fahrenheit.']\n",
      "06/29/2022 10:45:57 - INFO - __main__ -   Epoch: 174 | Batch: 4200/10001 (42%) | G Loss: 2.837029 | C Loss: -0.454073\n",
      "06/29/2022 10:45:57 - INFO - __main__ -   Text: ['It would have to be a Phs program.']\n",
      "06/29/2022 10:45:58 - INFO - __main__ -   Epoch: 174 | Batch: 4800/10001 (48%) | G Loss: 3.252928 | C Loss: -0.556498\n",
      "06/29/2022 10:45:58 - INFO - __main__ -   Text: ['The weather conditions can change drinks those on the premises.']\n",
      "06/29/2022 10:45:59 - INFO - __main__ -   Epoch: 174 | Batch: 5400/10001 (54%) | G Loss: 3.211589 | C Loss: -0.391995\n",
      "06/29/2022 10:45:59 - INFO - __main__ -   Text: [\"Players of Shenzhu filter out from PTC's pure .\"]\n",
      "06/29/2022 10:46:00 - INFO - __main__ -   Epoch: 174 | Batch: 6000/10001 (60%) | G Loss: 3.375119 | C Loss: -0.399488\n",
      "06/29/2022 10:46:00 - INFO - __main__ -   Text: [\"A knowledge weakens a player's ability to perform doubles when taking a flat with today's flat.\"]\n",
      "06/29/2022 10:46:01 - INFO - __main__ -   Epoch: 174 | Batch: 6600/10001 (66%) | G Loss: 3.327971 | C Loss: -0.489456\n",
      "06/29/2022 10:46:01 - INFO - __main__ -   Text: ['Chec is another indicator of other Dontnod content.']\n",
      "06/29/2022 10:46:02 - INFO - __main__ -   Epoch: 174 | Batch: 7200/10001 (72%) | G Loss: 3.303011 | C Loss: -0.474308\n",
      "06/29/2022 10:46:02 - INFO - __main__ -   Text: ['Order and Temperance.']\n",
      "06/29/2022 10:46:03 - INFO - __main__ -   Epoch: 174 | Batch: 7800/10001 (78%) | G Loss: 3.041275 | C Loss: -0.564471\n",
      "06/29/2022 10:46:04 - INFO - __main__ -   Text: [\"Marrill fifths to claim all the liabilities he's owed.\"]\n",
      "06/29/2022 10:46:05 - INFO - __main__ -   Epoch: 174 | Batch: 8400/10001 (84%) | G Loss: 2.596589 | C Loss: -0.483953\n",
      "06/29/2022 10:46:05 - INFO - __main__ -   Text: ['They are trying to figure out how to be happy.']\n",
      "06/29/2022 10:46:06 - INFO - __main__ -   Epoch: 174 | Batch: 9000/10001 (90%) | G Loss: 2.837680 | C Loss: -0.415844\n",
      "06/29/2022 10:46:06 - INFO - __main__ -   Text: [\"The title thieves has a mole in Barnes' head.\"]\n",
      "06/29/2022 10:46:07 - INFO - __main__ -   Epoch: 174 | Batch: 9600/10001 (96%) | G Loss: 3.004501 | C Loss: -0.453587\n",
      "06/29/2022 10:46:07 - INFO - __main__ -   Text: ['Not only can Burns check entomology without being a pocket scientist, it also could greatly alter reality.']\n",
      "06/29/2022 10:46:08 - INFO - __main__ -   * (Train) Epoch: 174 | G Loss: 3.0235 | C Loss: -0.4618 | Updates G: 35 | Updates C: 798\n",
      "06/29/2022 10:46:16 - INFO - __main__ -   Bleu-2:0.192 | B-Bleu-2:0.256\n",
      "06/29/2022 10:46:16 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4480873658068149\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 175 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:16.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:51.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:49:42 - INFO - __main__ -   Epoch: 175 | Batch: 0/10001 (0%) | G Loss: 3.371025 | C Loss: -0.570703\n",
      "06/29/2022 10:49:42 - INFO - __main__ -   Text: ['Now we can smoke Romeo.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.059\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:49:43 - INFO - __main__ -   Epoch: 175 | Batch: 600/10001 (6%) | G Loss: 3.710039 | C Loss: -0.549704\n",
      "06/29/2022 10:49:43 - INFO - __main__ -   Text: ['Nit Santiago was a tipoff for a sausage.\"']\n",
      "06/29/2022 10:49:44 - INFO - __main__ -   Epoch: 175 | Batch: 1200/10001 (12%) | G Loss: 3.904386 | C Loss: -0.314217\n",
      "06/29/2022 10:49:44 - INFO - __main__ -   Text: ['Like Sikr, Scribe is definitely a basketball player.']\n",
      "06/29/2022 10:49:45 - INFO - __main__ -   Epoch: 175 | Batch: 1800/10001 (18%) | G Loss: 3.534724 | C Loss: -0.500113\n",
      "06/29/2022 10:49:45 - INFO - __main__ -   Text: [\"The city's population is xenophobic.\"]\n",
      "06/29/2022 10:49:46 - INFO - __main__ -   Epoch: 175 | Batch: 2400/10001 (24%) | G Loss: 3.440542 | C Loss: -0.612296\n",
      "06/29/2022 10:49:46 - INFO - __main__ -   Text: [\"Actually, things don't go to Teebojwa for all time.\"]\n",
      "06/29/2022 10:49:47 - INFO - __main__ -   Epoch: 175 | Batch: 3000/10001 (30%) | G Loss: 2.926641 | C Loss: -0.495951\n",
      "06/29/2022 10:49:47 - INFO - __main__ -   Text: ['Pairs of bricks each human.']\n",
      "06/29/2022 10:49:48 - INFO - __main__ -   Epoch: 175 | Batch: 3600/10001 (36%) | G Loss: 3.123595 | C Loss: -0.473357\n",
      "06/29/2022 10:49:48 - INFO - __main__ -   Text: [\"He doesn't travel far from places and places that are hard to find.\"]\n",
      "06/29/2022 10:49:49 - INFO - __main__ -   Epoch: 175 | Batch: 4200/10001 (42%) | G Loss: 2.995553 | C Loss: -0.312753\n",
      "06/29/2022 10:49:49 - INFO - __main__ -   Text: ['You can see it here from the year \"Ayyyyyyyyyyy\".']\n",
      "06/29/2022 10:49:50 - INFO - __main__ -   Epoch: 175 | Batch: 4800/10001 (48%) | G Loss: 3.184040 | C Loss: -0.169558\n",
      "06/29/2022 10:49:50 - INFO - __main__ -   Text: ['Similar dual step format format to \"Forever Wide Range #.\"']\n",
      "06/29/2022 10:49:51 - INFO - __main__ -   Epoch: 175 | Batch: 5400/10001 (54%) | G Loss: 3.179109 | C Loss: -0.466550\n",
      "06/29/2022 10:49:51 - INFO - __main__ -   Text: ['The Indian Spirit is the greatest whip around.']\n",
      "06/29/2022 10:49:52 - INFO - __main__ -   Epoch: 175 | Batch: 6000/10001 (60%) | G Loss: 2.708731 | C Loss: -0.704525\n",
      "06/29/2022 10:49:53 - INFO - __main__ -   Text: ['Since 2nd grade benchmark, one should write, \"Teacher Pass\".']\n",
      "06/29/2022 10:49:54 - INFO - __main__ -   Epoch: 175 | Batch: 6600/10001 (66%) | G Loss: 3.068967 | C Loss: -0.444231\n",
      "06/29/2022 10:49:54 - INFO - __main__ -   Text: ['Shycott.']\n",
      "06/29/2022 10:49:55 - INFO - __main__ -   Epoch: 175 | Batch: 7200/10001 (72%) | G Loss: 2.980947 | C Loss: -0.547422\n",
      "06/29/2022 10:49:55 - INFO - __main__ -   Text: ['He is known for finding poetry, acting and acting funny people.']\n",
      "06/29/2022 10:49:56 - INFO - __main__ -   Epoch: 175 | Batch: 7800/10001 (78%) | G Loss: 3.032763 | C Loss: -0.546382\n",
      "06/29/2022 10:49:56 - INFO - __main__ -   Text: ['\"ESTORE!\"']\n",
      "06/29/2022 10:49:57 - INFO - __main__ -   Epoch: 175 | Batch: 8400/10001 (84%) | G Loss: 2.913914 | C Loss: -0.530021\n",
      "06/29/2022 10:49:57 - INFO - __main__ -   Text: ['Scrivly, \"The NY Post.\"']\n",
      "06/29/2022 10:49:58 - INFO - __main__ -   Epoch: 175 | Batch: 9000/10001 (90%) | G Loss: 3.526116 | C Loss: -0.534713\n",
      "06/29/2022 10:49:58 - INFO - __main__ -   Text: ['She is very confusing to boys, so I always try to balance it all.']\n",
      "06/29/2022 10:49:59 - INFO - __main__ -   Epoch: 175 | Batch: 9600/10001 (96%) | G Loss: 3.766778 | C Loss: -0.387518\n",
      "06/29/2022 10:49:59 - INFO - __main__ -   Text: ['The final test of Olympic speed.']\n",
      "06/29/2022 10:50:00 - INFO - __main__ -   * (Train) Epoch: 175 | G Loss: 3.0203 | C Loss: -0.4970 | Updates G: 30 | Updates C: 803\n",
      "06/29/2022 10:50:09 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.258\n",
      "06/29/2022 10:50:09 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46199755666092013\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 176 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:05.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:40.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:53:40 - INFO - __main__ -   Epoch: 176 | Batch: 0/10001 (0%) | G Loss: 3.863874 | C Loss: -0.887978\n",
      "06/29/2022 10:53:40 - INFO - __main__ -   Text: ['The IEC allows one to plant wings.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.068\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:53:41 - INFO - __main__ -   Epoch: 176 | Batch: 600/10001 (6%) | G Loss: 2.802760 | C Loss: -0.576195\n",
      "06/29/2022 10:53:42 - INFO - __main__ -   Text: ['This moves everything forward at the same time it sounds interesting\".']\n",
      "06/29/2022 10:53:43 - INFO - __main__ -   Epoch: 176 | Batch: 1200/10001 (12%) | G Loss: 2.382207 | C Loss: -0.299164\n",
      "06/29/2022 10:53:43 - INFO - __main__ -   Text: ['Of Destroy Underwear tacky.']\n",
      "06/29/2022 10:53:44 - INFO - __main__ -   Epoch: 176 | Batch: 1800/10001 (18%) | G Loss: 2.736326 | C Loss: -0.641838\n",
      "06/29/2022 10:53:44 - INFO - __main__ -   Text: ['Whilst he speaks, some say it right.']\n",
      "06/29/2022 10:53:45 - INFO - __main__ -   Epoch: 176 | Batch: 2400/10001 (24%) | G Loss: 3.545637 | C Loss: -0.669549\n",
      "06/29/2022 10:53:45 - INFO - __main__ -   Text: ['In the marketplace and crisis however, Waldorf owns the frigate.']\n",
      "06/29/2022 10:53:46 - INFO - __main__ -   Epoch: 176 | Batch: 3000/10001 (30%) | G Loss: 3.799636 | C Loss: -0.671861\n",
      "06/29/2022 10:53:46 - INFO - __main__ -   Text: ['Just because you\\'re against racism doesn\\'t mean what glad employee does is clueless.\"']\n",
      "06/29/2022 10:53:47 - INFO - __main__ -   Epoch: 176 | Batch: 3600/10001 (36%) | G Loss: 3.611334 | C Loss: -0.515747\n",
      "06/29/2022 10:53:47 - INFO - __main__ -   Text: ['Medicare.']\n",
      "06/29/2022 10:53:48 - INFO - __main__ -   Epoch: 176 | Batch: 4200/10001 (42%) | G Loss: 2.817306 | C Loss: -0.380847\n",
      "06/29/2022 10:53:48 - INFO - __main__ -   Text: ['It is to warn people that injuries and life in the world may not be as easy as they once thought.']\n",
      "06/29/2022 10:53:49 - INFO - __main__ -   Epoch: 176 | Batch: 4800/10001 (48%) | G Loss: 2.914151 | C Loss: -0.475246\n",
      "06/29/2022 10:53:49 - INFO - __main__ -   Text: ['Usually smaller and less dangerous people use the solution.']\n",
      "06/29/2022 10:53:50 - INFO - __main__ -   Epoch: 176 | Batch: 5400/10001 (54%) | G Loss: 3.201574 | C Loss: -0.474644\n",
      "06/29/2022 10:53:50 - INFO - __main__ -   Text: ['All mammals are free to move freely.']\n",
      "06/29/2022 10:53:51 - INFO - __main__ -   Epoch: 176 | Batch: 6000/10001 (60%) | G Loss: 3.001718 | C Loss: -0.386891\n",
      "06/29/2022 10:53:52 - INFO - __main__ -   Text: ['Teaching is the simplest part of the teaching of the God beyond known Moreover we must observe the different aspects of the']\n",
      "06/29/2022 10:53:52 - INFO - __main__ -   Epoch: 176 | Batch: 6600/10001 (66%) | G Loss: 2.842751 | C Loss: -0.439469\n",
      "06/29/2022 10:53:53 - INFO - __main__ -   Text: ['Physical activity is 5 seconds, or more than 50% faster.']\n",
      "06/29/2022 10:53:54 - INFO - __main__ -   Epoch: 176 | Batch: 7200/10001 (72%) | G Loss: 2.763176 | C Loss: -0.489160\n",
      "06/29/2022 10:53:54 - INFO - __main__ -   Text: ['It is possible to one-race theory.']\n",
      "06/29/2022 10:53:55 - INFO - __main__ -   Epoch: 176 | Batch: 7800/10001 (78%) | G Loss: 2.329506 | C Loss: -0.402587\n",
      "06/29/2022 10:53:55 - INFO - __main__ -   Text: ['An existing particle accelerator can execute this machine.']\n",
      "06/29/2022 10:53:56 - INFO - __main__ -   Epoch: 176 | Batch: 8400/10001 (84%) | G Loss: 3.036622 | C Loss: -0.508447\n",
      "06/29/2022 10:53:56 - INFO - __main__ -   Text: ['It has an appeal for readers of fantasy fairs.\"']\n",
      "06/29/2022 10:53:57 - INFO - __main__ -   Epoch: 176 | Batch: 9000/10001 (90%) | G Loss: 3.637571 | C Loss: -0.676453\n",
      "06/29/2022 10:53:57 - INFO - __main__ -   Text: ['These t-shirt shirts contain a comic cell phone.']\n",
      "06/29/2022 10:53:58 - INFO - __main__ -   Epoch: 176 | Batch: 9600/10001 (96%) | G Loss: 3.647224 | C Loss: -0.602770\n",
      "06/29/2022 10:53:58 - INFO - __main__ -   Text: ['\"Azilane\" is most likely not social college.']\n",
      "06/29/2022 10:53:59 - INFO - __main__ -   * (Train) Epoch: 176 | G Loss: 3.0511 | C Loss: -0.4645 | Updates G: 30 | Updates C: 803\n",
      "06/29/2022 10:54:07 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.239\n",
      "06/29/2022 10:54:07 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4457580050997384\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 177 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:57.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:57:38 - INFO - __main__ -   Epoch: 177 | Batch: 0/10001 (0%) | G Loss: 3.181585 | C Loss: -0.462526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.951\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 10:57:38 - INFO - __main__ -   Text: ['In Biodynamic we argue that fatty is one of the greatest aspects of non-hybrid fluids.']\n",
      "06/29/2022 10:57:39 - INFO - __main__ -   Epoch: 177 | Batch: 600/10001 (6%) | G Loss: 3.106082 | C Loss: -0.404224\n",
      "06/29/2022 10:57:39 - INFO - __main__ -   Text: ['Malcolm Horrocks: My Line Must Be William Howard!']\n",
      "06/29/2022 10:57:40 - INFO - __main__ -   Epoch: 177 | Batch: 1200/10001 (12%) | G Loss: 2.824951 | C Loss: -0.279600\n",
      "06/29/2022 10:57:41 - INFO - __main__ -   Text: ['While philosophers debate the definition of \"prediction\", it is the flavor of empty promises.']\n",
      "06/29/2022 10:57:42 - INFO - __main__ -   Epoch: 177 | Batch: 1800/10001 (18%) | G Loss: 2.572909 | C Loss: -0.339729\n",
      "06/29/2022 10:57:42 - INFO - __main__ -   Text: [\"A glance at an idea's upper limit or even its most fundamental state can give you an idea.\"]\n",
      "06/29/2022 10:57:43 - INFO - __main__ -   Epoch: 177 | Batch: 2400/10001 (24%) | G Loss: 3.254978 | C Loss: -0.414116\n",
      "06/29/2022 10:57:43 - INFO - __main__ -   Text: ['ABG wave complexity method.']\n",
      "06/29/2022 10:57:44 - INFO - __main__ -   Epoch: 177 | Batch: 3000/10001 (30%) | G Loss: 3.076248 | C Loss: -0.641329\n",
      "06/29/2022 10:57:44 - INFO - __main__ -   Text: ['He might suggest lazing all the time, but not always.']\n",
      "06/29/2022 10:57:45 - INFO - __main__ -   Epoch: 177 | Batch: 3600/10001 (36%) | G Loss: 3.348040 | C Loss: -0.484145\n",
      "06/29/2022 10:57:45 - INFO - __main__ -   Text: ['On the other hand it is possible to burn the sun in south-southeast Asia.']\n",
      "06/29/2022 10:57:46 - INFO - __main__ -   Epoch: 177 | Batch: 4200/10001 (42%) | G Loss: 3.626917 | C Loss: -0.459739\n",
      "06/29/2022 10:57:46 - INFO - __main__ -   Text: [\"A second isn't even in contact with law.\"]\n",
      "06/29/2022 10:57:47 - INFO - __main__ -   Epoch: 177 | Batch: 4800/10001 (48%) | G Loss: 3.047193 | C Loss: -0.519396\n",
      "06/29/2022 10:57:47 - INFO - __main__ -   Text: ['When we are led to believe they would be extraordinary.']\n",
      "06/29/2022 10:57:48 - INFO - __main__ -   Epoch: 177 | Batch: 5400/10001 (54%) | G Loss: 2.877941 | C Loss: -0.356174\n",
      "06/29/2022 10:57:48 - INFO - __main__ -   Text: ['He is a Calvinist character, from whose derived apudon founders the position of the Noble Companion.']\n",
      "06/29/2022 10:57:49 - INFO - __main__ -   Epoch: 177 | Batch: 6000/10001 (60%) | G Loss: 2.599721 | C Loss: -0.339939\n",
      "06/29/2022 10:57:49 - INFO - __main__ -   Text: ['This can also easily be done for managers.']\n",
      "06/29/2022 10:57:50 - INFO - __main__ -   Epoch: 177 | Batch: 6600/10001 (66%) | G Loss: 2.937927 | C Loss: -0.546426\n",
      "06/29/2022 10:57:50 - INFO - __main__ -   Text: ['Some voices may not be present.']\n",
      "06/29/2022 10:57:51 - INFO - __main__ -   Epoch: 177 | Batch: 7200/10001 (72%) | G Loss: 3.499728 | C Loss: -0.646551\n",
      "06/29/2022 10:57:52 - INFO - __main__ -   Text: ['Applications of this technique have been developed.']\n",
      "06/29/2022 10:57:52 - INFO - __main__ -   Epoch: 177 | Batch: 7800/10001 (78%) | G Loss: 3.607540 | C Loss: -0.421660\n",
      "06/29/2022 10:57:53 - INFO - __main__ -   Text: ['They have to be really strong because non-verbal expressions of love are rarely heard.\"']\n",
      "06/29/2022 10:57:54 - INFO - __main__ -   Epoch: 177 | Batch: 8400/10001 (84%) | G Loss: 3.568729 | C Loss: -0.618063\n",
      "06/29/2022 10:57:54 - INFO - __main__ -   Text: ['The only thing bigger is \"weaker\" \"ignoring the SMS.\"']\n",
      "06/29/2022 10:57:55 - INFO - __main__ -   Epoch: 177 | Batch: 9000/10001 (90%) | G Loss: 3.291336 | C Loss: -0.424382\n",
      "06/29/2022 10:57:55 - INFO - __main__ -   Text: [\"He ain't hit.\"]\n",
      "06/29/2022 10:57:56 - INFO - __main__ -   Epoch: 177 | Batch: 9600/10001 (96%) | G Loss: 2.698552 | C Loss: -0.453855\n",
      "06/29/2022 10:57:56 - INFO - __main__ -   Text: ['These two Course Mahras\" are web content.']\n",
      "06/29/2022 10:57:57 - INFO - __main__ -   * (Train) Epoch: 177 | G Loss: 2.9607 | C Loss: -0.4664 | Updates G: 38 | Updates C: 795\n",
      "06/29/2022 10:58:06 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.264\n",
      "06/29/2022 10:58:06 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46204051962079196\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 178 / 200 ========\n",
      "Training...\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:01:33 - INFO - __main__ -   Epoch: 178 | Batch: 0/10001 (0%) | G Loss: 2.718099 | C Loss: -0.440788\n",
      "06/29/2022 11:01:34 - INFO - __main__ -   Text: ['refers to using \"pommet-san\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 4.016\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:01:34 - INFO - __main__ -   Epoch: 178 | Batch: 600/10001 (6%) | G Loss: 2.705983 | C Loss: -0.444708\n",
      "06/29/2022 11:01:35 - INFO - __main__ -   Text: ['Samula has some marijuana.']\n",
      "06/29/2022 11:01:36 - INFO - __main__ -   Epoch: 178 | Batch: 1200/10001 (12%) | G Loss: 2.979445 | C Loss: -0.505297\n",
      "06/29/2022 11:01:36 - INFO - __main__ -   Text: ['The Earth is about seventy light years long, usually between the star and star-shaped region.']\n",
      "06/29/2022 11:01:37 - INFO - __main__ -   Epoch: 178 | Batch: 1800/10001 (18%) | G Loss: 3.158447 | C Loss: -0.439633\n",
      "06/29/2022 11:01:37 - INFO - __main__ -   Text: ['Our government is on arrest.']\n",
      "06/29/2022 11:01:38 - INFO - __main__ -   Epoch: 178 | Batch: 2400/10001 (24%) | G Loss: 3.526043 | C Loss: -0.344065\n",
      "06/29/2022 11:01:38 - INFO - __main__ -   Text: ['No silk !']\n",
      "06/29/2022 11:01:39 - INFO - __main__ -   Epoch: 178 | Batch: 3000/10001 (30%) | G Loss: 2.964407 | C Loss: -0.339886\n",
      "06/29/2022 11:01:39 - INFO - __main__ -   Text: ['Is my smartphone camera mas they? <PAD> redirective.']\n",
      "06/29/2022 11:01:40 - INFO - __main__ -   Epoch: 178 | Batch: 3600/10001 (36%) | G Loss: 3.123494 | C Loss: -0.714946\n",
      "06/29/2022 11:01:40 - INFO - __main__ -   Text: ['Their keyword is \"Peidae.\"']\n",
      "06/29/2022 11:01:41 - INFO - __main__ -   Epoch: 178 | Batch: 4200/10001 (42%) | G Loss: 3.276030 | C Loss: -0.675593\n",
      "06/29/2022 11:01:41 - INFO - __main__ -   Text: ['Although Bach does not cite a particular phrase (.. ) An example is is Arabic consonant.']\n",
      "06/29/2022 11:01:42 - INFO - __main__ -   Epoch: 178 | Batch: 4800/10001 (48%) | G Loss: 3.106613 | C Loss: -0.931282\n",
      "06/29/2022 11:01:42 - INFO - __main__ -   Text: ['Subjective belief is destroying social progress.\"']\n",
      "06/29/2022 11:01:43 - INFO - __main__ -   Epoch: 178 | Batch: 5400/10001 (54%) | G Loss: 2.768074 | C Loss: -0.500349\n",
      "06/29/2022 11:01:43 - INFO - __main__ -   Text: ['This is what Akira is talking about.']\n",
      "06/29/2022 11:01:44 - INFO - __main__ -   Epoch: 178 | Batch: 6000/10001 (60%) | G Loss: 2.571458 | C Loss: -0.656865\n",
      "06/29/2022 11:01:44 - INFO - __main__ -   Text: ['Science even works against evil.']\n",
      "06/29/2022 11:01:45 - INFO - __main__ -   Epoch: 178 | Batch: 6600/10001 (66%) | G Loss: 2.291503 | C Loss: -0.204067\n",
      "06/29/2022 11:01:45 - INFO - __main__ -   Text: ['Worms can also attack food bagels.']\n",
      "06/29/2022 11:01:46 - INFO - __main__ -   Epoch: 178 | Batch: 7200/10001 (72%) | G Loss: 2.477541 | C Loss: -0.226259\n",
      "06/29/2022 11:01:46 - INFO - __main__ -   Text: ['People can set up a mobile app.']\n",
      "06/29/2022 11:01:47 - INFO - __main__ -   Epoch: 178 | Batch: 7800/10001 (78%) | G Loss: 2.621065 | C Loss: -0.424470\n",
      "06/29/2022 11:01:47 - INFO - __main__ -   Text: ['The internet-step is fabulous\").']\n",
      "06/29/2022 11:01:48 - INFO - __main__ -   Epoch: 178 | Batch: 8400/10001 (84%) | G Loss: 3.180587 | C Loss: -0.689144\n",
      "06/29/2022 11:01:48 - INFO - __main__ -   Text: ['groups on Psychology.)']\n",
      "06/29/2022 11:01:49 - INFO - __main__ -   Epoch: 178 | Batch: 9000/10001 (90%) | G Loss: 3.112027 | C Loss: -0.512084\n",
      "06/29/2022 11:01:50 - INFO - __main__ -   Text: ['The game teaches you ropes in diving.']\n",
      "06/29/2022 11:01:51 - INFO - __main__ -   Epoch: 178 | Batch: 9600/10001 (96%) | G Loss: 3.116666 | C Loss: -0.574475\n",
      "06/29/2022 11:01:51 - INFO - __main__ -   Text: ['Neink has achieved good reception by using the best text for this task.']\n",
      "06/29/2022 11:01:51 - INFO - __main__ -   * (Train) Epoch: 178 | G Loss: 2.8967 | C Loss: -0.4798 | Updates G: 30 | Updates C: 803\n",
      "06/29/2022 11:02:00 - INFO - __main__ -   Bleu-2:0.193 | B-Bleu-2:0.223\n",
      "06/29/2022 11:02:00 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166002408983816\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 179 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:05:28 - INFO - __main__ -   Epoch: 179 | Batch: 0/10001 (0%) | G Loss: 2.814986 | C Loss: -0.425669\n",
      "06/29/2022 11:05:28 - INFO - __main__ -   Text: ['what a wicked concept, or even better of all.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.510\n",
      "  Test Loss: 3.968\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:05:29 - INFO - __main__ -   Epoch: 179 | Batch: 600/10001 (6%) | G Loss: 3.290262 | C Loss: -0.477009\n",
      "06/29/2022 11:05:29 - INFO - __main__ -   Text: ['\"I call it nanochemistry. <BOS>:\"']\n",
      "06/29/2022 11:05:30 - INFO - __main__ -   Epoch: 179 | Batch: 1200/10001 (12%) | G Loss: 3.039962 | C Loss: -0.361199\n",
      "06/29/2022 11:05:30 - INFO - __main__ -   Text: ['It is a by-platform for Tagalogics There are over 13 languages in the world.']\n",
      "06/29/2022 11:05:31 - INFO - __main__ -   Epoch: 179 | Batch: 1800/10001 (18%) | G Loss: 3.514892 | C Loss: -0.671694\n",
      "06/29/2022 11:05:32 - INFO - __main__ -   Text: ['Like it in Canada, it is predicated in first-class.']\n",
      "06/29/2022 11:05:33 - INFO - __main__ -   Epoch: 179 | Batch: 2400/10001 (24%) | G Loss: 3.147790 | C Loss: -0.712933\n",
      "06/29/2022 11:05:33 - INFO - __main__ -   Text: ['Suppose Scotland has an existential threat but does not hate Britain.']\n",
      "06/29/2022 11:05:34 - INFO - __main__ -   Epoch: 179 | Batch: 3000/10001 (30%) | G Loss: 2.908201 | C Loss: -0.386714\n",
      "06/29/2022 11:05:34 - INFO - __main__ -   Text: ['PCA is your \"lies detector.\"']\n",
      "06/29/2022 11:05:35 - INFO - __main__ -   Epoch: 179 | Batch: 3600/10001 (36%) | G Loss: 3.175506 | C Loss: -0.485202\n",
      "06/29/2022 11:05:35 - INFO - __main__ -   Text: ['The seller in the US, Apeckfeather, promises to sell the sum rocket seeds.']\n",
      "06/29/2022 11:05:36 - INFO - __main__ -   Epoch: 179 | Batch: 4200/10001 (42%) | G Loss: 2.808232 | C Loss: -0.381156\n",
      "06/29/2022 11:05:36 - INFO - __main__ -   Text: ['like this\".']\n",
      "06/29/2022 11:05:37 - INFO - __main__ -   Epoch: 179 | Batch: 4800/10001 (48%) | G Loss: 2.602420 | C Loss: -0.455483\n",
      "06/29/2022 11:05:37 - INFO - __main__ -   Text: ['Demology is a career.\"']\n",
      "06/29/2022 11:05:38 - INFO - __main__ -   Epoch: 179 | Batch: 5400/10001 (54%) | G Loss: 2.859970 | C Loss: -0.297911\n",
      "06/29/2022 11:05:38 - INFO - __main__ -   Text: [\"He assumes that he's one of the most beautiful humans in town.」\"]\n",
      "06/29/2022 11:05:39 - INFO - __main__ -   Epoch: 179 | Batch: 6000/10001 (60%) | G Loss: 3.195825 | C Loss: -0.376829\n",
      "06/29/2022 11:05:39 - INFO - __main__ -   Text: ['F.B. <PAD>.']\n",
      "06/29/2022 11:05:40 - INFO - __main__ -   Epoch: 179 | Batch: 6600/10001 (66%) | G Loss: 3.254564 | C Loss: -0.379955\n",
      "06/29/2022 11:05:40 - INFO - __main__ -   Text: ['Patients are development vector font W2 FX.']\n",
      "06/29/2022 11:05:41 - INFO - __main__ -   Epoch: 179 | Batch: 7200/10001 (72%) | G Loss: 3.444460 | C Loss: -0.450253\n",
      "06/29/2022 11:05:41 - INFO - __main__ -   Text: ['It gets yits 2 NEW!\"']\n",
      "06/29/2022 11:05:42 - INFO - __main__ -   Epoch: 179 | Batch: 7800/10001 (78%) | G Loss: 3.526505 | C Loss: -0.432684\n",
      "06/29/2022 11:05:42 - INFO - __main__ -   Text: ['Neither does this behavior feel anything other than polite!\"']\n",
      "06/29/2022 11:05:43 - INFO - __main__ -   Epoch: 179 | Batch: 8400/10001 (84%) | G Loss: 3.220768 | C Loss: -0.516431\n",
      "06/29/2022 11:05:43 - INFO - __main__ -   Text: ['The Laserner is very ingenious.']\n",
      "06/29/2022 11:05:44 - INFO - __main__ -   Epoch: 179 | Batch: 9000/10001 (90%) | G Loss: 3.406121 | C Loss: -0.307993\n",
      "06/29/2022 11:05:44 - INFO - __main__ -   Text: ['Some of these are on my AVID!']\n",
      "06/29/2022 11:05:45 - INFO - __main__ -   Epoch: 179 | Batch: 9600/10001 (96%) | G Loss: 3.134915 | C Loss: -0.458269\n",
      "06/29/2022 11:05:46 - INFO - __main__ -   Text: ['He is dancing now with lots (even if he is running) and lost through a hedgehog.']\n",
      "06/29/2022 11:05:46 - INFO - __main__ -   * (Train) Epoch: 179 | G Loss: 3.0820 | C Loss: -0.4683 | Updates G: 27 | Updates C: 806\n",
      "06/29/2022 11:05:55 - INFO - __main__ -   Bleu-2:0.205 | B-Bleu-2:0.238\n",
      "06/29/2022 11:05:55 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_12.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44330984824501235\n",
      "Train file used is number 12\n",
      "../../yahoo/subdivided_large/train_12.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 180 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:09:22 - INFO - __main__ -   Epoch: 180 | Batch: 0/10001 (0%) | G Loss: 2.815934 | C Loss: -0.534288\n",
      "06/29/2022 11:09:22 - INFO - __main__ -   Text: ['The robber barons would rather steal.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.512\n",
      "  Test Loss: 3.940\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:09:23 - INFO - __main__ -   Epoch: 180 | Batch: 600/10001 (6%) | G Loss: 2.964690 | C Loss: -0.480146\n",
      "06/29/2022 11:09:23 - INFO - __main__ -   Text: ['Unfortunately we are told that here on Earth.']\n",
      "06/29/2022 11:09:24 - INFO - __main__ -   Epoch: 180 | Batch: 1200/10001 (12%) | G Loss: 3.361484 | C Loss: -0.570273\n",
      "06/29/2022 11:09:25 - INFO - __main__ -   Text: ['in this category. <PAD> has been bugging them !!']\n",
      "06/29/2022 11:09:26 - INFO - __main__ -   Epoch: 180 | Batch: 1800/10001 (18%) | G Loss: 3.383551 | C Loss: -0.452537\n",
      "06/29/2022 11:09:26 - INFO - __main__ -   Text: ['At what price?']\n",
      "06/29/2022 11:09:27 - INFO - __main__ -   Epoch: 180 | Batch: 2400/10001 (24%) | G Loss: 3.256180 | C Loss: -0.429504\n",
      "06/29/2022 11:09:27 - INFO - __main__ -   Text: ['They are positive examples that motivated them to conclude \"I wish operation.\"']\n",
      "06/29/2022 11:09:28 - INFO - __main__ -   Epoch: 180 | Batch: 3000/10001 (30%) | G Loss: 3.238008 | C Loss: -0.410609\n",
      "06/29/2022 11:09:28 - INFO - __main__ -   Text: ['Yesononyool, they are big yum!\" <PAD>ononyool (to smell good).']\n",
      "06/29/2022 11:09:29 - INFO - __main__ -   Epoch: 180 | Batch: 3600/10001 (36%) | G Loss: 3.593827 | C Loss: -0.323939\n",
      "06/29/2022 11:09:29 - INFO - __main__ -   Text: ['Despite double-d rejection, I think mixed environments sound good.\"']\n",
      "06/29/2022 11:09:30 - INFO - __main__ -   Epoch: 180 | Batch: 4200/10001 (42%) | G Loss: 2.993298 | C Loss: -0.444419\n",
      "06/29/2022 11:09:30 - INFO - __main__ -   Text: ['Hence ambitious pursuits.']\n",
      "06/29/2022 11:09:31 - INFO - __main__ -   Epoch: 180 | Batch: 4800/10001 (48%) | G Loss: 2.822326 | C Loss: -0.354446\n",
      "06/29/2022 11:09:31 - INFO - __main__ -   Text: ['These things will involve inventions.\"']\n",
      "06/29/2022 11:09:32 - INFO - __main__ -   Epoch: 180 | Batch: 5400/10001 (54%) | G Loss: 2.900677 | C Loss: -0.443852\n",
      "06/29/2022 11:09:32 - INFO - __main__ -   Text: ['\"hurrah Bashid Miriam\" rated this gem']\n",
      "06/29/2022 11:09:33 - INFO - __main__ -   Epoch: 180 | Batch: 6000/10001 (60%) | G Loss: 3.180990 | C Loss: -0.404709\n",
      "06/29/2022 11:09:33 - INFO - __main__ -   Text: ['BMNO Protection is too short to read by tube.']\n",
      "06/29/2022 11:09:34 - INFO - __main__ -   Epoch: 180 | Batch: 6600/10001 (66%) | G Loss: 3.418640 | C Loss: -0.509138\n",
      "06/29/2022 11:09:34 - INFO - __main__ -   Text: [\"Pan's a warning because it would be half day in the future when a paranormal phenomenon .\"]\n",
      "06/29/2022 11:09:35 - INFO - __main__ -   Epoch: 180 | Batch: 7200/10001 (72%) | G Loss: 3.459803 | C Loss: -0.681152\n",
      "06/29/2022 11:09:36 - INFO - __main__ -   Text: [\"This has resulted in investigation of Philip Harum's thesis claimed on meditation.\"]\n",
      "06/29/2022 11:09:37 - INFO - __main__ -   Epoch: 180 | Batch: 7800/10001 (78%) | G Loss: 2.906136 | C Loss: -0.378107\n",
      "06/29/2022 11:09:37 - INFO - __main__ -   Text: ['She also has the great addictive and entertaining titles \"Drawn to Learn\" and \"Test Yourself\".']\n",
      "06/29/2022 11:09:38 - INFO - __main__ -   Epoch: 180 | Batch: 8400/10001 (84%) | G Loss: 3.114334 | C Loss: -0.557963\n",
      "06/29/2022 11:09:38 - INFO - __main__ -   Text: ['While these hobbies are descriptive, they are not perfect.']\n",
      "06/29/2022 11:09:39 - INFO - __main__ -   Epoch: 180 | Batch: 9000/10001 (90%) | G Loss: 2.909275 | C Loss: -0.384616\n",
      "06/29/2022 11:09:39 - INFO - __main__ -   Text: ['Ingenius plays the strong-man candidate to the man.']\n",
      "06/29/2022 11:09:40 - INFO - __main__ -   Epoch: 180 | Batch: 9600/10001 (96%) | G Loss: 3.163074 | C Loss: -0.463926\n",
      "06/29/2022 11:09:40 - INFO - __main__ -   Text: ['Earth\\'s Oldest astronomers.\"']\n",
      "06/29/2022 11:09:41 - INFO - __main__ -   * (Train) Epoch: 180 | G Loss: 3.0578 | C Loss: -0.4748 | Updates G: 39 | Updates C: 794\n",
      "06/29/2022 11:09:50 - INFO - __main__ -   Bleu-2:0.200 | B-Bleu-2:0.270\n",
      "06/29/2022 11:09:50 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_13.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4696043589552172\n",
      "Train file used is number 13\n",
      "../../yahoo/subdivided_large/train_13.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 181 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:13:20 - INFO - __main__ -   Epoch: 181 | Batch: 0/10001 (0%) | G Loss: 3.056807 | C Loss: -0.360219\n",
      "06/29/2022 11:13:20 - INFO - __main__ -   Text: ['He is the returning Home Ship owner who lives nearby.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 3.960\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:13:21 - INFO - __main__ -   Epoch: 181 | Batch: 600/10001 (6%) | G Loss: 3.463085 | C Loss: -0.535397\n",
      "06/29/2022 11:13:21 - INFO - __main__ -   Text: ['Line administrators can be classified as Prohenovitis control or prophylaxis block.']\n",
      "06/29/2022 11:13:22 - INFO - __main__ -   Epoch: 181 | Batch: 1200/10001 (12%) | G Loss: 3.879297 | C Loss: -0.632143\n",
      "06/29/2022 11:13:23 - INFO - __main__ -   Text: ['\"Drink agencies test me at a price\" (the guy is saying he uses drug-based alternatives).']\n",
      "06/29/2022 11:13:23 - INFO - __main__ -   Epoch: 181 | Batch: 1800/10001 (18%) | G Loss: 3.278344 | C Loss: -0.350117\n",
      "06/29/2022 11:13:24 - INFO - __main__ -   Text: [\"It's a very ordinary story that I'm having fun with.\"]\n",
      "06/29/2022 11:13:25 - INFO - __main__ -   Epoch: 181 | Batch: 2400/10001 (24%) | G Loss: 3.365459 | C Loss: -0.418563\n",
      "06/29/2022 11:13:25 - INFO - __main__ -   Text: ['Express flour seems to be lo fast then.']\n",
      "06/29/2022 11:13:26 - INFO - __main__ -   Epoch: 181 | Batch: 3000/10001 (30%) | G Loss: 3.369608 | C Loss: -0.692097\n",
      "06/29/2022 11:13:26 - INFO - __main__ -   Text: ['As intersection of Buddhism and Freemasonry.']\n",
      "06/29/2022 11:13:27 - INFO - __main__ -   Epoch: 181 | Batch: 3600/10001 (36%) | G Loss: 3.118812 | C Loss: -0.973617\n",
      "06/29/2022 11:13:27 - INFO - __main__ -   Text: [\"Swamy won't seem a pretty name, but Iain (as Iain from C.F.\"]\n",
      "06/29/2022 11:13:28 - INFO - __main__ -   Epoch: 181 | Batch: 4200/10001 (42%) | G Loss: 2.728096 | C Loss: -0.452768\n",
      "06/29/2022 11:13:28 - INFO - __main__ -   Text: ['The Tenets are inscribed in different places around the world.']\n",
      "06/29/2022 11:13:29 - INFO - __main__ -   Epoch: 181 | Batch: 4800/10001 (48%) | G Loss: 2.629010 | C Loss: -0.527417\n",
      "06/29/2022 11:13:29 - INFO - __main__ -   Text: ['It can also be played on the HD free stream, which is the only time it is playing on the']\n",
      "06/29/2022 11:13:30 - INFO - __main__ -   Epoch: 181 | Batch: 5400/10001 (54%) | G Loss: 3.013800 | C Loss: -0.348996\n",
      "06/29/2022 11:13:30 - INFO - __main__ -   Text: ['She is equipped for small life forms on small scales.']\n",
      "06/29/2022 11:13:31 - INFO - __main__ -   Epoch: 181 | Batch: 6000/10001 (60%) | G Loss: 3.412120 | C Loss: -0.565487\n",
      "06/29/2022 11:13:31 - INFO - __main__ -   Text: ['There may be a threat onset instead of a sudden fatal condition.']\n",
      "06/29/2022 11:13:32 - INFO - __main__ -   Epoch: 181 | Batch: 6600/10001 (66%) | G Loss: 3.582029 | C Loss: -0.732947\n",
      "06/29/2022 11:13:33 - INFO - __main__ -   Text: [\"There isn't much to what Hillary Clinton has said about it.</p></p>\"]\n",
      "06/29/2022 11:13:34 - INFO - __main__ -   Epoch: 181 | Batch: 7200/10001 (72%) | G Loss: 3.386797 | C Loss: -0.509036\n",
      "06/29/2022 11:13:34 - INFO - __main__ -   Text: ['The highly regarded model \"i vac\" relies on observations of Berlin Hansmuth.']\n",
      "06/29/2022 11:13:35 - INFO - __main__ -   Epoch: 181 | Batch: 7800/10001 (78%) | G Loss: 3.123596 | C Loss: -0.444819\n",
      "06/29/2022 11:13:35 - INFO - __main__ -   Text: ['Ladenard is only here because Silk is choosing the method of writing.']\n",
      "06/29/2022 11:13:36 - INFO - __main__ -   Epoch: 181 | Batch: 8400/10001 (84%) | G Loss: 2.981721 | C Loss: -0.398942\n",
      "06/29/2022 11:13:36 - INFO - __main__ -   Text: ['It is a shock.']\n",
      "06/29/2022 11:13:37 - INFO - __main__ -   Epoch: 181 | Batch: 9000/10001 (90%) | G Loss: 2.867326 | C Loss: -0.567921\n",
      "06/29/2022 11:13:37 - INFO - __main__ -   Text: ['Sometime Around.']\n",
      "06/29/2022 11:13:38 - INFO - __main__ -   Epoch: 181 | Batch: 9600/10001 (96%) | G Loss: 2.858564 | C Loss: -0.513194\n",
      "06/29/2022 11:13:38 - INFO - __main__ -   Text: ['It becomes a joke that dogs are trained to hunt people.']\n",
      "06/29/2022 11:13:39 - INFO - __main__ -   * (Train) Epoch: 181 | G Loss: 3.0445 | C Loss: -0.4694 | Updates G: 33 | Updates C: 800\n",
      "06/29/2022 11:13:48 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.287\n",
      "06/29/2022 11:13:48 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_14.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49105542215628595\n",
      "Train file used is number 14\n",
      "../../yahoo/subdivided_large/train_14.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 182 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:17:17 - INFO - __main__ -   Epoch: 182 | Batch: 0/10001 (0%) | G Loss: 2.927609 | C Loss: -0.421274\n",
      "06/29/2022 11:17:18 - INFO - __main__ -   Text: ['Scorching hands, clicking wheels etc might be bad for a chin.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.510\n",
      "  Test Loss: 4.021\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:17:19 - INFO - __main__ -   Epoch: 182 | Batch: 600/10001 (6%) | G Loss: 3.248631 | C Loss: -0.589791\n",
      "06/29/2022 11:17:19 - INFO - __main__ -   Text: ['This perfects : 238 \"class\", 1 \"oh\"; 121 \"won\".']\n",
      "06/29/2022 11:17:20 - INFO - __main__ -   Epoch: 182 | Batch: 1200/10001 (12%) | G Loss: 3.662304 | C Loss: -0.429753\n",
      "06/29/2022 11:17:20 - INFO - __main__ -   Text: ['After that, she will be always depressed.\"']\n",
      "06/29/2022 11:17:21 - INFO - __main__ -   Epoch: 182 | Batch: 1800/10001 (18%) | G Loss: 3.583094 | C Loss: -0.393663\n",
      "06/29/2022 11:17:21 - INFO - __main__ -   Text: ['The car trains on cargo truck or express luggage transfer.']\n",
      "06/29/2022 11:17:22 - INFO - __main__ -   Epoch: 182 | Batch: 2400/10001 (24%) | G Loss: 2.990459 | C Loss: -0.537132\n",
      "06/29/2022 11:17:22 - INFO - __main__ -   Text: ['Neurosis usually takes a long, unattractive to show.']\n",
      "06/29/2022 11:17:23 - INFO - __main__ -   Epoch: 182 | Batch: 3000/10001 (30%) | G Loss: 3.078529 | C Loss: -0.341554\n",
      "06/29/2022 11:17:23 - INFO - __main__ -   Text: ['Turtling and on that there is a change from Chelsea.']\n",
      "06/29/2022 11:17:24 - INFO - __main__ -   Epoch: 182 | Batch: 3600/10001 (36%) | G Loss: 2.741988 | C Loss: -0.373305\n",
      "06/29/2022 11:17:24 - INFO - __main__ -   Text: ['The project calls ZivaxLua based on US dollars use.']\n",
      "06/29/2022 11:17:25 - INFO - __main__ -   Epoch: 182 | Batch: 4200/10001 (42%) | G Loss: 3.358522 | C Loss: -0.545149\n",
      "06/29/2022 11:17:25 - INFO - __main__ -   Text: [', \"Let\\'s Not Kill Nothing\" has not received much positive opinion.']\n",
      "06/29/2022 11:17:26 - INFO - __main__ -   Epoch: 182 | Batch: 4800/10001 (48%) | G Loss: 3.473891 | C Loss: -0.621195\n",
      "06/29/2022 11:17:26 - INFO - __main__ -   Text: ['Aside from football, he is a true throwaway pagebook.']\n",
      "06/29/2022 11:17:27 - INFO - __main__ -   Epoch: 182 | Batch: 5400/10001 (54%) | G Loss: 3.065701 | C Loss: -0.358823\n",
      "06/29/2022 11:17:27 - INFO - __main__ -   Text: ['In this game, he lures people to his couch and beats them upon arrival.']\n",
      "06/29/2022 11:17:28 - INFO - __main__ -   Epoch: 182 | Batch: 6000/10001 (60%) | G Loss: 3.239742 | C Loss: -0.538846\n",
      "06/29/2022 11:17:29 - INFO - __main__ -   Text: ['The island is rated M.A.']\n",
      "06/29/2022 11:17:29 - INFO - __main__ -   Epoch: 182 | Batch: 6600/10001 (66%) | G Loss: 3.378314 | C Loss: -0.480123\n",
      "06/29/2022 11:17:30 - INFO - __main__ -   Text: [\"Aunty's claim postulates that the formula A is empirically correct only for well-developed hypotheses mathematically\"]\n",
      "06/29/2022 11:17:31 - INFO - __main__ -   Epoch: 182 | Batch: 7200/10001 (72%) | G Loss: 3.055315 | C Loss: -0.355964\n",
      "06/29/2022 11:17:31 - INFO - __main__ -   Text: ['.']\n",
      "06/29/2022 11:17:32 - INFO - __main__ -   Epoch: 182 | Batch: 7800/10001 (78%) | G Loss: 2.959751 | C Loss: -0.464241\n",
      "06/29/2022 11:17:32 - INFO - __main__ -   Text: ['Instincts provides a C++ template language.']\n",
      "06/29/2022 11:17:33 - INFO - __main__ -   Epoch: 182 | Batch: 8400/10001 (84%) | G Loss: 3.084849 | C Loss: -0.433934\n",
      "06/29/2022 11:17:33 - INFO - __main__ -   Text: ['The best number is about 0.33 or 0.42 while the shortest is about 0.']\n",
      "06/29/2022 11:17:34 - INFO - __main__ -   Epoch: 182 | Batch: 9000/10001 (90%) | G Loss: 3.175589 | C Loss: -0.573969\n",
      "06/29/2022 11:17:34 - INFO - __main__ -   Text: ['Oxies often cause serious health problems.']\n",
      "06/29/2022 11:17:35 - INFO - __main__ -   Epoch: 182 | Batch: 9600/10001 (96%) | G Loss: 3.170556 | C Loss: -0.503041\n",
      "06/29/2022 11:17:35 - INFO - __main__ -   Text: ['As alcohol consumption increases inactivity, it is closely associated with dangerously impaired judgment.']\n",
      "06/29/2022 11:17:36 - INFO - __main__ -   * (Train) Epoch: 182 | G Loss: 3.1043 | C Loss: -0.4711 | Updates G: 32 | Updates C: 801\n",
      "06/29/2022 11:17:45 - INFO - __main__ -   Bleu-2:0.196 | B-Bleu-2:0.236\n",
      "06/29/2022 11:17:45 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43233293624367247\n",
      "Train file used is number 15\n",
      "../../yahoo/subdivided_large/train_15.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 183 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:21:12 - INFO - __main__ -   Epoch: 183 | Batch: 0/10001 (0%) | G Loss: 3.195146 | C Loss: -0.470031\n",
      "06/29/2022 11:21:12 - INFO - __main__ -   Text: ['So Shahy\\'s day is mellow.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 4.232\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:21:13 - INFO - __main__ -   Epoch: 183 | Batch: 600/10001 (6%) | G Loss: 3.052706 | C Loss: -0.545295\n",
      "06/29/2022 11:21:13 - INFO - __main__ -   Text: ['Such travel expenses by certain people.\"']\n",
      "06/29/2022 11:21:14 - INFO - __main__ -   Epoch: 183 | Batch: 1200/10001 (12%) | G Loss: 2.977137 | C Loss: -0.484183\n",
      "06/29/2022 11:21:14 - INFO - __main__ -   Text: ['The lyrics are similar.']\n",
      "06/29/2022 11:21:15 - INFO - __main__ -   Epoch: 183 | Batch: 1800/10001 (18%) | G Loss: 3.012757 | C Loss: -0.422646\n",
      "06/29/2022 11:21:15 - INFO - __main__ -   Text: ['It has been promised the Eastern states of the US meet.']\n",
      "06/29/2022 11:21:16 - INFO - __main__ -   Epoch: 183 | Batch: 2400/10001 (24%) | G Loss: 3.394922 | C Loss: -0.580934\n",
      "06/29/2022 11:21:16 - INFO - __main__ -   Text: ['The black people use TIDAL demos as they read.']\n",
      "06/29/2022 11:21:17 - INFO - __main__ -   Epoch: 183 | Batch: 3000/10001 (30%) | G Loss: 2.884248 | C Loss: -0.452984\n",
      "06/29/2022 11:21:17 - INFO - __main__ -   Text: ['Also: 310 horizontal.\"']\n",
      "06/29/2022 11:21:18 - INFO - __main__ -   Epoch: 183 | Batch: 3600/10001 (36%) | G Loss: 3.123093 | C Loss: -0.513014\n",
      "06/29/2022 11:21:18 - INFO - __main__ -   Text: ['\"PU aide me!\"']\n",
      "06/29/2022 11:21:19 - INFO - __main__ -   Epoch: 183 | Batch: 4200/10001 (42%) | G Loss: 3.138453 | C Loss: -0.411208\n",
      "06/29/2022 11:21:19 - INFO - __main__ -   Text: ['It does not use lily and bile in potion and similar.']\n",
      "06/29/2022 11:21:20 - INFO - __main__ -   Epoch: 183 | Batch: 4800/10001 (48%) | G Loss: 3.382964 | C Loss: -0.579273\n",
      "06/29/2022 11:21:20 - INFO - __main__ -   Text: ['Lisinski has also of course pulled out of even his previous songs and also sequels.']\n",
      "06/29/2022 11:21:21 - INFO - __main__ -   Epoch: 183 | Batch: 5400/10001 (54%) | G Loss: 3.242560 | C Loss: -0.181701\n",
      "06/29/2022 11:21:21 - INFO - __main__ -   Text: ['Imagine a nation where every man called an asshole will get negative attention.']\n",
      "06/29/2022 11:21:22 - INFO - __main__ -   Epoch: 183 | Batch: 6000/10001 (60%) | G Loss: 2.721691 | C Loss: -0.432989\n",
      "06/29/2022 11:21:22 - INFO - __main__ -   Text: ['It\\'s world changing\". <PAD>\" ★ Gerald Mullen, EBT Hater']\n",
      "06/29/2022 11:21:23 - INFO - __main__ -   Epoch: 183 | Batch: 6600/10001 (66%) | G Loss: 2.520760 | C Loss: -0.231330\n",
      "06/29/2022 11:21:23 - INFO - __main__ -   Text: ['Svera num Yoga for each worked <PAD> it month.']\n",
      "06/29/2022 11:21:24 - INFO - __main__ -   Epoch: 183 | Batch: 7200/10001 (72%) | G Loss: 2.635642 | C Loss: -0.617623\n",
      "06/29/2022 11:21:25 - INFO - __main__ -   Text: ['It is very dangerous to drink at the table or to eat after dinner.']\n",
      "06/29/2022 11:21:26 - INFO - __main__ -   Epoch: 183 | Batch: 7800/10001 (78%) | G Loss: 3.251945 | C Loss: -0.488783\n",
      "06/29/2022 11:21:26 - INFO - __main__ -   Text: ['\"You serious?\"']\n",
      "06/29/2022 11:21:27 - INFO - __main__ -   Epoch: 183 | Batch: 8400/10001 (84%) | G Loss: 3.245233 | C Loss: -0.534347\n",
      "06/29/2022 11:21:27 - INFO - __main__ -   Text: ['On the other hand, James is the most delusional ha?!']\n",
      "06/29/2022 11:21:28 - INFO - __main__ -   Epoch: 183 | Batch: 9000/10001 (90%) | G Loss: 3.028186 | C Loss: -0.458209\n",
      "06/29/2022 11:21:28 - INFO - __main__ -   Text: ['Ken Safen - Releasing Homes - 3 .']\n",
      "06/29/2022 11:21:29 - INFO - __main__ -   Epoch: 183 | Batch: 9600/10001 (96%) | G Loss: 3.075753 | C Loss: -0.258952\n",
      "06/29/2022 11:21:29 - INFO - __main__ -   Text: ['Virtual Reality (VR) is a platform to test your knowledge.']\n",
      "06/29/2022 11:21:30 - INFO - __main__ -   * (Train) Epoch: 183 | G Loss: 3.0647 | C Loss: -0.4638 | Updates G: 40 | Updates C: 793\n",
      "06/29/2022 11:21:39 - INFO - __main__ -   Bleu-2:0.189 | B-Bleu-2:0.235\n",
      "06/29/2022 11:21:39 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4241146946349581\n",
      "Train file used is number 16\n",
      "../../yahoo/subdivided_large/train_16.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 184 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:25:09 - INFO - __main__ -   Epoch: 184 | Batch: 0/10001 (0%) | G Loss: 2.962104 | C Loss: -0.494012\n",
      "06/29/2022 11:25:09 - INFO - __main__ -   Text: ['He needs a way to express his ideals.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 4.152\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:25:10 - INFO - __main__ -   Epoch: 184 | Batch: 600/10001 (6%) | G Loss: 3.068672 | C Loss: -0.452811\n",
      "06/29/2022 11:25:10 - INFO - __main__ -   Text: ['always have fun day in and day out.']\n",
      "06/29/2022 11:25:11 - INFO - __main__ -   Epoch: 184 | Batch: 1200/10001 (12%) | G Loss: 3.435170 | C Loss: -0.422494\n",
      "06/29/2022 11:25:11 - INFO - __main__ -   Text: ['IoC has been analyzing graphs and VoIP addressing.']\n",
      "06/29/2022 11:25:12 - INFO - __main__ -   Epoch: 184 | Batch: 1800/10001 (18%) | G Loss: 3.666100 | C Loss: -1.094649\n",
      "06/29/2022 11:25:12 - INFO - __main__ -   Text: ['The next major road test is Traité International.']\n",
      "06/29/2022 11:25:13 - INFO - __main__ -   Epoch: 184 | Batch: 2400/10001 (24%) | G Loss: 3.551939 | C Loss: -0.707157\n",
      "06/29/2022 11:25:13 - INFO - __main__ -   Text: ['Regarding Israel, he argues that Jews became an extinct civilization on the Sabbath.']\n",
      "06/29/2022 11:25:14 - INFO - __main__ -   Epoch: 184 | Batch: 3000/10001 (30%) | G Loss: 2.661228 | C Loss: -0.397764\n",
      "06/29/2022 11:25:14 - INFO - __main__ -   Text: ['It has been known for its easy spread of codebases.']\n",
      "06/29/2022 11:25:15 - INFO - __main__ -   Epoch: 184 | Batch: 3600/10001 (36%) | G Loss: 2.445230 | C Loss: -0.334944\n",
      "06/29/2022 11:25:15 - INFO - __main__ -   Text: ['Important reductions in EM descent).']\n",
      "06/29/2022 11:25:16 - INFO - __main__ -   Epoch: 184 | Batch: 4200/10001 (42%) | G Loss: 2.161753 | C Loss: -0.237927\n",
      "06/29/2022 11:25:16 - INFO - __main__ -   Text: ['\"Oh, I\\'ll do that.\"']\n",
      "06/29/2022 11:25:17 - INFO - __main__ -   Epoch: 184 | Batch: 4800/10001 (48%) | G Loss: 2.738210 | C Loss: -0.418895\n",
      "06/29/2022 11:25:17 - INFO - __main__ -   Text: ['Light Top is a harsh hate group.']\n",
      "06/29/2022 11:25:18 - INFO - __main__ -   Epoch: 184 | Batch: 5400/10001 (54%) | G Loss: 3.204091 | C Loss: -0.449680\n",
      "06/29/2022 11:25:18 - INFO - __main__ -   Text: ['Animal : utp.']\n",
      "06/29/2022 11:25:19 - INFO - __main__ -   Epoch: 184 | Batch: 6000/10001 (60%) | G Loss: 2.794263 | C Loss: -0.540156\n",
      "06/29/2022 11:25:19 - INFO - __main__ -   Text: ['Harvard Disrupts.']\n",
      "06/29/2022 11:25:20 - INFO - __main__ -   Epoch: 184 | Batch: 6600/10001 (66%) | G Loss: 2.914152 | C Loss: -0.386310\n",
      "06/29/2022 11:25:20 - INFO - __main__ -   Text: ['Diogenetic experts should be careful to avoid extinction of the internet.']\n",
      "06/29/2022 11:25:21 - INFO - __main__ -   Epoch: 184 | Batch: 7200/10001 (72%) | G Loss: 3.352291 | C Loss: -0.375763\n",
      "06/29/2022 11:25:21 - INFO - __main__ -   Text: [\"It's pathetic.\"]\n",
      "06/29/2022 11:25:22 - INFO - __main__ -   Epoch: 184 | Batch: 7800/10001 (78%) | G Loss: 4.073836 | C Loss: -0.759303\n",
      "06/29/2022 11:25:22 - INFO - __main__ -   Text: ['This conspiracy theory is an extremely powerful one, with celebrities reported to be in it.']\n",
      "06/29/2022 11:25:23 - INFO - __main__ -   Epoch: 184 | Batch: 8400/10001 (84%) | G Loss: 3.967668 | C Loss: -0.974592\n",
      "06/29/2022 11:25:24 - INFO - __main__ -   Text: ['To teach it lies not with remembrance nor with her soul.\"']\n",
      "06/29/2022 11:25:25 - INFO - __main__ -   Epoch: 184 | Batch: 9000/10001 (90%) | G Loss: 2.231493 | C Loss: -0.323932\n",
      "06/29/2022 11:25:25 - INFO - __main__ -   Text: ['If we choose one step below the last, it will be 2351.']\n",
      "06/29/2022 11:25:26 - INFO - __main__ -   Epoch: 184 | Batch: 9600/10001 (96%) | G Loss: 1.984615 | C Loss: -0.405993\n",
      "06/29/2022 11:25:26 - INFO - __main__ -   Text: ['It has caused the boy to stroke his arm.']\n",
      "06/29/2022 11:25:26 - INFO - __main__ -   * (Train) Epoch: 184 | G Loss: 2.8223 | C Loss: -0.4913 | Updates G: 50 | Updates C: 783\n",
      "06/29/2022 11:25:36 - INFO - __main__ -   Bleu-2:0.197 | B-Bleu-2:0.255\n",
      "06/29/2022 11:25:36 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_17.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4518969177281974\n",
      "Train file used is number 17\n",
      "../../yahoo/subdivided_large/train_17.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 185 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:16.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:15.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:32.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:49.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:28:59 - INFO - __main__ -   Epoch: 185 | Batch: 0/10001 (0%) | G Loss: 2.660556 | C Loss: -0.471567\n",
      "06/29/2022 11:28:59 - INFO - __main__ -   Text: ['Figure out how to try out .']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.485\n",
      "  Test Loss: 4.148\n",
      "  Test took: 0:00:00\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:47.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:32:56 - INFO - __main__ -   Epoch: 186 | Batch: 0/10001 (0%) | G Loss: 3.152015 | C Loss: -0.429916\n",
      "06/29/2022 11:32:56 - INFO - __main__ -   Text: ['It\\'s called \"traditional therapy\", and doesn\\'t understand how physicians work.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.492\n",
      "  Test Loss: 4.161\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:32:57 - INFO - __main__ -   Epoch: 186 | Batch: 600/10001 (6%) | G Loss: 2.733383 | C Loss: -0.485220\n",
      "06/29/2022 11:32:57 - INFO - __main__ -   Text: ['They are convinced that religion is important.']\n",
      "06/29/2022 11:32:58 - INFO - __main__ -   Epoch: 186 | Batch: 1200/10001 (12%) | G Loss: 3.019620 | C Loss: -0.563045\n",
      "06/29/2022 11:32:58 - INFO - __main__ -   Text: ['This very handsome right and wrong young man.']\n",
      "06/29/2022 11:32:59 - INFO - __main__ -   Epoch: 186 | Batch: 1800/10001 (18%) | G Loss: 3.016919 | C Loss: -0.523909\n",
      "06/29/2022 11:32:59 - INFO - __main__ -   Text: ['However, Tarsier may be shy.']\n",
      "06/29/2022 11:33:00 - INFO - __main__ -   Epoch: 186 | Batch: 2400/10001 (24%) | G Loss: 3.021735 | C Loss: -0.512752\n",
      "06/29/2022 11:33:00 - INFO - __main__ -   Text: ['It is heavy success for our club cricket. <PAD>']\n",
      "06/29/2022 11:33:01 - INFO - __main__ -   Epoch: 186 | Batch: 3000/10001 (30%) | G Loss: 3.152710 | C Loss: -0.615944\n",
      "06/29/2022 11:33:01 - INFO - __main__ -   Text: ['He can be found to watch out.']\n",
      "06/29/2022 11:33:02 - INFO - __main__ -   Epoch: 186 | Batch: 3600/10001 (36%) | G Loss: 3.335086 | C Loss: -0.529512\n",
      "06/29/2022 11:33:02 - INFO - __main__ -   Text: ['10 mean better or worse.']\n",
      "06/29/2022 11:33:03 - INFO - __main__ -   Epoch: 186 | Batch: 4200/10001 (42%) | G Loss: 3.100265 | C Loss: -0.368875\n",
      "06/29/2022 11:33:03 - INFO - __main__ -   Text: ['VICCLA Legal Aid is the first legal aid conference.']\n",
      "06/29/2022 11:33:04 - INFO - __main__ -   Epoch: 186 | Batch: 4800/10001 (48%) | G Loss: 2.849696 | C Loss: -0.401127\n",
      "06/29/2022 11:33:04 - INFO - __main__ -   Text: ['The interviewer-plenty challenge.']\n",
      "06/29/2022 11:33:05 - INFO - __main__ -   Epoch: 186 | Batch: 5400/10001 (54%) | G Loss: 3.121339 | C Loss: -0.475908\n",
      "06/29/2022 11:33:05 - INFO - __main__ -   Text: ['The bald eagle flycarts want to bamboozle me\".']\n",
      "06/29/2022 11:33:06 - INFO - __main__ -   Epoch: 186 | Batch: 6000/10001 (60%) | G Loss: 3.337947 | C Loss: -0.773749\n",
      "06/29/2022 11:33:07 - INFO - __main__ -   Text: ['Given some details the pulse rate of the grooves is greater than that of the young.']\n",
      "06/29/2022 11:33:08 - INFO - __main__ -   Epoch: 186 | Batch: 6600/10001 (66%) | G Loss: 2.842782 | C Loss: -0.195328\n",
      "06/29/2022 11:33:08 - INFO - __main__ -   Text: ['Also, she likes jazz music and a relationship with Dr. Dimitrios.']\n",
      "06/29/2022 11:33:09 - INFO - __main__ -   Epoch: 186 | Batch: 7200/10001 (72%) | G Loss: 2.735907 | C Loss: -0.610684\n",
      "06/29/2022 11:33:09 - INFO - __main__ -   Text: ['The Idiocracy guidebook teaches Students to disregard their own thoughts.']\n",
      "06/29/2022 11:33:10 - INFO - __main__ -   Epoch: 186 | Batch: 7800/10001 (78%) | G Loss: 2.957990 | C Loss: -0.606287\n",
      "06/29/2022 11:33:10 - INFO - __main__ -   Text: ['Newsbusters was propelled by a frenzy of marketing.']\n",
      "06/29/2022 11:33:11 - INFO - __main__ -   Epoch: 186 | Batch: 8400/10001 (84%) | G Loss: 2.928396 | C Loss: -0.230206\n",
      "06/29/2022 11:33:11 - INFO - __main__ -   Text: ['The crowd is surprised, because the baseball is Poseidon\\'s biggest power station.\"']\n",
      "06/29/2022 11:33:12 - INFO - __main__ -   Epoch: 186 | Batch: 9000/10001 (90%) | G Loss: 2.947628 | C Loss: -0.526720\n",
      "06/29/2022 11:33:12 - INFO - __main__ -   Text: ['The sports many sports competitions in the Philippines have are basketball, baseball, football, basketball.']\n",
      "06/29/2022 11:33:13 - INFO - __main__ -   Epoch: 186 | Batch: 9600/10001 (96%) | G Loss: 2.832609 | C Loss: -0.249300\n",
      "06/29/2022 11:33:13 - INFO - __main__ -   Text: [\"She can't help but become an urban cynic when the problem is Muslims.\"]\n",
      "06/29/2022 11:33:14 - INFO - __main__ -   * (Train) Epoch: 186 | G Loss: 2.9073 | C Loss: -0.4692 | Updates G: 45 | Updates C: 788\n",
      "06/29/2022 11:33:22 - INFO - __main__ -   Bleu-2:0.201 | B-Bleu-2:0.265\n",
      "06/29/2022 11:33:22 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_19.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4658983587713842\n",
      "Train file used is number 19\n",
      "../../yahoo/subdivided_large/train_19.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 187 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:58.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:15.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:30.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:47.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:04.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:20\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:36:42 - INFO - __main__ -   Epoch: 187 | Batch: 0/10001 (0%) | G Loss: 2.662289 | C Loss: -0.443996\n",
      "06/29/2022 11:36:42 - INFO - __main__ -   Text: ['εვ This man\\'s singing is very uplifting.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.495\n",
      "  Test Loss: 4.137\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:36:43 - INFO - __main__ -   Epoch: 187 | Batch: 600/10001 (6%) | G Loss: 2.697113 | C Loss: -0.066226\n",
      "06/29/2022 11:36:43 - INFO - __main__ -   Text: ['He is placed in the top 10.']\n",
      "06/29/2022 11:36:44 - INFO - __main__ -   Epoch: 187 | Batch: 1200/10001 (12%) | G Loss: 2.715087 | C Loss: -0.451344\n",
      "06/29/2022 11:36:45 - INFO - __main__ -   Text: ['\"If it\\'s diabetic you\\'ll be moving for less money!\"']\n",
      "06/29/2022 11:36:46 - INFO - __main__ -   Epoch: 187 | Batch: 1800/10001 (18%) | G Loss: 2.953270 | C Loss: -0.480410\n",
      "06/29/2022 11:36:46 - INFO - __main__ -   Text: ['The duration and quality of the earth are also recognized.\"']\n",
      "06/29/2022 11:36:47 - INFO - __main__ -   Epoch: 187 | Batch: 2400/10001 (24%) | G Loss: 3.229277 | C Loss: -0.682920\n",
      "06/29/2022 11:36:47 - INFO - __main__ -   Text: ['Each word is woven in containing the forbidden.']\n",
      "06/29/2022 11:36:48 - INFO - __main__ -   Epoch: 187 | Batch: 3000/10001 (30%) | G Loss: 3.137019 | C Loss: -0.593212\n",
      "06/29/2022 11:36:48 - INFO - __main__ -   Text: ['Kristen controls a girl named \"Ldeb\".']\n",
      "06/29/2022 11:36:49 - INFO - __main__ -   Epoch: 187 | Batch: 3600/10001 (36%) | G Loss: 3.191054 | C Loss: -0.351638\n",
      "06/29/2022 11:36:49 - INFO - __main__ -   Text: ['The average score for education is fifty and fixed.']\n",
      "06/29/2022 11:36:50 - INFO - __main__ -   Epoch: 187 | Batch: 4200/10001 (42%) | G Loss: 2.773143 | C Loss: -0.447868\n",
      "06/29/2022 11:36:50 - INFO - __main__ -   Text: ['The octopus is faster infoot than a .']\n",
      "06/29/2022 11:36:51 - INFO - __main__ -   Epoch: 187 | Batch: 4800/10001 (48%) | G Loss: 3.113586 | C Loss: -0.635870\n",
      "06/29/2022 11:36:51 - INFO - __main__ -   Text: ['Your aspirations are lightening my life every morning\".']\n",
      "06/29/2022 11:36:52 - INFO - __main__ -   Epoch: 187 | Batch: 5400/10001 (54%) | G Loss: 3.110822 | C Loss: -0.363038\n",
      "06/29/2022 11:36:52 - INFO - __main__ -   Text: ['Whitley also sings for praise.']\n",
      "06/29/2022 11:36:53 - INFO - __main__ -   Epoch: 187 | Batch: 6000/10001 (60%) | G Loss: 3.111525 | C Loss: -0.258839\n",
      "06/29/2022 11:36:53 - INFO - __main__ -   Text: ['This is the problem of atomistic solids.']\n",
      "06/29/2022 11:36:54 - INFO - __main__ -   Epoch: 187 | Batch: 6600/10001 (66%) | G Loss: 3.092355 | C Loss: -0.508904\n",
      "06/29/2022 11:36:54 - INFO - __main__ -   Text: ['The variant is purely the Female.']\n",
      "06/29/2022 11:36:55 - INFO - __main__ -   Epoch: 187 | Batch: 7200/10001 (72%) | G Loss: 2.785903 | C Loss: -0.580711\n",
      "06/29/2022 11:36:55 - INFO - __main__ -   Text: ['2018 North Irish 40.']\n",
      "06/29/2022 11:36:56 - INFO - __main__ -   Epoch: 187 | Batch: 7800/10001 (78%) | G Loss: 2.761024 | C Loss: -0.470929\n",
      "06/29/2022 11:36:56 - INFO - __main__ -   Text: ['Monk is highly skilled behind the head.']\n",
      "06/29/2022 11:36:57 - INFO - __main__ -   Epoch: 187 | Batch: 8400/10001 (84%) | G Loss: 2.801905 | C Loss: -0.518609\n",
      "06/29/2022 11:36:57 - INFO - __main__ -   Text: ['Her boyfriends blackmail her into selling drugs.']\n",
      "06/29/2022 11:36:58 - INFO - __main__ -   Epoch: 187 | Batch: 9000/10001 (90%) | G Loss: 2.538744 | C Loss: -0.515228\n",
      "06/29/2022 11:36:58 - INFO - __main__ -   Text: ['\"A Devil\\'s Advocate\".']\n",
      "06/29/2022 11:36:59 - INFO - __main__ -   Epoch: 187 | Batch: 9600/10001 (96%) | G Loss: 2.864564 | C Loss: -0.489157\n",
      "06/29/2022 11:36:59 - INFO - __main__ -   Text: ['Learners: Next Ticket Rockets']\n",
      "06/29/2022 11:37:00 - INFO - __main__ -   * (Train) Epoch: 187 | G Loss: 2.8444 | C Loss: -0.4559 | Updates G: 51 | Updates C: 782\n",
      "06/29/2022 11:37:09 - INFO - __main__ -   Bleu-2:0.199 | B-Bleu-2:0.251\n",
      "06/29/2022 11:37:09 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4503631604848338\n",
      "Train file used is number 20\n",
      "../../yahoo/subdivided_large/train_20.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 188 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:40:37 - INFO - __main__ -   Epoch: 188 | Batch: 0/10001 (0%) | G Loss: 2.947067 | C Loss: -0.473762\n",
      "06/29/2022 11:40:37 - INFO - __main__ -   Text: ['\"cheap\" burbs are foodbeating.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 4.128\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:40:38 - INFO - __main__ -   Epoch: 188 | Batch: 600/10001 (6%) | G Loss: 3.108647 | C Loss: -0.536634\n",
      "06/29/2022 11:40:38 - INFO - __main__ -   Text: [\"Luckily, many South Koreans don't have Ryota and they are apparently addicted.\"]\n",
      "06/29/2022 11:40:39 - INFO - __main__ -   Epoch: 188 | Batch: 1200/10001 (12%) | G Loss: 3.457023 | C Loss: -0.586977\n",
      "06/29/2022 11:40:39 - INFO - __main__ -   Text: ['He has argued for \"Idiotism\".']\n",
      "06/29/2022 11:40:40 - INFO - __main__ -   Epoch: 188 | Batch: 1800/10001 (18%) | G Loss: 3.032763 | C Loss: -0.437258\n",
      "06/29/2022 11:40:41 - INFO - __main__ -   Text: ['\"To Be\".']\n",
      "06/29/2022 11:40:41 - INFO - __main__ -   Epoch: 188 | Batch: 2400/10001 (24%) | G Loss: 2.543449 | C Loss: -0.289295\n",
      "06/29/2022 11:40:42 - INFO - __main__ -   Text: ['The next thing you want to do is run a training race.\"']\n",
      "06/29/2022 11:40:43 - INFO - __main__ -   Epoch: 188 | Batch: 3000/10001 (30%) | G Loss: 2.503437 | C Loss: -0.338919\n",
      "06/29/2022 11:40:43 - INFO - __main__ -   Text: ['Rainbow is a play on conway.']\n",
      "06/29/2022 11:40:44 - INFO - __main__ -   Epoch: 188 | Batch: 3600/10001 (36%) | G Loss: 3.166833 | C Loss: -0.593684\n",
      "06/29/2022 11:40:44 - INFO - __main__ -   Text: ['The Ivermoss pingers sound like a wild loof frothing!']\n",
      "06/29/2022 11:40:45 - INFO - __main__ -   Epoch: 188 | Batch: 4200/10001 (42%) | G Loss: 3.065908 | C Loss: -0.529479\n",
      "06/29/2022 11:40:45 - INFO - __main__ -   Text: ['It is also Dad Yoga and friends that he can find it easy to get girls. <PAD> Dad Yoga too is much']\n",
      "06/29/2022 11:40:46 - INFO - __main__ -   Epoch: 188 | Batch: 4800/10001 (48%) | G Loss: 2.391630 | C Loss: -0.290388\n",
      "06/29/2022 11:40:46 - INFO - __main__ -   Text: ['Green medicine, medical terms.']\n",
      "06/29/2022 11:40:47 - INFO - __main__ -   Epoch: 188 | Batch: 5400/10001 (54%) | G Loss: 2.792598 | C Loss: -0.667785\n",
      "06/29/2022 11:40:47 - INFO - __main__ -   Text: [\"It's hard to tell if this is a music college after all.\"]\n",
      "06/29/2022 11:40:48 - INFO - __main__ -   Epoch: 188 | Batch: 6000/10001 (60%) | G Loss: 3.204591 | C Loss: -0.262165\n",
      "06/29/2022 11:40:48 - INFO - __main__ -   Text: ['Many people believe that Susan is a boy whose destiny goes to college.']\n",
      "06/29/2022 11:40:49 - INFO - __main__ -   Epoch: 188 | Batch: 6600/10001 (66%) | G Loss: 3.065911 | C Loss: -0.271404\n",
      "06/29/2022 11:40:49 - INFO - __main__ -   Text: ['Theoretical questions are considered \"Message complexity\" by Moore.']\n",
      "06/29/2022 11:40:50 - INFO - __main__ -   Epoch: 188 | Batch: 7200/10001 (72%) | G Loss: 3.029152 | C Loss: -0.439124\n",
      "06/29/2022 11:40:50 - INFO - __main__ -   Text: ['Little Alfred is the best acting teacher ever...']\n",
      "06/29/2022 11:40:51 - INFO - __main__ -   Epoch: 188 | Batch: 7800/10001 (78%) | G Loss: 2.906836 | C Loss: -0.575737\n",
      "06/29/2022 11:40:51 - INFO - __main__ -   Text: ['Therefore, flying has two specific properties.']\n",
      "06/29/2022 11:40:52 - INFO - __main__ -   Epoch: 188 | Batch: 8400/10001 (84%) | G Loss: 2.829861 | C Loss: -0.332555\n",
      "06/29/2022 11:40:53 - INFO - __main__ -   Text: ['An apparent human being who needs to understand the sciences, will need no explanation.']\n",
      "06/29/2022 11:40:54 - INFO - __main__ -   Epoch: 188 | Batch: 9000/10001 (90%) | G Loss: 3.025719 | C Loss: -0.553605\n",
      "06/29/2022 11:40:54 - INFO - __main__ -   Text: ['\"Weird self-replicating robots go crazy.\"']\n",
      "06/29/2022 11:40:55 - INFO - __main__ -   Epoch: 188 | Batch: 9600/10001 (96%) | G Loss: 3.202197 | C Loss: -0.681104\n",
      "06/29/2022 11:40:55 - INFO - __main__ -   Text: ['This seller is a Member of the Beatles.']\n",
      "06/29/2022 11:40:55 - INFO - __main__ -   * (Train) Epoch: 188 | G Loss: 2.8843 | C Loss: -0.4622 | Updates G: 42 | Updates C: 791\n",
      "06/29/2022 11:41:04 - INFO - __main__ -   Bleu-2:0.198 | B-Bleu-2:0.244\n",
      "06/29/2022 11:41:04 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4426860104030066\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 189 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:45.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:44:35 - INFO - __main__ -   Epoch: 189 | Batch: 0/10000 (0%) | G Loss: 3.176161 | C Loss: -0.611260\n",
      "06/29/2022 11:44:35 - INFO - __main__ -   Text: ['The tax laws of Massachusetts are:']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 4.045\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:44:36 - INFO - __main__ -   Epoch: 189 | Batch: 600/10000 (6%) | G Loss: 2.970530 | C Loss: -0.710332\n",
      "06/29/2022 11:44:36 - INFO - __main__ -   Text: ['When trying to import Unicode files']\n",
      "06/29/2022 11:44:37 - INFO - __main__ -   Epoch: 189 | Batch: 1200/10000 (12%) | G Loss: 3.175749 | C Loss: -0.789196\n",
      "06/29/2022 11:44:37 - INFO - __main__ -   Text: ['This sounds fantastic.']\n",
      "06/29/2022 11:44:38 - INFO - __main__ -   Epoch: 189 | Batch: 1800/10000 (18%) | G Loss: 2.761918 | C Loss: -0.346866\n",
      "06/29/2022 11:44:38 - INFO - __main__ -   Text: ['Banks needs to make a song).']\n",
      "06/29/2022 11:44:39 - INFO - __main__ -   Epoch: 189 | Batch: 2400/10000 (24%) | G Loss: 3.014030 | C Loss: -0.543630\n",
      "06/29/2022 11:44:39 - INFO - __main__ -   Text: ['During the TEAs, students can rank seniors by just how competitive they are.']\n",
      "06/29/2022 11:44:40 - INFO - __main__ -   Epoch: 189 | Batch: 3000/10000 (30%) | G Loss: 2.617426 | C Loss: -0.319799\n",
      "06/29/2022 11:44:40 - INFO - __main__ -   Text: ['The Ross Media magazine keeps you hooked indefinitely on a Climate-Change standup comic.']\n",
      "06/29/2022 11:44:41 - INFO - __main__ -   Epoch: 189 | Batch: 3600/10000 (36%) | G Loss: 2.556321 | C Loss: -0.401532\n",
      "06/29/2022 11:44:41 - INFO - __main__ -   Text: ['Gnanine states that 18th-century literary texts are less common.']\n",
      "06/29/2022 11:44:42 - INFO - __main__ -   Epoch: 189 | Batch: 4200/10000 (42%) | G Loss: 2.812006 | C Loss: -0.517579\n",
      "06/29/2022 11:44:42 - INFO - __main__ -   Text: ['Subnet now shares basic facts about protein stocks.']\n",
      "06/29/2022 11:44:43 - INFO - __main__ -   Epoch: 189 | Batch: 4800/10000 (48%) | G Loss: 3.479895 | C Loss: -0.333835\n",
      "06/29/2022 11:44:43 - INFO - __main__ -   Text: ['It is likely a lesser one.']\n",
      "06/29/2022 11:44:44 - INFO - __main__ -   Epoch: 189 | Batch: 5400/10000 (54%) | G Loss: 3.072764 | C Loss: -0.409765\n",
      "06/29/2022 11:44:44 - INFO - __main__ -   Text: ['This is inconsistent with the conception these phantoms call \"potential.\"']\n",
      "06/29/2022 11:44:45 - INFO - __main__ -   Epoch: 189 | Batch: 6000/10000 (60%) | G Loss: 3.438977 | C Loss: -0.401150\n",
      "06/29/2022 11:44:46 - INFO - __main__ -   Text: ['This boy may not be talking to anyone, so this will just be reported.']\n",
      "06/29/2022 11:44:47 - INFO - __main__ -   Epoch: 189 | Batch: 6600/10000 (66%) | G Loss: 2.635720 | C Loss: -0.381890\n",
      "06/29/2022 11:44:47 - INFO - __main__ -   Text: ['Small companies use NRROD with lasers.']\n",
      "06/29/2022 11:44:48 - INFO - __main__ -   Epoch: 189 | Batch: 7200/10000 (72%) | G Loss: 2.593434 | C Loss: -0.423254\n",
      "06/29/2022 11:44:48 - INFO - __main__ -   Text: ['Bosch thinks a typical interchange point is 200 m.']\n",
      "06/29/2022 11:44:49 - INFO - __main__ -   Epoch: 189 | Batch: 7800/10000 (78%) | G Loss: 2.798465 | C Loss: -0.462672\n",
      "06/29/2022 11:44:49 - INFO - __main__ -   Text: ['Read-out is on a common writing process.']\n",
      "06/29/2022 11:44:50 - INFO - __main__ -   Epoch: 189 | Batch: 8400/10000 (84%) | G Loss: 2.997975 | C Loss: -0.383832\n",
      "06/29/2022 11:44:50 - INFO - __main__ -   Text: [\"The next is implementations using Let's Encrypt world first.<br>\"]\n",
      "06/29/2022 11:44:51 - INFO - __main__ -   Epoch: 189 | Batch: 9000/10000 (90%) | G Loss: 3.079252 | C Loss: -0.350167\n",
      "06/29/2022 11:44:51 - INFO - __main__ -   Text: ['Keynes is the philosophical phrase: survival is in the news\".']\n",
      "06/29/2022 11:44:52 - INFO - __main__ -   Epoch: 189 | Batch: 9600/10000 (96%) | G Loss: 3.020098 | C Loss: -0.583587\n",
      "06/29/2022 11:44:52 - INFO - __main__ -   Text: ['I have the first EMD I have in Korea.']\n",
      "06/29/2022 11:44:53 - INFO - __main__ -   * (Train) Epoch: 189 | G Loss: 2.9113 | C Loss: -0.4551 | Updates G: 45 | Updates C: 788\n",
      "06/29/2022 11:45:02 - INFO - __main__ -   Bleu-2:0.190 | B-Bleu-2:0.259\n",
      "06/29/2022 11:45:02 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44883744824184246\n",
      "Train file used is number 1\n",
      "../../yahoo/subdivided_large/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 190 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:03.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:20.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:48:32 - INFO - __main__ -   Epoch: 190 | Batch: 0/10000 (0%) | G Loss: 3.252167 | C Loss: -0.275153\n",
      "06/29/2022 11:48:32 - INFO - __main__ -   Text: ['Her People advice is \"not allowed\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.510\n",
      "  Test Loss: 4.083\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:48:33 - INFO - __main__ -   Epoch: 190 | Batch: 600/10000 (6%) | G Loss: 2.781505 | C Loss: -0.319869\n",
      "06/29/2022 11:48:34 - INFO - __main__ -   Text: ['He is doubtful about a person\\'s soul or intellect, wood burner.\"']\n",
      "06/29/2022 11:48:35 - INFO - __main__ -   Epoch: 190 | Batch: 1200/10000 (12%) | G Loss: 2.906503 | C Loss: -0.625725\n",
      "06/29/2022 11:48:35 - INFO - __main__ -   Text: ['Certain similarities between the two projects exist.']\n",
      "06/29/2022 11:48:36 - INFO - __main__ -   Epoch: 190 | Batch: 1800/10000 (18%) | G Loss: 2.702041 | C Loss: -0.591236\n",
      "06/29/2022 11:48:36 - INFO - __main__ -   Text: ['Only a computer programmer can produce the best distribution.\"']\n",
      "06/29/2022 11:48:37 - INFO - __main__ -   Epoch: 190 | Batch: 2400/10000 (24%) | G Loss: 2.828772 | C Loss: -0.387142\n",
      "06/29/2022 11:48:37 - INFO - __main__ -   Text: ['When I say \"A million good people?\" No one knows where Big Rush is going to come from.\"']\n",
      "06/29/2022 11:48:38 - INFO - __main__ -   Epoch: 190 | Batch: 3000/10000 (30%) | G Loss: 3.091816 | C Loss: -0.483627\n",
      "06/29/2022 11:48:38 - INFO - __main__ -   Text: ['To find a better way of controlling bugs, C.)']\n",
      "06/29/2022 11:48:39 - INFO - __main__ -   Epoch: 190 | Batch: 3600/10000 (36%) | G Loss: 2.944382 | C Loss: -0.599880\n",
      "06/29/2022 11:48:39 - INFO - __main__ -   Text: [\"which is okay as long as you don't get hard behaviours.\"]\n",
      "06/29/2022 11:48:40 - INFO - __main__ -   Epoch: 190 | Batch: 4200/10000 (42%) | G Loss: 2.822206 | C Loss: -0.561899\n",
      "06/29/2022 11:48:40 - INFO - __main__ -   Text: ['The crab smells like stink.']\n",
      "06/29/2022 11:48:41 - INFO - __main__ -   Epoch: 190 | Batch: 4800/10000 (48%) | G Loss: 2.791846 | C Loss: -0.307793\n",
      "06/29/2022 11:48:41 - INFO - __main__ -   Text: ['How people do this in the workplace is unknown.']\n",
      "06/29/2022 11:48:42 - INFO - __main__ -   Epoch: 190 | Batch: 5400/10000 (54%) | G Loss: 3.510509 | C Loss: -0.418995\n",
      "06/29/2022 11:48:42 - INFO - __main__ -   Text: ['Pathetic.']\n",
      "06/29/2022 11:48:43 - INFO - __main__ -   Epoch: 190 | Batch: 6000/10000 (60%) | G Loss: 3.153648 | C Loss: -0.311171\n",
      "06/29/2022 11:48:43 - INFO - __main__ -   Text: ['that\\'s not actually what you do.\"']\n",
      "06/29/2022 11:48:44 - INFO - __main__ -   Epoch: 190 | Batch: 6600/10000 (66%) | G Loss: 2.712287 | C Loss: -0.365277\n",
      "06/29/2022 11:48:44 - INFO - __main__ -   Text: ['Compulsive gambling habits really does make me laugh.\"']\n",
      "06/29/2022 11:48:45 - INFO - __main__ -   Epoch: 190 | Batch: 7200/10000 (72%) | G Loss: 2.997036 | C Loss: -0.490865\n",
      "06/29/2022 11:48:45 - INFO - __main__ -   Text: ['The competition needs electricity to power the room.']\n",
      "06/29/2022 11:48:46 - INFO - __main__ -   Epoch: 190 | Batch: 7800/10000 (78%) | G Loss: 2.599599 | C Loss: -0.487919\n",
      "06/29/2022 11:48:46 - INFO - __main__ -   Text: ['It is possible to establish clusters of MITS-based libraries.']\n",
      "06/29/2022 11:48:47 - INFO - __main__ -   Epoch: 190 | Batch: 8400/10000 (84%) | G Loss: 2.738702 | C Loss: -0.654804\n",
      "06/29/2022 11:48:48 - INFO - __main__ -   Text: ['These animals often have intelligence of similar dimensions.']\n",
      "06/29/2022 11:48:49 - INFO - __main__ -   Epoch: 190 | Batch: 9000/10000 (90%) | G Loss: 2.511426 | C Loss: -0.406987\n",
      "06/29/2022 11:48:49 - INFO - __main__ -   Text: ['The song is \"Believe the Queen\".']\n",
      "06/29/2022 11:48:50 - INFO - __main__ -   Epoch: 190 | Batch: 9600/10000 (96%) | G Loss: 2.655460 | C Loss: -0.603721\n",
      "06/29/2022 11:48:50 - INFO - __main__ -   Text: ['Betternauer alerts them to $100 per cent of the meat.']\n",
      "06/29/2022 11:48:50 - INFO - __main__ -   * (Train) Epoch: 190 | G Loss: 2.8224 | C Loss: -0.4663 | Updates G: 44 | Updates C: 789\n",
      "06/29/2022 11:48:59 - INFO - __main__ -   Bleu-2:0.205 | B-Bleu-2:0.255\n",
      "06/29/2022 11:48:59 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4601697740628361\n",
      "Train file used is number 2\n",
      "../../yahoo/subdivided_large/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 191 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:53.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:52:27 - INFO - __main__ -   Epoch: 191 | Batch: 0/10001 (0%) | G Loss: 2.873707 | C Loss: -0.380421\n",
      "06/29/2022 11:52:27 - INFO - __main__ -   Text: ['It\\'s not at all what I say.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.502\n",
      "  Test Loss: 4.023\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:52:28 - INFO - __main__ -   Epoch: 191 | Batch: 600/10001 (6%) | G Loss: 2.990720 | C Loss: -0.354462\n",
      "06/29/2022 11:52:28 - INFO - __main__ -   Text: ['Both HSNN and [professional] trade are BS.']\n",
      "06/29/2022 11:52:29 - INFO - __main__ -   Epoch: 191 | Batch: 1200/10001 (12%) | G Loss: 2.735777 | C Loss: -0.361447\n",
      "06/29/2022 11:52:29 - INFO - __main__ -   Text: ['Orbweb Travel.']\n",
      "06/29/2022 11:52:30 - INFO - __main__ -   Epoch: 191 | Batch: 1800/10001 (18%) | G Loss: 2.849031 | C Loss: -0.495049\n",
      "06/29/2022 11:52:30 - INFO - __main__ -   Text: ['When a basketball team or a vanguard triumph you are flying fuck you!']\n",
      "06/29/2022 11:52:31 - INFO - __main__ -   Epoch: 191 | Batch: 2400/10001 (24%) | G Loss: 3.280677 | C Loss: -0.567504\n",
      "06/29/2022 11:52:32 - INFO - __main__ -   Text: ['For example, there is a dance quarterback that will help you.']\n",
      "06/29/2022 11:52:32 - INFO - __main__ -   Epoch: 191 | Batch: 3000/10001 (30%) | G Loss: 3.012210 | C Loss: -0.526220\n",
      "06/29/2022 11:52:33 - INFO - __main__ -   Text: ['The opponent is a colossi, so he will come in third.']\n",
      "06/29/2022 11:52:34 - INFO - __main__ -   Epoch: 191 | Batch: 3600/10001 (36%) | G Loss: 2.807375 | C Loss: -0.369829\n",
      "06/29/2022 11:52:34 - INFO - __main__ -   Text: ['They definitely win the carnival card because they have a clear plan for Gold and the crowd.']\n",
      "06/29/2022 11:52:35 - INFO - __main__ -   Epoch: 191 | Batch: 4200/10001 (42%) | G Loss: 2.658128 | C Loss: -0.456456\n",
      "06/29/2022 11:52:35 - INFO - __main__ -   Text: ['The number of fortifications on mountain peaks is a metric unique.']\n",
      "06/29/2022 11:52:36 - INFO - __main__ -   Epoch: 191 | Batch: 4800/10001 (48%) | G Loss: 2.899757 | C Loss: -0.593454\n",
      "06/29/2022 11:52:36 - INFO - __main__ -   Text: ['2005 Stock Afflex 7 MB 12 (@bench)']\n",
      "06/29/2022 11:52:37 - INFO - __main__ -   Epoch: 191 | Batch: 5400/10001 (54%) | G Loss: 2.905717 | C Loss: -0.656366\n",
      "06/29/2022 11:52:37 - INFO - __main__ -   Text: ['There is MANGO using a server.']\n",
      "06/29/2022 11:52:38 - INFO - __main__ -   Epoch: 191 | Batch: 6000/10001 (60%) | G Loss: 3.047093 | C Loss: -0.500091\n",
      "06/29/2022 11:52:38 - INFO - __main__ -   Text: ['']\n",
      "06/29/2022 11:52:39 - INFO - __main__ -   Epoch: 191 | Batch: 6600/10001 (66%) | G Loss: 2.649099 | C Loss: -0.469165\n",
      "06/29/2022 11:52:39 - INFO - __main__ -   Text: ['\"Proper name (a query)\" is a word used to describe probabilistic isomorphic system.']\n",
      "06/29/2022 11:52:40 - INFO - __main__ -   Epoch: 191 | Batch: 7200/10001 (72%) | G Loss: 3.031630 | C Loss: -0.632494\n",
      "06/29/2022 11:52:40 - INFO - __main__ -   Text: ['Dave has been to the bottom of the toilet here – and thus changes his mind over there.']\n",
      "06/29/2022 11:52:41 - INFO - __main__ -   Epoch: 191 | Batch: 7800/10001 (78%) | G Loss: 3.303274 | C Loss: -0.553151\n",
      "06/29/2022 11:52:41 - INFO - __main__ -   Text: ['This guy knows exactly what to do to JERSD.']\n",
      "06/29/2022 11:52:42 - INFO - __main__ -   Epoch: 191 | Batch: 8400/10001 (84%) | G Loss: 3.133702 | C Loss: -0.393511\n",
      "06/29/2022 11:52:43 - INFO - __main__ -   Text: ['This, almost fifty \"Super Ultriworld\" sassan!']\n",
      "06/29/2022 11:52:44 - INFO - __main__ -   Epoch: 191 | Batch: 9000/10001 (90%) | G Loss: 2.609107 | C Loss: -0.301671\n",
      "06/29/2022 11:52:44 - INFO - __main__ -   Text: ['The gist of J. Hopkins.']\n",
      "06/29/2022 11:52:45 - INFO - __main__ -   Epoch: 191 | Batch: 9600/10001 (96%) | G Loss: 2.273246 | C Loss: -0.270101\n",
      "06/29/2022 11:52:45 - INFO - __main__ -   Text: ['An important secret is this: the grandtastic skill.']\n",
      "06/29/2022 11:52:45 - INFO - __main__ -   * (Train) Epoch: 191 | G Loss: 2.7856 | C Loss: -0.4589 | Updates G: 46 | Updates C: 787\n",
      "06/29/2022 11:52:55 - INFO - __main__ -   Bleu-2:0.194 | B-Bleu-2:0.225\n",
      "06/29/2022 11:52:55 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4194256467657189\n",
      "Train file used is number 3\n",
      "../../yahoo/subdivided_large/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 192 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:07.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:24.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:41.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:57.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:13.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:29.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:46.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:03.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:56:14 - INFO - __main__ -   Epoch: 192 | Batch: 0/10001 (0%) | G Loss: 2.462961 | C Loss: -0.332176\n",
      "06/29/2022 11:56:14 - INFO - __main__ -   Text: ['Places fire coverors include Inscribed.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 3.983\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 11:56:15 - INFO - __main__ -   Epoch: 192 | Batch: 600/10001 (6%) | G Loss: 2.954834 | C Loss: -0.348503\n",
      "06/29/2022 11:56:15 - INFO - __main__ -   Text: ['They would advertise your interview to be a \"Monster Corporate!\"']\n",
      "06/29/2022 11:56:16 - INFO - __main__ -   Epoch: 192 | Batch: 1200/10001 (12%) | G Loss: 3.523608 | C Loss: -0.546386\n",
      "06/29/2022 11:56:16 - INFO - __main__ -   Text: ['The information will be considered a different thing from the forgery.']\n",
      "06/29/2022 11:56:17 - INFO - __main__ -   Epoch: 192 | Batch: 1800/10001 (18%) | G Loss: 3.315934 | C Loss: -0.359371\n",
      "06/29/2022 11:56:18 - INFO - __main__ -   Text: ['For example, such a \"reverse algebranet\" may call bits.']\n",
      "06/29/2022 11:56:19 - INFO - __main__ -   Epoch: 192 | Batch: 2400/10001 (24%) | G Loss: 2.869267 | C Loss: -0.493818\n",
      "06/29/2022 11:56:19 - INFO - __main__ -   Text: ['Of course we have to look at colors.\")']\n",
      "06/29/2022 11:56:20 - INFO - __main__ -   Epoch: 192 | Batch: 3000/10001 (30%) | G Loss: 2.931118 | C Loss: -0.454572\n",
      "06/29/2022 11:56:20 - INFO - __main__ -   Text: ['The words \"hearted or ill-judged\" apply here.']\n",
      "06/29/2022 11:56:21 - INFO - __main__ -   Epoch: 192 | Batch: 3600/10001 (36%) | G Loss: 3.262400 | C Loss: -0.964062\n",
      "06/29/2022 11:56:21 - INFO - __main__ -   Text: ['Only examine it more intently.\"']\n",
      "06/29/2022 11:56:22 - INFO - __main__ -   Epoch: 192 | Batch: 4200/10001 (42%) | G Loss: 2.856723 | C Loss: -0.717048\n",
      "06/29/2022 11:56:22 - INFO - __main__ -   Text: ['This is it for headphones audio to bypass a speaker amplifier.']\n",
      "06/29/2022 11:56:23 - INFO - __main__ -   Epoch: 192 | Batch: 4800/10001 (48%) | G Loss: 2.715946 | C Loss: -1.084660\n",
      "06/29/2022 11:56:23 - INFO - __main__ -   Text: ['It glazes off of the light.\"']\n",
      "06/29/2022 11:56:24 - INFO - __main__ -   Epoch: 192 | Batch: 5400/10001 (54%) | G Loss: 2.498755 | C Loss: -0.430557\n",
      "06/29/2022 11:56:24 - INFO - __main__ -   Text: ['A handsome guy also has to teach a \"dance\".']\n",
      "06/29/2022 11:56:25 - INFO - __main__ -   Epoch: 192 | Batch: 6000/10001 (60%) | G Loss: 2.911001 | C Loss: -0.445022\n",
      "06/29/2022 11:56:25 - INFO - __main__ -   Text: ['It is recommended that cream may be used in this way.']\n",
      "06/29/2022 11:56:26 - INFO - __main__ -   Epoch: 192 | Batch: 6600/10001 (66%) | G Loss: 2.659914 | C Loss: -0.526435\n",
      "06/29/2022 11:56:26 - INFO - __main__ -   Text: [\"The song is called, 'The Packers Top Step.'\"]\n",
      "06/29/2022 11:56:27 - INFO - __main__ -   Epoch: 192 | Batch: 7200/10001 (72%) | G Loss: 2.739198 | C Loss: -0.390416\n",
      "06/29/2022 11:56:27 - INFO - __main__ -   Text: ['The calculator can be used to explore any student term interest list.']\n",
      "06/29/2022 11:56:28 - INFO - __main__ -   Epoch: 192 | Batch: 7800/10001 (78%) | G Loss: 2.818311 | C Loss: -0.540933\n",
      "06/29/2022 11:56:28 - INFO - __main__ -   Text: ['A potential model for a professional-sized loyalty site is www.hopeton.com.']\n",
      "06/29/2022 11:56:29 - INFO - __main__ -   Epoch: 192 | Batch: 8400/10001 (84%) | G Loss: 3.198504 | C Loss: -0.455525\n",
      "06/29/2022 11:56:29 - INFO - __main__ -   Text: ['']\n",
      "06/29/2022 11:56:30 - INFO - __main__ -   Epoch: 192 | Batch: 9000/10001 (90%) | G Loss: 3.182464 | C Loss: -0.566864\n",
      "06/29/2022 11:56:31 - INFO - __main__ -   Text: ['This decreases to 1.5 for example if you have 2.']\n",
      "06/29/2022 11:56:32 - INFO - __main__ -   Epoch: 192 | Batch: 9600/10001 (96%) | G Loss: 3.119337 | C Loss: -0.576029\n",
      "06/29/2022 11:56:32 - INFO - __main__ -   Text: ['It has dimensions of 34 km which corresponds to 10.558 grams.']\n",
      "06/29/2022 11:56:32 - INFO - __main__ -   * (Train) Epoch: 192 | G Loss: 2.8238 | C Loss: -0.4720 | Updates G: 38 | Updates C: 795\n",
      "06/29/2022 11:56:41 - INFO - __main__ -   Bleu-2:0.218 | B-Bleu-2:0.245\n",
      "06/29/2022 11:56:41 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46232462697880916\n",
      "Train file used is number 4\n",
      "../../yahoo/subdivided_large/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 193 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:25.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:42.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:16.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:33.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:50.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:00:04 - INFO - __main__ -   Epoch: 193 | Batch: 0/10001 (0%) | G Loss: 2.845954 | C Loss: -0.292868\n",
      "06/29/2022 12:00:05 - INFO - __main__ -   Text: ['However confuse the deductive part becomes obvious.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.913\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:00:05 - INFO - __main__ -   Epoch: 193 | Batch: 600/10001 (6%) | G Loss: 2.451298 | C Loss: -0.569341\n",
      "06/29/2022 12:00:06 - INFO - __main__ -   Text: ['Griffin has a love affair with this pop superstar even when he\\'s not happy.\"']\n",
      "06/29/2022 12:00:07 - INFO - __main__ -   Epoch: 193 | Batch: 1200/10001 (12%) | G Loss: 2.371218 | C Loss: -0.031477\n",
      "06/29/2022 12:00:07 - INFO - __main__ -   Text: ['He wonders if Dennis has asked him to invite him to meet.']\n",
      "06/29/2022 12:00:08 - INFO - __main__ -   Epoch: 193 | Batch: 1800/10001 (18%) | G Loss: 2.591432 | C Loss: -0.290310\n",
      "06/29/2022 12:00:08 - INFO - __main__ -   Text: ['Nikolos lunches at you.']\n",
      "06/29/2022 12:00:09 - INFO - __main__ -   Epoch: 193 | Batch: 2400/10001 (24%) | G Loss: 2.956837 | C Loss: -0.375365\n",
      "06/29/2022 12:00:09 - INFO - __main__ -   Text: ['It has to be right in the middle of the field of space.']\n",
      "06/29/2022 12:00:10 - INFO - __main__ -   Epoch: 193 | Batch: 3000/10001 (30%) | G Loss: 3.046524 | C Loss: -0.548987\n",
      "06/29/2022 12:00:10 - INFO - __main__ -   Text: ['\" These gossip stories are not reported to law enforcement.\"']\n",
      "06/29/2022 12:00:11 - INFO - __main__ -   Epoch: 193 | Batch: 3600/10001 (36%) | G Loss: 3.076264 | C Loss: -0.477100\n",
      "06/29/2022 12:00:11 - INFO - __main__ -   Text: ['She also occasionally takes computer science courses.)']\n",
      "06/29/2022 12:00:12 - INFO - __main__ -   Epoch: 193 | Batch: 4200/10001 (42%) | G Loss: 2.982036 | C Loss: -0.332277\n",
      "06/29/2022 12:00:12 - INFO - __main__ -   Text: ['Guru Brain is a conceptual framework guide.']\n",
      "06/29/2022 12:00:13 - INFO - __main__ -   Epoch: 193 | Batch: 4800/10001 (48%) | G Loss: 2.968737 | C Loss: -0.597891\n",
      "06/29/2022 12:00:13 - INFO - __main__ -   Text: ['Names include: Bucky Moose and Horned Yellowvision.']\n",
      "06/29/2022 12:00:14 - INFO - __main__ -   Epoch: 193 | Batch: 5400/10001 (54%) | G Loss: 2.999306 | C Loss: -0.413016\n",
      "06/29/2022 12:00:14 - INFO - __main__ -   Text: ['The whole thing is just wandering\".']\n",
      "06/29/2022 12:00:15 - INFO - __main__ -   Epoch: 193 | Batch: 6000/10001 (60%) | G Loss: 3.293240 | C Loss: -0.367680\n",
      "06/29/2022 12:00:15 - INFO - __main__ -   Text: [\"Soon comes the one who 'leyves st.'\"]\n",
      "06/29/2022 12:00:16 - INFO - __main__ -   Epoch: 193 | Batch: 6600/10001 (66%) | G Loss: 2.848938 | C Loss: -0.253666\n",
      "06/29/2022 12:00:16 - INFO - __main__ -   Text: ['The winners are Dylan Couples and Jon Henson.']\n",
      "06/29/2022 12:00:17 - INFO - __main__ -   Epoch: 193 | Batch: 7200/10001 (72%) | G Loss: 2.691259 | C Loss: -0.454490\n",
      "06/29/2022 12:00:17 - INFO - __main__ -   Text: ['i.e.']\n",
      "06/29/2022 12:00:18 - INFO - __main__ -   Epoch: 193 | Batch: 7800/10001 (78%) | G Loss: 2.742025 | C Loss: -0.479518\n",
      "06/29/2022 12:00:19 - INFO - __main__ -   Text: ['These guys don\\'t need a driver but I think they are way too early.\"']\n",
      "06/29/2022 12:00:19 - INFO - __main__ -   Epoch: 193 | Batch: 8400/10001 (84%) | G Loss: 2.868083 | C Loss: -0.651137\n",
      "06/29/2022 12:00:20 - INFO - __main__ -   Text: ['Bi .']\n",
      "06/29/2022 12:00:20 - INFO - __main__ -   Epoch: 193 | Batch: 9000/10001 (90%) | G Loss: 2.769245 | C Loss: -0.253501\n",
      "06/29/2022 12:00:21 - INFO - __main__ -   Text: ['No one knows she\\'s gay, but she knows she is.\"']\n",
      "06/29/2022 12:00:22 - INFO - __main__ -   Epoch: 193 | Batch: 9600/10001 (96%) | G Loss: 2.668190 | C Loss: -0.444061\n",
      "06/29/2022 12:00:22 - INFO - __main__ -   Text: ['Guns and weapons are exchanged internationally.']\n",
      "06/29/2022 12:00:22 - INFO - __main__ -   * (Train) Epoch: 193 | G Loss: 2.7779 | C Loss: -0.4460 | Updates G: 38 | Updates C: 795\n",
      "06/29/2022 12:00:31 - INFO - __main__ -   Bleu-2:0.208 | B-Bleu-2:0.252\n",
      "06/29/2022 12:00:31 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45984120491084773\n",
      "Train file used is number 5\n",
      "../../yahoo/subdivided_large/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 194 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:10.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:28.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:21.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:38.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:04:01 - INFO - __main__ -   Epoch: 194 | Batch: 0/10001 (0%) | G Loss: 3.137789 | C Loss: -0.589955\n",
      "06/29/2022 12:04:02 - INFO - __main__ -   Text: ['They decide to kill Mobley.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.507\n",
      "  Test Loss: 3.862\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:04:03 - INFO - __main__ -   Epoch: 194 | Batch: 600/10001 (6%) | G Loss: 3.602277 | C Loss: -0.506220\n",
      "06/29/2022 12:04:03 - INFO - __main__ -   Text: ['Best Among Others For Greater Heights is the final Londoner of the year to score in The Best of All']\n",
      "06/29/2022 12:04:04 - INFO - __main__ -   Epoch: 194 | Batch: 1200/10001 (12%) | G Loss: 3.649812 | C Loss: -0.196000\n",
      "06/29/2022 12:04:04 - INFO - __main__ -   Text: ['He is also the owner of the Weigh Club.']\n",
      "06/29/2022 12:04:05 - INFO - __main__ -   Epoch: 194 | Batch: 1800/10001 (18%) | G Loss: 2.830783 | C Loss: -0.147392\n",
      "06/29/2022 12:04:05 - INFO - __main__ -   Text: ['The Killer, or Fistilomus aka ...']\n",
      "06/29/2022 12:04:06 - INFO - __main__ -   Epoch: 194 | Batch: 2400/10001 (24%) | G Loss: 2.702457 | C Loss: -0.300609\n",
      "06/29/2022 12:04:06 - INFO - __main__ -   Text: ['Slattery says of men who can\\'t make common sense: \"You\\'re an idiot.\"']\n",
      "06/29/2022 12:04:07 - INFO - __main__ -   Epoch: 194 | Batch: 3000/10001 (30%) | G Loss: 2.656769 | C Loss: -0.482239\n",
      "06/29/2022 12:04:07 - INFO - __main__ -   Text: ['This implies square functions: move a bar.']\n",
      "06/29/2022 12:04:08 - INFO - __main__ -   Epoch: 194 | Batch: 3600/10001 (36%) | G Loss: 2.815109 | C Loss: -0.509919\n",
      "06/29/2022 12:04:08 - INFO - __main__ -   Text: ['They musicians call \"The Diary.\"']\n",
      "06/29/2022 12:04:09 - INFO - __main__ -   Epoch: 194 | Batch: 4200/10001 (42%) | G Loss: 3.063704 | C Loss: -0.572054\n",
      "06/29/2022 12:04:09 - INFO - __main__ -   Text: ['the best Frobiuski.']\n",
      "06/29/2022 12:04:10 - INFO - __main__ -   Epoch: 194 | Batch: 4800/10001 (48%) | G Loss: 2.857528 | C Loss: -0.210209\n",
      "06/29/2022 12:04:10 - INFO - __main__ -   Text: ['Whether you eat traditional food, dance, and dance.']\n",
      "06/29/2022 12:04:11 - INFO - __main__ -   Epoch: 194 | Batch: 5400/10001 (54%) | G Loss: 2.392717 | C Loss: -0.419307\n",
      "06/29/2022 12:04:11 - INFO - __main__ -   Text: ['Napaildrennon is different from old scramblefish.']\n",
      "06/29/2022 12:04:12 - INFO - __main__ -   Epoch: 194 | Batch: 6000/10001 (60%) | G Loss: 2.957409 | C Loss: -0.620377\n",
      "06/29/2022 12:04:12 - INFO - __main__ -   Text: ['You cannot do that!']\n",
      "06/29/2022 12:04:13 - INFO - __main__ -   Epoch: 194 | Batch: 6600/10001 (66%) | G Loss: 3.073741 | C Loss: -0.548620\n",
      "06/29/2022 12:04:14 - INFO - __main__ -   Text: ['Crumb can leave a cost that is literally $23 in higher education.']\n",
      "06/29/2022 12:04:15 - INFO - __main__ -   Epoch: 194 | Batch: 7200/10001 (72%) | G Loss: 2.978989 | C Loss: -0.457799\n",
      "06/29/2022 12:04:15 - INFO - __main__ -   Text: [\"Any-how, it's maybeno!\"]\n",
      "06/29/2022 12:04:16 - INFO - __main__ -   Epoch: 194 | Batch: 7800/10001 (78%) | G Loss: 2.792029 | C Loss: -0.544047\n",
      "06/29/2022 12:04:16 - INFO - __main__ -   Text: ['http://throughput.idata.org http://alsoworks. <PAD> Failure.']\n",
      "06/29/2022 12:04:17 - INFO - __main__ -   Epoch: 194 | Batch: 8400/10001 (84%) | G Loss: 3.390598 | C Loss: -0.492384\n",
      "06/29/2022 12:04:17 - INFO - __main__ -   Text: ['Persistent object is unrelated to fact being a velocity, sex, or anything of that sort.']\n",
      "06/29/2022 12:04:18 - INFO - __main__ -   Epoch: 194 | Batch: 9000/10001 (90%) | G Loss: 3.415692 | C Loss: -0.614389\n",
      "06/29/2022 12:04:18 - INFO - __main__ -   Text: ['Blues Helpings provides a concise and meaningful community Help.']\n",
      "06/29/2022 12:04:19 - INFO - __main__ -   Epoch: 194 | Batch: 9600/10001 (96%) | G Loss: 2.746262 | C Loss: -0.517030\n",
      "06/29/2022 12:04:19 - INFO - __main__ -   Text: ['There is a risk if you do not test injection from a true pump.']\n",
      "06/29/2022 12:04:20 - INFO - __main__ -   * (Train) Epoch: 194 | G Loss: 2.8705 | C Loss: -0.4717 | Updates G: 34 | Updates C: 799\n",
      "06/29/2022 12:04:29 - INFO - __main__ -   Bleu-2:0.204 | B-Bleu-2:0.247\n",
      "06/29/2022 12:04:29 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45184588998115716\n",
      "Train file used is number 6\n",
      "../../yahoo/subdivided_large/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 195 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:01.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:18.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:35.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:52.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:10.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:07:55 - INFO - __main__ -   Epoch: 195 | Batch: 0/10001 (0%) | G Loss: 2.339992 | C Loss: -0.491545\n",
      "06/29/2022 12:07:55 - INFO - __main__ -   Text: ['The story is very whimsical based on a romantic relationship.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 4.012\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:07:56 - INFO - __main__ -   Epoch: 195 | Batch: 600/10001 (6%) | G Loss: 2.298235 | C Loss: -0.612659\n",
      "06/29/2022 12:07:56 - INFO - __main__ -   Text: ['All songs.']\n",
      "06/29/2022 12:07:57 - INFO - __main__ -   Epoch: 195 | Batch: 1200/10001 (12%) | G Loss: 2.557882 | C Loss: -0.472158\n",
      "06/29/2022 12:07:57 - INFO - __main__ -   Text: ['The focus of these programs is education.']\n",
      "06/29/2022 12:07:58 - INFO - __main__ -   Epoch: 195 | Batch: 1800/10001 (18%) | G Loss: 2.842226 | C Loss: -0.401478\n",
      "06/29/2022 12:07:58 - INFO - __main__ -   Text: ['\"They are outside of the world,\" she says.']\n",
      "06/29/2022 12:07:59 - INFO - __main__ -   Epoch: 195 | Batch: 2400/10001 (24%) | G Loss: 3.970373 | C Loss: -0.431542\n",
      "06/29/2022 12:08:00 - INFO - __main__ -   Text: ['You can tell Hobbes a lot of ways.']\n",
      "06/29/2022 12:08:01 - INFO - __main__ -   Epoch: 195 | Batch: 3000/10001 (30%) | G Loss: 4.350996 | C Loss: -0.428047\n",
      "06/29/2022 12:08:01 - INFO - __main__ -   Text: ['Estelle later married a dangerous poet when she first discovers that she lives in London.']\n",
      "06/29/2022 12:08:02 - INFO - __main__ -   Epoch: 195 | Batch: 3600/10001 (36%) | G Loss: 3.854473 | C Loss: -1.005919\n",
      "06/29/2022 12:08:02 - INFO - __main__ -   Text: ['Fredder Than Thing!']\n",
      "06/29/2022 12:08:03 - INFO - __main__ -   Epoch: 195 | Batch: 4200/10001 (42%) | G Loss: 3.125263 | C Loss: -0.456752\n",
      "06/29/2022 12:08:03 - INFO - __main__ -   Text: ['Hah!']\n",
      "06/29/2022 12:08:04 - INFO - __main__ -   Epoch: 195 | Batch: 4800/10001 (48%) | G Loss: 2.252834 | C Loss: -0.571680\n",
      "06/29/2022 12:08:04 - INFO - __main__ -   Text: [\"The hacker is resistant to medical if you don't keep companies information up to date.\"]\n",
      "06/29/2022 12:08:05 - INFO - __main__ -   Epoch: 195 | Batch: 5400/10001 (54%) | G Loss: 1.893587 | C Loss: -0.497355\n",
      "06/29/2022 12:08:05 - INFO - __main__ -   Text: ['It is the critical age.']\n",
      "06/29/2022 12:08:06 - INFO - __main__ -   Epoch: 195 | Batch: 6000/10001 (60%) | G Loss: 2.234484 | C Loss: -0.358759\n",
      "06/29/2022 12:08:06 - INFO - __main__ -   Text: ['His father is an atheist.\"']\n",
      "06/29/2022 12:08:07 - INFO - __main__ -   Epoch: 195 | Batch: 6600/10001 (66%) | G Loss: 2.603951 | C Loss: -0.570654\n",
      "06/29/2022 12:08:07 - INFO - __main__ -   Text: ['elevator basic income calculation can be viewed as: diner pays tax on meters.']\n",
      "06/29/2022 12:08:08 - INFO - __main__ -   Epoch: 195 | Batch: 7200/10001 (72%) | G Loss: 2.765673 | C Loss: -0.452957\n",
      "06/29/2022 12:08:08 - INFO - __main__ -   Text: ['In season 2002, the debate franchise goes down.']\n",
      "06/29/2022 12:08:09 - INFO - __main__ -   Epoch: 195 | Batch: 7800/10001 (78%) | G Loss: 2.883073 | C Loss: -0.405282\n",
      "06/29/2022 12:08:09 - INFO - __main__ -   Text: ['In emergency notice you can choose what all kinds of fonts to get in an online bulletin system.']\n",
      "06/29/2022 12:08:10 - INFO - __main__ -   Epoch: 195 | Batch: 8400/10001 (84%) | G Loss: 3.230933 | C Loss: -0.391114\n",
      "06/29/2022 12:08:10 - INFO - __main__ -   Text: ['This show is a landmark for the music industry .']\n",
      "06/29/2022 12:08:11 - INFO - __main__ -   Epoch: 195 | Batch: 9000/10001 (90%) | G Loss: 3.278240 | C Loss: -0.550286\n",
      "06/29/2022 12:08:12 - INFO - __main__ -   Text: ['Hodgson often describes himself as a son of a sex-crazed prostitute.']\n",
      "06/29/2022 12:08:13 - INFO - __main__ -   Epoch: 195 | Batch: 9600/10001 (96%) | G Loss: 2.734269 | C Loss: -0.205056\n",
      "06/29/2022 12:08:13 - INFO - __main__ -   Text: ['Climate4NetToday is a novel emotional generator and used the following code:']\n",
      "06/29/2022 12:08:13 - INFO - __main__ -   * (Train) Epoch: 195 | G Loss: 2.5791 | C Loss: -0.4731 | Updates G: 34 | Updates C: 799\n",
      "06/29/2022 12:08:22 - INFO - __main__ -   Bleu-2:0.205 | B-Bleu-2:0.250\n",
      "06/29/2022 12:08:22 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4555749444805465\n",
      "Train file used is number 7\n",
      "../../yahoo/subdivided_large/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 196 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:34.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:37.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:55.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:12.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:11:52 - INFO - __main__ -   Epoch: 196 | Batch: 0/10001 (0%) | G Loss: 2.370406 | C Loss: -0.232098\n",
      "06/29/2022 12:11:52 - INFO - __main__ -   Text: [\"The song is 'Happy Birthday.'\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.482\n",
      "  Test Loss: 3.952\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:11:53 - INFO - __main__ -   Epoch: 196 | Batch: 600/10001 (6%) | G Loss: 2.421876 | C Loss: -0.392255\n",
      "06/29/2022 12:11:53 - INFO - __main__ -   Text: ['All winning passwords are paid via private message service']\n",
      "06/29/2022 12:11:54 - INFO - __main__ -   Epoch: 196 | Batch: 1200/10001 (12%) | G Loss: 2.811923 | C Loss: -0.504499\n",
      "06/29/2022 12:11:54 - INFO - __main__ -   Text: [\"The episodes seem to be related to Hermione's lesbian fantasies.\"]\n",
      "06/29/2022 12:11:55 - INFO - __main__ -   Epoch: 196 | Batch: 1800/10001 (18%) | G Loss: 2.618115 | C Loss: -0.415690\n",
      "06/29/2022 12:11:55 - INFO - __main__ -   Text: ['In these cases, the issue of human rights is being questioned.\"']\n",
      "06/29/2022 12:11:56 - INFO - __main__ -   Epoch: 196 | Batch: 2400/10001 (24%) | G Loss: 2.498535 | C Loss: -0.375556\n",
      "06/29/2022 12:11:56 - INFO - __main__ -   Text: [\"There's no way there's a whole different truth.\"]\n",
      "06/29/2022 12:11:57 - INFO - __main__ -   Epoch: 196 | Batch: 3000/10001 (30%) | G Loss: 2.620874 | C Loss: -0.445809\n",
      "06/29/2022 12:11:57 - INFO - __main__ -   Text: [\"He's good at sitting down and putting his pants on so he can use his money.\"]\n",
      "06/29/2022 12:11:58 - INFO - __main__ -   Epoch: 196 | Batch: 3600/10001 (36%) | G Loss: 2.822352 | C Loss: -0.474972\n",
      "06/29/2022 12:11:58 - INFO - __main__ -   Text: ['It has to be in constant condition.']\n",
      "06/29/2022 12:11:59 - INFO - __main__ -   Epoch: 196 | Batch: 4200/10001 (42%) | G Loss: 2.863436 | C Loss: -0.415429\n",
      "06/29/2022 12:11:59 - INFO - __main__ -   Text: ['The Ayn Randian Theory.']\n",
      "06/29/2022 12:12:00 - INFO - __main__ -   Epoch: 196 | Batch: 4800/10001 (48%) | G Loss: 2.557174 | C Loss: -0.371488\n",
      "06/29/2022 12:12:00 - INFO - __main__ -   Text: ['He instrates fears that Omar may not be as nice as he believes.']\n",
      "06/29/2022 12:12:01 - INFO - __main__ -   Epoch: 196 | Batch: 5400/10001 (54%) | G Loss: 2.930797 | C Loss: -0.395371\n",
      "06/29/2022 12:12:01 - INFO - __main__ -   Text: ['According to TVLocal.com, Jill Stein should be walking away.']\n",
      "06/29/2022 12:12:02 - INFO - __main__ -   Epoch: 196 | Batch: 6000/10001 (60%) | G Loss: 3.138190 | C Loss: -0.411588\n",
      "06/29/2022 12:12:03 - INFO - __main__ -   Text: ['Male predators plan these predators to invade Earth before mating with their female offspring.']\n",
      "06/29/2022 12:12:04 - INFO - __main__ -   Epoch: 196 | Batch: 6600/10001 (66%) | G Loss: 3.026649 | C Loss: -0.537783\n",
      "06/29/2022 12:12:04 - INFO - __main__ -   Text: ['Current pricing tutorials on VHN are also geared towards men.']\n",
      "06/29/2022 12:12:05 - INFO - __main__ -   Epoch: 196 | Batch: 7200/10001 (72%) | G Loss: 3.039171 | C Loss: -0.520704\n",
      "06/29/2022 12:12:05 - INFO - __main__ -   Text: ['Writing such a script is impossible.']\n",
      "06/29/2022 12:12:06 - INFO - __main__ -   Epoch: 196 | Batch: 7800/10001 (78%) | G Loss: 3.188570 | C Loss: -0.448209\n",
      "06/29/2022 12:12:06 - INFO - __main__ -   Text: [\"Dickie won't jog.\"]\n",
      "06/29/2022 12:12:07 - INFO - __main__ -   Epoch: 196 | Batch: 8400/10001 (84%) | G Loss: 3.158612 | C Loss: -0.391328\n",
      "06/29/2022 12:12:07 - INFO - __main__ -   Text: [\"Things like the Kisan'es.\"]\n",
      "06/29/2022 12:12:08 - INFO - __main__ -   Epoch: 196 | Batch: 9000/10001 (90%) | G Loss: 2.783570 | C Loss: -0.543732\n",
      "06/29/2022 12:12:08 - INFO - __main__ -   Text: ['Seanchan and Arvind are putting up some hilarious tracks.']\n",
      "06/29/2022 12:12:09 - INFO - __main__ -   Epoch: 196 | Batch: 9600/10001 (96%) | G Loss: 2.997950 | C Loss: -0.515438\n",
      "06/29/2022 12:12:09 - INFO - __main__ -   Text: ['Piles are quirky.']\n",
      "06/29/2022 12:12:10 - INFO - __main__ -   * (Train) Epoch: 196 | G Loss: 2.7427 | C Loss: -0.4471 | Updates G: 50 | Updates C: 783\n",
      "06/29/2022 12:12:18 - INFO - __main__ -   Bleu-2:0.201 | B-Bleu-2:0.264\n",
      "06/29/2022 12:12:18 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46485198908034187\n",
      "Train file used is number 8\n",
      "../../yahoo/subdivided_large/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 197 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:51.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:01:59.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:17.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:34.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:50.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:15:43 - INFO - __main__ -   Epoch: 197 | Batch: 0/10001 (0%) | G Loss: 3.132145 | C Loss: -0.635296\n",
      "06/29/2022 12:15:43 - INFO - __main__ -   Text: [\"There are certain things I'm not going to say.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.490\n",
      "  Test Loss: 3.904\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:15:44 - INFO - __main__ -   Epoch: 197 | Batch: 600/10001 (6%) | G Loss: 2.748639 | C Loss: -0.397548\n",
      "06/29/2022 12:15:44 - INFO - __main__ -   Text: ['BrigA is an enzyme brought into the biosynthetic farbenumber.']\n",
      "06/29/2022 12:15:45 - INFO - __main__ -   Epoch: 197 | Batch: 1200/10001 (12%) | G Loss: 2.667869 | C Loss: -0.511923\n",
      "06/29/2022 12:15:45 - INFO - __main__ -   Text: ['This can be achieved by taking root from a tree.']\n",
      "06/29/2022 12:15:46 - INFO - __main__ -   Epoch: 197 | Batch: 1800/10001 (18%) | G Loss: 2.913950 | C Loss: -0.347508\n",
      "06/29/2022 12:15:46 - INFO - __main__ -   Text: ['In 2014, when it comes to film-making, Iran is the top performer.']\n",
      "06/29/2022 12:15:47 - INFO - __main__ -   Epoch: 197 | Batch: 2400/10001 (24%) | G Loss: 2.782419 | C Loss: -0.419717\n",
      "06/29/2022 12:15:47 - INFO - __main__ -   Text: ['It could cover the past as well like the present, but that\\'s not the point.\"']\n",
      "06/29/2022 12:15:48 - INFO - __main__ -   Epoch: 197 | Batch: 3000/10001 (30%) | G Loss: 2.837823 | C Loss: -0.471123\n",
      "06/29/2022 12:15:48 - INFO - __main__ -   Text: ['He may catch pups in the zoo.']\n",
      "06/29/2022 12:15:49 - INFO - __main__ -   Epoch: 197 | Batch: 3600/10001 (36%) | G Loss: 2.519291 | C Loss: -0.309412\n",
      "06/29/2022 12:15:50 - INFO - __main__ -   Text: ['Picking Cinnabots is a lifestyle exercised by Runfish and Picking Hedgerows.']\n",
      "06/29/2022 12:15:51 - INFO - __main__ -   Epoch: 197 | Batch: 4200/10001 (42%) | G Loss: 2.774339 | C Loss: -0.481065\n",
      "06/29/2022 12:15:51 - INFO - __main__ -   Text: ['Human traders can add machine technology to their trade.']\n",
      "06/29/2022 12:15:52 - INFO - __main__ -   Epoch: 197 | Batch: 4800/10001 (48%) | G Loss: 3.504021 | C Loss: -0.822615\n",
      "06/29/2022 12:15:52 - INFO - __main__ -   Text: ['But I think he is fake.\"']\n",
      "06/29/2022 12:15:53 - INFO - __main__ -   Epoch: 197 | Batch: 5400/10001 (54%) | G Loss: 2.834091 | C Loss: -0.702359\n",
      "06/29/2022 12:15:53 - INFO - __main__ -   Text: ['Charlie McNeil\".']\n",
      "06/29/2022 12:15:54 - INFO - __main__ -   Epoch: 197 | Batch: 6000/10001 (60%) | G Loss: 2.501099 | C Loss: -0.559702\n",
      "06/29/2022 12:15:54 - INFO - __main__ -   Text: ['The more effective generation route runs via calculations.']\n",
      "06/29/2022 12:15:55 - INFO - __main__ -   Epoch: 197 | Batch: 6600/10001 (66%) | G Loss: 2.355010 | C Loss: -0.381383\n",
      "06/29/2022 12:15:55 - INFO - __main__ -   Text: ['The organization claims to be moral.']\n",
      "06/29/2022 12:15:56 - INFO - __main__ -   Epoch: 197 | Batch: 7200/10001 (72%) | G Loss: 2.934341 | C Loss: -0.614585\n",
      "06/29/2022 12:15:56 - INFO - __main__ -   Text: ['Many other creators have described their results as \"perfect\".']\n",
      "06/29/2022 12:15:57 - INFO - __main__ -   Epoch: 197 | Batch: 7800/10001 (78%) | G Loss: 3.178560 | C Loss: -0.530677\n",
      "06/29/2022 12:15:57 - INFO - __main__ -   Text: ['They also met my usual procedure for the top decoration.']\n",
      "06/29/2022 12:15:58 - INFO - __main__ -   Epoch: 197 | Batch: 8400/10001 (84%) | G Loss: 2.806103 | C Loss: -0.326752\n",
      "06/29/2022 12:15:58 - INFO - __main__ -   Text: [\"As you can see, the running back thing doesn't seem to work out so well.\"]\n",
      "06/29/2022 12:15:59 - INFO - __main__ -   Epoch: 197 | Batch: 9000/10001 (90%) | G Loss: 2.736691 | C Loss: -0.521581\n",
      "06/29/2022 12:15:59 - INFO - __main__ -   Text: ['Harris writes that \"Good travelers get fat as roadkill.\"']\n",
      "06/29/2022 12:16:00 - INFO - __main__ -   Epoch: 197 | Batch: 9600/10001 (96%) | G Loss: 2.536453 | C Loss: -0.404546\n",
      "06/29/2022 12:16:00 - INFO - __main__ -   Text: ['Galaxy Books are Home Science Tutorials.']\n",
      "06/29/2022 12:16:01 - INFO - __main__ -   * (Train) Epoch: 197 | G Loss: 2.7074 | C Loss: -0.4580 | Updates G: 35 | Updates C: 798\n",
      "06/29/2022 12:16:10 - INFO - __main__ -   Bleu-2:0.201 | B-Bleu-2:0.240\n",
      "06/29/2022 12:16:10 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44111800916823773\n",
      "Train file used is number 9\n",
      "../../yahoo/subdivided_large/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 198 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:52.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:09.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:27.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:44.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:02.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:19.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:36.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:54.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:11.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:19:38 - INFO - __main__ -   Epoch: 198 | Batch: 0/10001 (0%) | G Loss: 2.800127 | C Loss: -0.320074\n",
      "06/29/2022 12:19:38 - INFO - __main__ -   Text: ['While Kochai17: \"isil destroys common hill.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.487\n",
      "  Test Loss: 4.067\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:19:39 - INFO - __main__ -   Epoch: 198 | Batch: 600/10001 (6%) | G Loss: 3.156173 | C Loss: -0.335816\n",
      "06/29/2022 12:19:39 - INFO - __main__ -   Text: ['The idea is to force the chemicals to be electrocyclic.']\n",
      "06/29/2022 12:19:40 - INFO - __main__ -   Epoch: 198 | Batch: 1200/10001 (12%) | G Loss: 3.469272 | C Loss: -0.380717\n",
      "06/29/2022 12:19:40 - INFO - __main__ -   Text: ['People have different borders.']\n",
      "06/29/2022 12:19:41 - INFO - __main__ -   Epoch: 198 | Batch: 1800/10001 (18%) | G Loss: 2.973073 | C Loss: -0.550536\n",
      "06/29/2022 12:19:42 - INFO - __main__ -   Text: ['Over all we have to work harder in order to solve every problem.']\n",
      "06/29/2022 12:19:42 - INFO - __main__ -   Epoch: 198 | Batch: 2400/10001 (24%) | G Loss: 2.493852 | C Loss: -0.396464\n",
      "06/29/2022 12:19:43 - INFO - __main__ -   Text: ['The goal is that best practices can be taught to teach them.']\n",
      "06/29/2022 12:19:44 - INFO - __main__ -   Epoch: 198 | Batch: 3000/10001 (30%) | G Loss: 2.462516 | C Loss: -0.639813\n",
      "06/29/2022 12:19:44 - INFO - __main__ -   Text: ['Nostratics is a fictitious string workarfare technique that he has been practising.']\n",
      "06/29/2022 12:19:45 - INFO - __main__ -   Epoch: 198 | Batch: 3600/10001 (36%) | G Loss: 2.748864 | C Loss: -0.469170\n",
      "06/29/2022 12:19:45 - INFO - __main__ -   Text: ['Schools of physics expect random people.']\n",
      "06/29/2022 12:19:46 - INFO - __main__ -   Epoch: 198 | Batch: 4200/10001 (42%) | G Loss: 3.109729 | C Loss: -0.432712\n",
      "06/29/2022 12:19:46 - INFO - __main__ -   Text: ['Feisty enjoys having power to walk on water and to come down from heaven.']\n",
      "06/29/2022 12:19:47 - INFO - __main__ -   Epoch: 198 | Batch: 4800/10001 (48%) | G Loss: 2.998593 | C Loss: -0.558214\n",
      "06/29/2022 12:19:47 - INFO - __main__ -   Text: ['Turn 2, I\\'m RIGHT!\"']\n",
      "06/29/2022 12:19:48 - INFO - __main__ -   Epoch: 198 | Batch: 5400/10001 (54%) | G Loss: 3.209885 | C Loss: -0.554601\n",
      "06/29/2022 12:19:48 - INFO - __main__ -   Text: [\"It is easily seen from the outside looking in — he can't feel what is inside.\"]\n",
      "06/29/2022 12:19:49 - INFO - __main__ -   Epoch: 198 | Batch: 6000/10001 (60%) | G Loss: 2.978004 | C Loss: -0.600579\n",
      "06/29/2022 12:19:49 - INFO - __main__ -   Text: ['However, where successful are the Independent Hawks who lack the support of the international Islamist organisation.']\n",
      "06/29/2022 12:19:50 - INFO - __main__ -   Epoch: 198 | Batch: 6600/10001 (66%) | G Loss: 2.655985 | C Loss: -0.418895\n",
      "06/29/2022 12:19:50 - INFO - __main__ -   Text: ['Esch can serve as a guardian angel for children ages five and up.']\n",
      "06/29/2022 12:19:51 - INFO - __main__ -   Epoch: 198 | Batch: 7200/10001 (72%) | G Loss: 3.386087 | C Loss: -0.603222\n",
      "06/29/2022 12:19:52 - INFO - __main__ -   Text: ['The small subject matter level should encompass subjects which often size.']\n",
      "06/29/2022 12:19:53 - INFO - __main__ -   Epoch: 198 | Batch: 7800/10001 (78%) | G Loss: 3.594366 | C Loss: -0.675023\n",
      "06/29/2022 12:19:53 - INFO - __main__ -   Text: ['Ray Lewis was angry at me when he taught me how to sing.']\n",
      "06/29/2022 12:19:54 - INFO - __main__ -   Epoch: 198 | Batch: 8400/10001 (84%) | G Loss: 2.668274 | C Loss: -0.321672\n",
      "06/29/2022 12:19:54 - INFO - __main__ -   Text: ['They aspire to drive innovation beyond their traditional educational backgrounds.']\n",
      "06/29/2022 12:19:55 - INFO - __main__ -   Epoch: 198 | Batch: 9000/10001 (90%) | G Loss: 2.597903 | C Loss: -0.550646\n",
      "06/29/2022 12:19:55 - INFO - __main__ -   Text: ['Sandy gives you the idea there is something wrong with the soul.']\n",
      "06/29/2022 12:19:56 - INFO - __main__ -   Epoch: 198 | Batch: 9600/10001 (96%) | G Loss: 3.294841 | C Loss: -0.520648\n",
      "06/29/2022 12:19:56 - INFO - __main__ -   Text: [\"It is called 'Crazy Hacks' which is something similar but learns coding through jokes.\"]\n",
      "06/29/2022 12:19:57 - INFO - __main__ -   * (Train) Epoch: 198 | G Loss: 2.8470 | C Loss: -0.4625 | Updates G: 38 | Updates C: 795\n",
      "06/29/2022 12:20:06 - INFO - __main__ -   Bleu-2:0.207 | B-Bleu-2:0.262\n",
      "06/29/2022 12:20:06 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46920262065104357\n",
      "Train file used is number 10\n",
      "../../yahoo/subdivided_large/train_10.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 199 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:17.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:33.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:50.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:08.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:26.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:43.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:00.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:16.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:33.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:50.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:23:30 - INFO - __main__ -   Epoch: 199 | Batch: 0/10001 (0%) | G Loss: 3.061944 | C Loss: -0.416454\n",
      "06/29/2022 12:23:30 - INFO - __main__ -   Text: ['Bdhicatriism is not taught.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 4.031\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:23:31 - INFO - __main__ -   Epoch: 199 | Batch: 600/10001 (6%) | G Loss: 2.800419 | C Loss: -0.420096\n",
      "06/29/2022 12:23:31 - INFO - __main__ -   Text: ['Means and means are to reach this heaven.\"']\n",
      "06/29/2022 12:23:32 - INFO - __main__ -   Epoch: 199 | Batch: 1200/10001 (12%) | G Loss: 2.674081 | C Loss: -0.479084\n",
      "06/29/2022 12:23:33 - INFO - __main__ -   Text: ['The meaning of any circle is floating in front of its colored flag.']\n",
      "06/29/2022 12:23:34 - INFO - __main__ -   Epoch: 199 | Batch: 1800/10001 (18%) | G Loss: 2.782416 | C Loss: -0.138177\n",
      "06/29/2022 12:23:34 - INFO - __main__ -   Text: [\"Bucky can bet he's guilty of insurance fraud.\"]\n",
      "06/29/2022 12:23:35 - INFO - __main__ -   Epoch: 199 | Batch: 2400/10001 (24%) | G Loss: 3.120185 | C Loss: -0.414462\n",
      "06/29/2022 12:23:35 - INFO - __main__ -   Text: [\"In contrast, Amazon's EC test process is highly similar to mine.\"]\n",
      "06/29/2022 12:23:36 - INFO - __main__ -   Epoch: 199 | Batch: 3000/10001 (30%) | G Loss: 2.994917 | C Loss: -0.420397\n",
      "06/29/2022 12:23:36 - INFO - __main__ -   Text: ['If they are usually two-fingered or very distraught, they may be.']\n",
      "06/29/2022 12:23:37 - INFO - __main__ -   Epoch: 199 | Batch: 3600/10001 (36%) | G Loss: 2.950579 | C Loss: -0.409512\n",
      "06/29/2022 12:23:37 - INFO - __main__ -   Text: ['Nitrocop3 is the first high Explosive bomb.']\n",
      "06/29/2022 12:23:38 - INFO - __main__ -   Epoch: 199 | Batch: 4200/10001 (42%) | G Loss: 3.131931 | C Loss: -0.575540\n",
      "06/29/2022 12:23:38 - INFO - __main__ -   Text: ['This is another valid reason that Teenage Cookies on this planet are new.']\n",
      "06/29/2022 12:23:39 - INFO - __main__ -   Epoch: 199 | Batch: 4800/10001 (48%) | G Loss: 2.725917 | C Loss: -0.436512\n",
      "06/29/2022 12:23:39 - INFO - __main__ -   Text: [\"If you're a musician there is no matter in play whether you have your poi or schimm.\"]\n",
      "06/29/2022 12:23:40 - INFO - __main__ -   Epoch: 199 | Batch: 5400/10001 (54%) | G Loss: 3.151887 | C Loss: -0.522778\n",
      "06/29/2022 12:23:40 - INFO - __main__ -   Text: ['To understand the vast lines language.']\n",
      "06/29/2022 12:23:41 - INFO - __main__ -   Epoch: 199 | Batch: 6000/10001 (60%) | G Loss: 2.747519 | C Loss: -0.357657\n",
      "06/29/2022 12:23:41 - INFO - __main__ -   Text: ['From Sun Rum a 40 km field seems to be in good hands.']\n",
      "06/29/2022 12:23:42 - INFO - __main__ -   Epoch: 199 | Batch: 6600/10001 (66%) | G Loss: 3.062311 | C Loss: -0.454193\n",
      "06/29/2022 12:23:43 - INFO - __main__ -   Text: ['Voetters are the soft numbers\".']\n",
      "06/29/2022 12:23:44 - INFO - __main__ -   Epoch: 199 | Batch: 7200/10001 (72%) | G Loss: 2.760903 | C Loss: -0.466799\n",
      "06/29/2022 12:23:44 - INFO - __main__ -   Text: ['Understandingly, the ideological threat is the USA.']\n",
      "06/29/2022 12:23:45 - INFO - __main__ -   Epoch: 199 | Batch: 7800/10001 (78%) | G Loss: 2.846773 | C Loss: -0.526407\n",
      "06/29/2022 12:23:45 - INFO - __main__ -   Text: ['This species is somewhat distinguishing from them, then found.']\n",
      "06/29/2022 12:23:46 - INFO - __main__ -   Epoch: 199 | Batch: 8400/10001 (84%) | G Loss: 2.886615 | C Loss: -0.244777\n",
      "06/29/2022 12:23:46 - INFO - __main__ -   Text: ['Deuscon is also good for pushing new Vector / Cross Demos.']\n",
      "06/29/2022 12:23:47 - INFO - __main__ -   Epoch: 199 | Batch: 9000/10001 (90%) | G Loss: 2.801959 | C Loss: -0.411445\n",
      "06/29/2022 12:23:47 - INFO - __main__ -   Text: ['He tries to enlist Baker or someone who may try to redeem Miranda.']\n",
      "06/29/2022 12:23:48 - INFO - __main__ -   Epoch: 199 | Batch: 9600/10001 (96%) | G Loss: 2.809886 | C Loss: -0.516597\n",
      "06/29/2022 12:23:48 - INFO - __main__ -   Text: ['Later, young Dutch managers and viewers are never happy about Australia.']\n",
      "06/29/2022 12:23:49 - INFO - __main__ -   * (Train) Epoch: 199 | G Loss: 2.8600 | C Loss: -0.4515 | Updates G: 43 | Updates C: 790\n",
      "06/29/2022 12:23:58 - INFO - __main__ -   Bleu-2:0.209 | B-Bleu-2:0.273\n",
      "06/29/2022 12:23:58 - INFO - utils -   Loading features from cached file ../../yahoo/subdivided_large/cached_lm_gpt_bert_100_train_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4824021288050695\n",
      "Train file used is number 11\n",
      "../../yahoo/subdivided_large/train_11.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 200 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of    120.    Elapsed: 0:00:18.\n",
      "  Batch    20  of    120.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    120.    Elapsed: 0:00:53.\n",
      "  Batch    40  of    120.    Elapsed: 0:01:11.\n",
      "  Batch    50  of    120.    Elapsed: 0:01:29.\n",
      "  Batch    60  of    120.    Elapsed: 0:01:46.\n",
      "  Batch    70  of    120.    Elapsed: 0:02:04.\n",
      "  Batch    80  of    120.    Elapsed: 0:02:22.\n",
      "  Batch    90  of    120.    Elapsed: 0:02:39.\n",
      "  Batch   100  of    120.    Elapsed: 0:02:56.\n",
      "  Batch   110  of    120.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:27:29 - INFO - __main__ -   Epoch: 200 | Batch: 0/10001 (0%) | G Loss: 2.954727 | C Loss: -0.388816\n",
      "06/29/2022 12:27:29 - INFO - __main__ -   Text: ['Formally, it is Rose who says, \"continue on with your pencil trying.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.505\n",
      "  Test Loss: 4.076\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:27:30 - INFO - __main__ -   Epoch: 200 | Batch: 600/10001 (6%) | G Loss: 2.911909 | C Loss: -0.479223\n",
      "06/29/2022 12:27:30 - INFO - __main__ -   Text: ['The idea is teenagers fantasising about becoming Christians.']\n",
      "06/29/2022 12:27:31 - INFO - __main__ -   Epoch: 200 | Batch: 1200/10001 (12%) | G Loss: 2.806674 | C Loss: -0.464667\n",
      "06/29/2022 12:27:31 - INFO - __main__ -   Text: ['One may pick up a terrified animal in captivity.']\n",
      "06/29/2022 12:27:32 - INFO - __main__ -   Epoch: 200 | Batch: 1800/10001 (18%) | G Loss: 2.901225 | C Loss: -0.451518\n",
      "06/29/2022 12:27:33 - INFO - __main__ -   Text: ['He instructs and encourages people to do so... However, according to it, a monk.']\n",
      "06/29/2022 12:27:34 - INFO - __main__ -   Epoch: 200 | Batch: 2400/10001 (24%) | G Loss: 3.143499 | C Loss: -0.575087\n",
      "06/29/2022 12:27:34 - INFO - __main__ -   Text: ['Bridge it Critical thought.']\n",
      "06/29/2022 12:27:35 - INFO - __main__ -   Epoch: 200 | Batch: 3000/10001 (30%) | G Loss: 2.924463 | C Loss: -0.505601\n",
      "06/29/2022 12:27:35 - INFO - __main__ -   Text: ['They are masters at algorithms.']\n",
      "06/29/2022 12:27:36 - INFO - __main__ -   Epoch: 200 | Batch: 3600/10001 (36%) | G Loss: 3.111618 | C Loss: -0.519363\n",
      "06/29/2022 12:27:36 - INFO - __main__ -   Text: ['Characteristics.']\n",
      "06/29/2022 12:27:37 - INFO - __main__ -   Epoch: 200 | Batch: 4200/10001 (42%) | G Loss: 2.555955 | C Loss: -0.427661\n",
      "06/29/2022 12:27:37 - INFO - __main__ -   Text: ['These glib stories require trying.']\n",
      "06/29/2022 12:27:38 - INFO - __main__ -   Epoch: 200 | Batch: 4800/10001 (48%) | G Loss: 2.501880 | C Loss: -0.346592\n",
      "06/29/2022 12:27:38 - INFO - __main__ -   Text: ['It is roughly that.']\n",
      "06/29/2022 12:27:39 - INFO - __main__ -   Epoch: 200 | Batch: 5400/10001 (54%) | G Loss: 3.025099 | C Loss: -0.518663\n",
      "06/29/2022 12:27:39 - INFO - __main__ -   Text: ['It may not be too dissimilar to the style of Crazy Taxi.']\n",
      "06/29/2022 12:27:40 - INFO - __main__ -   Epoch: 200 | Batch: 6000/10001 (60%) | G Loss: 3.226683 | C Loss: -0.420465\n",
      "06/29/2022 12:27:40 - INFO - __main__ -   Text: ['songs can be played on console.']\n",
      "06/29/2022 12:27:41 - INFO - __main__ -   Epoch: 200 | Batch: 6600/10001 (66%) | G Loss: 3.081150 | C Loss: -0.175307\n",
      "06/29/2022 12:27:41 - INFO - __main__ -   Text: ['\"The Hellmouth Must Be Living!\"']\n",
      "06/29/2022 12:27:42 - INFO - __main__ -   Epoch: 200 | Batch: 7200/10001 (72%) | G Loss: 2.961037 | C Loss: -0.419948\n",
      "06/29/2022 12:27:42 - INFO - __main__ -   Text: ['This type of insect useful for looking for information.']\n",
      "06/29/2022 12:27:43 - INFO - __main__ -   Epoch: 200 | Batch: 7800/10001 (78%) | G Loss: 2.838380 | C Loss: -0.382359\n",
      "06/29/2022 12:27:43 - INFO - __main__ -   Text: ['The statement takes simply: 0 means yes in mathematics.']\n",
      "06/29/2022 12:27:44 - INFO - __main__ -   Epoch: 200 | Batch: 8400/10001 (84%) | G Loss: 2.769212 | C Loss: -0.444809\n",
      "06/29/2022 12:27:44 - INFO - __main__ -   Text: ['Along the way, they did the same thing in Canada.']\n",
      "06/29/2022 12:27:45 - INFO - __main__ -   Epoch: 200 | Batch: 9000/10001 (90%) | G Loss: 2.699341 | C Loss: -0.466718\n",
      "06/29/2022 12:27:45 - INFO - __main__ -   Text: ['Technically, they are all bioterrorists.']\n",
      "06/29/2022 12:27:46 - INFO - __main__ -   Epoch: 200 | Batch: 9600/10001 (96%) | G Loss: 2.891541 | C Loss: -0.507060\n",
      "06/29/2022 12:27:46 - INFO - __main__ -   Text: ['Egyptian writing software is called fruits.']\n",
      "06/29/2022 12:27:47 - INFO - __main__ -   * (Train) Epoch: 200 | G Loss: 2.8545 | C Loss: -0.4548 | Updates G: 45 | Updates C: 788\n",
      "06/29/2022 12:27:56 - INFO - __main__ -   Bleu-2:0.194 | B-Bleu-2:0.258\n",
      "06/29/2022 12:27:56 - INFO - __main__ -   Loading generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45238257336303395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/29/2022 12:28:06 - INFO - __main__ -   Epoch 0/100 | Value Loss:0.0027733826637268066 | Mean values:0.013250696659088134 | Mean BLEU scores:0.014062321186065674 | Mean Entropy: 0.04949480056762695\n",
      "06/29/2022 12:36:59 - INFO - __main__ -   Epoch 50/100 | Value Loss:0.188032543361187 | Mean values:0.6787426024675369 | Mean BLEU scores:0.6843200778961182 | Mean Entropy: 2.490745210647583\n",
      "06/29/2022 12:45:42 - INFO - __main__ -   Saving decoder\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', type=int, default=0)\n",
    "    parser.add_argument('--epochs', type=int, default=15)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--gp_lambda', type=int, default=10)\n",
    "    parser.add_argument('--n_layers', type=int, default=20, help=\"Number of layers of generator and critic\")\n",
    "    parser.add_argument('--block_dim', type=int, default=100)\n",
    "    parser.add_argument('--interval', type=int, default=10, help=\"Steps before logging output\")\n",
    "    parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available())\n",
    "    \n",
    "    # Optimus parameters\n",
    "    parser.add_argument(\"--train_data_file\", default=None, type=str, required=True,\n",
    "                        help=\"The input training data file (a text file).\")\n",
    "    parser.add_argument(\"--valid_data_file\", default=None, type=str, required=True,\n",
    "                        help=\"The input validation data file (a text file).\")\n",
    "    parser.add_argument(\"--checkpoint_dir\", default=None, type=str, required=True,\n",
    "                        help=\"The directory where checkpoints are saved.\")\n",
    "    parser.add_argument('--generator_dir', default=None, type=str, help=\"Directory where GAN models are saved\")\n",
    "    parser.add_argument(\"--output_dir\", default=None, type=str, required=True,\n",
    "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "    parser.add_argument(\"--dataset\", default='Snli', type=str, help=\"The dataset.\")    \n",
    "    parser.add_argument(\"--latent_size\", default=32, type=int, help=\"Latent space dimension.\")\n",
    "    ## Encoder options\n",
    "    parser.add_argument(\"--encoder_model_type\", default=\"bert\", type=str,\n",
    "                        help=\"The encoder model architecture to be fine-tuned.\")\n",
    "    parser.add_argument(\"--encoder_model_name_or_path\", default=\"bert-base-cased\", type=str,\n",
    "                        help=\"The encoder model checkpoint for weights initialization.\")\n",
    "    parser.add_argument(\"--encoder_config_name\", default=\"\", type=str,\n",
    "                        help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "    parser.add_argument(\"--encoder_tokenizer_name\", default=\"\", type=str,\n",
    "                        help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "    ## Decoder options\n",
    "    parser.add_argument(\"--decoder_model_type\", default=\"gpt2\", type=str,\n",
    "                        help=\"The decoder model architecture to be fine-tuned.\")\n",
    "    parser.add_argument(\"--decoder_model_name_or_path\", default=\"bert-base-cased\", type=str,\n",
    "                        help=\"The decoder model checkpoint for weights initialization.\")\n",
    "    parser.add_argument(\"--decoder_config_name\", default=\"\", type=str,\n",
    "                        help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "    parser.add_argument(\"--decoder_tokenizer_name\", default=\"\", type=str,\n",
    "                        help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "    parser.add_argument(\"--per_gpu_train_batch_size\", default=1, type=int,\n",
    "                        help=\"Batch size per GPU/CPU for training.\")\n",
    "    parser.add_argument(\"--max_seq_length\", default=512, type=int,\n",
    "                        help=\"Optional input sequence length before tokenization. The sequence will be dropped if it is longer the max_seq_length\")\n",
    "\n",
    "    ## Variational auto-encoder(check this)\n",
    "    parser.add_argument(\"--prompt\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--padding_text\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--length\", type=int, default=20)\n",
    "    parser.add_argument(\"--block_size\", default=-1, type=int,\n",
    "                        help=\"Optional input sequence length after tokenization.\"\n",
    "                             \"The training dataset will be truncated in block of this size for training.\"\n",
    "                             \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n",
    "    parser.add_argument(\"--do_lower_case\", action='store_true',\n",
    "                        help=\"Set this flag if you are using an uncased model.\")\n",
    "    parser.add_argument(\"--use_philly\", action='store_true',\n",
    "                        help=\"Use Philly for computing.\")\n",
    "    parser.add_argument('--gloabl_step_eval', type=int, default=661,\n",
    "                        help=\"Evaluate the results at the given global step\")\n",
    "    # Reinforcement learning parameters\n",
    "    parser.add_argument('--finetune_decoder', type=bool, default=True)\n",
    "    parser.add_argument('--epochs_rl', type=int, default=1000)\n",
    "    parser.add_argument('--batch_size_rl', type=int, default=32)\n",
    "    parser.add_argument('--lr_rl', type=float, default=1e-6)\n",
    "\n",
    "\n",
    "    # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "    args = parser.parse_args(\"--dataset EMNLP \\\n",
    "    --checkpoint_dir=output_dir_768_0_unsure \\\n",
    "    --output_dir=output_dir_768_0_unsure \\\n",
    "    --encoder_model_type=bert \\\n",
    "    --encoder_model_name_or_path=bert-base-cased \\\n",
    "    --decoder_model_type=gpt2 \\\n",
    "    --decoder_model_name_or_path=gpt2 \\\n",
    "    --train_data_file=../../yahoo/subdivided_large/train \\\n",
    "    --valid_data_file=../../yahoo/unlabelled_short/test.txt \\\n",
    "    --per_gpu_train_batch_size 12 \\\n",
    "    --block_size 100 \\\n",
    "    --max_seq_length 24 \\\n",
    "    --gloabl_step_eval 508523 \\\n",
    "    --latent_size 768 \\\n",
    "    --block_dim 100 \\\n",
    "    --n_layers 10 \\\n",
    "    --interval 50 \\\n",
    "    --epochs 200 \\\n",
    "    --finetune_decoder False \\\n",
    "    --lr_rl 1e-6 \\\n",
    "    --epochs_rl 100 \\\n",
    "    --batch_size_rl 32\".split())\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    global_step = args.gloabl_step_eval\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    #args.n_gpu = torch.cuda.device_count()\n",
    "    args.device = torch.device(\"cuda:0\")\n",
    "    args.n_gpu=1\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)       \n",
    "    \n",
    "    args.encoder_model_type = args.encoder_model_type.lower()\n",
    "    args.decoder_model_type = args.decoder_model_type.lower()\n",
    "\n",
    "    output_encoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-encoder-{}'.format(global_step))\n",
    "    output_decoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-decoder-{}'.format(global_step)) \n",
    "    checkpoints = [ [output_encoder_dir, output_decoder_dir] ]\n",
    "\n",
    "    # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "    encoder_config_class, encoder_model_class, encoder_tokenizer_class = MODEL_CLASSES[args.encoder_model_type]\n",
    "    model_encoder = encoder_model_class.from_pretrained(output_encoder_dir, latent_size=args.latent_size)\n",
    "    tokenizer_encoder = encoder_tokenizer_class.from_pretrained(args.encoder_tokenizer_name if args.encoder_tokenizer_name else args.encoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "\n",
    "    model_encoder.to(args.device)\n",
    "    if args.block_size <= 0:\n",
    "        args.block_size = tokenizer_encoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "    args.block_size = min(args.block_size, tokenizer_encoder.max_len_single_sentence)\n",
    "\n",
    "    # Load a trained Decoder model and vocabulary that you have fine-tuned\n",
    "    decoder_config_class, decoder_model_class, decoder_tokenizer_class = MODEL_CLASSES[args.decoder_model_type]\n",
    "    model_decoder = decoder_model_class.from_pretrained(output_decoder_dir, latent_size=args.latent_size)\n",
    "    tokenizer_decoder = decoder_tokenizer_class.from_pretrained(args.decoder_tokenizer_name if args.decoder_tokenizer_name else args.decoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "    model_decoder.to(args.device)\n",
    "    if args.block_size <= 0:\n",
    "        args.block_size = tokenizer_decoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "    args.block_size = min(args.block_size, tokenizer_decoder.max_len_single_sentence)\n",
    "\n",
    "    # Chunyuan: Add Padding token to GPT2\n",
    "    special_tokens_dict = {'pad_token': '<PAD>', 'bos_token': '<BOS>', 'eos_token': '<EOS>'}\n",
    "    num_added_toks = tokenizer_decoder.add_special_tokens(special_tokens_dict)\n",
    "    logger.info('We have added {} tokens to GPT2'.format(num_added_toks))\n",
    "    model_decoder.resize_token_embeddings(len(tokenizer_decoder))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n",
    "    assert tokenizer_decoder.pad_token == '<PAD>'\n",
    "\n",
    "    #train_loader, num_txt = build_dataload_and_cache_examples(args, [tokenizer_encoder, tokenizer_decoder], num_txt) \n",
    "    generator = Generator(args.n_layers, args.block_dim,args.latent_size)\n",
    "    critic = Critic(args.n_layers, args.block_dim,args.latent_size)\n",
    "\n",
    "    if args.generator_dir!=None:\n",
    "        logger.info(\"Loading generator and critic\")\n",
    "        generator.load_state_dict(torch.load(args.generator_dir+'/generator_'+str(args.gloabl_step_eval)+'.th'))\n",
    "        critic.load_state_dict(torch.load(args.generator_dir+'/critic_'+str(args.gloabl_step_eval)+'.th'))\n",
    "\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "    c_optimizer = optim.Adam(critic.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    if args.cuda:\n",
    "        generator = generator.cuda()\n",
    "        critic = critic.cuda()\n",
    "    \n",
    "    logger.info('G Parameters:{}'.format(sum([p.numel() for p in generator.parameters() if \\\n",
    "                                p.requires_grad])))\n",
    "    logger.info('C Parameters:{}'.format(sum([p.numel() for p in critic.parameters() if \\\n",
    "                                p.requires_grad])))\n",
    "    \n",
    "    device = args.device\n",
    "    \n",
    "    best_bleu = 0\n",
    "    reference = list()\n",
    "    with(open(args.valid_data_file,\"r\")) as valid:\n",
    "        for sents in valid:\n",
    "            reference.append(sents.replace(\"\\n\", \"\"))\n",
    "            \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        \n",
    "        #Insert GAN-BERT Code Here\n",
    "        \n",
    "        train_loader, num_txt = build_dataload_and_cache_examples(args, [tokenizer_encoder, tokenizer_decoder], num_txt) \n",
    "        \n",
    "        print(\"Train classification discriminator\")\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "        # Perform one full pass over the training set.\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch, args.epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        tr_g_loss = 0\n",
    "        tr_d_loss = 0\n",
    "\n",
    "        # Put the model into training mode.\n",
    "        transformer.train() \n",
    "        #generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Progress update every print_each_n_step batches.\n",
    "            if step % print_each_n_step == 0 and not step == 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                # Report progress.\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            b_label_mask = batch[3].to(device)\n",
    "\n",
    "            real_batch_size = b_input_ids.shape[0]\n",
    "\n",
    "            # Encode real data in the Transformer\n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            hidden_states = model_outputs.last_hidden_state[:,0,:] \n",
    "            #hidden_states = model_outputs[-1]\n",
    "            #print(\"  Number of real sentences (labelled and unlabelled): {}\".format(len(hidden_states)))\n",
    "            \n",
    "            # Generate fake data that should have the same distribution of the ones\n",
    "            # encoded by the transformer. \n",
    "            # First noisy input are used in input to the Generator\n",
    "            fixed_noise = torch.Tensor(np.random.normal(0, 1, (real_batch_size, args.latent_size))).to(args.device)\n",
    "            test_z_gb = generator(fixed_noise).data\n",
    "            fake_sentences = rollout_test(model_decoder, test_z_gb, tokenizer_decoder, args.max_seq_length, real_batch_size, 0, 1)\n",
    "            #print(\"  Number of generated sentences: {}\".format(len(fake_sentences)))\n",
    "\n",
    "            b_input_ids_fake, b_input_mask_fake = generate_data_fake(fake_sentences)\n",
    "            model_outputs_fake = transformer(b_input_ids_fake, attention_mask=b_input_mask_fake)\n",
    "            hidden_states_fake = model_outputs_fake.last_hidden_state[:,0,:] \n",
    "            #hidden_states_fake = model_outputs_fake[-1]\n",
    "\n",
    "            #noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "            # Gnerate Fake data\n",
    "            #gen_rep = generator(noise)\n",
    "            #print(\"Length of generator output {}\".format(len(gen_rep)))\n",
    "            #print(\"Length of single generator output {}\".format(len(gen_rep[0])))\n",
    "\n",
    "            # Generate the output of the Discriminator for real and fake data.\n",
    "            # First, we put together the output of the tranformer and the generator\n",
    "            disciminator_input = torch.cat([hidden_states, hidden_states_fake], dim=0)\n",
    "            # Then, we select the output of the disciminator\n",
    "            features, logits, probs = discriminator(disciminator_input)\n",
    "\n",
    "            # Finally, we separate the discriminator's output for the real and fake\n",
    "            # data\n",
    "            features_list = torch.split(features, real_batch_size)\n",
    "            D_real_features = features_list[0]\n",
    "            D_fake_features = features_list[1]\n",
    "\n",
    "            logits_list = torch.split(logits, real_batch_size)\n",
    "            D_real_logits = logits_list[0]\n",
    "            D_fake_logits = logits_list[1]\n",
    "\n",
    "            probs_list = torch.split(probs, real_batch_size)\n",
    "            D_real_probs = probs_list[0]\n",
    "            D_fake_probs = probs_list[1]\n",
    "\n",
    "            #---------------------------------\n",
    "            #  LOSS evaluation\n",
    "            #---------------------------------\n",
    "            # Generator's LOSS estimation\n",
    "            g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "            g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "            g_loss = g_loss_d + g_feat_reg\n",
    "\n",
    "            # Disciminator's LOSS estimation\n",
    "            logits = D_real_logits[:,0:-1]\n",
    "            log_probs = F.log_softmax(logits, dim=-1)\n",
    "            # The discriminator provides an output for labeled and unlabeled real data\n",
    "            # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "            label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "            per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "            per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "            labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "            # It may be the case that a batch does not contain labeled examples, \n",
    "            # so the \"supervised loss\" in this case is not evaluated\n",
    "            if labeled_example_count == 0:\n",
    "              D_L_Supervised = 0\n",
    "            else:\n",
    "              D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "\n",
    "            D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "            D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "            d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "\n",
    "            #---------------------------------\n",
    "            #  OPTIMIZATION\n",
    "            #---------------------------------\n",
    "            # Avoid gradient accumulation\n",
    "            #gen_optimizer.zero_grad()\n",
    "            dis_optimizer.zero_grad()\n",
    "\n",
    "            # Calculate weigth updates\n",
    "            # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "            g_loss.backward(retain_graph=True)\n",
    "            d_loss.backward() \n",
    "\n",
    "            # Apply modifications\n",
    "            #gen_optimizer.step()\n",
    "            dis_optimizer.step()\n",
    "\n",
    "            # A detail log of the individual losses\n",
    "            #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "            #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "            #             g_loss_d, g_feat_reg))\n",
    "\n",
    "            # Save the losses to print them later\n",
    "            tr_g_loss += g_loss.item()\n",
    "            tr_d_loss += d_loss.item()\n",
    "\n",
    "            # Update the learning rate with the scheduler\n",
    "            if apply_scheduler:\n",
    "              scheduler_d.step()\n",
    "              #scheduler_g.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "        avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "        print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #     TEST ON THE EVALUATION DATASET\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our test set.\n",
    "        print(\"\")\n",
    "        print(\"Running Test...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        transformer.eval() #maybe redundant\n",
    "        discriminator.eval()\n",
    "        #generator.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_test_accuracy = 0\n",
    "\n",
    "        total_test_loss = 0\n",
    "        nb_test_steps = 0\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels_ids = []\n",
    "\n",
    "        #loss\n",
    "        nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in test_dataloader:\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "                model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "                hidden_states = model_outputs.last_hidden_state[:,0,:] \n",
    "                #hidden_states = model_outputs[-1]\n",
    "                _, logits, probs = discriminator(hidden_states)\n",
    "                ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "                filtered_logits = logits[:,0:-1]\n",
    "                # Accumulate the test loss.\n",
    "                total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "\n",
    "            # Accumulate the predictions and the input labels\n",
    "            _, preds = torch.max(filtered_logits, 1)\n",
    "            all_preds += preds.detach().cpu()\n",
    "            all_labels_ids += b_labels.detach().cpu()\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        all_preds = torch.stack(all_preds).numpy()\n",
    "        all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "        test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "        print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "        avg_test_loss = avg_test_loss.item()\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        test_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "        print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch + 1,\n",
    "                'Training Loss generator': avg_train_loss_g,\n",
    "                'Training Loss discriminator': avg_train_loss_d,\n",
    "                'Valid. Loss': avg_test_loss,\n",
    "                'Valid. Accur.': test_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Test Time': test_time\n",
    "            }\n",
    "        )\n",
    "\n",
    "        accuracy_array.append(test_accuracy)\n",
    "        \n",
    "        #OPTAGAN Code\n",
    "        \n",
    "        g_loss, c_loss = train(epoch)\n",
    "\n",
    "        data_test = list()\n",
    "        for i in range(2):\n",
    "            test_noise = torch.Tensor(np.random.normal(0, 1, (250, args.latent_size))).to(args.device)\n",
    "            test_z = generator(test_noise).data\n",
    "            new_sent = rollout_test(model_decoder, test_z, tokenizer_decoder, args.max_seq_length, 250, 0, 1)\n",
    "            data_test.extend(new_sent)\n",
    "\n",
    "        p_reference = random.sample(reference, 500)\n",
    "        bleu = calc_blue_parallel_func(p_reference, data_test, 2, 500)\n",
    "        b_bleu = calc_blue_parallel_func(data_test, p_reference, 2, 500)\n",
    "        logger.info(\"Bleu-2:{:0.3f} | B-Bleu-2:{:0.3f}\".format(bleu, b_bleu))\n",
    "        \n",
    "        print(bleu+b_bleu)\n",
    "        if (bleu+b_bleu) > best_bleu:\n",
    "            best_bleu = bleu + b_bleu\n",
    "            logger.info('* Saving. Best Score:{:0.3f} | Bleu-2:{:0.3f} | B-Bleu-2:{:0.3f}'.format(best_bleu, bleu, b_bleu))\n",
    "            torch.save(generator.state_dict(), args.output_dir+'/generator_'+str(args.gloabl_step_eval)+'.th')\n",
    "            torch.save(critic.state_dict(), args.output_dir+'/critic_'+str(args.gloabl_step_eval)+'.th')\n",
    "            \n",
    "        \n",
    "\n",
    "    if args.finetune_decoder: \n",
    "        logger.info(\"Loading generator\")\n",
    "        generator.load_state_dict(torch.load(args.output_dir+'/generator_'+str(args.gloabl_step_eval)+'.th'))\n",
    "        \n",
    "        model_decoder.train()\n",
    "        generator.eval()\n",
    "        dec_optimizer = optim.Adam(model_decoder.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "        value_loss = nn.L1Loss()\n",
    "        B = args.batch_size_rl\n",
    "        total_scores = 0\n",
    "        total_entropy = 0\n",
    "        total_values = 0\n",
    "        total_v_loss = 0\n",
    "        for epoch_ in range(args.epochs_rl):\n",
    "            if epoch_ == 200:\n",
    "                # Finetune decoder after training of value head\n",
    "                dec_optimizer = optim.Adam(model_decoder.parameters(), lr=args.lr_rl, betas=(0.5, 0.999))\n",
    "            noise = torch.from_numpy(np.random.normal(0, 1, (B, args.latent_size))).float()\n",
    "            noise = noise.to(args.device)\n",
    "            z_fake = generator(noise)            \n",
    "            sents, logprobs, values, entropy = rollout(model_decoder, z_fake, tokenizer_decoder, args.max_seq_length, B, 1)\n",
    "            p_reference = random.sample(reference, 500)\n",
    "\n",
    "            blue = []\n",
    "            for i in sents:\n",
    "                blue.append(calc_blue_parallel_func(p_reference, [i], 1, 0))\n",
    "\n",
    "            values = torch.stack(values, dim=1)\n",
    "            logprobs = torch.stack(logprobs, dim=1)\n",
    "            entropy = torch.stack(entropy, dim=1)\n",
    "\n",
    "            # Get tokens and mask of batch\n",
    "            toks_gpt = [([50258] + tokenizer_decoder.encode(j) + [50259]) for j in sents]\n",
    "            toks_gpt, mask = pad_seq(toks_gpt, tokenizer_decoder.encode(\"<PAD>\")[0], values.size(1)+1)\n",
    "            toks_gpt = torch.tensor(toks_gpt).to(args.device)\n",
    "            mask = torch.tensor(mask).to(args.device)\n",
    "              \n",
    "            values = values * mask[:,1:]\n",
    "            logprobs = logprobs * mask[:,1:]\n",
    "            entropy = entropy * mask[:,1:]\n",
    "            scores = torch.tensor(blue).to(args.device)\n",
    "            # Get value loss\n",
    "            v_loss = value_loss(torch.sum(values, dim=1), scores) \n",
    "              \n",
    "            if epoch_ >= 200:\n",
    "                R = 0\n",
    "                rewards = []\n",
    "\n",
    "                # Discount future rewards back to the present using gamma\n",
    "                for j in range(len(values.tolist())):\n",
    "                    R = 0\n",
    "                    batch_rewards = []\n",
    "                    for r in reversed(values.tolist()[j]):\n",
    "                        R = r + 0.99 * R\n",
    "                        batch_rewards.insert(0,R)\n",
    "                    rewards.append(batch_rewards)\n",
    "\n",
    "                # Penalizing low entropy states\n",
    "                rewards = torch.FloatTensor(rewards).to(args.device)\n",
    "                rewards = rewards + torch.log(torch.clamp(entropy,0.2,1))\n",
    "                # Calculate loss\n",
    "                d_loss = torch.sum(torch.mul(logprobs, rewards.detach()).mul(-1))\n",
    "            else:\n",
    "                d_loss = torch.tensor(0)\n",
    "\n",
    "            # Backpropagate losses\n",
    "            loss = v_loss + d_loss              \n",
    "            dec_optimizer.zero_grad()              \n",
    "            loss.backward()\n",
    "            dec_optimizer.step()\n",
    "\n",
    "            total_scores += torch.mean(scores).item()\n",
    "            total_values += torch.mean(torch.sum(values,-1)).item()\n",
    "            total_v_loss += v_loss.item()\n",
    "            total_entropy += torch.mean(torch.mean(entropy,dim=1)).item()\n",
    "            if (epoch_ % args.interval) == 0:\n",
    "                logger.info(\"Epoch {}/{} | Value Loss:{} | Mean values:{} | Mean BLEU scores:{} | Mean Entropy: {}\".format(epoch_, \n",
    "                args.epochs_rl, total_v_loss/args.interval, total_values/args.interval, total_scores/args.interval, total_entropy/args.interval))\n",
    "                total_scores = 0\n",
    "                total_values = 0\n",
    "                total_v_loss = 0\n",
    "                total_entropy = 0\n",
    "        logger.info(\"Saving decoder\")\n",
    "        output_decoder_dir = os.path.join(args.output_dir, 'checkpoint-decoder-{}'.format(global_step))\n",
    "        if not os.path.exists(output_decoder_dir):\n",
    "            os.makedirs(output_decoder_dir)\n",
    "        model_decoder.save_pretrained(output_decoder_dir)\n",
    "        torch.save(args, os.path.join(output_decoder_dir, 'training_encoder_args.bin'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a70a35fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.515\n"
     ]
    }
   ],
   "source": [
    "print(max(accuracy_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "967334e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_array[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c07743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGNCAYAAAD6s8DpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABuwklEQVR4nO3deXxU9b3/8dcnGyEhJEDCFvZdFA2Kiopr3bWCtbV21W5qW7vc9tdb29621u7LbW17bdW6dbNqXRBb9yoquAECskPYCQQSQkJC9uT7++OcmUwmM8kkDCTMvJ+PRx5Jzvmec74zZ/uc73bMOYeIiIhIokvp7QyIiIiIHA0KekRERCQpKOgRERGRpKCgR0RERJKCgh4RERFJCgp6REREJCko6BEREZGk0CtBj5k9aGbOzMZ1Y5ltZrYtbNoN/npu6Ob2nZkt7M4yvcHMxvl5ffAoba/Dd9xbenKM9GAbt/nbOO9IbUPkWGZmk83sSTMr9c+Vyt7Ok3jM7Hx/n1x7lLbXp+6b5llpZq93Z7luBz1m9h3/wzszm9rd5Y+GvnTzPppCgqTQnzoz22dmb5nZ/5nZ2b2dT+mbx6iZTTGzO81svZnVmNkhM9tgZn+Idq5HOeaazWyvmf3bzC7rJF1XP+eFbetFf/pOM0uN8fP82szeNbMKM2vyf79tZr8ys1O6WD7LzCr9bT7URdptfrpqMxsWJc1CP82krvLup78twndSZ2Yb/f00Kpb19JT/Hc8HLgf+BfwA+NmR3KbExsxSgN8AK4F/+tO+7B8jT3WyXK6ZbTezxq6O/77OeSMrfw+YY2YfjHW5tO5sxMwM+CzgAAM+B/y/7qwjzp4E3gL2dHO544Da+Genz6gC7vD/TgMGAycBnwe+aGYvAJ90zu0NW+59Ry2HXfsW3gW25Ahu4/+Ah4EdR3AbxwQz+zLwa7wHoVfxbnIOOAW4GbjRzL7mnPtdlFWEHnOZeMfb5cDlZvYV4C94N81w3/d/R5q3LSR/E/COTweMAi7z8xjpsxjexfB7/ud5F3gEqABygBOBLwFfN7NbnHN3RvlMHwZy/W1+wMyGOOf2R0kbMMD/LDd3ka47XgUW+n/nAxcDXwCuNbPZzrnNcdxWqPHAdOBPzrkbj9A2pGeuwzvHPubaXqvwe+AK4Cozu9E5d0+E5e4ExgDfds4tOzpZPXKcc0+Z2Trgx2b2uIvlFRPOuZh/gEvwLgAP4AUaZUBGd9bhr+dBfz3jurHMNmBbvNP25R9gnP89PdjN9BE/OzABeMVPsxzI7O3PmKw/fekYBT7pHxP7gXMizD/bn+eAT4TNi3rMAZ/y59UAWVG27fAf2rrI40/9tIHfCzpJ+30/zQ7grChphgI/wbv4R1vPm0AL8HN/fV/rYn86YBPQDBwXIc1CP82kGPfLbX7628KmpwMvBa7FR/C4OCfS9vXT+z/AYrwHjf5h00cA5f45Nzls3of9/fkakNKDbTpgYW9/9gj5+qaftwtjSt/NlT/mr/xM4Ff+3x/uJP2FwOvAIbynrPnANKIEPXilR7cAa4B6vKf8/8N72upwkwBu8Ndzg///eYGLaISfB7vaef52fgps8Ld/AHg+0pcZsq3bgCLg30AlXgnSq8CZEZYZiff0uRgoBRqB3cBDwPQI6ceF572L/RNIv62TNFnAOj/dV8PmRfqOM4Av4z0tH/A/3zbgqSjfyzTgfj9NA7DPPwY+H+kEAoYD9/r7uiVkX3Y4RkK/D2Ai3vG4H6gGXgBO8NMVAPfgBeb1wBLg/Ah5vc1f33lR8pYfsp4GvOPyUxHWk4F33D4DbPfTVuDdmC6Lctx0eoz6ad8HPOevqwHYiFf6lRshDwv9dWT4x9gGf5lOjx28ko8Kf9lLOkl3KW2BUU4sxxze+Vzjzz81ynq7DHrwSiv34F/kgaV4gUVhhLQTgCb/sx8fwzmTFmX6CX7eXsArKW0A1naynm1++g/6v5/uZB8dVtDjz7vWn7cmbPpH8B5sKv1jfx3wP0C/KN/9QiKcg50co7eFLN/T6+VpeNfLwHE3Lmz+LLzjvspf5+PA6JD9+zDeA3ed/1lPirC9KXjnylI/bQPeuXkPMKqL/BURw/XcXy4Vr1QvEITUAcX+9xkedKThldC9BRz0170c79oRcxCCd411wF+jzP+AP/9t/OMbKPS/7ypgrL/vvgG8DOzCuxeVAQuAMzo5VxcS43XRXybF/36W4F0LDvl/fz7aZ6Yb1z0//Vg/b/+I6fvrxhc9zP9iNoRdFP4TJf0H8U6gOryb1E/xbn4H/IMoUtDzW3/6buB3wP/6B9ASf9q2sPQ30D7oGecftJX+z20hP/PCd17YuvL8neeAd/wv+V7/4GwFbopykvzLP3j/gxcIPhryuaeGLXOdn/bfeMWMPwee8L/XGsJOXo5A0OOn+4yfbknY9G0RvuOH/LSr/P3zM7yqii3Ar8LSXuF/vhb/M/4U+CPwBrA1wgn0nr/N1XhFs7/FDxLoPOhZiPc087p/jDzu76NyYDKwGe9icoef10a8i/KYsDzcRvSgZwXexXyVn7d78I5dB1wfln64/5lf94+Zn/r5D5SOfDbsM9xG18foTf5nqsYLIn+Gd7F0eMdpXlgeFvrznsYLqB/AO76+3sWxECiNeTuG4+sdP+2nwj5PZ0HPIX/+rCjrjCXoCVzE7/H/v8X//7sR0v7Qn/f3WK9tUbb5O389H/X/DzzwnR0l/TZ/fhpt17fzw9IE9lE8gp7AU/vqkGn3+9N2AvfhnRuL/WmvEBbg0ck56G/7QdrOt8Axep6/bB49u14+j3cjC1wvH8R7GAzM/zfetfM5f/7z/vQNeDf7cmCR/9ke87e1DxgQtr1b8c6vJ/19+SvgWT/9HsICZnp2Pc/AC4odXqniH/HOuUfwzv0bQtKm+5/JAeuBu/CuTyvpJICJclwEjv+bOkkTOBZuxzsPXySkpBaYjXddfAm4299/D+Hdh5qAS6OcqyuI8broL/P3kO/nDrx2SNuIco7SzeteyHK78II26/L768YXfau/4W+FTFvqZ3BSWNoB/k5vIuxi539oR8cb2pn+tGJgcMj0TLxi5g4XVsKCnrALUIeLcNjOWxg27W5/+t2hXxzeTbQK70QNze95IZ8jfPs3+dP/EDZ9KCFPySHTT/IPtmfDpo/jyAQ9E/10zYRcCMO/N7yngVZ/P6dGWM+QkL/z/e+pETg3QtpRYf8Hvru/EOFpm86DHgd8Jyz9d/3pFXgXlJSQeZ/w5/0mbJnbiB70OLyLeGrI9On+d7Y2LH2/8M8X8v2t9vMUXgwd9RjFe3JpwLuBTAub9wdCAoCQ6Qtpu4nlx3K8+Mvd5y/34xjS/jjwvcRyzAGf9ufVhH/+8O+6i+0GbhZn+P8HSl62Efa0iPfk6oDPxPodRNhepr/PKgP5Bq6k86frbbQFPafSdt6EXksC++hwq7fS8G7KDrjPn3aD//8TEY61wHq+0s1z8LxI2/fnHc71ssPNOmz+x6IcoxVEP+/DP1shkUu3LsYLYv7YyfZvCJsX7Xr+E3/6gvBt4V0TCiLsg9/T/pqSGvL55sZ4XDzspz+lkzQD8B7+mmkLgB4JmZ9LhOsEXnu53cC6aOcqsV8XP+Knf5eQoBTIxjs3HP5DhT+929e9kPlP+vM71Jh0SBvjl2x4wUgLIREybRHnz8PSf8yf/ucI68rFu5iE39D+RNhTZIQDclvY9BuiHKTbwtNG2HkLQ/7PwHsirSYk4AqZH3h6/F6EPC2KkD4dL+BbGsv36y+zAK80Ij1k2jiOTNCTGXIAD432vQED/TSL6SKCBr7up/1tjHl1/gE+NMr8ByMcI4HPt5WwIAyvcZ7z92NO2LxUf3+8Ejb9NqIHPYeAgRHyFXiKH9DVZ/TTf81Pf07Y9KjHKPAdf5mfRJg3CO+iUEfIhZa2G+rcWI85f7ln/OVujiHtzX7aZyLsk0raSgN+FrJeB3y5i+PAdTJ/LN51Z33Y9EDJS3j14Vp/eqQn1XG0L1m7jbAqXj9dIEi+O2RaoIqtDhgUYZlt/jKB6oR/+P9/PMI+6m7QszAkv7/HK+53eE+2E/y0y/1jPC/CelLxSkje6eY5eB6Rg67DuV4u72Jbr0eYF2hbFOm8H+vPe6Abx/x7wJYo24/peu5/p5V4pUIju9heCl4hwB4iB5d5eEHyozHm/w0/r11t9wy8YMThlf51OG6jLBco5QwvGe/WdZG20qWLI6QPdEp4OWRat697IfP/SJTzPvwn1t5bF+CVDjzvnAvtTfMQXjHjDWb2P865Jn/6yf7vV8NX5JyrMrMVwLlhs6Iug1ec2RJjXntiKl5bl8XOuYoI81/GqxefGWHe0vAJzrkmM9uLt6PaMbMr8G4es/BKR8L3QT7d743WXRbyt4uWyDl30MyeBt4PrDCzx/GqcN52zoX3fpvt/362G/nY5pzb1430ASucc+HHw27/90bnXHXoDOdci78/utPFd5Nz7mCE6Tv934PwSjAAMLPj8erIz8FrTJgZtlxhN7YdOBdeDp/hnDtgZsv97UzDKx4P9U43thNPubT1xGrBeyp/Fvg/59wzh7Hez+LdNB4Mm/4gcA1eD9JYj7lxIXkM2E5br7OAQE+lBwITnHPNZvZ3vOD+E3g3hs58C7gar1fJY865+hjzGMm5tF0vG/GOwbvwbg47zSwLr7S4HPiq13mtgwa8XqvhenIOHs71sqvjs8P1lLZzO9J5H7gftTu3/R58H8N7MD4J73wNHeagMdbtR7meT8M75t92zu0OXybMFLzSyU3A/0TZP3VE3j+RDPF/H+gskXPuTf+afS3esdIuvZmdBXwFLzgaihfMhiqkY8/W7lwXT8YL5hZGSP8q3nUi9Bg5nOte4DjMj7CtdmINegIXgQfDMlLh3xSvAebiPX2BdzAAhHeJDiiNMC3qMv4FpzzGvPZEYNvRgo3A9LwI8yqjLNNM+5MMv+vuHXgH64t4B1QtXuAxD+/k7BdTjg/PSP93C12cOHhtB74JfJS2bsX1ZvYY8P9cW7f3PP93d7qYRzoOYlEVPsE/RiLO8zXjPbHFqrKT9UDIvjWz2XgnaqDaYQFtbRuK8M6N7uzXwzkeu/udBtKPjiFtIE2ki/x259y4bm67U/44MZ/G+x7/Gjb7Oby8v9/MhjvnAp+jFO/mMTIsPc65hfgBv5ml4T29h2/zOGAOXsnSW2GzH8QLej5HF0GPc26bmf0eb0iPr+C19eipHzjnbutk/iC8z1VAx6CuKz05B4/k8Rnp/G2ONi/kvA8/t38NfNXPy/N416U6f94NeCVEkVRGmR5+Pc/zf8dyvQsEKZPpfP8MiGFd0PY5MkP+7iptu3RmdjXe/boe7160Ga8UpxWv1OtcIl+zKqNsp8N1Ee84qXDOdQgwQ+7pQ8PSQ8+Oq/7+766+j66DHjMrwLshA/zDzP4RJemNtAU9gYMz4iBdeA0/w4UusyUsD2l4EdyurvLbQ4FtR8oXeE/uoem6zf8Mt+Gd9Cc75/aEzT+jp+vugfP938ucc82dJXTO1eEXrZvZaLxI+wbg43hPzoHBDiv934V4jdxiEbWU6RjzP3gn3fn+jTXIzL6FF/R0R+jxuCbC/KjHo/PLerthEV5j5gvxipc7c6H/e3E3t9FTV9IWvOyK8oQMXmD0E//vxXjH9/vw2jJ0V+ABb5qZRfsuTzCzM51zb3Sxrh/7efuWmd3Xg7zEKnAcLHfOndxpyo56cg4ezvXyiJ/zZjYUr8fparxeV9Vh8z8Sh81U+r9jKcENfA9POuc+EIdtB0rmhtD1Q2s0P8Qr7ZrlnFsXOsPM7qZjTUxPVAGDzSw9pBYosI3APf1gWHrowXWPtsCyy1LLWEZkvh6v2GsZXoOrSD9lwIVmNt5f5l3/d4cvzsxy8Z5+w0VdBu/Jq8sRWEO0dDP9BrwSl5PMLC/C/ECQ8G6EebHKx4tQ34gQ8AygrWjviPKLwr/u//v37izrnNvpnPs73nhNxXgjYQYOtsBT8WVxyeixZRLeE83CCPOiXTw6O0aX+7/PC5/hH59FtHVHPlyP4V3ATzOzi6Il8uedhleM/Fi0dHH2Of/3v4h83XnQn/8Za4uIHsR76vygX2oTMzPrh1d11YoXMEXa5vNheYvKOVeJd3MJrfqLO+dcDd5N4ngzG3ykthPiaFwvD8cEvHvbCxECnlH+/MO1Hu+8OdHMOpQqRkk728y6U9oczXv+72mHsY5JeA2PwwOeFLz7bTwsx9sP50SYdw7e9e/dsPTQs+veNLzztssH7liCnsDJ/QXn3Gcj/eC34MerfwdvDJcDwEfNbFbY+m6jrRgr1IP+7++EnrhmlonXBbg79gMFZta/y5SAX/z2d7wxS34YOs/MJuI9NTTRsYi9O/bhXShO8YOcwPrT8bqJdlkXebj8oPTfeAfIcrz91ln6AjObEWFWNl5RbDNtdeN/xovaP29mHQ7yIz1kfi/bhvdEc2LoRDP7DF6AGElnx+jf8I63L0V4ZcEP8RqY/80513BYucZrt0VbEPyQX8/fjpmdidd+D+C/wm8kR4Jfqngp3nXkQ1GuPZ/CK6magF8K5bzRiX+E96D2rJ/3SPIiTLsG74nxeefcZ6Jc667Fqwa41n+A68of8KoObsIrGT1Sfo33me+PFIiY2SAzi8uD1VG6Xh6Obf7vORbyuhL/uvsnuvkmgkj8tkV/wCvhvcsPmIPMLMOvJcEvTf89XknF7yKd82Y2wsymx7j5hf7v2Z0l6sI2YHJowOY/ONyG1xsrHgIlrT/1H7YD28mi7XUmoSWgPbru+d99EV5JZ2VXmep055v37pspwCrnXGcN0O7DKxr/lJl93zlXY2Y34o1X8LqZPYJXHzcHb3yf1wiL/pxzi/068C8Bq/02I014VQMH6F7j3v/gdRt9zsxew2vEt9I593Qny9yKV1Vzi5mdijeuRT7eRS4HuMU5t7UbeWjHOddqZr/zt7PKvPejZOA9FQ32t3d+J6vojjwzu83/Ow2vzv8kvAZrKXjtIa6P4aZZCCw3s1V4Txc78Q68K/GKIH8XuAE658rN7KN4pQCvmNmz/jID8Yb9H403rH0iugMvuFlkZo/iFb/OwjveH8Mbsypc1GPUbw/yVbyxnN7111mGV2p0Bt6T4zfjlXnnXOBG+Qu883UhXsmuw3sNxfl4T1Ffdc79JV7b7cJn8J4E/9ZFI+B78b7nG/HaJkDb2CTfBRab2TK8BrQVeMHOONqq6l4LWVegauveaBvzG/f/k7Yq3mivsAikb/SrOB8lejuSw+bvw1PwBr/bbGbP47UZHIx33p2D1zA7Xq/HOKLXy8PhnCs1s4fxxkVbYd5rd3KBi/BKClYQubahu34AnI7X0WOjmf0Lr0fbaLyu8d+g7WH+h3jX4Jvx2qG9jNceaCheW5+z8O6ha2PY7st4JUeX4FWt98Rv8BrDL/cbOzf5eZiON9bX+3u43iDn3ENmNhfvmFhjZvNpa786Hq8L/d9D0vf0unce3r308Vgz1lnXtcDAQlG7nIakDQzSdHXItIvwnsRq8QKXp4htROZ1eDeB3f4XkEsMIzKHTM/G68K2i7Yuew+GzHdEHpE5D6/B4SZ/+5V4F9JIXe7OI0J3zpD5kfKbhteFeS1eg6tSvKehsZG+E3reZT30px6vlOktvKeNOZ0s3y7P/vfxPbyTrMT/TvbgPWl8hAjd2IHj8cb9KMErBdqL11L/xrB0EfdByPxufx+drTPK/riN6F3Wo62nQ7786Vf633G1f9y8QFv7p24fo36ai/31HPC/+2K8wCQvQr4W0knX7xiPn2l+ngLVF7V43aP/SNi4GRH2ybYebtOF5xsvMN/hzzuxi+Wz/O+7kbCu13i9jH6Dd5OrxLuwV+ANdvobvLZ1gbRT/O2VEjJsRJRtBsYUWxF2fDmij/Ac6GbsiMPghJ0scyVedeA+/zspxQv4fhS+Dzs7zv3553W2feJ7vYw6nx6c9/5x8WP/nKnHe2C7E68kr8O5EkP+tkU6xvGu6bf433FgxOFNeIP2hY9fZ3jVp//xj8NGvOvkIuDb+KNOx7iff+Pnt8PrTsLSPUiE648/7wa8c+MQXs+/J4EZxPe6mIIXiC+l7ZqyDPgi0Udkjvm656d/iE6GXgj/MX8hEREROQb4TRXWA3c5577S2/npLX6j9W3AQ86rfu5SLG16REREpI9wXtXhb4Ebzaw7Y4Almm/jdQr5bqwLHHaDLhERETnqfoRXNTWO7o2PlhD8htd78N4nFnObX1VviYiISFJQ9ZaIiIgkhaSv3srPz3fjxo3r7WyIiIgcFcuWLSt3zhX0dj56Q9IHPePGjWPp0kjvuBMREUk8Zra9t/PQW1S9JSIiIklBQY+IiIgkBQU9IiIikhQU9IiIiEhSUNAjIiIiSUFBj4iIiCQFBT0iIiKSFBT0iIiISFJQ0CMiIiJJQUGPiIiIJAUFPSIiIpIUFPQkgQ2l1TjnejsbHawvPdgn8yUiIolJQU+C277/EJfc8RqPLt3Z21lpZ3VJFZfe8ToPvbOjt7MiIiJJQkFPgttSfgiAx5eV9HJO2iveVwPAHS9toraxuZdzI3JsqKpror6ppbezkfSaWlqpadB161ikoCfB7a6sA+CdbRXsOlDby7lps32/l5ey6gYeWLytdzMjcoz48N1v8pNn1vV2NpLa7so6LrnjNT5+79u9nRXpAQU9Ca7kQB0p5v29YOXuXstHS6ujpbWt/c6OilpG5GZy4XFDuWvhZg4cauy1vIkcC6rrm1hfWs3KXVW9nZW4a2g+sqVXTS2t7KmqY09VHYcOo4RmS1kNH7rrTbaUHeK9XZXtSt3i9RmO9HeR7BT0JLjdlXUUDurPKWMHMX95Sa81HP6f+av5xH1tT0Y7K2oZPTiLb1wyjZrGZv721vZeyZfIsWLj3mrAu/EmUgeAxcXlzPj+C2wpqzli27jloXc546cvc8ZPX+acX7zSoyrC1lbHpx5cQl1TC188fyKtDjbt9fK8tfwQM77/Au9srTisfL62sYwTb3uBrX6zBIk/BT0JbndlPSNz+zOvaCQb99awbk91r+TjtY1lLN12gKaWVgC2VxxizOAspg7PYeqwHJZsP9Ar+Uo0iXQzlPYC5251fTNlNQ29nJvInHM0tbS2+wkt4Y3kH+/soLGllbe2HF7A0Jml2w5wxoQhfPl9k9l/qJGX1u3t9jre2VbB9v21fP/907nm5FGA1wMV4M3N+2lsaeW51aWHlc9nV5fS0NzKE+/uOqz1SHQKeo5hlbWNnPWzl3ll/b6oaUr8kp4rThxJWorxr/eOfBVXaVU9p/34Jd7YXA7Avup6SirraGxpZVv5IeqbWth7sIExg7MAmDkmj5U7KzvcsB96ewdn/vQ/bN/f8annV89v4EN3vXHEP8ux5LWNZZz645d4o7i8t7MSVzc88A4/f259b2fjqLtv0VbO+tnL7Kny2uUFbrAAW8q6Lgn49pOr+MrDy49Y/iJvczWTv/Nsu5/p33uOR5ZE7qVZ09AcDEBW7DwyDz5l1Q3sP9TIxccP4yvvm8ywgf2Yv7z718GnVpSQlZHKRdOHMXZINpnpKawv9QLRQN4XH+a5F1h+/oropfKvbNjHWT97maq6psPaVrJS0HMM+9d7eyiprGP5zsqI85tbWik9WE9hXn8GZ2dwQmEuS7cd+RKVJ5eXsK+6gX+9tweAFTva8reutDrYoHrsEC/oOWlUHlV1Te2KdP+4cDPffnIVu6vqeWFN+6eyHftrufu1zSzb3lZyJLB6dxXlNY3c8OASXlhzeE+cfcXmshoWbijjrS37ezsrR41zjl+/sIEf/mstJZV1vOw/1GworWZkbibQddBTVdfEY0t38fqmoxcAV9c38cS7uzhz4hD+38VTgj+njB3ENx9fxZ9e29JhmedXl1Lf1Mqwgf1YEeU6drgCweLU4TmkphhXnTSSVzfu61Y7wobmFv793h4uOX44WRlppKYYU4blBNcdyPuGvdXsO1jfo3zu2F/LjopaikbnsbOijnd3RL5Wv7V5PyWVdby5uXv7Vr3+PAp6jmHzl3vd0PdWRT7J9lY30NLqGJnXH4Ci0XmsKqmiuRuBwuPLdvHxe9/uVrXJUyu8fAWeWlbuqiQtxUhLMTaUHmRHhRf0jPZLeorG5AFtF46H39nBz59bz/tPGsmE/GwWhT09/ealjTS1OFqdV6oknvLqRvqnpzJ9xEA+//d3WR5y0fz1Cxv42iMrjko+vvjQu1Gf7MG7+F5795uceNvznHjb8/zg6TVR0z7lH+M79vednodH2t/e2s7vXi7m2lmjGJGbyeLicpxzrN9TzfnThtIvLSXY/uXNzfu58vevc7C+/VP/c6v30NjSSsWhxqPWSeD5NXtpaG7l6xdP5ZYLJgd/HvzUaVwxYwQ/fmYdD73d/riYv6KE0YP7c92pY9i0r4bq+silF48s2cHVf1jcaenGwg37mHfn4g439/V+teC04QMBmFtUSFOL49+r9sT82V5ZX8bB+mbmzSwMTps2PIcNpdXUNDSzaV8NF00fBsDibgYjAYHr3A+uOp5+aSlRS6M2+/s+/LrYmYbmFub8/OWIgWeyUdBzjNpZUctSvx3MnihPFoHu6oV+0DNzTB51TS1s3Bt7g8F7XtvCouJydlbUxZR+3Z6DrC+tZuqwHLbvr2VnRS0rdlYybUQOEwsGsH5PdbC7eqB6a/LQHLIzUlnpBz1/eXM7JxQO5I4PF3HOlALe3ro/2KNh3Z6DzF9Rwkmj8wCv+k485TUNDB3Yj7985jRSzXjGv6g753jonR08sbyERUf4yd85x4tr9/Li2uhtJv78xjbe2VrBZSeMYOyQbB5buitiIO6cY/4K78K//1Bj0oyLsnBDGRMKsvn5NSdy1qR83ti8n10H6qhuaOa4EQMZn58dHH/ryeW7WF1ykGfDbuBPLi8J9trcUn7kGgiHmr+8hDGDszjZf4gJyEhL4XcfmckZE4bwqxc2BAObfdX1LC4uZ+5Jhcwck4dzsKqkY8+0u1/dzDcfX8XyHZW8vqks6vYfW7aLFTsrWRbWPnBd6UGGDezH4OwMAI4fOZBJQwcEH85i8dSKEvIHZHDWxCHBaVOHD6S8ppGX1+/DOfjIaaMZlJXe49K1RcVljMjN5MRRuVw0fRj/XrUnYkl2oJSvO+fywg1llNc0MnnYgB7lLZH0uaDHzC41sw1mVmxmt0aYf4OZlZnZCv/nsyHzrjezTf7P9Uc350dXoPv59BEDo5b0lBzwAoJASc9Jo/IAYi5GXrfnIBv8HiMrdnnLNDS38Pm/LYt6wZi/ooTUFOP2uccD8NqmMt7bWcVJo/KYOjyH9aXV7KioJSsjlSH+RSg1xZgxKpcVOyvZtLeatXsOcs3Jo0hNMc6alE99Uyvvbve2/4vn1pPTL40fXOWtf3eCBj2/fH49F/zvQi7434V86R+xtcsor2kgf0A/Bmamc8rYQSwq9qqE1pdWU17TiBn8/Ln1tHbRsPRw1De10tjcGrX6paquiT8s3Mx5Uwv4+QdP5KZzJ1Dd0Mx7EW527+6oZEdFLedPLQC8QP9Y9afXtvDrFzfGlHZ9aTUnjMzFzJgzKZ/K2iYeW+Y1bD1uRA4TCrKDPbgCN77QUoE9VXW8vbWCuUVeqcTmGNr/HK59B+t5Y3M5c4tGYmYd5qemGN+6fBoVhxr50+tbAXhg8TZaHcybOZIi/yEm/Nr0lze38dNn13PliSPIyUxr12bmm4+9F2zw29rqeGOzd7yHBx0bSquZ6pfyAJgZV88sZMm2AzE9NB041Mh/1u/jyhNHkpbadss8bngOQLBUc+boQZw5KT9YMtcdLX7+z5qUj5kxr6iQikONPL6sfYPmppZWdlTUkpeVzjb/oTIWgaBtzqT8buUrEfWpoMfMUoE7gcuA6cBHzGx6hKSPOOeK/J97/WUHA98HTgdOA75vZoOOUtaPKuccTy4v4dRxgzhl7CBKo5T0lISV9IwdksWgrPSYGwzOX15CWorRLy0l2C5n2bYDPLu6lK88vIIHF29tl7611fH0it2cMzmf08YPZtjAfvz1ze1UNzRTNDqPaSNyKKmsY83ug4wZnNXu4njS6DzW7jnII0t2kppiXHniSABOnzCY1BRjcXE5b2/Zzysbyvj8eZOY5l9wEjHocc7xt7d2YEBOvzSeXrmbsuque+vsr2kMBpJzJuezbs9BymsagjeKr180hVUlVTx7mD1MOlNZ51Wl7KiojfiUeverm6mqa+K/L5kGwJkT8zGDxRGeWp9aUUK/tBQ+d86E4DqPVf9YsoO7Fm6mqrbzxqcH65soqaxj2gjv+D7Lv0kFhnSYMswrMd15oI6Ne2vYXVXP6MH9eWvr/mCD5wUrduMcfPH8SaSnWkyNng/XgpW7aXUEA61IThyVxxUzRnDv61u4bcEa/rhwM1fPLGTS0BzysjIYn5/drv2fc457X9/KqeMG8dvrvJKiQJXOhtJqHlm6k9+/XIxzjnWlB6k41Eiaf60IaG5pZdPemmCAEnDBtKEAvLO167Zif1hYTFNLKx89fUy76VP9dS4u3s+4IVkMys7g7En57D3YEBxxPlZrdldRWdvE2ZO9/X3u1AJOGzeYbz+5iodDXtWzo6KW5lbHh08d7W+769Keg/VNvLSuY9CWrPraN3AaUOyc2+KcawQeBubGuOwlwIvOuQrn3AHgReDSI5TPXrV2z0GK99Uwt6iQ4bmZVNU1UdfYsZHa7so6Bmdn0D8jFfCecE4anRd8mlq2vYL/fmxlxC6lra2OBSt3c86UAk4clRsMlBYVl5OaYlwwbSi3Pb2WeXcu5tq73uTau97k6j++we6qeubNLMTMK6UJ9G6YOSaP4/ynraXbKoLteQJmjs6jqcXxl7e2c9akfApy+gEwMDOdotF5vF5czs+fW8+wgf244cxxZKankj8gI+KT2q+e39Ch7UBvO9TQzHfnr47pIrW1/BBVdU187uwJfOcKL+ZfGUPpXHlNA/n+9xZ4oltcXM6i4nImFGTz+fMmMXVYDr96YUNMDcBLq+r56sPLo7aziOTAIS9tc6sLVmOu2FnJR+55i2vvepP7Fm1lbtFIpo/0joXB2RkcP3Igr4d9L00trfzrvT1ceNwwjh+RC7S169lWfoivPbqi04aZa3ZXcevj78W9oXtjcyvfeXIVb26OvWF1fVML28oP0djSyrOrO29HsqE00P7Eu6EW5PRj2vAc9h9qZNSg/uRkpjOhIJuWVsdDb3uB0I/mzcA5L9ipbWzm0aU7KRqdx6ShAxgzOKtb49/sOlDLl/6xvNvtgBas3M2MwlwmDe28+uTrF0+hobmVB9/YxkdOG82vPnRScN5JfmlvoJRk+U6vpO/aWaNJTTHmTM5nZ0Ud2/cfYr5f0ry1/BDv7aoKlnh9+NTRrN5dFcz/Vv97nxoW9EwZlkNWRmq7ICuS3ZV1/PnN7Xxg5iimDGu/jiED+gWvU4GSqkCQevPflnHtXW9y/6L2D4bRBNoXnTnRWz49NYU/f/o0zp5cwK1PrAqW9AUC2EuPH87QnH4xtet5bnUpjc2tzC0aGVNeEl1fC3oKgdA3Y+7yp4W7xszeM7PHzGx0N5fFzG40s6VmtrSsLHodcV8V6IH1vuOGMnyg15sjUmlPSWUdI/My200rGp3Hpn01VNU18a0nVvHo0l0RL+Bvb61gjx/AnDQqj9W7D9LU0sri4nJmjs7jnk+cwk3nTqB/eiqpKUZqipGVnsoVM0Zw8fThAMGnlpzMNCbkDwheeFodjA0LeopGe4Vyjc2tzAs7Oc+alM/KnZW8u6OSr144JRjEjczrT0ll+8/tnOPeRVv49pOruOOljX1i3Jqq2iY+ft/b/PWt7fzqhQ1dpg8EpUVj8phRmEtqinVZJdnc0kpFbSP5A7yL8AmFuQzMTGPhhjLe3lLB2ZPySU0xvnHJVLaWH4rpBbTPrNrD/BW7WVwc+w0+UNIDBG+2T7y7i2U7DpCaYpw3tYBbL5vWbpmzJuWzfMeBdiPlLtpUTsWhRubNLCQ3K52BmWnBkp6nVuzmiXdLOg0g//3eHh5esjPubZhWlVTx97d3cP0D78TcQ27T3hpaHZgRvFlHs760faNbaAtgA4HQhHwvsHj83RJGDerPOZPzOWl0Ho8t28Un7nuHreWH+Px5E720BQOC7X9iMX95CU+v3M3/vVIc8zL7qut5b1cVl80Y3mXaCQUD+N6V0/nmpdP4ydUzSE1pK+0tGp3HvuqG4LVs/nKvpO/SE7z1Br6H1zaVs2DFbk4ZO4iMtBTmryhhUXE5U4YN4AMnj8I5glVdkb5P8KvUC3O7PK/ueGkjOPiviyZHnB/YJ4GgZ/TgLK4/YyxDczLZXnGI+xd3HfT8YWExd7+6hStmjAgGUQD9M1L50ydnMX3EQP7ql/QFzqkJBQOY47f36qq6ev7yEsYNyQrmMdn1taAnFk8D45xzJ+KV5vy5uytwzt3jnJvlnJtVUFAQ9wweaetLq8nLSmf4wEyG+11YI/Vi2l1ZF6zaCjhptNdg8If/WsvGvTVRL8RPLt9FdkYqFx03jKIxeTQ2t/L2lgreK6nirEn5pKWm8K3LjuMfN85u93Pnx04OBiVn+U8tJ43KIyXFGJGbycDMNADGDGkf9AzPzWT4wEwy01O4+Pj2F8/AxW5CQTYfOmVUcHphXn9Kwt4ndqC2ifqmVkbmZnLHS5v43xfa2lHUNjbzw3+tpeIovvJiX3U9H77nTdaUHOSCaUNZvqMyOO7Q2t0H+cVz6zuU0q3cWUl2RiqTh+bQPyOVqcNyghfn5pZW/veFDbznt7EKqKhtxDkoGNDWTurMifksWLmbuqaW4BPo+44byqyxg/jtS5s6bHf+8pJg42doC746uzHsqarj58+tD5YWhlbfBG62K3ZWcsqYQfzjxtnc/YlZjMhtf0yePamAphbHO9vaBqebv6KEvKx0zp3inZ9jh2QHg57QUseABxZvbdetPfBE3FWQ0V2Bkpgxg7P4/N/fjWkQuXV+t+Z5RYX+w0Rb6aRzjv99YUOw6/P6PQcZmJnGiNy2h5WzJgeCHu/GPaEgG/DGuJkTbAMykk37anhvVyV3fvRkLvHPoQkF2Wzff6hdQ3HnHHe/upm3IwwDEPhO//rm9pjf1feGHxSfPSm2a+n1Z47j8+dN7ND2p2jMoOD6giV904eRk5kOwPj8bEbmZnL3q5spqazj47PHcMHUoTy9cjdLtlVw1qR8ThqVS06/tODnWF96kLQUY+LQ7A75KBrjValHe+3Dql1VXiB5xlhGDcqKmOa4EQPb5R3gB3NP4B83zuaTZ4zzGqBHKSl1zvGzZ9fzi+c2cNVJI7njuqIOaTLSUrho+jBW7aqkqraJLWWHyB+QQW7/dM6alE/FoUbW7jnYceW+vQfreXPLfuYWFUZsa5WM+lrQUwKMDvl/lD8tyDm33zkXaOBwL3BKrMsmivWlB5k2PAczawt6Drav5nHOUXKgLtiIOaDIb8z82LJdzCjM5ZqTR/Hc6tJ2VQW7DtQyf/lurioaSf+M1OATwh8WFuNcWwlOV4YOzOQTs8cG65/NLHjhDq/eArjhrHF86YLJDOiX1m76zDF5XDR9GD+ce0K7OumRef3ZXVnfrjQn0Hj7u1dOZ27RSO55bUvwRvzUit3ct2hrj0Zj7YmdFbV86K432b6/lvtvOJUfzTvBCzKX76a11fGNx1byh4Wbuf7+d9p1OV6xs5IZo3KDT8FFY/JYuauS1lbH65vK+f3LxXzknreCgz+C110dCJb0gNeup6XVkZpizPZ7nZgZt142jX3VDe2eQuubWvju/NX89Nm2l1m2BT3R24A9ubyEPy7czFa/h1Cl36U4LcXYUlZDfVML6/YcDPa2i2TWOO+JPVAqc6ihmRfW7OXyGSPISPP295jBWeysqMU5F8xXIH1pVT23/2st94VUJQR6LL2wZu9hvWsp3PrSgwzol8aTXziT08cP5muPruTPb2zrdJkNpdVkpqfwpQsmBauhAt7dcYDfv1zM7/6zyV9/NdOGD2x3gzpjwhAuPG5YsMQjJzM9WCIwxz8Xr55ZyIXHDeP+G07lshkjgstOzB9AU4tj14G268O+6gZ++ux6PnHfO+1GEK5tbObd7ZW8/6SRYPCbFzfF9J28vqmcvKz0YJVlT00fMZCJBdn8z/zV/PL5DV5JX0gbITOvimvXgTr6p6dy8fThzJs5kvKaRuqbWpnjP4zNnjiERcVeCf76PdVMKMimX1pqh+0VjfKq1Nfu7hg0LNt+gI/d+xbDBmbyxfMnRc3z5TNGcMnxw5g+ouNnn+pXhwVeHxKqpdXxnfmruevVzXzs9DH85sNFpEdpbzNncj6tDt7cUs6W8ppgSd9p4wcDnT+UBHqWXXHiiKhpkk1fC3qWAJPNbLyZZQDXAQtCE5hZ6N67CghcpZ8HLjazQX4D5ov9acesv761vcM7WFpbHRv9CyPQVr1V1b6h68G6Zg41tnQo6RmUncE4v5Tlm5dO4+qZhe1GRQX/YmfwpQu8It3CvP7kD+jHG5v3M6BfWqc3sHA/nHeCdxH1BRpojokQ9Nx87sSIF5j01BT+9MlZwdKKgMK8/tQ1tXAgpHQh0MZn1KAsPjNnfLt2FIFxjY5Gw87ifdV86K43OXCokb999nTmTM5nZF5/Ths3mKdWlPCvVXtYs/sgHzi5kHd3HOCjf3qLg/VN1De1sDYsSCgalUd1fTNbyr22DLn90ykc1J8bHlgS7MJb7r+WYEho0DMpUNKWy0D/aRlg1rjB3oteX91MZa0XLL2yfh/VDc3srKhjx/5a9tc0sKOiln5pKazaVRX1VQKBko8yP+g64K/v+JED2VJ2iLV7DtLU4jotWs9MT+XUcYN4dWMZLa2OF9aWUtfU0u6GN3pwFrsO1LFtfy0HapuYkJ/Npn017D1Yz4KVJTjXlpeWVse2/bWcMnYQdU0tvLA2fg2315dWM3V4DjmZ6dx/w6lcNH0Y31+whrtf3RxMU9/Uwp2vFAeD7fWlB5k6LIcJBQMoGp3HkyHvwAv0unpp3T6q6prYUFodPEdCv597r5/FCYW5wWkT8rMxa2sDkpeVwb3Xz+Lsye1LWwKlQqHd1gNVPoOzM/jC39t6Yr6ztYLGllY+dMoorj9jLE8s3xXxhr19/yHufX0LzS2tOOdYXFzOWRPz21VV9URGWgoP33gG4/Kzuee1Le1K+gIC14CLjx9Gdr80zps6lJzMNNJSjNMneIH9nEle259bH3+PZTsOdKjaCggfH+zFtXv53lOr+c6Tq/jEfW8zODuDf958RrCre8R1jM7j7k/MCgbnoQL7MfB9BzS1tPLVR1bw0Ns7+MJ5E/nRvBM6/e6KRueRnZHKouJytpQdCu7TUYP6k9Mvrd1I3eEWFZczbGA/JnfR1iqZ9KmgxznXDNyCF6ysAx51zq0xs9vN7Co/2ZfNbI2ZrQS+DNzgL1sB/BAvcFoC3O5POyYdrG/iu/NX841/rmxXkrHrQB2HGluCdcnZ/dLI6ZfG3rA2PeE9t0J94ORRXHPyKOZMzmf2hCHthmXfUFrNE8t3ccOZ44KlRGZG0Wjvgjt7wuCoTySxuOT44Zw2fjCjoxQXd0cgf6E9uIJjEw3qz4zCXCbkZzN/RQm7K71uvMARfbEhwHu7KvnQXW/S3Op45KYzOGVsW9H31TML2VJ+iO89tZppw3P41QdP4p5PnsLqkoP8ceHmYJAwMzTo8S/Ob24u54U1e7nixBE8cuMZ5Gdn8ODibQDsP+QFPfkD2i7QY4dkceFxw7ju1Pa9TgD+3yVTqWlo5g8LvZv1k8u9IfbBu1C+57/Je15RIYcaW6L2RgkM/BYIuqpqm+iXlsL0kQPZUn4o2FB0ZtjYLeHmFhVSvK+Grzy8nMeXlVCY159ZId/bmMFZNLa08rzfjuZmv83Kok3lwWN3R0UtNQ3NlByoo7G5lWtnjaIwr3+PXjkQiTdA4MHguZeZnsofP3Yyl88Yzi+e3xB8QHlg8TZ++fwG/uY3NF6/pzrYnu3aWaNZX1rNwo1lfhXObiYNHUBjcyv3LdpKTUNz1Jt0qMtOGM7VMws7vSGD1/YD2gf66/3qkMe/cCYzxwziu/NXU1XbxOLicjLSUjht/GC+cN4kUs144t32heVrdx/kmj++wY/+vY7H393F5rJDlB6s7/BA0lMFOf14+MbZXHjcMG46Z2KHYOLcKQWcUDiQ688cB3j74HNnT+BDs0YFS4gvmj6MUYP68/yaUlLNuNAfNDDciNz+wZGgd1bU8oW/L+OxZbt4ZtUeThiZy6M3nxG1WisWhXl+UBLyvsO6xhZu/MtSnl65m1svm8Z/Xzqty2qn9NQUZk8YwvNr9rL/UGMw6DEzpvoDJEbS2up4o7g82A1ePGldJzm6nHPPAM+ETfteyN/fAr4VZdn7gfuPaAaPkkA1zdLtB3h5/T7ed5x34q4LGVI9YHhuZrt2AhAS9AzqGPR8+X1tjfICw7I/+MY27nhpI69uLGNAvzS+4N9UAopG5/HSun2HfXE7a1J+3C6QgYCupLIu+BRcUllHZnoKg7LSMTPmFhXym5c2Bp/Epw3Piblh57Or9jBr3OB2jQujeWFNKev2VNPc2soDi7eR2z+dv3/2dMblt29LcNmMEXzvqTVU1jbxm2uLSEkxLpg2jLlFI3lg8VYC8W2gYTfAxIIBDOiXxu9fLqauqYWrZxYyKDuDojF5wZdQBqu3QvJqZtx7/ayI+Z02fCBXzyzkwTe2cfXMQhZuKOPjs8fyzKo9LCouY9LQHFIMPnHGWB5ZupMVOw8wdXgOizaVk5+TwbThA2lsbg2ODrvfD3oqa5vIy0pnQv4AKg7t5JUN+xiRm8mwgZkR8xFw7azRHDjUyE+f9d6x9YXzJpIS8vQbKBl8asVuMtNTmFdUyM+fXc9f3tzG2j0HmTMpn0XF5WworeagX8U2sWAAc4tGcvdrWyirbohpP3ZmT1U9B+ubg0EPQFpqCj+46gQWbijjVy9s4CfzZvDHhV4j4PnLS/jQrFHsP9QYDGQ+eMoo7np1M794bgPNFzkO1Dbxyw+exA//vZZ7X/dGyw3vaRTJDWeNjynPg7MzyMtKbzdWz4bSaoYPzKQwrz8/mncCl//udf746mZe31TOrLGDyExPJTM9lZPHDGrXWHzlzko+ft/bDOiXxrThOfzmxU186qxxAHEd/yW3f3rU4zYvK4N/fensdtNCr2fgPQwt+uYFMW2raLT33r/fvLiRFDNe/vp5wSYDhysQlARKYuoaW7j+gXdYsq2Cn1w9o0MX+M6cNSmf//ivIwlUb4FXmvTU8t045zoENmv3HORASDd48fSpkh5pEyix6J+eyi+e2xCsXthQWo0Z7bpPDs/NpPRg++qt5TsOkGIwdnDHBnzhrp01mrSUFO54aRPv7arim5dOIy+r/RPk+dOGMmxgPy48LvJTU28IBHQlB9qX9BTm9Q9eAObN9KrW/vzmdk4ek8e5Uws6NOyMZGdFLZ//+7tdttdwzvG7/2zixr8u4zcvbeT3LxczZnAWj33+jA4BD3gX9GtOGcWFxw3lvKltRfdfv2gqLa2Oe17bzLCB/dpdeAM9TfZVN1CY159T/EaTE/IHsKOilsbmVsprGshISyGnX+zPMV+7aAo4+NQDS2hsaeXqmYXMmez1CFm+4wBThuUwfcRABmamsWJnJXuq6vjMn5dw2wLvtRGby2po9o/L8hov6KqsaySvf0bwaXRxcXlwUMyu3HTuRH76gRkU5vXnQ7NGt5sXeE/buj0HmVGYS0ZaCmdOymflripSU4yvXzwF8M6PzSE9XObNLKSl1cXlRbvB7uRh7TcKcvrxmTnj+fd7e/ivR1dQ3dDMJ2aPZdO+Gp70S0oCVR0ZaSl8/eIprNtzkO/OX82grHTOmVLA3KJCav2G5bEEPd0xIT+7XenmupAqtONGDGReUSEPLN7K+tLqYBsh8NqShHb//vEz6xjQL41/3nwGt111PKUH6/nNSxsZMzirQ8eEY8VJo/PYtr+WJ1eUcMNZ4+IW8ARMG+ENyOqc44nlu3hnawW/vvakbgU80L4dZeDcAm9U6OqG5ohDdwQacwc6lIhHQU8fFTiIv3HJVDbsrQ62R1lfepCxg7PIDrm5DRuYSWlISU9rq+OpFbuZM7mA3Kx0ujJ5WA5rb7+ELT+5nE0/uoyPzx7bIc3xI3N5+9sXRmyA3FsGZaWTmZ7SrnrL66bfVro1dkh2sGpl3sxCJhZ0bNgZSWBU187qy51z/OSZdfz6xY18YGYhG390GVt+cjn//vKcDj2UQv30AzO49/pT2z2ZjRmSxUdPG0OrI2L7l0AV19yikcESkMB4LTsqaimraSA/O6NbxdijBmXx8dljKT1Yz4SCbE4oHBgcAXhxcTlFo71edyeNzmP5jkrueHETDc2tLNt+gNrG5uB3Y9ZWvXWgtoncrPRgtUqra8t7LD5y2hgW33oB48MCxhG5mW0Nu/3vZ86ktjYcRaPzGOC3b9hSfoi8rHQGZ2cwZVgOx40YGHydRVfeKC5v16h878H64GsNAqWs4eO1ANx4zgQGZaXz8vp9XF1UyNcumkJaigWrD0OrrN5/4kimjxhI6cF6rjjRa6wdGKZhzOCsDg35D1dot/WmllaK91W3C6y+dtEUWv0ixtASm7Mm5Qe7f5dU1vHO1go+etoYRg3KYvaEIZw3tYD6pta4ldz2hsCxlNMvjS+cG73Bck9NHT6Q6vpmdlfV89RyrypzXicDOEYzaegAhg3sR1qKtbsGBwZdDATk2/cfCp6XizZ53fiHdlHKmmwU9PRRJZV1ZKSmcP2Z45hRmMuvX9xIQ3NLsCFlqBG5mZRVNwRLL5bt8IZXv3pm7INRmRkpKdauSqGvMzN/rJ72JT2jwqr0PnraGHIy07hixggmRmjYGUmgWH/dnsj15QDv7ariT69v5WOnj+FXHzqJjLQUUlKsx/Xnt1wwmUFZ6R0ao4LXlqFfWgrXhHTZb2uvUUN5TWO7qq3YtzmJIdkZfPS0McEBJYF2wdfM0Xls3FvNP5ft5ITCgV738q0VrN9TTUZqCpMKBrRr0zMoK53Rg/qTnto+SDkcaakpwerMQNXfuVOG0j89lY+ePqatKmFPNVvKapgQEjTNKxrJyp2VHToFhNtSVsNH732bO0J6LX3vqdVcd8+b7KyoZUNpNYV5/cnt3/FBIicznW9cMo0h2Rn810VTGJSdwXlTC6iqa2JoTr92bW9SUoxvX34cGakpXOuXaE0oGMCZE4dwut8jJ56mDc+hrLqBnRW1bC0/RFOLCw4UCl4j8U/PGU9hXn+OH9nWWDq0+3egsXPoiMvfvHQamelt4+gci04alUdu/3S+euGUmB4QuysQlLy8bi/vbKtgXpTXdHTFzLjshBEUjc5r16ZyyvD2jaVv+usy3v/7RcxfXsI72yqYE+MwAslEQU8ftbuynhF53tPtNy+dRkllHfe+vpVt5Yc6NHQcNjCTVtdWxfDk8pJgl85EV5jXP1jSU9/UQnlNIyPDSlk+eMoolv3PRQwZ0C9YH95ZD66WVsfizd7I0yWVdcEn/6rapmDVCXjfc0ZaCt+8bFpcgsWCnH68/e0L+ViEou/ZE4aw+geXMLGgrT6/rWfOIcqrG9p1V4/V4OwM3vzW+/jMnPHBPAQHXPNLaE4anUerg6yMNK+nSmoKi4vLWV9azaShAxiem0lZWPVWWmoKYwZnkWIwI6TX0eEItOs5yW9UPzw3k/duuzg4Jk2g/YTXw6Xte7qqaCRmdHhfXE1Dc7sG2oHSoKff201Lq6OytpFX1pfR1OL49YsbWb+nul17nnAfPX0Mb337fcEn8cAbucOrw8CrOlr1g4s5MaTq7y+fPo1ffPDEmL+PWAWCkqdWlLBuT8c2gQC3XjqNhd84r10votDu308t383JY/LaVWMdN2Ig733/kg49rI4l2f3SWPKdC/n0nNjaSHVXICj53cteO6/OXtPRle9dOZ1Hbzqj3bSBmekU5vX3X/Tsvew5u18aX31kBY3NrcyZPCTK2pKXgp4+quRAbfDmPWdyPnMm5XPHSxtpdXS48Aa6re+p8nqtPLNqDxdNH9auCixRFYaMyhwIfsLHJjKzYC+QQdkZDApr2Blu7e6DVNY2cYU/3slG/ynqp8+u44rfvc7eg/U0+z1v3jdtaLvu4IcrIy0l6pNgeK+5gZnp5A/ox+Z9New/1NCu59bhbPOi6cPIH9CPyUO942zmmEH0S0vh8+dN9HpVjRvE65vKvfGiRuSQP6Bfh4bM4AVLRaPz4nYcHj9yIGOHZLXrkZge9gLIg/XN7KtuaNfuYURuf2aPH8L8kK7iew/W84E/LObSO15ja/khnHM8taKEnMw0yqobeGNzOc+sKqWxpZXzphYwf0UJm/Z1LGUNF5qfC48bxpDsjA5vHQ8IHzsmLTX6vj8cowZlcdq4wTy5vIT1pdXeYH0F7bswm1nEXpln+69+2LC3mqtndrxhR+qqfaw5kp8hEJSUVTcwa+ygw2oeEK0k/rgRXg+u+ct3k5piPH3LHM6enE9u/3ROH6+gJ9yxf8QmqN2V9e16Xn3z0mk0tXgX7PAnx0Dju70H63l1YxmVtU0RL1CJqDCvP+U1DdQ3tbDbD34i9VgLNaFgQKfd1gMNAAOlH+v8hoivbiyjvqmVO17axKLicsprGg/ryS0eJhZks7mshv01jT0q6Ynky++bzH++dm7wqX9wdgaLb70g2KMv8E61vQcbmDY8h/wBGZTXNFDX2EJDc2uwmuAnV8/gr585PS55Avj6xVN5+ktzogYGoedFaA8X8Bq0b9tf672yYFM5H7zrDUoO1JGRlsKvXtjA8p2VbN9fy39fOo2czDTmL9/N/BUlTCjI5rcfnklOvzTvgSNCqU00mempvPz18zod3O5omTtzJJvLDvH0Sq9dSaw3+kB1Z1qKccWJendTTxznNxqfe4SuyVP9Hqnzl5dwzuR8Rg/O4i+fPo3Xv3l+Ujz4dpeCnj6oqaWVvdX17UosZozK5f0njSS3f3qHgf0CQc/ynZX89Nl15A/IaNcLI5EFnpw27a2hpNIbNj/S2EShJuRnd9ptfVFxGdOG53DiqFxyMtNYv8drHLunqp4RuZk8unQnd75SzMDMNM6f1rtF+xMKBrB690GaW127gQkPR3pqSof2DfkD+gWDjdCeJNOGD2TIgH7UN7UGv/9Bfs+/zPTUuF50M9JSOi1VC21gPLGgfUPoS08YQWZ6Cv/1yEo+ft/bVNc389DnZvPZsyfw7/f28PNn15ORlsLcopFcdsJwnlm1h3e2VjCvyHv31y0XeIFLd6vqcrPSD2tcq3i5YsYI0lONXQfqutU7bEJ+NmMGZ3H+tKFdjgkkkZ04Ko9+aSnBkuN4mzZ8IC2tjtKD9cEqVTOLawl0IlEY2AeVVtXjHBSGvSz0F9ecSFl1Q4fROwdnZZCRmsLdr25hQL807rt+Vp+40B4N50wpIC3F+Nd7u+mXnooZXXY7nVAwgH8u20V1fVPwvT4B9U0tLNl2gE/MHuu/NsMrOg40bP6/j57MJ+97myXbDvCR00ZHHN7+aJpYkE1js9eAvafVW911/MhccvunU1XXxLQROeyr9qq2Au1j8iI09D0acvt7VQl7quo6dKHO7Z/Ov750drAKdNrwHIYOzGRCQTZ/e2s7b2+t4IoZIxiYmc68okIeXeq9UyvQ0+azcyZw/tShHXqVHSvysjI4b+pQXly7N6bBDwPMjEdvOiP4Pj3pvhvPmcC8oq4HkuypQElSVkYqF0UZiFHaJMed8RjTNppy+wt3/4zUiONhpKQYhYP6Mzg7g398bnZwOPZkMDg7g3OnFLBg5W52VdQyLCezy4Av2IMrQrueN7fs9xsAtr3kcUNpNa9tLGf04P6cMnYQnz17AkCPup7GW2jblYI4lfR0JTXFewfS0Jx+FAzoFwy2AkHPkegFE6vjRw5kfH7kdy1NGjqAc6YUcM6UgmA33pzM9GD1U+Ap+fQJQxiRm8kpYwcFz7eUFGNyhK7qx5IP+J/v+G6+I2t4bmbEHmsSm8z0yNfteBk3JJusjFQuPX44WRkqx+iKvqE+KDDY3si82MdX+OPHT2ZgZnqHRrzJYO7MQv6zfh8vrtsbcQyVcIGePev2HGTi0AFkZ6QGq26eXrGbgZlpnOm/oHPq8ByqG5p5deM+Puh3F7/lgkmcPmFwnwguQ9uu9KTLek/d9v7jOVDbiJkF2xK1lfT0XjXID+ed0O0XjN5w5jimDc8J7vPUFOPvnz2dzPTEKt249ITh/ONzs5k9If7d4qX3pKWm8M+bz+iyWl88Cnr6oGi9kDrTnSLrRHPRccPIzkilur45pu9szOAs0lONW59Yxa1PrOLC44byp0/Ooq6phefWlHLVSSODJQWBouOmFhds1JmemhJ80WNvG+WPh9PU4uLWkDkWBTn9gq91CPwu9huH5/ViSU9Xr7uIJDXFOgywN6Eg8V7QaGacMbH3A3WJv9DxlaRzCnr6oN1VdeQPyEi4J80jpX9GKpecMJwn3i2JqXQsIy2Fuz9xCpv3HWJzWQ0PL9nJy+v3UdPQTG1jS7seWYGSo9A3WvclaakpjB2SzdbyQ73WlibQVmHzPq+6cFCWGryKSN+koKcPcM7xm5c28fL6vfzjc7PZdaBORZXdNK+okCfeLWFUjN/bBdOGccE0r6fc21sr+MVzGxiRl8mI3Mx2o+LmZKYzerA3Cm9f7b0ysSCbg3VNvTaadnpqCnlZ6VTWNpGRlkJmupoKikjfpKCnl7W2Or63YDV/e2sHAH96bQu7K+tiapsibeZMyufHV5/AlTO6N5ZIeqr3AshbHlrOhr3V3HTuhA7Bw88+cCJZfbj3yn9dNIU9VfW9mof8Af28gQn7px+RAfZEROJBj2QxaGl1fObBJby+qeyw1vPerko+fPebFO9re5/Tz59fz9/e2sFN507gihkjuHfRVnaqpKfbUlKMj50+tkc9hy4/YURw/JVIPbLOmpTPTP/N5n3RtOEDOX/q0F7NQ6AHV2+25xER6YpKemKwr7qe/6zfR2Z6asSXQcbirS37+eyfl1LT0MwT75bw35dOwznHE++WcPH0YXzrsuPYUlbDc2tKaWl1SdkLq7ekpBi/+OCJvLqxjOO6MeKutAk0os5Tex4R6cMU9MQg0IV88eZyWltdt9tOrNhZyfX3v8PowVmkpVhwoLuNe2soq27gwuO8AaUmFAzgw6eO5qG3d3T5KgWJr+NGDFTAcxiCQY/GcxGRPkzVWzEIDBZYWdvEmt0Hu738A4u3kpmeyqM3ncElxw/nvZIqqmqbgtVlZ4UM6/+1i6Zw3amjma0XxckxRNVbInIsUNATg8CLLKHtZZSxOtTQzAtr9nLFiSMYnO29E8s5eHNLOYuLy5mQn92u/U7+gH787JoTe3VUW5HuUvWWiBwLFPTEoKSyltz+6UwbnsOi4u41Zn5x7V7qmlqCDWSLRueRnZHKy+v38fbWig6Dookci9qCHgXrItJ3KeiJwe7Kegrz+jNnUj5Lth2gvqkl5mWfXF5CYV5/Zo31ev+kp6Ywe8IQnlxeQm1ji4IeSQiBV2D05isoRES6oqAnBiUH6hiZ15+zJufT2NzKkm0VMS1XXtPAouJyrioa2a7x85zJ+TS1OFIMDQsvCWHS0AGcNn4ws8b13a79IiIKemKwu7KOUYP6c/r4waSnGos2xdau518rd9PS6rh6ZvuxX+b4pTsnjsrT24slIQzol8ajN52hQTVFpE9T0NOFg/VNVDc0MzIvk6yMNM6YmM/j75Z0+SbnxuZW7l+8jRmFuR1uBIGn4mv8t3aLiIjIkaegpwuBMXoCgwV+9cLJlNc0cP+irR3SvraxjMraRgD+8c4OdlTU8rWLp3RIZ2Y8etMZfGL22COYcxEREQmloKcLu/0xegLdyk8eM4iLpw/j7te2UHGoMZhufelBPnn/O1zzxzco3lfD71/exOnjB3PelJ6N4CwiIiLxpaCnC+FBD8B/XzqV2sZm7nylODgt0M6ntKqey3/7OuU1jXzzsml6+aKIiEgfoaCnC7sq68hITQmOQwIwaWgOHzh5FH97azvV9U2AN2jhxIJsHr7xDAZkpnHliSM4uQ+/pFJERCTZKOjpwu7KekbkZXZ439ZHThtDQ3Mrz60upaG5hbe3VDBnUj4zRuXyxq0XcMeHi3onwyIiIhKRXjjahd2Vde2qtgJOHpPHmMFZPLViN6MHZ1HX1DbQYGZ66tHOpoiIiHRBJT1dCAxMGM7MmFc0kjc2l/PEu7tITTFma6BBERGRPktBTyeaWlrZW10fsaQHYO7MQlodPLp0FyeNymVgpgYaFBER6av6XNBjZpea2QYzKzazWztJd42ZOTOb5f8/zszqzGyF/3PX4ealtKoe54ga9EwsGMCMwlygbZRlERER6Zv6VJseM0sF7gQuAnYBS8xsgXNubVi6HOArwNthq9jsnCuKV352VNQCRKzeCpg3s5BVJVXMmazxeERERPqyPhX0AKcBxc65LQBm9jAwF1gblu6HwM+BbxzJzLy9ZT8pBieOzo2a5hOzxzJmcBan6kWLIiIifVpfq94qBHaG/L/LnxZkZicDo51z/46w/HgzW25mr5rZ2YebmdeLyzlpdF6nbXUy0lK4aPowDUIoIiLSx/W1oKdTZpYC/Br4eoTZe4AxzrmZwNeAh8xsYJT13GhmS81saVlZWcRtHaxvYuXOSs5WWx0REZGE0NeCnhJgdMj/o/xpATnACcBCM9sGzAYWmNks51yDc24/gHNuGbAZ6Pi2T2/+Pc65Wc65WQUFkdvivLl5P62O4Ng7IiIicmzra0HPEmCymY03swzgOmBBYKZzrso5l++cG+ecGwe8BVzlnFtqZgV+Q2jMbAIwGdjS04wsLi4nKyOVmXqVhIiISELoUw2ZnXPNZnYL8DyQCtzvnFtjZrcDS51zCzpZ/BzgdjNrAlqBm51zFT3Ny6Lick4fP5iMtL4WF4qIiEhP9KmgB8A59wzwTNi070VJe17I348Dj8cjD7sr69hSdoiPnT42HqsTERGRPkDFGBEsKi4HNOCgiIhIIlHQE8Hqkipy+qUxZdiA3s6KiIiIxImCngi2lB1iQkG2xt4RERFJIAp6IthSVsOEApXyiIiIJBIFPWFqG5vZXVXPhPzs3s6KiIiIxJGCnjBbyw8BqKRHREQkwSjoCbOlLBD0qKRHREQkkSjoCbO5rAYzGK/qLRERkYSioCfMlrJDjMztT2Z6am9nRUREROJIQU+YLeU1TByq9jwiIiKJRkFPCOccW8sOqeeWiIhIAlLQE2LvwQYONbYwUY2YRUREEo6CnhBbymoAdVcXERFJRAp6QmwuV3d1ERGRRKWgJ8SWshqyMlIZPjCzt7MiIiIicaagJ8T2/bWMHaIXjYqIiCQiBT0hahubyclM6+1siIiIyBGgoCdEU4sjI1VfiYiISCLSHT5EU0sr6amq2hIREUlECnpCNDa3kq6SHhERkYSkO3yIppZW0tP0lYiIiCQi3eFDqE2PiIhI4tIdPkSz2vSIiIgkLAU9IRpbnNr0iIiIJCjd4UN4vbf0lYiIiCQi3eFDNLW0kqGGzCIiIglJd/gQGqdHREQkcSno8TnnaFKbHhERkYSlO7yvqcUBKOgRERFJULrD+5paWgE0To+IiEiC0h3eFwh60tSmR0REJCEp6PE1+kGPqrdEREQSk+7wvkCbHlVviYiIJKY+d4c3s0vNbIOZFZvZrZ2ku8bMnJnNCpn2LX+5DWZ2SXe229Tsl/SkqXpLREQkEaX1dgZCmVkqcCdwEbALWGJmC5xza8PS5QBfAd4OmTYduA44HhgJvGRmU5xzLbFsu0nVWyIiIgmtr93hTwOKnXNbnHONwMPA3Ajpfgj8HKgPmTYXeNg51+Cc2woU++uLidr0iIiIJLa+docvBHaG/L/LnxZkZicDo51z/+7usp1Rmx4REZHEdkzd4c0sBfg18PXDXM+NZrbUzJaWlZUBqt4SERFJdH3tDl8CjA75f5Q/LSAHOAFYaGbbgNnAAr8xc1fLBjnn7nHOzXLOzSooKABCGjJrnB4REZGE1NeCniXAZDMbb2YZeA2TFwRmOueqnHP5zrlxzrlxwFvAVc65pX6668ysn5mNByYD78S64WCbHr1lXUREJCH1qd5bzrlmM7sFeB5IBe53zq0xs9uBpc65BZ0su8bMHgXWAs3AF2PtuQVq0yMiIpLo+lTQA+CcewZ4Jmza96KkPS/s/x8DP+7JdtWmR0REJLHpDu9rC3rUpkdERCQRKejxNTarpEdERCSR6Q7vC7bpUUNmERGRhKQ7vK+5VSU9IiIiiUx3eF+jxukRERFJaAp6fIHqLZX0iIiIJCbd4X3qsi4iIpLYdIf3NbW0kmKQmqLqLRERkUSkoMfX2NKqUh4REZEEpru8r6nZ6RUUIiIiCUx3eV9TS6teNioiIpLAdJf3NbW0qru6iIhIAlPQ41ObHhERkcQWl7u8mT1kZmfHY129palFbXpEREQSWbzu8rOBhWa2xsy+bGZ5cVrvUdPUrJIeERGRRBaXu7xzbgJwObAB+BVQYmYPmNnseKz/aPAaMqtNj4iISKKKW9GGc+5559wHgDHAz4DzgcVmttzMbjazAfHa1pGgNj0iIiKJLe53eedcqXPuh8CZwOvAScAfgN1m9kszy473NuOhSUGPiIhIQov7Xd7MLjCzR4GtwAzgN3gB0O+Bm4G/xHub8aCGzCIiIoktLR4rMbMhwKeAG4GJwLt4Ac4/nHP1frK3zGwVcF88thlvTS2tDMyMy9chIiIifVC87vIlQCvwCPAx59ySKOnWA/vitM24alTvLRERkYQWr6Dn28ADzrkDnSVyzq0Axsdpm3Gl11CIiIgktrgEPc65X8djPb1JbXpEREQSW7xGZP6Nmf01yry/mtkv47GdI0nv3hIREUls8SrauAp4Icq854F5cdrOEaMu6yIiIoktXnf5QmBHlHm7/Pl9WlOLU9AjIiKSwOJ1lz8ATIoybxJQE6ftHDFNLa1kqCGziIhIworXXf4l4H/MbFjoRP//bwMvxmk7R0xTSytpKWrTIyIikqji1WX9u8ASYJOZ/Yu2Kq0rgXrgf+K0nSPCOafqLRERkQQXry7r28zsVOB24CJgCFAOPAl83zm3PR7bOVKaWhyAqrdEREQSWNzeu+Cc2wZ8Ml7rO5qaWloB1GVdREQkgalog9CgR1+HiIhIoopbSY+ZDQU+AkwFMsNmO+fcZ+K1rXhrVNAjIiKS8OL1lvWpwJv++rLx2vMMBlLxurNXdWNdlwK/9Ze91zn3s7D5NwNfBFrwusLf6Jxba2bjgHXABj/pW865m2PZZrBNj4IeERGRhBWvu/wv8XpvDQMMuAzoD3wWqAWujmUlZpYK3OkvPx34iJlND0v2kHNuhnOuCPgFEPrer83OuSL/J6aAB6Cp2S/pSVObHhERkUQVr6DnVOAPQENgvc65Zufc/cD/AXfEuJ7TgGLn3BbnXCPwMDA3NIFz7mDIv9mAO5yMg9r0iIiIJIN43eUHABXOuVa8qqz8kHlL8IKiWBQCO0P+j/gKCzP7opltxivp+XLIrPFmttzMXjWzs6NtxMxuNLOlZra0rKxMbXpERESSQLzu8tuA4f7fG4APhcy7EqiM03YAcM7d6ZybCHyTtoEP9wBjnHMzga8BD5nZwCjL3+Ocm+Wcm1VQUKA2PSIiIkkgXnf5F/EGJQSvjc2nzGyDma0BvgLcH+N6SoDRIf+P8qdF8zD+G9ydcw3Ouf3+38uAzcCUWDaq6i0REZHEF68u698C+gE45x41szrgw0AWXk+sP8W4niXAZDMbjxfsXAd8NDSBmU12zm3y/70C2ORPL8CrYmsxswnAZGBLLBsNNmTW4IQiIiIJ67CDHr/H1TRgd2Cac+5p4Onurss512xmtwDP43VZv985t8bMbgeWOucWALeY2YVAE153+Ov9xc8BbjezJqAVuNk5VxHLdoNtevQaChERkYQVj5IeByzFK3V54bBX5twzwDNh074X8vdXoiz3OPB4T7apNj0iIiKJ77Dv8n6PrZ143cePSWrTIyIikvjidZe/G/iqmWXEaX1HlV44KiIikvji1ZA5B5gIbDGz5/C6j4cOGuicc9+P07birrFZJT0iIiKJLl5Bz7dD/v50hPkO6LNBT7BNjxoyi4iIJKy4BD3OuWM6WghUb6WlqHpLREQkUR3TwUq8NKnLuoiISMLTXR51WRcREUkGcaneMrNWunjbuXMuNR7bOhLUZV1ERCTxxash8+10DHqGABfjvZ7iwTht54hoamklxSBVbXpEREQSVrwaMt8Wabr/ioqngap4bOdIaWxpVSmPiIhIgjuid3rnXAvwB+CrR3I7h6up2ak9j4iISII7Gnf6fsDgo7CdHmtqaVXPLRERkQQXr4bMYyJMzgBOAH6G90LSPquppVWvoBAREUlw8WrIvI3IvbcM2Ax8MU7bOSLUpkdERCTxxSvo+TQdg556YDuwxG/b02c1tahNj4iISKKLV++tB+Oxnt7S1KySHhERkUQXlzu9mU0xs3OjzDvHzCbHYztHiteQWW16REREElm8ijfuAN4fZd6VwG/itJ0jQm16REREEl+87vSzgNeizHsNODVO2zkimhT0iIiIJLx43elz8BouR9IE5MZpO0eEGjKLiIgkvnjd6bcA74sy7wK8Lu19lsbpERERSXzxCnr+AvyXmX3RzPoBmFk/M/si3iso/hyn7RwRjeq9JSIikvDiNU7Pr/Da7fwe+K2ZVeC9eiIFeBz4eZy2c0ToNRQiIiKJL17j9LQAHzSzC4CLgCFAOfCCc25hPLZxJDW1ONJTVL0lIiKSyOJV0gOAc+5l4OV4rvNoUO8tERGRxBevwQmvNLNbosz7opldHo/tHCmq3hIREUl88brTfxfIjjKvvz+/z2psblWXdRERkQQXrzv9NODdKPNWAMfFaTtHRHOrI01tekRERBJavIKeFGBAlHk5QHqctnNEqHpLREQk8cXrTr8S+FiUeR8D3ovTdo4IlfSIiIgkvnj13vpf4HEz+yfwJ2AXUAjcCFwNfChO2zkinIO0FJX0iIiIJLJ4jdPzpJl9Bfgx8AF/sgE1wJedc0/EYztHgnPe7zS9hkJERCShxa14wzn3e7zSnSuATwCXAiOB1WZ2f7y2E28OL+pR9ZaIiEhii2udjnOu2jn3HPAOMAdYhTdY4bWxrsPMLjWzDWZWbGa3Rph/s5mtMrMVZrbIzKaHzPuWv9wGM7sktjx7v9PUZV1ERCShxe1Ob2a5ZnajmS0GNgDfAQ4AX8Ar8YllHanAncBlwHTgI6FBje8h59wM51wR8Avg1/6y04HrgOPxSpn+4K+vU37Mo5IeERGRBHdYQY+ZpZjZ5Wb2CLAHuAsYixe4AHzVOXe3c+5gjKs8DSh2zm1xzjUCDwNzQxOErSubtrhlLvCwc67BObcVKPbX1zm16REREUkKPW7IbGb/C3wUGArUA08CfwZeAgYCEV9L0YVCYGfI/7uA0yNs+4vA14AM4IKQZd8KW7YwSt5vxOtZRuGYsaShkh4REZFEdzglPf+FF/A8A4xxzn3MOfeCc66VttKXI8I5d6dzbiLwTeB/erD8Pc65Wc65WYMHDQbUZV1ERCTRHc6d/j6gGq+31gYz+z8z67o6qXMlwOiQ/0f506J5GJjXw2WBkDY9qt4SERFJaD0OepxznwOG4424vBS4CXjTzNbhlcD0pLRnCTDZzMabWQZew+QFoQnMbHLIv1cAm/y/FwDXmVk/MxsPTMbrRdbF5/B+q6RHREQksR3Wnd45V++c+4dz7lJgDPAtoAW4FW9wwp+Z2cfNLDPG9TXjtQV6HlgHPOqcW2Nmt5vZVX6yW8xsjZmtwGvXc72/7BrgUWAt8BzwRedcS5fbDIzTo5IeERGRhGbOxb/5jZnNwgtGrgOGAFXOuUFx31AcHH/iTHfo8h9x3/WzeN9xw3o7OyIiIkeUmS1zzs3q7Xz0hiNSp+OcW+qc+xLe+DzXAAuPxHbioa1Nj6q3REREElm8XjgakXOuCa8r+5NHcjuHI1DSpS7rIiIiiS3pizc0IrOIiEhyUNCjEZlFRESSQtIHPQTfsq6vQkREJJEl/Z0+UNKTquotERGRhKagx/+drt5bIiIiCS3p7/Qq6REREUkOCnr8sp50NWQWERFJaEkf9BDsvaWvQkREJJEl/Z1e4/SIiIgkBwU9/m8FPSIiIolNQY/TOD0iIiLJIOnv9G0vHFVJj4iISCJT0KMu6yIiIkkh6YOeQFGPBicUERFJbEl/pw+M06OCHhERkcSmoAdvYEIzRT0iIiKJTEGPU88tERGRZJD0d3uH0xg9IiIiSSDpgx6cuquLiIgkg6QPehyQquotERGRhJf0d3vn9IZ1ERGRZKCgB6eBCUVERJKAgh6ngQlFRESSge726BUUIiIiySDpgx5vnB4FPSIiIolOQQ9O1VsiIiJJIOnv9s6pektERCQZJH3QA+qyLiIikgySPuhRSY+IiEhyUNCjNj0iIiJJoc/d7c3sUjPbYGbFZnZrhPlfM7O1Zvaemf3HzMaGzGsxsxX+z4JYtqeSHhERkeSQ1tsZCGVmqcCdwEXALmCJmS1wzq0NSbYcmOWcqzWzzwO/AD7sz6tzzhV1Z5sOSNO7t0RERBJeX7vbnwYUO+e2OOcagYeBuaEJnHOvOOdq/X/fAkYdzgadcxqnR0REJAn0taCnENgZ8v8uf1o0nwGeDfk/08yWmtlbZjYv1o2mqfeWiIhIwutT1VvdYWYfB2YB54ZMHuucKzGzCcDLZrbKObc5wrI3AjcC9B8+UQ2ZRUREkkBfu9uXAKND/h/lT2vHzC4EvgNc5ZxrCEx3zpX4v7cAC4GZkTbinLvHOTfLOTcrJTVVDZlFRESSQF8LepYAk81svJllANcB7XphmdlM4G68gGdfyPRBZtbP/zsfOAsIbQAdkXNOgxOKiIgkgT5VveWcazazW4DngVTgfufcGjO7HVjqnFsA/BIYAPzTzAB2OOeuAo4D7jazVrxg7mdhvb4ibxN1WRcREUkGfSroAXDOPQM8EzbteyF/XxhluTeAGd3foLqsi4iIJIOkv9t74/SopEdERCTRKehxjjT13hIREUl4SX+3V0mPiIhIckj6oAc0OKGIiEgyUNADGpxQREQkCehuj7qsi4iIJAMFPahNj4iISDJQ0IOCHhERkWSgoAfUZV1ERCQJ6G6PSnpERESSgYIeVNIjIiKSDHS3RyU9IiIiyUBBDxqcUEREJBko6EFvWRcREUkGutuj6i0REZFkoKAHVW+JiIgkAwU9qHpLREQkGehuj0p6REREkoGCHtSmR0REJBko6EGDE4qIiCQD3e1RSY+IiEgyUNCD2vSIiIgkAwU9qPeWiIhIMtDdHlVviYiIJAMFPah6S0REJBko6EHVWyIiIslAd3tU0iMiIpIMFPSgNj0iIiLJQEEPGpxQREQkGehuj0p6REREkoGCHhT0iIiIJAMFPUCqgh4REZGEl/RBjwFmCnpEREQSXZ8LeszsUjPbYGbFZnZrhPlfM7O1Zvaemf3HzMaGzLvezDb5P9fHtsE4Zl5ERET6rD4V9JhZKnAncBkwHfiImU0PS7YcmOWcOxF4DPiFv+xg4PvA6cBpwPfNbFCX21TUIyIikhT6VNCDF6wUO+e2OOcagYeBuaEJnHOvOOdq/X/fAkb5f18CvOicq3DOHQBeBC7taoOq2RIREUkOfS3oKQR2hvy/y58WzWeAZ3u4LKDaLRERkWSR1tsZ6Ckz+zgwCzi3B8veCNwIkDl8YpxzJiIiIn1RXyvpKQFGh/w/yp/WjpldCHwHuMo519CdZQGcc/c452Y552alpqbGJeMiIiLSt/W1oGcJMNnMxptZBnAdsCA0gZnNBO7GC3j2hcx6HrjYzAb5DZgv9qd1StVbIiIiyaFPVW8555rN7Ba8YCUVuN85t8bMbgeWOucWAL8EBgD/9MfX2eGcu8o5V2FmP8QLnABud85VdLVNNWQWERFJDuac6+089Krc0dNc1c71vZ0NERGRo8LMljnnZvV2PnpDX6veOupU0iMiIpIckj7oERERkeSQ9EGPSnpERESSg4Ie9d8SERFJCgp6FPOIiIgkBQU9vZ0BEREROSoU9CjqERERSQpJH/SorEdERCQ5JH3Qo5IeERGR5KCgp7czICIiIkeFgh4V9YiIiCQFBT29nQERERE5KpI+6FHUIyIikhySPuhRzCMiIpIcFPSoTY+IiEhSUNDT2xkQERGRoyLpgx5FPSIiIskh6YMexTwiIiLJQUGP2vSIiIgkBQU9vZ0BEREROSoU9CjqERERSQpJH/SIiIhIckj6oEdtekRERJKDgp7ezoCIiIgcFQp6FPWIiIgkBQU9vZ0BEREROSoU9KioR0REJCko6OntDIiIiMhRkfRBT1qqwh4REZFkkPRBT1ZGWm9nQURERI6CpA96REREJDko6BEREZGkoKBHREREkkKfC3rM7FIz22BmxWZ2a4T555jZu2bWbGYfDJvXYmYr/J8FRy/XIiIi0tf1qVa8ZpYK3AlcBOwClpjZAufc2pBkO4AbgP8XYRV1zrmiI51PEREROfb0qaAHOA0ods5tATCzh4G5QDDocc5t8+e19kYGRURE5NjU16q3CoGdIf/v8qfFKtPMlprZW2Y2L1oiM7vRT7e0rKysh1kVERGRY0lfC3oO11jn3Czgo8AdZjYxUiLn3D3OuVnOuVkFBQVHN4ciIiLSK/pa0FMCjA75f5Q/LSbOuRL/9xZgITAznpkTERGRY1dfC3qWAJPNbLyZZQDXATH1wjKzQWbWz/87HziLkLZAIiIiktz6VNDjnGsGbgGeB9YBjzrn1pjZ7WZ2FYCZnWpmu4APAXeb2Rp/8eOApWa2EngF+FlYry8RERFJYuac6+089KpZs2a5pUuX9nY2REREjgozW+a3f006faqkR0RERORISfqSHjOrBjb0dj6OkHygvLczcQTp8x3b9PmOXYn82SDxP99U51xOb2eiN/S1wQl7w4ZELeYzs6WJ+tlAn+9Yp8937ErkzwbJ8fl6Ow+9RdVbIiIikhQU9IiIiEhSUNAD9/R2Bo6gRP5soM93rNPnO3Yl8mcDfb6ElfQNmUVERCQ5qKRHREREkkLSBj1mdqmZbTCzYjO7tbfzc7jMbLSZvWJma81sjZl9xZ9+m5mVmNkK/+fy3s5rT5nZNjNb5X+Opf60wWb2oplt8n8P6u18dpeZTQ3ZPyvM7KCZffVY3ndmdr+Z7TOz1SHTIu4r8/zOPxffM7OTey/nsYny+X5pZuv9z/CkmeX508eZWV3Ifryr1zIeoyifL+rxaGbf8vffBjO7pHdyHbson++RkM+2zcxW+NOPqf3Xyb0gYc6/w+KcS7ofIBXYDEwAMoCVwPTeztdhfqYRwMn+3znARmA6cBvw/3o7f3H6jNuA/LBpvwBu9f++Ffh5b+fzMD9jKlAKjD2W9x1wDnAysLqrfQVcDjwLGDAbeLu389/Dz3cxkOb//fOQzzcuNN2x8BPl80U8Hv3rzEqgHzDev7am9vZn6O7nC5v/v8D3jsX918m9IGHOv8P5SdaSntOAYufcFudcI/AwMLeX83RYnHN7nHPv+n9X4727rLB3c3VUzAX+7P/9Z2Be72UlLt4HbHbObe/tjBwO59xrQEXY5Gj7ai7wF+d5C8gzsxFHJaM9FOnzOedecN77AwHeAkYd9YzFSZT9F81c4GHnXINzbitQjHeN7bM6+3xmZsC1wD+OaqbipJN7QcKcf4cjWYOeQmBnyP+7SKAAwczGATOBt/1Jt/jFlvcfi9U/IRzwgpktM7Mb/WnDnHN7/L9LgWG9k7W4uY72F9tE2XcQfV8l4vn4abyn54DxZrbczF41s7N7K1NxEOl4TLT9dzaw1zm3KWTaMbn/wu4FyXT+RZWsQU/CMrMBwOPAV51zB4E/AhOBImAPXrHtsWqOc+5k4DLgi2Z2TuhM55XVHrPdEc0sA7gK+Kc/KZH2XTvH+r7qjJl9B2gG/u5P2gOMcc7NBL4GPGRmA3srf4chYY/HMB+h/YPHMbn/ItwLghL5/OtKsgY9JcDokP9H+dOOaWaWjneQ/9059wSAc26vc67FOdcK/Ik+XuzcGedcif97H/Ak3mfZGyiK9X/v670cHrbLgHedc3shsfadL9q+Spjz0cxuAK4EPubfWPCrffb7fy/Da/Mypdcy2UOdHI+JtP/SgA8AjwSmHYv7L9K9gCQ4/2KRrEHPEmCymY33n66vAxb0cp4Oi18PfR+wzjn365DpoXWzVwOrw5c9FphZtpnlBP7GazS6Gm+/Xe8nux54qndyGBftnjATZd+FiLavFgCf9HuRzAaqQorhjxlmdinw38BVzrnakOkFZpbq/z0BmAxs6Z1c9lwnx+MC4Doz62dm4/E+3ztHO39xciGw3jm3KzDhWNt/0e4FJPj5F7PebkndWz94LdY34kXt3+nt/MTh88zBK658D1jh/1wO/BVY5U9fAIzo7bz28PNNwOshshJYE9hnwBDgP8Am4CVgcG/ntYefLxvYD+SGTDtm9x1e8LYHaMJrI/CZaPsKr9fInf65uAqY1dv57+HnK8ZrGxE4/+7y017jH7MrgHeB9/d2/nv4+aIej8B3/P23Abist/Pfk8/nT38QuDks7TG1/zq5FyTM+Xc4PxqRWURERJJCslZviYiISJJR0CMiIiJJQUGPiIiIJAUFPSIiIpIUFPSIiIhIUlDQIyJBZnaDmbkoP5W9mK8HzWxX1ylFRKJL6+0MiEif9CG88UtCNUdKKCJyrFDQIyKRrHDOFfd2JkRE4knVWyLSLSFVYOeY2XwzqzGz/WZ2p5n1D0s7wsz+YmblZtbgv6H74xHWOd7M/mpmpX66LWb22wjpZprZ62ZWa2abzOzmsPnDzezPZrbbX88eM/uXmQ2N/zchIscalfSISCSp/ssXQ7U672WTAX8DHgX+gPfyye/hvU7jBgi+I+1VYBDwbbxXNHwc+KuZZTnn7vHTjcd7V1Otv45NwBi896uFGgg8BNwB3A58CvijmW1wzr3ip/krMBb4hr+9YcD7gKwefg8ikkAU9IhIJOsjTPs33hvEA55xzv0//+8XzMwBt5vZT5xzG/GCksnA+c65hX66Z81sGPAjM7vPOdcC/ADoD5zknNsdsv4/h20/B/hCIMAxs9eAS/Be1BoIes4Avu2c+3vIcv+M+VOLSEJT0CMikVxNx4bMlWH/Pxr2/8PAj/BKfTYC5wAlIQFPwN+AB4DpeC84vBj4V1jAE0ltSIkOzrkGM9uIVyoUsAT4hv+m6ZeB1U4vGBQRn4IeEYlkdQwNmfdG+b/Q/z0Y703W4UpD5oP39udYuqMfiDCtAcgM+f/DwPeB/8arBttjZncBPwqrmhORJKSGzCLSU8Oi/F/i/64AhkdYbnjIfIBy2gKlw+Kc2+ec+6JzrhCYBjyIV312UzzWLyLHNgU9ItJT14b9fx3QCrzt//8qMMrMzgpL91FgH7DW//8F4EozGxHPzDnnNjjnvo1XQnRCPNctIscmVW+JSCRFZpYfYfrSkL8vN7Nf4gUtp+FVK/3FObfJn/8g8BXgCTP7Dl4V1seAi4Cb/EbM+MtdDrxhZj8BivFKfi51znXo3h6NmeUCLwF/x2uI3QTMxes99kKs6xGRxKWgR0QiidbjqSDk748DXwc+DzQCfwICvblwzh0ys3OBXwA/w+t9tQH4hHPubyHptpnZbLxG0D8FBuBVkT3VzTzXA+8Cn8Prtt7qb+9jzrnurktEEpCpY4OIdIeZ3YDX+2qyRm0WkWOJ2vSIiIhIUlDQIyIiIklB1VsiIiKSFFTSIyIiIklBQY+IiIgkBQU9IiIikhQU9IiIiEhSUNAjIiIiSUFBj4iIiCSF/w9zJJOCKSwQTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(accuracy_array)\n",
    "plt.title('Additional Discriminator OPTAGAN Performance (Yahoo)', fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.xlim(0,200)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9ec8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save = pd.DataFrame(accuracy_array)\n",
    "df_to_save.to_csv('accuracy_array_optagan_yahoo_nt_rt_768_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18eae8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generating Sentences\n",
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# import argparse\n",
    "\n",
    "# import logging\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "\n",
    "# from modules.gan import Generator\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "# import pickle\n",
    "# import random\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "# from tqdm import tqdm, trange\n",
    "\n",
    "# from func import GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig, BertConfig\n",
    "# from func import GPT2LMHeadModel, GPT2Tokenizer, GPT2ForLatentConnector, GPT2ForLatentConnectorValueHead\n",
    "# from func import OpenAIGPTLMHeadModel, OpenAIGPTTokenizer\n",
    "# from func import XLNetLMHeadModel, XLNetTokenizer\n",
    "# from func import TransfoXLLMHeadModel, TransfoXLTokenizer\n",
    "# from func import BertForLatentConnector, BertTokenizer\n",
    "\n",
    "# from collections import defaultdict\n",
    "# import pdb\n",
    "# from modules.utils import rollout_test\n",
    "\n",
    "# MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "\n",
    "# ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) for conf in (GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig)), ())\n",
    "\n",
    "# logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "#                     datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "#                     level = logging.INFO)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# MODEL_CLASSES = {\n",
    "#     'gpt2': (GPT2Config, GPT2ForLatentConnector, GPT2Tokenizer),\n",
    "#     'bert': (BertConfig, BertForLatentConnector, BertTokenizer),\n",
    "#     'gpt2v': (GPT2Config, GPT2ForLatentConnectorValueHead, GPT2Tokenizer)\n",
    "# }\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--seed', type=int, default=0)\n",
    "#     parser.add_argument('--new_sent', type=int, default=1, help=\"Number of sentences to generate\")\n",
    "#     parser.add_argument('--n_layers', type=int, default=20, help=\"Number of layers of generator\")\n",
    "#     parser.add_argument('--block_dim', type=int, default=100)\n",
    "#     parser.add_argument('--interval', type=int, default=10)\n",
    "#     parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available())\n",
    "#     parser.add_argument('--generator_dir', default=None, type=str, required=True, help=\"Directory of GAN model checkpoint\")\n",
    "#     parser.add_argument(\"--checkpoint_dir\", default=None, type=str, required=True,\n",
    "#                         help=\"The directory where checkpoints are saved.\")\n",
    "#     parser.add_argument(\"--output_dir\", default=None, type=str, required=True,\n",
    "#                         help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "#     parser.add_argument(\"--save\", default=False, type=bool, help=\"Save results to file.\")\n",
    "#     parser.add_argument(\"--latent_size\", default=32, type=int, help=\"Latent space dimension.\")\n",
    "#     parser.add_argument(\"--output_name\", default=\"results\", type=str, help=\"File name of output\")\n",
    "#     parser.add_argument(\"--batch_size\", default=100, type=int, help=\"Batch size to generate outputs\")\n",
    "#     ## Encoder options\n",
    "#     parser.add_argument(\"--encoder_model_type\", default=\"bert\", type=str,\n",
    "#                         help=\"The encoder model architecture to be fine-tuned.\")\n",
    "#     parser.add_argument(\"--encoder_model_name_or_path\", default=\"bert-base-cased\", type=str,\n",
    "#                         help=\"The encoder model checkpoint for weights initialization.\")\n",
    "#     parser.add_argument(\"--encoder_config_name\", default=\"\", type=str,\n",
    "#                         help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "#     parser.add_argument(\"--encoder_tokenizer_name\", default=\"\", type=str,\n",
    "#                         help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "#     ## Decoder options\n",
    "#     parser.add_argument(\"--decoder_model_type\", default=\"gpt2\", type=str,\n",
    "#                         help=\"The decoder model architecture to be fine-tuned.\")\n",
    "#     parser.add_argument(\"--decoder_model_name_or_path\", default=\"gpt2\", type=str,\n",
    "#                         help=\"The decoder model checkpoint for weights initialization.\")\n",
    "#     parser.add_argument(\"--decoder_config_name\", default=\"\", type=str,\n",
    "#                         help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "#     parser.add_argument(\"--decoder_tokenizer_name\", default=\"\", type=str,\n",
    "#                         help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "#     parser.add_argument(\"--max_seq_length\", default=512, type=int,\n",
    "#                         help=\"Optional input sequence length before tokenization. The sequence will be dropped if it is longer the max_seq_length\")\n",
    "#     parser.add_argument(\"--finetune_decoder\", default=False, type=bool,\n",
    "#                         help=\"Uses finetuned decoder in output dir if true.\")\n",
    "\n",
    "#     ## Variational auto-encoder(check this)\n",
    "#     parser.add_argument(\"--top_k\", type=int, default=0)\n",
    "#     parser.add_argument(\"--top_p\", type=float, default=1.0)\n",
    "#     parser.add_argument(\"--prompt\", type=str, default=\"\")\n",
    "#     parser.add_argument(\"--padding_text\", type=str, default=\"\")\n",
    "#     parser.add_argument(\"--length\", type=int, default=20)\n",
    "#     parser.add_argument(\"--block_size\", default=-1, type=int,\n",
    "#                         help=\"Optional input sequence length after tokenization.\"\n",
    "#                              \"The training dataset will be truncated in block of this size for training.\"\n",
    "#                              \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n",
    "#     parser.add_argument(\"--do_lower_case\", action='store_true',\n",
    "#                         help=\"Set this flag if you are using an uncased model.\")\n",
    "#     parser.add_argument(\"--use_philly\", action='store_true',\n",
    "#                         help=\"Use Philly for computing.\")\n",
    "#     parser.add_argument('--gloabl_step_eval', type=int, default=508523,\n",
    "#                         help=\"Evaluate the results at the given global step\")\n",
    "\n",
    "#     # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "#     args = parser.parse_args(\"--checkpoint_dir=output_dir_yahoo_768_0 \\\n",
    "#     --output_dir=output_dir_yahoo_768_0 \\\n",
    "#     --generator_dir=output_dir_yahoo_768_0 \\\n",
    "#     --block_size 100 \\\n",
    "#     --max_seq_length 60 \\\n",
    "#     --gloabl_step_eval 24000 \\\n",
    "#     --latent_size 32 \\\n",
    "#     --block_dim 100 \\\n",
    "#     --new_sent 100 \\\n",
    "#     --n_layers 10 \\\n",
    "#     --top_p 0.9 \\\n",
    "#     --output_name=results \\\n",
    "#     --save True\".split())\n",
    "#     global_step = args.gloabl_step_eval\n",
    "\n",
    "#     np.random.seed(args.seed)\n",
    "#     torch.manual_seed(args.seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "#     args.n_gpu = torch.cuda.device_count()\n",
    "#     if args.n_gpu > 0:\n",
    "#         torch.cuda.manual_seed_all(args.seed)       \n",
    "    \n",
    "#     args.encoder_model_type = args.encoder_model_type.lower()\n",
    "#     args.decoder_model_type = args.decoder_model_type.lower()\n",
    "\n",
    "#     output_encoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-encoder-{}'.format(global_step))\n",
    "#     output_decoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-decoder-{}'.format(global_step))\n",
    "#     if not args.finetune_decoder:\n",
    "#         output_decoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-decoder-{}'.format(global_step))\n",
    "#     else:\n",
    "#          output_decoder_dir = os.path.join(args.output_dir, 'checkpoint-decoder-{}'.format(global_step))\n",
    "#     checkpoints = [ [output_encoder_dir, output_decoder_dir] ]\n",
    "\n",
    "#     # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "#     encoder_config_class, encoder_model_class, encoder_tokenizer_class = MODEL_CLASSES[args.encoder_model_type]\n",
    "#     model_encoder = encoder_model_class.from_pretrained(output_encoder_dir, latent_size=args.latent_size)\n",
    "#     tokenizer_encoder = encoder_tokenizer_class.from_pretrained(args.encoder_tokenizer_name if args.encoder_tokenizer_name else args.encoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "\n",
    "#     model_encoder.to(args.device)\n",
    "#     if args.block_size <= 0:\n",
    "#         args.block_size = tokenizer_encoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "#     args.block_size = min(args.block_size, tokenizer_encoder.max_len_single_sentence)\n",
    "\n",
    "#     # Load a trained Decoder model and vocabulary that you have fine-tuned\n",
    "#     if not args.finetune_decoder:\n",
    "#         decoder_config_class, decoder_model_class, decoder_tokenizer_class = MODEL_CLASSES[args.decoder_model_type]\n",
    "#     else:\n",
    "#         decoder_config_class, decoder_model_class, decoder_tokenizer_class = MODEL_CLASSES[\"gpt2v\"]\n",
    "#     model_decoder = decoder_model_class.from_pretrained(output_decoder_dir, latent_size=args.latent_size)\n",
    "#     tokenizer_decoder = decoder_tokenizer_class.from_pretrained(args.decoder_tokenizer_name if args.decoder_tokenizer_name else args.decoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "#     model_decoder.to(args.device)\n",
    "#     if args.block_size <= 0:\n",
    "#         args.block_size = tokenizer_decoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "#     args.block_size = min(args.block_size, tokenizer_decoder.max_len_single_sentence)\n",
    "\n",
    "#     # Chunyuan: Add Padding token to GPT2\n",
    "#     special_tokens_dict = {'pad_token': '<PAD>', 'bos_token': '<BOS>', 'eos_token': '<EOS>'}\n",
    "#     num_added_toks = tokenizer_decoder.add_special_tokens(special_tokens_dict)\n",
    "#     logger.info('We have added {} tokens to GPT2'.format(num_added_toks))\n",
    "#     model_decoder.resize_token_embeddings(len(tokenizer_decoder))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n",
    "#     assert tokenizer_decoder.pad_token == '<PAD>'\n",
    "    \n",
    "#     generator = Generator(args.n_layers, args.block_dim, args.latent_size)\n",
    "\n",
    "#     if args.cuda:\n",
    "#         generator = generator.cuda()\n",
    "\n",
    "#     generator.load_state_dict(torch.load(args.generator_dir+'/generator_'+str(args.gloabl_step_eval)+'.th'))\n",
    "#     generator.eval()\n",
    "#     model_decoder.eval()\n",
    "#     model_encoder.eval()\n",
    "#     if args.save:\n",
    "#         if not os.path.exists(args.output_dir+\"/{}.txt\".format(args.output_name)):\n",
    "#             with open(args.output_dir+\"/{}.txt\".format(args.output_name), 'w'): \n",
    "#                 pass\n",
    "\n",
    "#     for i in range(int(args.new_sent/args.batch_size)):\n",
    "#         # sample noise\n",
    "#         noise = torch.Tensor(np.random.normal(0, 1, (args.batch_size, args.latent_size))).to(args.device)\n",
    "#         new_z = generator(noise).data\n",
    "\n",
    "#         # create new sent\n",
    "#         sents = rollout_test(model_decoder, new_z, tokenizer_decoder, args.max_seq_length, args.batch_size, args.top_k, args.top_p)\n",
    "\n",
    "#         if args.save:\n",
    "#             with open(args.output_dir+\"/{}.txt\".format(args.output_name), 'a') as file:\n",
    "#                 for i in sents:\n",
    "#                     file.write(i+\"\\n\")\n",
    "#         else:\n",
    "#             for i in sents:\n",
    "#                 logger.info(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab174fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
