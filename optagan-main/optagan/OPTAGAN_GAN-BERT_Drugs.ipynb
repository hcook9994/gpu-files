{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55271308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import datetime\n",
    "now_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e4c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b69f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['UNK',1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac22c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_l=pd.read_csv(\"../../drugs/subdivided/train_l.csv\", index_col=\"Unnamed: 0\")\n",
    "df_test_l=pd.read_csv(\"../../drugs/subdivided/test_l.csv\", index_col=\"Unnamed: 0\")\n",
    "df_u=pd.read_csv(\"../../drugs/subdivided/u.csv\", index_col=\"Unnamed: 0\")\n",
    "# df_train_u=pd.read_csv(\"../../drugs/assigned/train_u.csv\", index_col=\"Unnamed: 0\")#.head(10000)\n",
    "# df_test_u=pd.read_csv(\"../../drugs/assigned/test_u.csv\", index_col=\"Unnamed: 0\")#.head(5000)\n",
    "# df_all = pd.concat([df_train_l, df_test_l, df_u, df_train_u, df_test_u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a181b3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_u['0'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52d4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l =  list(df_train_l.to_records(index=False))\n",
    "test_l = list(df_test_l.to_records(index=False))\n",
    "u_list = list(df_u.to_records(index=False))\n",
    "# test_u = list(df_test_u.to_records(index=False))\n",
    "# train_u = list(df_train_u.to_records(index=False))\n",
    "# data_all = list(df_all[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f5408f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 45\n",
    "batch_size = 64\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "#num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-6 #5e-6?\n",
    "#learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 200\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "#model_name=\"google/electra-large-discriminator\"\n",
    "#model_name=\"google/electra-small-discriminator\"\n",
    "#model_name=\"microsoft/deberta-v2-xxlarge\"\n",
    "#model_name=\"microsoft/deberta-v3-base\"\n",
    "#model_name = \"google/electra-base-discriminator\" - 0.47 best when only change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4758bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7beb0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  examples = []\n",
    "\n",
    "  # Count the percentage of labeled examples  \n",
    "  num_labeled_examples = 0\n",
    "  for label_mask in label_masks:\n",
    "    if label_mask: \n",
    "      num_labeled_examples += 1\n",
    "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "  # if required it applies the balance\n",
    "  for index, ex in enumerate(input_examples): \n",
    "    if label_mask_rate == 1 or not balance_label_examples:\n",
    "      examples.append((ex, label_masks[index]))\n",
    "    else:\n",
    "      # IT SIMULATE A LABELED EXAMPLE\n",
    "      if label_masks[index]:\n",
    "        balance = int(1/label_mask_rate)\n",
    "        balance = int(math.log(balance,2))\n",
    "        if balance < 1:\n",
    "          balance = 1\n",
    "        for b in range(0, int(balance)):\n",
    "          examples.append((ex, label_masks[index]))\n",
    "      else:\n",
    "        examples.append((ex, label_masks[index]))\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for (text, label_mask) in examples:\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[text[1]])\n",
    "    label_mask_array.append(label_mask)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "  label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f98a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_fake(input_examples):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for text in input_examples:\n",
    "    encoded_sent = tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return input_ids, input_mask_array # Trains with this batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd53b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the examples\n",
    "labeled_examples = train_l\n",
    "unlabeled_examples = u_list\n",
    "test_examples = test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c169846",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "if unlabeled_examples:\n",
    "  train_examples = train_examples + unlabeled_examples\n",
    "  #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
    "  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bcab6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d197ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "#hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "#generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  #generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800d0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats = []\n",
    "\n",
    "accuracy_array=[]\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "#g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
    "#gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "  scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db4d007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/harry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#OPTAGAN\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import argparse\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from modules.gan import Generator, Critic\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from func import GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig, BertConfig\n",
    "from func import GPT2LMHeadModel, GPT2Tokenizer, GPT2ForLatentConnector, GPT2ForLatentConnectorValueHead\n",
    "from func import OpenAIGPTLMHeadModel, OpenAIGPTTokenizer\n",
    "from func import XLNetLMHeadModel, XLNetTokenizer\n",
    "from func import TransfoXLLMHeadModel, TransfoXLTokenizer\n",
    "from func import BertForLatentConnector, BertTokenizer\n",
    "\n",
    "from collections import defaultdict\n",
    "from utils import (TextDataset_Split, TextDataset_2Tokenizers, BucketingDataLoader)\n",
    "import pdb\n",
    "from modules.utils import (calc_blue_parallel_func, pad_seq, rollout, rollout_test)\n",
    "#from transformers.modeling_utils import top_k_top_p_filtering\n",
    "\n",
    "\n",
    "MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) for conf in (GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig)), ())\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'gpt2': (GPT2Config, GPT2ForLatentConnectorValueHead, GPT2Tokenizer),\n",
    "    'bert': (BertConfig, BertForLatentConnector, BertTokenizer)\n",
    "}\n",
    "\n",
    "num_txt = 1\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer):\n",
    "    if isinstance(tokenizer, list):\n",
    "        dataset = TextDataset_2Tokenizers(tokenizer, args, args.train_data_file, block_size=args.block_size)\n",
    "    else:\n",
    "        dataset = TextDataset_Split(tokenizer, args, args.train_data_file, block_size=args.block_size)\n",
    "    return dataset\n",
    "\n",
    "def build_dataload_and_cache_examples(args, tokenizer, num_txt):\n",
    "    if isinstance(tokenizer, list):\n",
    "        args.batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "        if num_txt<=9:\n",
    "            concatenation=\"{}_{}{}\".format(args.train_data_file, num_txt, \".txt\")\n",
    "            file_path=concatenation\n",
    "            print(\"Train file used is number {}\".format(num_txt))\n",
    "            print(concatenation)\n",
    "            num_txt=num_txt+1\n",
    "        else:\n",
    "            num_txt=1\n",
    "            concatenation=\"{}_{}{}\".format(args.train_data_file, num_txt, \".txt\")\n",
    "            file_path=concatenation\n",
    "            print(\"Train file used is number {}\".format(num_txt))\n",
    "        dataloader = BucketingDataLoader(file_path, args.batch_size, args.max_seq_length, tokenizer, args, bucket=100, shuffle=True)\n",
    "    else:\n",
    "        pass \n",
    "    return dataloader, num_txt\n",
    "\n",
    "def compute_grad_penalty(critic, real_data, fake_data):\n",
    "    B = real_data.size(0)\n",
    "    alpha = torch.FloatTensor(np.random.random((B, 1)))\n",
    "    if args.cuda:\n",
    "        alpha = alpha.cuda()\n",
    "    sample = alpha*real_data + (1-alpha)*fake_data\n",
    "    sample.requires_grad_(True)\n",
    "    score = critic(sample)\n",
    "\n",
    "    outputs = torch.FloatTensor(B, 1).fill_(1.0) #args.latent_size\n",
    "    outputs.requires_grad_(False)\n",
    "    if args.cuda:\n",
    "        outputs = outputs.cuda()\n",
    "    grads = autograd.grad(\n",
    "        outputs=score,\n",
    "        inputs=sample,\n",
    "        grad_outputs=outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True)[0]\n",
    "    grad_penalty = ((grads.norm(2, dim=1) - 1.) ** 2).mean()\n",
    "    return grad_penalty\n",
    "\n",
    "def train(epoch):\n",
    "    model_encoder.eval()\n",
    "    model_decoder.eval()\n",
    "    generator.train()\n",
    "    critic.train()\n",
    "    c_train_loss = 0.\n",
    "    g_train_loss = 0.\n",
    "    g_batches = 0\n",
    "    c_batches = 0\n",
    "    c_loss_0 = 1\n",
    "    g_loss_0 = 1\n",
    "    for i, x in enumerate(train_loader):\n",
    "        x = x[0]\n",
    "        if args.cuda:\n",
    "            x = x.cuda()\n",
    "        # Generate noise\n",
    "        B = args.per_gpu_train_batch_size\n",
    "        noise = torch.from_numpy(np.random.normal(0, 1, (B,\n",
    "                                 args.latent_size))).float()\n",
    "        if args.cuda:\n",
    "            noise = noise.cuda()\n",
    "        # Get original text latent embeddings\n",
    "        with torch.no_grad(): \n",
    "            pooled_hidden_fea = model_encoder(x, attention_mask=(x > 0).float())[1]\n",
    "            mean, logvar = model_encoder.linear(pooled_hidden_fea).chunk(2, -1)\n",
    "            z_real = mean.squeeze(1) \n",
    "\n",
    "        # Evaluate and get losses\n",
    "        z_fake = generator(noise)\n",
    "        real_score = critic(z_real)\n",
    "        fake_score = critic(z_fake)\n",
    "        grad_penalty = compute_grad_penalty(critic, z_real.data, z_fake.data)\n",
    "        c_loss = -torch.mean(real_score) + torch.mean(fake_score) + \\\n",
    "                 args.gp_lambda*grad_penalty\n",
    "\n",
    "        fake_score = critic(generator(noise))\n",
    "        g_loss = -torch.mean(fake_score)\n",
    "        \n",
    "        r_g = abs(((g_loss.item() - g_loss_0) / (g_loss_0 + 0.001))) \n",
    "        r_c = abs(((c_loss.item() - c_loss_0) / (c_loss_0 + 0.001))) \n",
    "        \n",
    "        # Update critic or generator\n",
    "        if ((2 + epoch) / epoch) * r_c > r_g:\n",
    "            c_optimizer.zero_grad()\n",
    "            c_batches += 1\n",
    "            c_train_loss += c_loss.item()\n",
    "            c_loss.backward()\n",
    "            c_optimizer.step()\n",
    "        else:\n",
    "            g_optimizer.zero_grad()\n",
    "            g_batches += 1\n",
    "            g_train_loss += g_loss.item()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "        c_loss_0 = c_loss.item()\n",
    "        g_loss_0 = g_loss.item()\n",
    "\n",
    "        if args.interval > 0 and i % args.interval == 0:\n",
    "            logger.info('Epoch: {} | Batch: {}/{} ({:.0f}%) | G Loss: {:.6f} | C Loss: {:.6f}'.format(\n",
    "                epoch, args.batch_size*i, len(train_loader.dataset),\n",
    "                100.*(args.batch_size*i)/len(train_loader.dataset),\n",
    "                g_loss.item(), c_loss.item()\n",
    "            ))\n",
    "            test_noise = torch.Tensor(np.random.normal(0, 1, (1, args.latent_size))).to(args.device)\n",
    "            test_new_z = generator(test_noise).data\n",
    "            # create new sent\n",
    "            test_z = rollout_test(model_decoder, test_new_z, tokenizer_decoder, args.max_seq_length, 1, 0, 1)\n",
    "            logger.info(\"Text: {}\".format(test_z))\n",
    "\n",
    "    c_train_loss /= c_batches + 1\n",
    "    g_train_loss /= g_batches + 1\n",
    "    logger.info('* (Train) Epoch: {} | G Loss: {:.4f} | C Loss: {:.4f} | Updates G: {} | Updates C: {}'.format(\n",
    "        epoch, g_train_loss, c_train_loss, g_batches, c_batches\n",
    "    ))\n",
    "    return (g_train_loss, c_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13eef4b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 11:56:21 - INFO - func.configuration_utils -   loading configuration file output_dir_768_0_unsure_2/checkpoint-encoder-508523/config.json\n",
      "07/06/2022 11:56:21 - INFO - func.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "07/06/2022 11:56:21 - INFO - func.modeling_utils -   loading weights file output_dir_768_0_unsure_2/checkpoint-encoder-508523/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size_rl=32, block_dim=100, block_size=100, checkpoint_dir='output_dir_768_0_unsure_2', cuda=True, dataset='EMNLP', decoder_config_name='', decoder_model_name_or_path='gpt2', decoder_model_type='gpt2', decoder_tokenizer_name='', do_lower_case=False, encoder_config_name='', encoder_model_name_or_path='bert-base-cased', encoder_model_type='bert', encoder_tokenizer_name='', epochs=200, epochs_rl=100, finetune_decoder=True, generator_dir=None, gloabl_step_eval=508523, gp_lambda=10, interval=50, latent_size=768, length=20, lr=0.0001, lr_rl=1e-06, max_seq_length=24, n_layers=10, output_dir='output_dir_768_0_unsure_2', padding_text='', per_gpu_train_batch_size=12, prompt='', seed=0, train_data_file='../../drugs/subdivided/train', use_philly=False, valid_data_file='../../drugs/subdivided/test.txt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 11:56:24 - INFO - func.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/harry/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "07/06/2022 11:56:24 - INFO - func.configuration_utils -   loading configuration file output_dir_768_0_unsure_2/checkpoint-decoder-508523/config.json\n",
      "07/06/2022 11:56:24 - INFO - func.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"latent_size\": 768,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50260\n",
      "}\n",
      "\n",
      "07/06/2022 11:56:24 - INFO - func.modeling_utils -   loading weights file output_dir_768_0_unsure_2/checkpoint-decoder-508523/pytorch_model.bin\n",
      "07/06/2022 11:56:27 - INFO - func.modeling_utils -   Weights of GPT2ForLatentConnectorValueHead not initialized from pretrained model: ['v_head.linear1.weight', 'v_head.linear1.bias', 'v_head.linear2.weight', 'v_head.linear2.bias']\n",
      "07/06/2022 11:56:30 - INFO - func.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/harry/.cache/torch/pytorch_transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "07/06/2022 11:56:30 - INFO - func.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/harry/.cache/torch/pytorch_transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "07/06/2022 11:56:30 - INFO - func.tokenization_utils -   Adding <PAD> to the vocabulary\n",
      "07/06/2022 11:56:30 - INFO - func.tokenization_utils -   Assigning <PAD> to the pad_token key of the tokenizer\n",
      "07/06/2022 11:56:30 - INFO - func.tokenization_utils -   Adding <BOS> to the vocabulary\n",
      "07/06/2022 11:56:30 - INFO - func.tokenization_utils -   Assigning <BOS> to the bos_token key of the tokenizer\n",
      "07/06/2022 11:56:30 - INFO - func.tokenization_utils -   Adding <EOS> to the vocabulary\n",
      "07/06/2022 11:56:30 - INFO - func.tokenization_utils -   Assigning <EOS> to the eos_token key of the tokenizer\n",
      "07/06/2022 11:56:30 - INFO - __main__ -   We have added 3 tokens to GPT2\n",
      "07/06/2022 11:56:30 - INFO - __main__ -   G Parameters:255468\n",
      "07/06/2022 11:56:30 - INFO - __main__ -   C Parameters:178001\n",
      "07/06/2022 11:56:30 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 1 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:12.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:24.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:34.\n",
      "  Batch    40  of     91.    Elapsed: 0:00:47.\n",
      "  Batch    50  of     91.    Elapsed: 0:00:57.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:08.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:18.\n",
      "  Batch    80  of     91.    Elapsed: 0:01:31.\n",
      "  Batch    90  of     91.    Elapsed: 0:01:42.\n",
      "\n",
      "  Average training loss generetor: 0.578\n",
      "  Average training loss discriminator: 3.537\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 11:58:13 - INFO - __main__ -   Epoch: 1 | Batch: 0/4473 (0%) | G Loss: 0.143998 | C Loss: 2.106655\n",
      "07/06/2022 11:58:13 - INFO - __main__ -   Text: ['']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.122\n",
      "  Test Loss: 2.363\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 11:58:16 - INFO - __main__ -   Epoch: 1 | Batch: 600/4473 (13%) | G Loss: 140.450867 | C Loss: -90.006653\n",
      "07/06/2022 11:58:16 - INFO - __main__ -   Text: ['']\n",
      "07/06/2022 11:58:18 - INFO - __main__ -   Epoch: 1 | Batch: 1200/4473 (27%) | G Loss: 138.968994 | C Loss: -92.040695\n",
      "07/06/2022 11:58:18 - INFO - __main__ -   Text: ['']\n",
      "07/06/2022 11:58:20 - INFO - __main__ -   Epoch: 1 | Batch: 1800/4473 (40%) | G Loss: 108.917297 | C Loss: -74.575439\n",
      "07/06/2022 11:58:20 - INFO - __main__ -   Text: ['']\n",
      "07/06/2022 11:58:22 - INFO - __main__ -   Epoch: 1 | Batch: 2400/4473 (54%) | G Loss: 65.285095 | C Loss: -46.023949\n",
      "07/06/2022 11:58:22 - INFO - __main__ -   Text: ['']\n",
      "07/06/2022 11:58:24 - INFO - __main__ -   Epoch: 1 | Batch: 3000/4473 (67%) | G Loss: 61.069958 | C Loss: -45.126663\n",
      "07/06/2022 11:58:24 - INFO - __main__ -   Text: ['property H Traffic Bio Pa ( Fl. Eliq. Satana. in others. For. Dominican.']\n",
      "07/06/2022 11:58:26 - INFO - __main__ -   Epoch: 1 | Batch: 3600/4473 (80%) | G Loss: 52.684032 | C Loss: -37.237572\n",
      "07/06/2022 11:58:26 - INFO - __main__ -   Text: ['<BOS>']\n",
      "07/06/2022 11:58:28 - INFO - __main__ -   Epoch: 1 | Batch: 4200/4473 (94%) | G Loss: 50.030518 | C Loss: -37.846489\n",
      "07/06/2022 11:58:28 - INFO - __main__ -   Text: ['']\n",
      "07/06/2022 11:58:29 - INFO - __main__ -   * (Train) Epoch: 1 | G Loss: 80.2487 | C Loss: -55.0704 | Updates G: 27 | Updates C: 345\n",
      "07/06/2022 11:58:42 - INFO - __main__ -   Bleu-2:0.218 | B-Bleu-2:0.141\n",
      "07/06/2022 11:58:42 - INFO - __main__ -   * Saving. Best Score:0.359 | Bleu-2:0.218 | B-Bleu-2:0.141\n",
      "07/06/2022 11:58:42 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35873896975354685\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 2 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.640\n",
      "  Average training loss discriminator: 3.272\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:01:10 - INFO - __main__ -   Epoch: 2 | Batch: 0/4327 (0%) | G Loss: 43.014771 | C Loss: -31.842443\n",
      "07/06/2022 12:01:10 - INFO - __main__ -   Text: ['French Com On Prou Dis Public H0 Partner Lift']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.133\n",
      "  Test Loss: 2.318\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:01:12 - INFO - __main__ -   Epoch: 2 | Batch: 600/4327 (14%) | G Loss: 39.095104 | C Loss: -29.921501\n",
      "07/06/2022 12:01:12 - INFO - __main__ -   Text: ['Street.\". Imperialulate V. two.,, toeight. Object. Sang. on. Buffalo.']\n",
      "07/06/2022 12:01:14 - INFO - __main__ -   Epoch: 2 | Batch: 1200/4327 (28%) | G Loss: 33.127010 | C Loss: -25.961527\n",
      "07/06/2022 12:01:14 - INFO - __main__ -   Text: ['Abd and.......\" Kreq. and which).*']\n",
      "07/06/2022 12:01:16 - INFO - __main__ -   Epoch: 2 | Batch: 1800/4327 (42%) | G Loss: 26.858595 | C Loss: -22.323219\n",
      "07/06/2022 12:01:16 - INFO - __main__ -   Text: ['']\n",
      "07/06/2022 12:01:18 - INFO - __main__ -   Epoch: 2 | Batch: 2400/4327 (55%) | G Loss: 27.721952 | C Loss: -23.120628\n",
      "07/06/2022 12:01:18 - INFO - __main__ -   Text: ['And.']\n",
      "07/06/2022 12:01:20 - INFO - __main__ -   Epoch: 2 | Batch: 3000/4327 (69%) | G Loss: 21.628948 | C Loss: -18.313736\n",
      "07/06/2022 12:01:20 - INFO - __main__ -   Text: ['it\\'s To Mass conversion Group Blizzard U. and Stack The Lib. about. \" with.. and.']\n",
      "07/06/2022 12:01:22 - INFO - __main__ -   Epoch: 2 | Batch: 3600/4327 (83%) | G Loss: 19.053427 | C Loss: -16.491646\n",
      "07/06/2022 12:01:23 - INFO - __main__ -   Text: [') B And - Dou . B . . Not Note 6 But S in Make D To, .']\n",
      "07/06/2022 12:01:25 - INFO - __main__ -   Epoch: 2 | Batch: 4200/4327 (97%) | G Loss: 16.248304 | C Loss: -14.747479\n",
      "07/06/2022 12:01:25 - INFO - __main__ -   Text: ['At She Sound Mr A Sub do The 49 Ref go Sc Die Bridge. All.']\n",
      "07/06/2022 12:01:25 - INFO - __main__ -   * (Train) Epoch: 2 | G Loss: 26.7779 | C Loss: -22.7358 | Updates G: 38 | Updates C: 322\n",
      "07/06/2022 12:01:39 - INFO - __main__ -   Bleu-2:0.269 | B-Bleu-2:0.217\n",
      "07/06/2022 12:01:39 - INFO - __main__ -   * Saving. Best Score:0.487 | Bleu-2:0.269 | B-Bleu-2:0.217\n",
      "07/06/2022 12:01:39 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4865607456962568\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 3 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 2.950\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:04:07 - INFO - __main__ -   Epoch: 3 | Batch: 0/4417 (0%) | G Loss: 15.372740 | C Loss: -13.916681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.158\n",
      "  Test Loss: 2.277\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:04:07 - INFO - __main__ -   Text: ['Man Bud Off Friday Mark Off Bu NFL Ground Jim Strong The Bed Star - Batman Major Below The Dis Nom, Super']\n",
      "07/06/2022 12:04:09 - INFO - __main__ -   Epoch: 3 | Batch: 600/4417 (14%) | G Loss: 12.935278 | C Loss: -12.053637\n",
      "07/06/2022 12:04:09 - INFO - __main__ -   Text: ['The It The growing before care ren strip being even was revokeding did Tao strip entering and Internet Menu.']\n",
      "07/06/2022 12:04:11 - INFO - __main__ -   Epoch: 3 | Batch: 1200/4417 (27%) | G Loss: 11.396201 | C Loss: -11.268661\n",
      "07/06/2022 12:04:11 - INFO - __main__ -   Text: ['On Police Safety Ref Am Swe Only & Cam in Spolenla ski tours life, Smith. to']\n",
      "07/06/2022 12:04:13 - INFO - __main__ -   Epoch: 3 | Batch: 1800/4417 (41%) | G Loss: 9.888249 | C Loss: -9.915992\n",
      "07/06/2022 12:04:13 - INFO - __main__ -   Text: ['Disc For started The B Special could Destroy , Right ( Do Special + Right A No Seen Dis, Spive']\n",
      "07/06/2022 12:04:15 - INFO - __main__ -   Epoch: 3 | Batch: 2400/4417 (54%) | G Loss: 8.324009 | C Loss: -8.284950\n",
      "07/06/2022 12:04:15 - INFO - __main__ -   Text: ['and lerer were about dull in and their last was damaged but not in – Wor .']\n",
      "07/06/2022 12:04:17 - INFO - __main__ -   Epoch: 3 | Batch: 3000/4417 (68%) | G Loss: 7.856437 | C Loss: -7.609927\n",
      "07/06/2022 12:04:18 - INFO - __main__ -   Text: ['immediatelying into the Lening for needing by that sung a liquidity inside another E Sabed price.']\n",
      "07/06/2022 12:04:19 - INFO - __main__ -   Epoch: 3 | Batch: 3600/4417 (82%) | G Loss: 5.540950 | C Loss: -5.910586\n",
      "07/06/2022 12:04:20 - INFO - __main__ -   Text: ['h view ret \"\" Entry: Status: Not that; 0 The avs 1: * Perry: By do']\n",
      "07/06/2022 12:04:22 - INFO - __main__ -   Epoch: 3 | Batch: 4200/4417 (95%) | G Loss: 6.170320 | C Loss: -6.410457\n",
      "07/06/2022 12:04:22 - INFO - __main__ -   Text: ['Dad has a good record at the PA100 at the road as all injuries in accompanied by etc etc when he used']\n",
      "07/06/2022 12:04:23 - INFO - __main__ -   * (Train) Epoch: 3 | G Loss: 9.2177 | C Loss: -8.9088 | Updates G: 60 | Updates C: 308\n",
      "07/06/2022 12:04:36 - INFO - __main__ -   Bleu-2:0.313 | B-Bleu-2:0.270\n",
      "07/06/2022 12:04:36 - INFO - __main__ -   * Saving. Best Score:0.583 | Bleu-2:0.313 | B-Bleu-2:0.270\n",
      "07/06/2022 12:04:36 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5829394012691473\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 4 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 2.664\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:07:04 - INFO - __main__ -   Epoch: 4 | Batch: 0/4322 (0%) | G Loss: 5.480330 | C Loss: -5.846866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 2.237\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:07:04 - INFO - __main__ -   Text: ['4 Odds later has once had four successful failed / 5 Low blood count by Biopops just (race']\n",
      "07/06/2022 12:07:06 - INFO - __main__ -   Epoch: 4 | Batch: 600/4322 (14%) | G Loss: 4.567106 | C Loss: -4.859366\n",
      "07/06/2022 12:07:06 - INFO - __main__ -   Text: ['Posagh has been employed by the network-CCTP a number of times, since 2004 and has done extensive reviews']\n",
      "07/06/2022 12:07:08 - INFO - __main__ -   Epoch: 4 | Batch: 1200/4322 (28%) | G Loss: 3.204555 | C Loss: -3.537360\n",
      "07/06/2022 12:07:09 - INFO - __main__ -   Text: ['\"\" wrote on a Don autoredy who believed the advertised doesn\\'t go away and the label \"\"\"\" revealed']\n",
      "07/06/2022 12:07:11 - INFO - __main__ -   Epoch: 4 | Batch: 1800/4322 (42%) | G Loss: 3.544371 | C Loss: -3.528652\n",
      "07/06/2022 12:07:11 - INFO - __main__ -   Text: ['The goal meters the 48 hutes and the Run Recovery and then the 50 hutes that took the 51 hutes']\n",
      "07/06/2022 12:07:13 - INFO - __main__ -   Epoch: 4 | Batch: 2400/4322 (56%) | G Loss: 3.377097 | C Loss: -3.344601\n",
      "07/06/2022 12:07:13 - INFO - __main__ -   Text: [\"Falconings are not required at all, and Chris, from text, 'strong and fit', looks after his mum\"]\n",
      "07/06/2022 12:07:15 - INFO - __main__ -   Epoch: 4 | Batch: 3000/4322 (69%) | G Loss: 4.124861 | C Loss: -3.446234\n",
      "07/06/2022 12:07:15 - INFO - __main__ -   Text: ['His vocal voice is reliable and precise, while Miyaz frequently bars with wheel running for a little while, found']\n",
      "07/06/2022 12:07:17 - INFO - __main__ -   Epoch: 4 | Batch: 3600/4322 (83%) | G Loss: 4.297698 | C Loss: -3.781632\n",
      "07/06/2022 12:07:17 - INFO - __main__ -   Text: [\"Ads in the ad thread (subscription/error) sometimes go dry over a week after they aren't there yet\"]\n",
      "07/06/2022 12:07:19 - INFO - __main__ -   Epoch: 4 | Batch: 4200/4322 (97%) | G Loss: 3.993537 | C Loss: -3.273690\n",
      "07/06/2022 12:07:19 - INFO - __main__ -   Text: ['Today & kg My The body company @ misc Linear mic M m Med 5 M max used Never, Getsmal,']\n",
      "07/06/2022 12:07:20 - INFO - __main__ -   * (Train) Epoch: 4 | G Loss: 3.9859 | C Loss: -3.6524 | Updates G: 78 | Updates C: 282\n",
      "07/06/2022 12:07:33 - INFO - __main__ -   Bleu-2:0.348 | B-Bleu-2:0.279\n",
      "07/06/2022 12:07:33 - INFO - __main__ -   * Saving. Best Score:0.627 | Bleu-2:0.348 | B-Bleu-2:0.279\n",
      "07/06/2022 12:07:33 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274116224633793\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 5 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 2.295\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:10:01 - INFO - __main__ -   Epoch: 5 | Batch: 0/4527 (0%) | G Loss: 4.213312 | C Loss: -3.481590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 2.210\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:10:01 - INFO - __main__ -   Text: ['Sheep \\' Complete \\' Botulations Really Beat ng Thro Que changing Pulse ongoing regular \" Piggy + Not']\n",
      "07/06/2022 12:10:03 - INFO - __main__ -   Epoch: 5 | Batch: 600/4527 (13%) | G Loss: 4.456403 | C Loss: -3.316022\n",
      "07/06/2022 12:10:04 - INFO - __main__ -   Text: ['She records the opening time at 6:1 with daily from 7:1, then songs exclusively at 6:1']\n",
      "07/06/2022 12:10:05 - INFO - __main__ -   Epoch: 5 | Batch: 1200/4527 (27%) | G Loss: 4.877418 | C Loss: -3.704350\n",
      "07/06/2022 12:10:06 - INFO - __main__ -   Text: [\"Oklahoma oil can't do this job for many caused among believed in the stun amount his person will start next around single\"]\n",
      "07/06/2022 12:10:08 - INFO - __main__ -   Epoch: 5 | Batch: 1800/4527 (40%) | G Loss: 4.225913 | C Loss: -3.574392\n",
      "07/06/2022 12:10:08 - INFO - __main__ -   Text: ['gain letter (\" pump blood grain ... pump) cr inf protest share \" bucket ... thy still spite can suff']\n",
      "07/06/2022 12:10:10 - INFO - __main__ -   Epoch: 5 | Batch: 2400/4527 (53%) | G Loss: 4.792653 | C Loss: -3.881783\n",
      "07/06/2022 12:10:10 - INFO - __main__ -   Text: ['\"Regular Groups have a negative impact on us, Hines89 has mineflex\" \"Active Groups have a positive']\n",
      "07/06/2022 12:10:12 - INFO - __main__ -   Epoch: 5 | Batch: 3000/4527 (66%) | G Loss: 4.294024 | C Loss: -3.622393\n",
      "07/06/2022 12:10:12 - INFO - __main__ -   Text: [\"datostme d'uhn obrito hatch daundiss joss-tab fav mostheck\"]\n",
      "07/06/2022 12:10:14 - INFO - __main__ -   Epoch: 5 | Batch: 3600/4527 (80%) | G Loss: 4.435875 | C Loss: -3.736581\n",
      "07/06/2022 12:10:14 - INFO - __main__ -   Text: ['The report was a million times not good, this sabb publication exactly ceased saying sabb session anymore jokingly which']\n",
      "07/06/2022 12:10:16 - INFO - __main__ -   Epoch: 5 | Batch: 4200/4527 (93%) | G Loss: 4.873686 | C Loss: -4.363424\n",
      "07/06/2022 12:10:16 - INFO - __main__ -   Text: ['\"Abilities remain in since terror for 30-hours for 50-hours Sunil and Magogasehad on']\n",
      "07/06/2022 12:10:17 - INFO - __main__ -   * (Train) Epoch: 5 | G Loss: 4.5805 | C Loss: -3.8546 | Updates G: 78 | Updates C: 299\n",
      "07/06/2022 12:10:31 - INFO - __main__ -   Bleu-2:0.380 | B-Bleu-2:0.305\n",
      "07/06/2022 12:10:31 - INFO - __main__ -   * Saving. Best Score:0.685 | Bleu-2:0.380 | B-Bleu-2:0.305\n",
      "07/06/2022 12:10:31 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68482195673446\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 6 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.709\n",
      "  Average training loss discriminator: 1.913\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:12:59 - INFO - __main__ -   Epoch: 6 | Batch: 0/4467 (0%) | G Loss: 4.693820 | C Loss: -3.754760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 2.225\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:12:59 - INFO - __main__ -   Text: ['Dream Lik strips are always checked rather then they usually leave messages, claims and controlled effects must be checked long after']\n",
      "07/06/2022 12:13:01 - INFO - __main__ -   Epoch: 6 | Batch: 600/4467 (13%) | G Loss: 4.936628 | C Loss: -3.836319\n",
      "07/06/2022 12:13:02 - INFO - __main__ -   Text: ['Limited to a $226 fee, Christina applied on a $450 price, 27 hits, Jon shows like']\n",
      "07/06/2022 12:13:03 - INFO - __main__ -   Epoch: 6 | Batch: 1200/4467 (27%) | G Loss: 4.750345 | C Loss: -4.332338\n",
      "07/06/2022 12:13:04 - INFO - __main__ -   Text: ['Animal memory is but one of the many horrible illusions, switched or deeply broken ones that can occur in the Vatican of']\n",
      "07/06/2022 12:13:06 - INFO - __main__ -   Epoch: 6 | Batch: 1800/4467 (40%) | G Loss: 4.714523 | C Loss: -3.889759\n",
      "07/06/2022 12:13:06 - INFO - __main__ -   Text: ['Karma is always troubled, due to not actually vocalised illness from feeling another ecloped offerlets but will present']\n",
      "07/06/2022 12:13:08 - INFO - __main__ -   Epoch: 6 | Batch: 2400/4467 (54%) | G Loss: 4.944964 | C Loss: -4.143084\n",
      "07/06/2022 12:13:08 - INFO - __main__ -   Text: ['Laws and pretty much behavioral responses are of total loss from exercise 23,49-42, and even to wearing wear']\n",
      "07/06/2022 12:13:10 - INFO - __main__ -   Epoch: 6 | Batch: 3000/4467 (67%) | G Loss: 4.891199 | C Loss: -4.258932\n",
      "07/06/2022 12:13:10 - INFO - __main__ -   Text: ['Juliet Time updates at 100 meter this morning, and shares hours while still whole day recording, network TV and video']\n",
      "07/06/2022 12:13:12 - INFO - __main__ -   Epoch: 6 | Batch: 3600/4467 (81%) | G Loss: 4.644832 | C Loss: -4.030489\n",
      "07/06/2022 12:13:12 - INFO - __main__ -   Text: ['And, with his formant thanks for a censorship, it was sent between her and obligatory viewing for him,which']\n",
      "07/06/2022 12:13:14 - INFO - __main__ -   Epoch: 6 | Batch: 4200/4467 (94%) | G Loss: 4.847881 | C Loss: -4.047654\n",
      "07/06/2022 12:13:14 - INFO - __main__ -   Text: ['It has tripled the fermenter base while Pasch has tackled it down to the basic mixer making it 15k']\n",
      "07/06/2022 12:13:15 - INFO - __main__ -   * (Train) Epoch: 6 | G Loss: 4.6988 | C Loss: -4.0019 | Updates G: 95 | Updates C: 277\n",
      "07/06/2022 12:13:29 - INFO - __main__ -   Bleu-2:0.390 | B-Bleu-2:0.303\n",
      "07/06/2022 12:13:29 - INFO - __main__ -   * Saving. Best Score:0.694 | Bleu-2:0.390 | B-Bleu-2:0.303\n",
      "07/06/2022 12:13:29 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6937237470386718\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 7 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.712\n",
      "  Average training loss discriminator: 1.576\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:15:57 - INFO - __main__ -   Epoch: 7 | Batch: 0/4364 (0%) | G Loss: 4.644175 | C Loss: -4.099543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 2.279\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:15:57 - INFO - __main__ -   Text: [\"Qualysnai has also partnered an avocado 1:auri round on the phone that's full of information that he has\"]\n",
      "07/06/2022 12:15:59 - INFO - __main__ -   Epoch: 7 | Batch: 600/4364 (14%) | G Loss: 4.982431 | C Loss: -4.311100\n",
      "07/06/2022 12:16:00 - INFO - __main__ -   Text: ['Thij alert according, \"His girlfriend has lying sent her a fortnight of letters: \\'He is seeking, sent']\n",
      "07/06/2022 12:16:02 - INFO - __main__ -   Epoch: 7 | Batch: 1200/4364 (27%) | G Loss: 4.413657 | C Loss: -3.926299\n",
      "07/06/2022 12:16:02 - INFO - __main__ -   Text: ['Worilti then drops it; Nasal claims that it can cause comedhons (talks my beard every']\n",
      "07/06/2022 12:16:04 - INFO - __main__ -   Epoch: 7 | Batch: 1800/4364 (41%) | G Loss: 5.031369 | C Loss: -3.862780\n",
      "07/06/2022 12:16:04 - INFO - __main__ -   Text: ['Record ó asleep, and pain is impossible, just dropping the \"Execute\" button for a fortnight as']\n",
      "07/06/2022 12:16:06 - INFO - __main__ -   Epoch: 7 | Batch: 2400/4364 (55%) | G Loss: 5.181570 | C Loss: -4.206730\n",
      "07/06/2022 12:16:06 - INFO - __main__ -   Text: ['Dr. V is surprised are dying but enra pleeds almost daily and called through his own isthmus,']\n",
      "07/06/2022 12:16:08 - INFO - __main__ -   Epoch: 7 | Batch: 3000/4364 (69%) | G Loss: 4.589252 | C Loss: -3.982393\n",
      "07/06/2022 12:16:08 - INFO - __main__ -   Text: ['According to Maryal Vito, who was long due for the Dhrames and noticed no distress outside the shop']\n",
      "07/06/2022 12:16:10 - INFO - __main__ -   Epoch: 7 | Batch: 3600/4364 (82%) | G Loss: 5.242267 | C Loss: -4.553618\n",
      "07/06/2022 12:16:10 - INFO - __main__ -   Text: ['Part of his effort was to become much larger; he had surgery in March and a blood count varied between 5 and']\n",
      "07/06/2022 12:16:12 - INFO - __main__ -   Epoch: 7 | Batch: 4200/4364 (96%) | G Loss: 4.440128 | C Loss: -3.847731\n",
      "07/06/2022 12:16:13 - INFO - __main__ -   Text: ['It is mentioned that the robot now has a huge roots, and produces at least 50,000']\n",
      "07/06/2022 12:16:13 - INFO - __main__ -   * (Train) Epoch: 7 | G Loss: 4.6904 | C Loss: -4.0265 | Updates G: 94 | Updates C: 269\n",
      "07/06/2022 12:16:27 - INFO - __main__ -   Bleu-2:0.405 | B-Bleu-2:0.292\n",
      "07/06/2022 12:16:27 - INFO - __main__ -   * Saving. Best Score:0.697 | Bleu-2:0.405 | B-Bleu-2:0.292\n",
      "07/06/2022 12:16:27 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6968129378831389\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 8 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.715\n",
      "  Average training loss discriminator: 1.299\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:18:55 - INFO - __main__ -   Epoch: 8 | Batch: 0/4330 (0%) | G Loss: 4.651422 | C Loss: -4.020066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 2.350\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:18:55 - INFO - __main__ -   Text: ['If an adult will have strokes as she was ruled diabetic at age 63, there are risks of ICV and']\n",
      "07/06/2022 12:18:57 - INFO - __main__ -   Epoch: 8 | Batch: 600/4330 (14%) | G Loss: 4.654204 | C Loss: -4.268357\n",
      "07/06/2022 12:18:57 - INFO - __main__ -   Text: ['ABF and 1/99/10 must practice each second after each descent,even if needing 12 breathe per']\n",
      "07/06/2022 12:19:00 - INFO - __main__ -   Epoch: 8 | Batch: 1200/4330 (28%) | G Loss: 4.702381 | C Loss: -3.878986\n",
      "07/06/2022 12:19:00 - INFO - __main__ -   Text: ['Short is down due to a daily performance deficiency shared via: memory is lower due to a weight loss shared caused by']\n",
      "07/06/2022 12:19:02 - INFO - __main__ -   Epoch: 8 | Batch: 1800/4330 (42%) | G Loss: 4.574953 | C Loss: -3.931801\n",
      "07/06/2022 12:19:02 - INFO - __main__ -   Text: ['Painfully, he insistedently makes recorded records while doxing, making use of constant exercises such as chicken –']\n",
      "07/06/2022 12:19:04 - INFO - __main__ -   Epoch: 8 | Batch: 2400/4330 (55%) | G Loss: 4.111141 | C Loss: -3.713466\n",
      "07/06/2022 12:19:04 - INFO - __main__ -   Text: ['GUM helped atmisable too alnivexminute with complications such as cardiac arity without']\n",
      "07/06/2022 12:19:06 - INFO - __main__ -   Epoch: 8 | Batch: 3000/4330 (69%) | G Loss: 5.009951 | C Loss: -4.146532\n",
      "07/06/2022 12:19:06 - INFO - __main__ -   Text: ['If they had any of their exercise training which evilophobe, push trem experts but you could muster them, you']\n",
      "07/06/2022 12:19:08 - INFO - __main__ -   Epoch: 8 | Batch: 3600/4330 (83%) | G Loss: 4.687593 | C Loss: -4.045958\n",
      "07/06/2022 12:19:08 - INFO - __main__ -   Text: [\"Hence, to achieve 'llownessness', 350 ml/kg of mediole glucoride (the\"]\n",
      "07/06/2022 12:19:10 - INFO - __main__ -   Epoch: 8 | Batch: 4200/4330 (97%) | G Loss: 4.749724 | C Loss: -3.446773\n",
      "07/06/2022 12:19:10 - INFO - __main__ -   Text: ['Nitrogen is suggested the quickest amount:5b) Lutt “massment forever” been will often']\n",
      "07/06/2022 12:19:11 - INFO - __main__ -   * (Train) Epoch: 8 | G Loss: 4.5856 | C Loss: -3.9001 | Updates G: 102 | Updates C: 258\n",
      "07/06/2022 12:19:25 - INFO - __main__ -   Bleu-2:0.420 | B-Bleu-2:0.306\n",
      "07/06/2022 12:19:25 - INFO - __main__ -   * Saving. Best Score:0.726 | Bleu-2:0.420 | B-Bleu-2:0.306\n",
      "07/06/2022 12:19:25 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7256970348562447\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 9 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.716\n",
      "  Average training loss discriminator: 1.116\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:21:53 - INFO - __main__ -   Epoch: 9 | Batch: 0/4372 (0%) | G Loss: 4.403572 | C Loss: -3.714888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 2.454\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:21:53 - INFO - __main__ -   Text: ['Encapted none for junk and 1ptor for spam; and 1ptone shall above 120.5\",']\n",
      "07/06/2022 12:21:55 - INFO - __main__ -   Epoch: 9 | Batch: 600/4372 (14%) | G Loss: 4.349333 | C Loss: -3.927914\n",
      "07/06/2022 12:21:55 - INFO - __main__ -   Text: ['Babu discontinued these two endless rounds with hundreds or even thousands of these, all being forgotten after inflation of two century']\n",
      "07/06/2022 12:21:57 - INFO - __main__ -   Epoch: 9 | Batch: 1200/4372 (27%) | G Loss: 4.913548 | C Loss: -3.307684\n",
      "07/06/2022 12:21:57 - INFO - __main__ -   Text: ['Casiano is also able to forget to discard his emotions, and does not miss any music from every day till']\n",
      "07/06/2022 12:21:59 - INFO - __main__ -   Epoch: 9 | Batch: 1800/4372 (41%) | G Loss: 4.480857 | C Loss: -3.966952\n",
      "07/06/2022 12:21:59 - INFO - __main__ -   Text: ['Feeling Stop Then p may initially feel depressed and ask then which will result in sudden discomfort in response to this or that']\n",
      "07/06/2022 12:22:01 - INFO - __main__ -   Epoch: 9 | Batch: 2400/4372 (55%) | G Loss: 4.425523 | C Loss: -3.786687\n",
      "07/06/2022 12:22:02 - INFO - __main__ -   Text: [\"This year, Kel'ina took the outright hit out of some cupcakes in the finals, fulfilling up\"]\n",
      "07/06/2022 12:22:04 - INFO - __main__ -   Epoch: 9 | Batch: 3000/4372 (69%) | G Loss: 4.495160 | C Loss: -3.906460\n",
      "07/06/2022 12:22:04 - INFO - __main__ -   Text: [\"That's when Shaft decides, it doubled a volume of beef every week with his weight and wet mouth and promised\"]\n",
      "07/06/2022 12:22:06 - INFO - __main__ -   Epoch: 9 | Batch: 3600/4372 (82%) | G Loss: 4.527019 | C Loss: -3.871417\n",
      "07/06/2022 12:22:06 - INFO - __main__ -   Text: ['Instructors have written 370 public TD out with no trouble since arriving either on the phone to anyone who has laps but']\n",
      "07/06/2022 12:22:08 - INFO - __main__ -   Epoch: 9 | Batch: 4200/4372 (96%) | G Loss: 4.341489 | C Loss: -3.735662\n",
      "07/06/2022 12:22:08 - INFO - __main__ -   Text: ['Bailey’s intention to better herself through pregnancy keeps her available in a short period ’kitty has 231']\n",
      "07/06/2022 12:22:09 - INFO - __main__ -   * (Train) Epoch: 9 | G Loss: 4.4081 | C Loss: -3.7543 | Updates G: 87 | Updates C: 277\n",
      "07/06/2022 12:22:22 - INFO - __main__ -   Bleu-2:0.404 | B-Bleu-2:0.299\n",
      "07/06/2022 12:22:22 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702208488642454\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 10 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.717\n",
      "  Average training loss discriminator: 0.993\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:24:50 - INFO - __main__ -   Epoch: 10 | Batch: 0/4473 (0%) | G Loss: 4.433750 | C Loss: -3.766413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 2.532\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:24:50 - INFO - __main__ -   Text: ['Instead of clamping her feet, she lifts the cup and licks ductempo to the same rhythm by']\n",
      "07/06/2022 12:24:52 - INFO - __main__ -   Epoch: 10 | Batch: 600/4473 (13%) | G Loss: 4.457379 | C Loss: -3.843458\n",
      "07/06/2022 12:24:52 - INFO - __main__ -   Text: ['His lips were actually frozen as he was under an iron spell, rumours were that Christopher was under an iron cookie as']\n",
      "07/06/2022 12:24:54 - INFO - __main__ -   Epoch: 10 | Batch: 1200/4473 (27%) | G Loss: 4.839889 | C Loss: -3.660856\n",
      "07/06/2022 12:24:54 - INFO - __main__ -   Text: ['However’s internet is mostly online as he struggles with eating and is unable to exercise regularly, according to his']\n",
      "07/06/2022 12:24:56 - INFO - __main__ -   Epoch: 10 | Batch: 1800/4473 (40%) | G Loss: 4.695998 | C Loss: -4.041117\n",
      "07/06/2022 12:24:56 - INFO - __main__ -   Text: ['If you put a flywheel on it, it will spin to a low rate while being slowed, indefinitely, or']\n",
      "07/06/2022 12:24:59 - INFO - __main__ -   Epoch: 10 | Batch: 2400/4473 (54%) | G Loss: 4.072927 | C Loss: -3.514557\n",
      "07/06/2022 12:24:59 - INFO - __main__ -   Text: ['In his frustration, poet of the year and a day old, Boynet soon died and he was soon unable to']\n",
      "07/06/2022 12:25:01 - INFO - __main__ -   Epoch: 10 | Batch: 3000/4473 (67%) | G Loss: 4.770893 | C Loss: -3.434842\n",
      "07/06/2022 12:25:01 - INFO - __main__ -   Text: ['Opposition is lower than that of a hip replacement which puts the person on a new faith when there is less constant']\n",
      "07/06/2022 12:25:03 - INFO - __main__ -   Epoch: 10 | Batch: 3600/4473 (80%) | G Loss: 4.460526 | C Loss: -3.709945\n",
      "07/06/2022 12:25:03 - INFO - __main__ -   Text: ['Absolution: tired, drained and depressed three-month cycle take over, the programmes have come and gone - for']\n",
      "07/06/2022 12:25:05 - INFO - __main__ -   Epoch: 10 | Batch: 4200/4473 (94%) | G Loss: 4.492865 | C Loss: -3.940225\n",
      "07/06/2022 12:25:05 - INFO - __main__ -   Text: ['In addition, as some endocrinologists in studies are wasting, there are times when a doctor may put 10 kg']\n",
      "07/06/2022 12:25:06 - INFO - __main__ -   * (Train) Epoch: 10 | G Loss: 4.2799 | C Loss: -3.6644 | Updates G: 106 | Updates C: 266\n",
      "07/06/2022 12:25:20 - INFO - __main__ -   Bleu-2:0.417 | B-Bleu-2:0.292\n",
      "07/06/2022 12:25:20 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7086126510348036\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 11 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.717\n",
      "  Average training loss discriminator: 0.926\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:27:48 - INFO - __main__ -   Epoch: 11 | Batch: 0/4473 (0%) | G Loss: 4.234250 | C Loss: -3.593594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 2.610\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:27:48 - INFO - __main__ -   Text: ['(He does not even joke when talk shows >CART> or <Ginet>) issued in this Spring']\n",
      "07/06/2022 12:27:50 - INFO - __main__ -   Epoch: 11 | Batch: 600/4473 (13%) | G Loss: 4.185150 | C Loss: -3.576699\n",
      "07/06/2022 12:27:50 - INFO - __main__ -   Text: ['Whites may not possess much caffeine, but that is not the last feeling: Beedoff makes the same connection when']\n",
      "07/06/2022 12:27:52 - INFO - __main__ -   Epoch: 11 | Batch: 1200/4473 (27%) | G Loss: 4.352085 | C Loss: -3.451308\n",
      "07/06/2022 12:27:53 - INFO - __main__ -   Text: ['As Tetris, his expression has gained a little bit of roving, and his maul muscle has become']\n",
      "07/06/2022 12:27:54 - INFO - __main__ -   Epoch: 11 | Batch: 1800/4473 (40%) | G Loss: 4.125967 | C Loss: -3.405948\n",
      "07/06/2022 12:27:55 - INFO - __main__ -   Text: ['Since, this is how the NKNDG settership becomes to all the bullies that roll on.']\n",
      "07/06/2022 12:27:57 - INFO - __main__ -   Epoch: 11 | Batch: 2400/4473 (54%) | G Loss: 4.369746 | C Loss: -3.625789\n",
      "07/06/2022 12:27:57 - INFO - __main__ -   Text: ['\"Though therapy is extremely demanding, I do not use Addictive strategies and mediate regularly the condition of my teeth']\n",
      "07/06/2022 12:27:59 - INFO - __main__ -   Epoch: 11 | Batch: 3000/4473 (67%) | G Loss: 4.427394 | C Loss: -3.586591\n",
      "07/06/2022 12:27:59 - INFO - __main__ -   Text: ['Ant-,couldnt, knew already Jr., will sooner be available in another account and thus would only have to pay']\n",
      "07/06/2022 12:28:01 - INFO - __main__ -   Epoch: 11 | Batch: 3600/4473 (80%) | G Loss: 4.219629 | C Loss: -3.070222\n",
      "07/06/2022 12:28:01 - INFO - __main__ -   Text: ['It was initially reported that she would be getting a half pittance, additional progressions still had paid after 23 months']\n",
      "07/06/2022 12:28:03 - INFO - __main__ -   Epoch: 11 | Batch: 4200/4473 (94%) | G Loss: 3.996657 | C Loss: -3.419818\n",
      "07/06/2022 12:28:03 - INFO - __main__ -   Text: ['TheChild will remain untreated for a few days as Malal is still recovering from a botched diet (1) available']\n",
      "07/06/2022 12:28:04 - INFO - __main__ -   * (Train) Epoch: 11 | G Loss: 4.1247 | C Loss: -3.4950 | Updates G: 116 | Updates C: 256\n",
      "07/06/2022 12:28:18 - INFO - __main__ -   Bleu-2:0.420 | B-Bleu-2:0.287\n",
      "07/06/2022 12:28:18 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7066546878235199\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 12 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.717\n",
      "  Average training loss discriminator: 0.876\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:30:46 - INFO - __main__ -   Epoch: 12 | Batch: 0/4327 (0%) | G Loss: 3.843779 | C Loss: -3.335376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 2.688\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:30:46 - INFO - __main__ -   Text: ['\"BT is hardly free of stress... he needs to regain his sources of energy and his bike rate when he sleeps']\n",
      "07/06/2022 12:30:48 - INFO - __main__ -   Epoch: 12 | Batch: 600/4327 (14%) | G Loss: 4.262588 | C Loss: -3.469727\n",
      "07/06/2022 12:30:48 - INFO - __main__ -   Text: ['A typical adult has around 10 to 15 minutes of sleep, at which point the child has to take bath or wear']\n",
      "07/06/2022 12:30:50 - INFO - __main__ -   Epoch: 12 | Batch: 1200/4327 (28%) | G Loss: 4.283244 | C Loss: -3.383583\n",
      "07/06/2022 12:30:51 - INFO - __main__ -   Text: ['It also performs better with newer phones (65%) than plasma, sometimes mixing up the performance with arefools']\n",
      "07/06/2022 12:30:53 - INFO - __main__ -   Epoch: 12 | Batch: 1800/4327 (42%) | G Loss: 3.832066 | C Loss: -2.570826\n",
      "07/06/2022 12:30:53 - INFO - __main__ -   Text: ['After dieting food, inexpluitantly, it contains adhering to sainthood: \"A']\n",
      "07/06/2022 12:30:55 - INFO - __main__ -   Epoch: 12 | Batch: 2400/4327 (55%) | G Loss: 3.717633 | C Loss: -3.371581\n",
      "07/06/2022 12:30:55 - INFO - __main__ -   Text: ['Later, while pinning my pretend tendon and turning him on(fasting) and causing Dialysis Road to bleed']\n",
      "07/06/2022 12:30:57 - INFO - __main__ -   Epoch: 12 | Batch: 3000/4327 (69%) | G Loss: 3.477015 | C Loss: -2.955420\n",
      "07/06/2022 12:30:57 - INFO - __main__ -   Text: ['Guru Nanathil and colleagues reported 48 deaths in total for heliocon, 8 total deaths for heliocon']\n",
      "07/06/2022 12:30:59 - INFO - __main__ -   Epoch: 12 | Batch: 3600/4327 (83%) | G Loss: 3.653269 | C Loss: -2.911191\n",
      "07/06/2022 12:30:59 - INFO - __main__ -   Text: ['Still, after experiencing phroidtic episodes for a short time on D trompegfaz (set before']\n",
      "07/06/2022 12:31:01 - INFO - __main__ -   Epoch: 12 | Batch: 4200/4327 (97%) | G Loss: 3.925547 | C Loss: -3.467170\n",
      "07/06/2022 12:31:02 - INFO - __main__ -   Text: [\"Von Zuijster's μ's are now a huge pleasure because he does many lean movements (which are almost\"]\n",
      "07/06/2022 12:31:02 - INFO - __main__ -   * (Train) Epoch: 12 | G Loss: 3.9022 | C Loss: -3.2909 | Updates G: 113 | Updates C: 247\n",
      "07/06/2022 12:31:16 - INFO - __main__ -   Bleu-2:0.441 | B-Bleu-2:0.310\n",
      "07/06/2022 12:31:16 - INFO - __main__ -   * Saving. Best Score:0.751 | Bleu-2:0.441 | B-Bleu-2:0.310\n",
      "07/06/2022 12:31:16 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7513949758582849\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 13 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.716\n",
      "  Average training loss discriminator: 0.845\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:33:44 - INFO - __main__ -   Epoch: 13 | Batch: 0/4417 (0%) | G Loss: 3.334579 | C Loss: -2.490713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.225\n",
      "  Test Loss: 2.788\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:33:44 - INFO - __main__ -   Text: ['Marian and her partner (both self booked)\" were spotted on his desk at the end of the song, and shown']\n",
      "07/06/2022 12:33:46 - INFO - __main__ -   Epoch: 13 | Batch: 600/4417 (14%) | G Loss: 3.506152 | C Loss: -2.947740\n",
      "07/06/2022 12:33:46 - INFO - __main__ -   Text: [\"The dentist won, by Alzheimer's diagnosis, in the interim, £3.99/day () and a\"]\n",
      "07/06/2022 12:33:48 - INFO - __main__ -   Epoch: 13 | Batch: 1200/4417 (27%) | G Loss: 3.828966 | C Loss: -3.273105\n",
      "07/06/2022 12:33:48 - INFO - __main__ -   Text: ['Electrical bit breaks took place to save his life while leaving nothing to hear of pain rays, as it had been with']\n",
      "07/06/2022 12:33:50 - INFO - __main__ -   Epoch: 13 | Batch: 1800/4417 (41%) | G Loss: 3.372278 | C Loss: -2.922885\n",
      "07/06/2022 12:33:50 - INFO - __main__ -   Text: ['The test results showed that in the beginning year students cannot coming in normally, and therefore without fresh inhalation and contact']\n",
      "07/06/2022 12:33:52 - INFO - __main__ -   Epoch: 13 | Batch: 2400/4417 (54%) | G Loss: 3.849449 | C Loss: -3.190011\n",
      "07/06/2022 12:33:53 - INFO - __main__ -   Text: ['There are ratings that can assist in tracing the rope and listing each row after tip kw37 with Pet Droper']\n",
      "07/06/2022 12:33:55 - INFO - __main__ -   Epoch: 13 | Batch: 3000/4417 (68%) | G Loss: 3.904928 | C Loss: -3.477412\n",
      "07/06/2022 12:33:55 - INFO - __main__ -   Text: ['Zelena is usually supertapesome (veryly \"dancing\") and develops severe suffusive pitch on']\n",
      "07/06/2022 12:33:57 - INFO - __main__ -   Epoch: 13 | Batch: 3600/4417 (82%) | G Loss: 3.482168 | C Loss: -2.935953\n",
      "07/06/2022 12:33:57 - INFO - __main__ -   Text: ['With a grief\"♰ and a \"gunshot when unsure\"al headbleeding in the gym from']\n",
      "07/06/2022 12:33:59 - INFO - __main__ -   Epoch: 13 | Batch: 4200/4417 (95%) | G Loss: 3.406302 | C Loss: -2.834238\n",
      "07/06/2022 12:33:59 - INFO - __main__ -   Text: ['Michelli was under the impression he should only smoke tobacco but got sent to']\n",
      "07/06/2022 12:34:00 - INFO - __main__ -   * (Train) Epoch: 13 | G Loss: 3.7445 | C Loss: -3.1550 | Updates G: 118 | Updates C: 250\n",
      "07/06/2022 12:34:14 - INFO - __main__ -   Bleu-2:0.443 | B-Bleu-2:0.299\n",
      "07/06/2022 12:34:14 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7417840615874605\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 14 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.714\n",
      "  Average training loss discriminator: 0.826\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:36:42 - INFO - __main__ -   Epoch: 14 | Batch: 0/4322 (0%) | G Loss: 3.807409 | C Loss: -3.045511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.228\n",
      "  Test Loss: 2.837\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:36:42 - INFO - __main__ -   Text: ['\"dognately liquids or water\") didn\\'t leave a significant amount of blood as it was \"before 4']\n",
      "07/06/2022 12:36:44 - INFO - __main__ -   Epoch: 14 | Batch: 600/4322 (14%) | G Loss: 4.122451 | C Loss: -3.216952\n",
      "07/06/2022 12:36:44 - INFO - __main__ -   Text: ['In the past, he was able to see himself after performing various routines and tend to bouts of rage members have been']\n",
      "07/06/2022 12:36:46 - INFO - __main__ -   Epoch: 14 | Batch: 1200/4322 (28%) | G Loss: 3.432137 | C Loss: -2.949182\n",
      "07/06/2022 12:36:46 - INFO - __main__ -   Text: ['Indeed, Jones lost all blood in his blood series to cancer and can barely control his own blood and sing happens weekly']\n",
      "07/06/2022 12:36:48 - INFO - __main__ -   Epoch: 14 | Batch: 1800/4322 (42%) | G Loss: 3.431871 | C Loss: -2.986839\n",
      "07/06/2022 12:36:48 - INFO - __main__ -   Text: ['Bye now, in life you didn\\'t put yourself in danger, so you delayed your meals for two hours\", -']\n",
      "07/06/2022 12:36:50 - INFO - __main__ -   Epoch: 14 | Batch: 2400/4322 (56%) | G Loss: 3.400771 | C Loss: -2.857299\n",
      "07/06/2022 12:36:50 - INFO - __main__ -   Text: [\"She went on to delay the birth of her daughter for 1 year, as per her father's orders in the early\"]\n",
      "07/06/2022 12:36:53 - INFO - __main__ -   Epoch: 14 | Batch: 3000/4322 (69%) | G Loss: 3.610804 | C Loss: -3.053334\n",
      "07/06/2022 12:36:53 - INFO - __main__ -   Text: ['William\\'s seeming intermittent frustration keeps him from experiencing moneyed \"torrento\"s for 4 tests, over the']\n",
      "07/06/2022 12:36:55 - INFO - __main__ -   Epoch: 14 | Batch: 3600/4322 (83%) | G Loss: 3.914837 | C Loss: -3.164072\n",
      "07/06/2022 12:36:55 - INFO - __main__ -   Text: ['But, Efi continues, microphones are the only pillar: \"Speaking... Freeing...\"\".']\n",
      "07/06/2022 12:36:57 - INFO - __main__ -   Epoch: 14 | Batch: 4200/4322 (97%) | G Loss: 3.612300 | C Loss: -2.838174\n",
      "07/06/2022 12:36:57 - INFO - __main__ -   Text: ['He continues doing record keeping, attending 32.4% monthly growth in backup Jesus plans for the next years,']\n",
      "07/06/2022 12:36:57 - INFO - __main__ -   * (Train) Epoch: 14 | G Loss: 3.5340 | C Loss: -2.9949 | Updates G: 109 | Updates C: 251\n",
      "07/06/2022 12:37:11 - INFO - __main__ -   Bleu-2:0.431 | B-Bleu-2:0.300\n",
      "07/06/2022 12:37:11 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7314945378229917\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 15 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:37.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.714\n",
      "  Average training loss discriminator: 0.811\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:39:39 - INFO - __main__ -   Epoch: 15 | Batch: 0/4527 (0%) | G Loss: 3.118749 | C Loss: -2.864873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.223\n",
      "  Test Loss: 2.901\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:39:40 - INFO - __main__ -   Text: ['Gains are measured after routine physical exercise including walking for 2 minutes per day for 6 months, followed by walk for']\n",
      "07/06/2022 12:39:42 - INFO - __main__ -   Epoch: 15 | Batch: 600/4527 (13%) | G Loss: 3.187122 | C Loss: -2.868501\n",
      "07/06/2022 12:39:42 - INFO - __main__ -   Text: ['Following protracted labor, and even called scolding progress on Facebook during which time it was given 0.25sec;']\n",
      "07/06/2022 12:39:44 - INFO - __main__ -   Epoch: 15 | Batch: 1200/4527 (27%) | G Loss: 3.327927 | C Loss: -2.725847\n",
      "07/06/2022 12:39:44 - INFO - __main__ -   Text: ['After everything, pirates will drive to seek companionship and the rear end drives to search for waves of converts (in']\n",
      "07/06/2022 12:39:46 - INFO - __main__ -   Epoch: 15 | Batch: 1800/4527 (40%) | G Loss: 3.535399 | C Loss: -2.900480\n",
      "07/06/2022 12:39:46 - INFO - __main__ -   Text: ['AWeller () often exhibits relief two to three times before he laps says he damages when hit in third or fourth']\n",
      "07/06/2022 12:39:48 - INFO - __main__ -   Epoch: 15 | Batch: 2400/4527 (53%) | G Loss: 3.236798 | C Loss: -2.277706\n",
      "07/06/2022 12:39:48 - INFO - __main__ -   Text: ['Izzy is extremely unreachable, and the tape says \"it\\'s probably the hardest I have ever done Doctor\" While']\n",
      "07/06/2022 12:39:50 - INFO - __main__ -   Epoch: 15 | Batch: 3000/4527 (66%) | G Loss: 3.448396 | C Loss: -2.927182\n",
      "07/06/2022 12:39:50 - INFO - __main__ -   Text: ['Unlike most Mensa countries, leaving boys standing for three years pasta is favoured, as it is not necessary one day']\n",
      "07/06/2022 12:39:52 - INFO - __main__ -   Epoch: 15 | Batch: 3600/4527 (80%) | G Loss: 3.399606 | C Loss: -2.910163\n",
      "07/06/2022 12:39:52 - INFO - __main__ -   Text: ['I am very astonished that I did not give life, and that I write and respond to other cancers like Ramines']\n",
      "07/06/2022 12:39:54 - INFO - __main__ -   Epoch: 15 | Batch: 4200/4527 (93%) | G Loss: 3.253312 | C Loss: -2.701580\n",
      "07/06/2022 12:39:55 - INFO - __main__ -   Text: ['In a statement, one vegan user reports: minrows子 said that is when IoS heat [may']\n",
      "07/06/2022 12:39:56 - INFO - __main__ -   * (Train) Epoch: 15 | G Loss: 3.3848 | C Loss: -2.8371 | Updates G: 116 | Updates C: 261\n",
      "07/06/2022 12:40:09 - INFO - __main__ -   Bleu-2:0.437 | B-Bleu-2:0.292\n",
      "07/06/2022 12:40:09 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7285386253417337\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 16 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.714\n",
      "  Average training loss discriminator: 0.796\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:42:37 - INFO - __main__ -   Epoch: 16 | Batch: 0/4467 (0%) | G Loss: 3.255506 | C Loss: -2.582583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 2.948\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:42:38 - INFO - __main__ -   Text: ['After applying the filters (womens and women) on its temperature record on overnight radio, it achieved - office']\n",
      "07/06/2022 12:42:39 - INFO - __main__ -   Epoch: 16 | Batch: 600/4467 (13%) | G Loss: 3.505203 | C Loss: -2.878113\n",
      "07/06/2022 12:42:40 - INFO - __main__ -   Text: ['In addition, the only medication that most potential candidates in this treatment have used is to pack their blood into a small']\n",
      "07/06/2022 12:42:42 - INFO - __main__ -   Epoch: 16 | Batch: 1200/4467 (27%) | G Loss: 3.331317 | C Loss: -2.701888\n",
      "07/06/2022 12:42:42 - INFO - __main__ -   Text: ['Poisonis was quick to forget, and presented texts that used a daring phrase: Extollunging pills cross']\n",
      "07/06/2022 12:42:44 - INFO - __main__ -   Epoch: 16 | Batch: 1800/4467 (40%) | G Loss: 3.380989 | C Loss: -2.912809\n",
      "07/06/2022 12:42:44 - INFO - __main__ -   Text: ['Then another girl called \"Kongchan\" started a ramification of the Mindless story, but it wasn\\'t']\n",
      "07/06/2022 12:42:46 - INFO - __main__ -   Epoch: 16 | Batch: 2400/4467 (54%) | G Loss: 3.937039 | C Loss: -2.508323\n",
      "07/06/2022 12:42:46 - INFO - __main__ -   Text: [\"Like a fake cop, 35,000 years after his test he takes a step back to the 'step watch',\"]\n",
      "07/06/2022 12:42:48 - INFO - __main__ -   Epoch: 16 | Batch: 3000/4467 (67%) | G Loss: 3.266368 | C Loss: -2.561044\n",
      "07/06/2022 12:42:48 - INFO - __main__ -   Text: ['Balcas has yet to seem to produce a synthetic soap thoughwatchNote and Craugh notes \"Liveline\\'s']\n",
      "07/06/2022 12:42:50 - INFO - __main__ -   Epoch: 16 | Batch: 3600/4467 (81%) | G Loss: 3.172724 | C Loss: -2.692849\n",
      "07/06/2022 12:42:50 - INFO - __main__ -   Text: ['It was an elliptic free podcast presented 3-5 sleepless hours a day for 5 days, due to the']\n",
      "07/06/2022 12:42:52 - INFO - __main__ -   Epoch: 16 | Batch: 4200/4467 (94%) | G Loss: 2.918622 | C Loss: -2.602850\n",
      "07/06/2022 12:42:52 - INFO - __main__ -   Text: ['Cast into play, saying yes with your bedside eyes on like \"Spanish, orberg ank\" that inflicts']\n",
      "07/06/2022 12:42:53 - INFO - __main__ -   * (Train) Epoch: 16 | G Loss: 3.2152 | C Loss: -2.7042 | Updates G: 109 | Updates C: 263\n",
      "07/06/2022 12:43:07 - INFO - __main__ -   Bleu-2:0.428 | B-Bleu-2:0.300\n",
      "07/06/2022 12:43:07 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7273262818696787\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 17 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.712\n",
      "  Average training loss discriminator: 0.791\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:45:35 - INFO - __main__ -   Epoch: 17 | Batch: 0/4364 (0%) | G Loss: 2.679245 | C Loss: -2.463805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.223\n",
      "  Test Loss: 2.996\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:45:36 - INFO - __main__ -   Text: ['It takes me about 4 to 5 hours to recycle every piece that I look at in this cartridge, the only one']\n",
      "07/06/2022 12:45:38 - INFO - __main__ -   Epoch: 17 | Batch: 600/4364 (14%) | G Loss: 3.059042 | C Loss: -2.575530\n",
      "07/06/2022 12:45:38 - INFO - __main__ -   Text: [\"While the RFID captures volume, recording the duo's operation at the same level as their standard HMV @\"]\n",
      "07/06/2022 12:45:40 - INFO - __main__ -   Epoch: 17 | Batch: 1200/4364 (27%) | G Loss: 2.988751 | C Loss: -2.856853\n",
      "07/06/2022 12:45:40 - INFO - __main__ -   Text: ['For example, the probiotics induced novelty for about 25 on their survey and returned when asked if they can eat a']\n",
      "07/06/2022 12:45:42 - INFO - __main__ -   Epoch: 17 | Batch: 1800/4364 (41%) | G Loss: 3.097707 | C Loss: -2.699998\n",
      "07/06/2022 12:45:42 - INFO - __main__ -   Text: [\"Colasco's confusion comes through and Curry collapses every two seconds, conflicting her praise and rightness and all that\"]\n",
      "07/06/2022 12:45:44 - INFO - __main__ -   Epoch: 17 | Batch: 2400/4364 (55%) | G Loss: 3.408044 | C Loss: -2.916441\n",
      "07/06/2022 12:45:44 - INFO - __main__ -   Text: ['When using the long press drug, this UTV /blog/daily/postheal time-saving ability was']\n",
      "07/06/2022 12:45:46 - INFO - __main__ -   Epoch: 17 | Batch: 3000/4364 (69%) | G Loss: 3.035222 | C Loss: -2.571096\n",
      "07/06/2022 12:45:46 - INFO - __main__ -   Text: ['Initially, I was really worried about the hardness of the dings, but the doctor assured me that I would only']\n",
      "07/06/2022 12:45:48 - INFO - __main__ -   Epoch: 17 | Batch: 3600/4364 (82%) | G Loss: 2.737655 | C Loss: -2.582017\n",
      "07/06/2022 12:45:49 - INFO - __main__ -   Text: [\"Gay and I have to come back to join dudes with sinew, but I wasn't able to find any\"]\n",
      "07/06/2022 12:45:51 - INFO - __main__ -   Epoch: 17 | Batch: 4200/4364 (96%) | G Loss: 3.134582 | C Loss: -2.562546\n",
      "07/06/2022 12:45:51 - INFO - __main__ -   Text: ['Tanooki had may med five sessions of no penis annually, but his gorgeous body allowed him to still use his']\n",
      "07/06/2022 12:45:51 - INFO - __main__ -   * (Train) Epoch: 17 | G Loss: 3.0351 | C Loss: -2.5639 | Updates G: 128 | Updates C: 235\n",
      "07/06/2022 12:46:05 - INFO - __main__ -   Bleu-2:0.448 | B-Bleu-2:0.314\n",
      "07/06/2022 12:46:05 - INFO - __main__ -   * Saving. Best Score:0.761 | Bleu-2:0.448 | B-Bleu-2:0.314\n",
      "07/06/2022 12:46:05 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7614634221471188\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 18 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.712\n",
      "  Average training loss discriminator: 0.784\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:48:33 - INFO - __main__ -   Epoch: 18 | Batch: 0/4330 (0%) | G Loss: 2.860883 | C Loss: -2.531332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 3.074\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:48:33 - INFO - __main__ -   Text: ['Then two years later they found out that the Revise dose left acid on the tooth surface and the yellowish polar']\n",
      "07/06/2022 12:48:35 - INFO - __main__ -   Epoch: 18 | Batch: 600/4330 (14%) | G Loss: 2.966841 | C Loss: -2.538414\n",
      "07/06/2022 12:48:35 - INFO - __main__ -   Text: ['Exabarther, especially after being told in Dhaesa that he has just 2 meals for 15 days,']\n",
      "07/06/2022 12:48:37 - INFO - __main__ -   Epoch: 18 | Batch: 1200/4330 (28%) | G Loss: 2.921577 | C Loss: -2.457111\n",
      "07/06/2022 12:48:38 - INFO - __main__ -   Text: ['Vistarius gave the inside track of how she climbed faster, moved her pegs, took concentration, and that']\n",
      "07/06/2022 12:48:40 - INFO - __main__ -   Epoch: 18 | Batch: 1800/4330 (42%) | G Loss: 3.287549 | C Loss: -2.574350\n",
      "07/06/2022 12:48:40 - INFO - __main__ -   Text: ['When increase in life stress is aggravated by a meal, sulleone triggers LH2 setup| takes SRSI']\n",
      "07/06/2022 12:48:42 - INFO - __main__ -   Epoch: 18 | Batch: 2400/4330 (55%) | G Loss: 2.693312 | C Loss: -2.286993\n",
      "07/06/2022 12:48:42 - INFO - __main__ -   Text: ['Just because they are not seen as sweet or romantic, and just because they are British, or if they are unaware']\n",
      "07/06/2022 12:48:44 - INFO - __main__ -   Epoch: 18 | Batch: 3000/4330 (69%) | G Loss: 2.679259 | C Loss: -2.294771\n",
      "07/06/2022 12:48:44 - INFO - __main__ -   Text: ['It repeatedly vomiting crumbs in bed, eating away at it, and after losing 1000 calories, vomiting after losing 1000']\n",
      "07/06/2022 12:48:46 - INFO - __main__ -   Epoch: 18 | Batch: 3600/4330 (83%) | G Loss: 2.763184 | C Loss: -2.365366\n",
      "07/06/2022 12:48:46 - INFO - __main__ -   Text: ['He and his partner, Faith and Tiffany, quit smoking voluntarily, using their skin cream as they receive treatment, and']\n",
      "07/06/2022 12:48:48 - INFO - __main__ -   Epoch: 18 | Batch: 4200/4330 (97%) | G Loss: 2.809593 | C Loss: -2.110125\n",
      "07/06/2022 12:48:48 - INFO - __main__ -   Text: ['It is taking with it 2 courses of High - Very Low, and Ni drinking in it first 1']\n",
      "07/06/2022 12:48:49 - INFO - __main__ -   * (Train) Epoch: 18 | G Loss: 2.9066 | C Loss: -2.4251 | Updates G: 105 | Updates C: 255\n",
      "07/06/2022 12:49:03 - INFO - __main__ -   Bleu-2:0.449 | B-Bleu-2:0.302\n",
      "07/06/2022 12:49:03 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7516544710151462\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 19 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.712\n",
      "  Average training loss discriminator: 0.773\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:51:31 - INFO - __main__ -   Epoch: 19 | Batch: 0/4372 (0%) | G Loss: 2.900609 | C Loss: -2.288184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.223\n",
      "  Test Loss: 3.147\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:51:31 - INFO - __main__ -   Text: ['File credits include: \"This scene is a large part of my childhood story since I tried you before if you gave']\n",
      "07/06/2022 12:51:33 - INFO - __main__ -   Epoch: 19 | Batch: 600/4372 (14%) | G Loss: 2.964895 | C Loss: -2.418423\n",
      "07/06/2022 12:51:33 - INFO - __main__ -   Text: ['The severity with which Katie might recover is 8-12 x weeks (2 weeks dorm/grows lifestyle']\n",
      "07/06/2022 12:51:35 - INFO - __main__ -   Epoch: 19 | Batch: 1200/4372 (27%) | G Loss: 2.718499 | C Loss: -2.399642\n",
      "07/06/2022 12:51:35 - INFO - __main__ -   Text: ['This is a poor visual deficiency lifer, your only competition with PBJ is your wrist, but after this,']\n",
      "07/06/2022 12:51:37 - INFO - __main__ -   Epoch: 19 | Batch: 1800/4372 (41%) | G Loss: 2.989300 | C Loss: -2.469932\n",
      "07/06/2022 12:51:37 - INFO - __main__ -   Text: ['He writes \"`dromed recover too much but now nothing seems to give us anything except a tough reprieve']\n",
      "07/06/2022 12:51:39 - INFO - __main__ -   Epoch: 19 | Batch: 2400/4372 (55%) | G Loss: 2.777274 | C Loss: -2.449372\n",
      "07/06/2022 12:51:39 - INFO - __main__ -   Text: ['Inside, she continues to do well at gym, making her twenty-eightth highest rated race after three weeks']\n",
      "07/06/2022 12:51:41 - INFO - __main__ -   Epoch: 19 | Batch: 3000/4372 (69%) | G Loss: 2.890800 | C Loss: -2.317509\n",
      "07/06/2022 12:51:42 - INFO - __main__ -   Text: ['Moslem has done self-meditation on his side of the picture, but when the day they got ragged']\n",
      "07/06/2022 12:51:44 - INFO - __main__ -   Epoch: 19 | Batch: 3600/4372 (82%) | G Loss: 2.934023 | C Loss: -2.337187\n",
      "07/06/2022 12:51:44 - INFO - __main__ -   Text: ['Hardsley says that his ability to place his food sequentially fails 11% of the time, the results of']\n",
      "07/06/2022 12:51:46 - INFO - __main__ -   Epoch: 19 | Batch: 4200/4372 (96%) | G Loss: 2.418914 | C Loss: -2.152760\n",
      "07/06/2022 12:51:46 - INFO - __main__ -   Text: ['Opposing to frequent, assorted alcohol intake, Pesus may consume less liquid than the regular diet increased by egg options']\n",
      "07/06/2022 12:51:46 - INFO - __main__ -   * (Train) Epoch: 19 | G Loss: 2.7513 | C Loss: -2.3011 | Updates G: 117 | Updates C: 247\n",
      "07/06/2022 12:52:01 - INFO - __main__ -   Bleu-2:0.469 | B-Bleu-2:0.316\n",
      "07/06/2022 12:52:01 - INFO - __main__ -   * Saving. Best Score:0.784 | Bleu-2:0.469 | B-Bleu-2:0.316\n",
      "07/06/2022 12:52:01 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7844855812357372\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 20 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.711\n",
      "  Average training loss discriminator: 0.767\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:54:29 - INFO - __main__ -   Epoch: 20 | Batch: 0/4473 (0%) | G Loss: 2.684272 | C Loss: -2.260749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.217\n",
      "  Test Loss: 3.159\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:54:29 - INFO - __main__ -   Text: ['Such was the previous \"Storyboard Car Pro challenge\", however, the \"Uncle Teresa\" featured suffered a suffering']\n",
      "07/06/2022 12:54:31 - INFO - __main__ -   Epoch: 20 | Batch: 600/4473 (13%) | G Loss: 2.500075 | C Loss: -2.107624\n",
      "07/06/2022 12:54:31 - INFO - __main__ -   Text: ['She tells \"lescha is good and sex free because the scales are too small for 3 x 6 cups and']\n",
      "07/06/2022 12:54:33 - INFO - __main__ -   Epoch: 20 | Batch: 1200/4473 (27%) | G Loss: 2.524208 | C Loss: -1.597547\n",
      "07/06/2022 12:54:33 - INFO - __main__ -   Text: ['The variation of the breath osmogram shows outward split (with most streaks getting smaller and the latter times being slower']\n",
      "07/06/2022 12:54:35 - INFO - __main__ -   Epoch: 20 | Batch: 1800/4473 (40%) | G Loss: 2.643621 | C Loss: -2.203085\n",
      "07/06/2022 12:54:36 - INFO - __main__ -   Text: ['O Wait till your nose pops off and eat Chips*, but The customer can wake up later if you pour water and']\n",
      "07/06/2022 12:54:38 - INFO - __main__ -   Epoch: 20 | Batch: 2400/4473 (54%) | G Loss: 2.431889 | C Loss: -2.163888\n",
      "07/06/2022 12:54:38 - INFO - __main__ -   Text: ['giwiFE rounds up on every bite – 0.02 Me free until hours after removing the']\n",
      "07/06/2022 12:54:40 - INFO - __main__ -   Epoch: 20 | Batch: 3000/4473 (67%) | G Loss: 2.664254 | C Loss: -1.870637\n",
      "07/06/2022 12:54:40 - INFO - __main__ -   Text: [\"It's no longer known whether the virus causes bruise fever, stomach flu, ectopy (Weight abnormally\"]\n",
      "07/06/2022 12:54:42 - INFO - __main__ -   Epoch: 20 | Batch: 3600/4473 (80%) | G Loss: 2.772756 | C Loss: -2.094232\n",
      "07/06/2022 12:54:42 - INFO - __main__ -   Text: ['On a pre-game note, this month, she added strippers to her list of very slow dance moves and']\n",
      "07/06/2022 12:54:44 - INFO - __main__ -   Epoch: 20 | Batch: 4200/4473 (94%) | G Loss: 2.402250 | C Loss: -2.118707\n",
      "07/06/2022 12:54:44 - INFO - __main__ -   Text: ['Following several months of follow-up, the blood levels in the chorin at this point have eased somewhat due']\n",
      "07/06/2022 12:54:45 - INFO - __main__ -   * (Train) Epoch: 20 | G Loss: 2.6087 | C Loss: -2.1649 | Updates G: 125 | Updates C: 247\n",
      "07/06/2022 12:54:59 - INFO - __main__ -   Bleu-2:0.434 | B-Bleu-2:0.301\n",
      "07/06/2022 12:54:59 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735155481753722\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 21 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.711\n",
      "  Average training loss discriminator: 0.760\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:57:27 - INFO - __main__ -   Epoch: 21 | Batch: 0/4473 (0%) | G Loss: 2.398891 | C Loss: -2.104546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.223\n",
      "  Test Loss: 3.267\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 12:57:27 - INFO - __main__ -   Text: ['Even slow songs are \"broken\" again upon re-use by a UK publication record, which occurs in 600']\n",
      "07/06/2022 12:57:29 - INFO - __main__ -   Epoch: 21 | Batch: 600/4473 (13%) | G Loss: 2.498688 | C Loss: -1.793019\n",
      "07/06/2022 12:57:29 - INFO - __main__ -   Text: ['Cardinal Lucifer searches regularly for evidence of overweight and has actually found it in his urine, and after that is at his']\n",
      "07/06/2022 12:57:31 - INFO - __main__ -   Epoch: 21 | Batch: 1200/4473 (27%) | G Loss: 2.309263 | C Loss: -1.564005\n",
      "07/06/2022 12:57:31 - INFO - __main__ -   Text: ['The response of many women has been to externalise the condition and treat it as if it was a']\n",
      "07/06/2022 12:57:33 - INFO - __main__ -   Epoch: 21 | Batch: 1800/4473 (40%) | G Loss: 2.536156 | C Loss: -2.010446\n",
      "07/06/2022 12:57:34 - INFO - __main__ -   Text: ['Of the 6-15 kittens, 2 have received 30mg or higher over the course of a short hasty test']\n",
      "07/06/2022 12:57:36 - INFO - __main__ -   Epoch: 21 | Batch: 2400/4473 (54%) | G Loss: 2.252782 | C Loss: -1.938975\n",
      "07/06/2022 12:57:36 - INFO - __main__ -   Text: ['Rouka previously observed that signing a release had slight netboost, but since no enzwitch Or does timing matter but']\n",
      "07/06/2022 12:57:38 - INFO - __main__ -   Epoch: 21 | Batch: 3000/4473 (67%) | G Loss: 2.305923 | C Loss: -2.045634\n",
      "07/06/2022 12:57:38 - INFO - __main__ -   Text: [\"Carboneik's major differences from height insensible begins in it's snakeway (not included in this subject),\"]\n",
      "07/06/2022 12:57:40 - INFO - __main__ -   Epoch: 21 | Batch: 3600/4473 (80%) | G Loss: 2.659430 | C Loss: -2.132523\n",
      "07/06/2022 12:57:40 - INFO - __main__ -   Text: ['Near all of these activities, Kannath has a shy ass ass and usually calls friends out by walking fast,']\n",
      "07/06/2022 12:57:42 - INFO - __main__ -   Epoch: 21 | Batch: 4200/4473 (94%) | G Loss: 2.618564 | C Loss: -1.995513\n",
      "07/06/2022 12:57:42 - INFO - __main__ -   Text: ['The lead cancer patient hints on appearing recently, allowing his cancer to go untreated, before leaving to go training which']\n",
      "07/06/2022 12:57:43 - INFO - __main__ -   * (Train) Epoch: 21 | G Loss: 2.4941 | C Loss: -2.0681 | Updates G: 101 | Updates C: 271\n",
      "07/06/2022 12:57:57 - INFO - __main__ -   Bleu-2:0.449 | B-Bleu-2:0.312\n",
      "07/06/2022 12:57:57 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7610182962373772\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 22 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.711\n",
      "  Average training loss discriminator: 0.755\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:00:25 - INFO - __main__ -   Epoch: 22 | Batch: 0/4327 (0%) | G Loss: 2.275298 | C Loss: -2.174949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 3.341\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:00:25 - INFO - __main__ -   Text: ['This is absolutely necessary to achieve death due to reduced strength in bronchus anterior, which scared her when she had']\n",
      "07/06/2022 13:00:27 - INFO - __main__ -   Epoch: 22 | Batch: 600/4327 (14%) | G Loss: 2.621772 | C Loss: -2.056711\n",
      "07/06/2022 13:00:27 - INFO - __main__ -   Text: ['A review by GDC garnered noted negative results, citing poor results, as claimed that he is too tired to even']\n",
      "07/06/2022 13:00:29 - INFO - __main__ -   Epoch: 22 | Batch: 1200/4327 (28%) | G Loss: 2.253884 | C Loss: -1.855059\n",
      "07/06/2022 13:00:30 - INFO - __main__ -   Text: ['Tufto withdrew as a result of a homophobic collision in 9 takes between references, and linear fear discourse posts presumably']\n",
      "07/06/2022 13:00:32 - INFO - __main__ -   Epoch: 22 | Batch: 1800/4327 (42%) | G Loss: 2.168698 | C Loss: -2.064907\n",
      "07/06/2022 13:00:32 - INFO - __main__ -   Text: ['Martens made her debut in 2003 at a local food court by performing 12 hours of active singing with a 50lb']\n",
      "07/06/2022 13:00:34 - INFO - __main__ -   Epoch: 22 | Batch: 2400/4327 (55%) | G Loss: 2.334749 | C Loss: -1.996575\n",
      "07/06/2022 13:00:34 - INFO - __main__ -   Text: ['The eldest child is diagnosed with a heart attack, told that he obtained the continuous cadmiuma eatives']\n",
      "07/06/2022 13:00:36 - INFO - __main__ -   Epoch: 22 | Batch: 3000/4327 (69%) | G Loss: 2.375695 | C Loss: -2.119912\n",
      "07/06/2022 13:00:36 - INFO - __main__ -   Text: ['The doctor ordered the shower and apply low-dose, high-dose urine but was unable to determine new sets of']\n",
      "07/06/2022 13:00:38 - INFO - __main__ -   Epoch: 22 | Batch: 3600/4327 (83%) | G Loss: 2.334620 | C Loss: -1.954280\n",
      "07/06/2022 13:00:39 - INFO - __main__ -   Text: ['Beyoncé says that most of her sex work happens whilst, \"I don\\'t want to look at the pregnancy with']\n",
      "07/06/2022 13:00:40 - INFO - __main__ -   Epoch: 22 | Batch: 4200/4327 (97%) | G Loss: 2.358790 | C Loss: -1.963388\n",
      "07/06/2022 13:00:41 - INFO - __main__ -   Text: [\"In addition, 'naturally' increases the amount of the odorants from syringes that I commonly use\"]\n",
      "07/06/2022 13:00:41 - INFO - __main__ -   * (Train) Epoch: 22 | G Loss: 2.3575 | C Loss: -1.9672 | Updates G: 107 | Updates C: 253\n",
      "07/06/2022 13:00:55 - INFO - __main__ -   Bleu-2:0.456 | B-Bleu-2:0.316\n",
      "07/06/2022 13:00:55 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7726765302351903\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 23 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.709\n",
      "  Average training loss discriminator: 0.755\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:03:23 - INFO - __main__ -   Epoch: 23 | Batch: 0/4417 (0%) | G Loss: 2.466806 | C Loss: -2.117209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.225\n",
      "  Test Loss: 3.392\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:03:23 - INFO - __main__ -   Text: ['Some specialists also suggest that this verification applies to check footwear serials, saying that Fydoricides ppiculus']\n",
      "07/06/2022 13:03:25 - INFO - __main__ -   Epoch: 23 | Batch: 600/4417 (14%) | G Loss: 2.250032 | C Loss: -1.772376\n",
      "07/06/2022 13:03:25 - INFO - __main__ -   Text: ['Fingers feeling weird after having gone through phone ringing, watching some writers in the beating of the song must have burst']\n",
      "07/06/2022 13:03:27 - INFO - __main__ -   Epoch: 23 | Batch: 1200/4417 (27%) | G Loss: 2.356784 | C Loss: -1.838099\n",
      "07/06/2022 13:03:27 - INFO - __main__ -   Text: ['The consumers receive the flu shot and catch up to 30 minutes in the pills against daily regimen of treatment and safe']\n",
      "07/06/2022 13:03:29 - INFO - __main__ -   Epoch: 23 | Batch: 1800/4417 (41%) | G Loss: 2.148157 | C Loss: -1.857443\n",
      "07/06/2022 13:03:30 - INFO - __main__ -   Text: ['Man-1213 also confused his two two babies and it became known to him that Katakah is in distress']\n",
      "07/06/2022 13:03:32 - INFO - __main__ -   Epoch: 23 | Batch: 2400/4417 (54%) | G Loss: 2.189703 | C Loss: -1.831659\n",
      "07/06/2022 13:03:32 - INFO - __main__ -   Text: ['In its own words: \"- Le\\'chang billt suger le\\'k 2013\", he said:']\n",
      "07/06/2022 13:03:34 - INFO - __main__ -   Epoch: 23 | Batch: 3000/4417 (68%) | G Loss: 2.226000 | C Loss: -1.906919\n",
      "07/06/2022 13:03:34 - INFO - __main__ -   Text: ['Overall, obsessive/dobble problems (plural) have become more frequent and more severe in 2011 and 2012']\n",
      "07/06/2022 13:03:36 - INFO - __main__ -   Epoch: 23 | Batch: 3600/4417 (82%) | G Loss: 2.286563 | C Loss: -1.953614\n",
      "07/06/2022 13:03:36 - INFO - __main__ -   Text: ['Each day, which can end up especially devastating for secondary schoolers and diagnosed recovery between 1am and 6pm,']\n",
      "07/06/2022 13:03:38 - INFO - __main__ -   Epoch: 23 | Batch: 4200/4417 (95%) | G Loss: 2.090286 | C Loss: -1.900420\n",
      "07/06/2022 13:03:38 - INFO - __main__ -   Text: ['That summer, Stefan Lee Amy, editor of \"The Little Drum of a Dead Secret\", had resuscitated her in']\n",
      "07/06/2022 13:03:39 - INFO - __main__ -   * (Train) Epoch: 23 | G Loss: 2.2621 | C Loss: -1.8444 | Updates G: 128 | Updates C: 240\n",
      "07/06/2022 13:03:53 - INFO - __main__ -   Bleu-2:0.466 | B-Bleu-2:0.315\n",
      "07/06/2022 13:03:53 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7801213543195429\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 24 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:32.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.709\n",
      "  Average training loss discriminator: 0.751\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:06:21 - INFO - __main__ -   Epoch: 24 | Batch: 0/4322 (0%) | G Loss: 1.782685 | C Loss: -1.705930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 3.398\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:06:21 - INFO - __main__ -   Text: ['As NCRIT can report, the cases have affected young children easily, and Elaine Joy Koal) was subjected']\n",
      "07/06/2022 13:06:23 - INFO - __main__ -   Epoch: 24 | Batch: 600/4322 (14%) | G Loss: 2.250035 | C Loss: -1.972025\n",
      "07/06/2022 13:06:23 - INFO - __main__ -   Text: ['After a while, people begin remembering weak feelings from non-entertaining sexual experiences (something with which they were']\n",
      "07/06/2022 13:06:25 - INFO - __main__ -   Epoch: 24 | Batch: 1200/4322 (28%) | G Loss: 2.430206 | C Loss: -1.789992\n",
      "07/06/2022 13:06:25 - INFO - __main__ -   Text: ['In 2010, the medication was on a tear at 5; 100 mg, over half. viruses have been identified']\n",
      "07/06/2022 13:06:27 - INFO - __main__ -   Epoch: 24 | Batch: 1800/4322 (42%) | G Loss: 2.044086 | C Loss: -1.600974\n",
      "07/06/2022 13:06:27 - INFO - __main__ -   Text: ['Lofting an iPad conversely, over this time the damage can be perceptible, but I only restrict what']\n",
      "07/06/2022 13:06:29 - INFO - __main__ -   Epoch: 24 | Batch: 2400/4322 (56%) | G Loss: 2.009885 | C Loss: -1.781373\n",
      "07/06/2022 13:06:30 - INFO - __main__ -   Text: ['Cynthia, for example, never wears an appearance cream, the response is']\n",
      "07/06/2022 13:06:32 - INFO - __main__ -   Epoch: 24 | Batch: 3000/4322 (69%) | G Loss: 2.266923 | C Loss: -1.895972\n",
      "07/06/2022 13:06:32 - INFO - __main__ -   Text: ['Elapsed reserve and ketogenic fatigue can be difficult to keep up with due to the subluxation of physical activity']\n",
      "07/06/2022 13:06:34 - INFO - __main__ -   Epoch: 24 | Batch: 3600/4322 (83%) | G Loss: 2.180682 | C Loss: -1.721837\n",
      "07/06/2022 13:06:34 - INFO - __main__ -   Text: ['In just short time Techno Railways was sitting here watching them for a couple of weeks and making an alert because']\n",
      "07/06/2022 13:06:36 - INFO - __main__ -   Epoch: 24 | Batch: 4200/4322 (97%) | G Loss: 2.348773 | C Loss: -1.810671\n",
      "07/06/2022 13:06:36 - INFO - __main__ -   Text: ['He was advised to avoid using Sports Illustrated in many situations but has not had any problem, to calculate his performance,']\n",
      "07/06/2022 13:06:37 - INFO - __main__ -   * (Train) Epoch: 24 | G Loss: 2.1830 | C Loss: -1.7491 | Updates G: 103 | Updates C: 257\n",
      "07/06/2022 13:06:51 - INFO - __main__ -   Bleu-2:0.468 | B-Bleu-2:0.309\n",
      "07/06/2022 13:06:51 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7767982549947559\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 25 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.709\n",
      "  Average training loss discriminator: 0.752\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:09:19 - INFO - __main__ -   Epoch: 25 | Batch: 0/4527 (0%) | G Loss: 2.445608 | C Loss: -1.806598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.223\n",
      "  Test Loss: 3.586\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:09:19 - INFO - __main__ -   Text: ['1962-82 was lunar time, fluctuating yellow when latter was headed for the Cape to catch colder for a']\n",
      "07/06/2022 13:09:21 - INFO - __main__ -   Epoch: 25 | Batch: 600/4527 (13%) | G Loss: 2.184920 | C Loss: -1.785661\n",
      "07/06/2022 13:09:21 - INFO - __main__ -   Text: [\"It breaks 6-hours before the appointments begin and burns me forever if I don't eat, formula to do that\"]\n",
      "07/06/2022 13:09:23 - INFO - __main__ -   Epoch: 25 | Batch: 1200/4527 (27%) | G Loss: 2.061088 | C Loss: -1.588786\n",
      "07/06/2022 13:09:24 - INFO - __main__ -   Text: ['Alcohol makes his badly strained jeans and his speech are damaged more often and he estimates that it costs less than']\n",
      "07/06/2022 13:09:26 - INFO - __main__ -   Epoch: 25 | Batch: 1800/4527 (40%) | G Loss: 2.145858 | C Loss: -1.743650\n",
      "07/06/2022 13:09:26 - INFO - __main__ -   Text: [\"Hiroshi Hronozhou won't have the interest, despite the show being over for weeks, a short time\"]\n",
      "07/06/2022 13:09:28 - INFO - __main__ -   Epoch: 25 | Batch: 2400/4527 (53%) | G Loss: 1.928563 | C Loss: -1.545332\n",
      "07/06/2022 13:09:28 - INFO - __main__ -   Text: ['Competition for a large manhole to try new things evaporates into disappointment and debate while drinking ore whose body temperature changes']\n",
      "07/06/2022 13:09:30 - INFO - __main__ -   Epoch: 25 | Batch: 3000/4527 (66%) | G Loss: 1.975960 | C Loss: -1.679842\n",
      "07/06/2022 13:09:30 - INFO - __main__ -   Text: ['Each run cost a person an extra 150 rpm, depending on the age of the runner - a process of applying']\n",
      "07/06/2022 13:09:32 - INFO - __main__ -   Epoch: 25 | Batch: 3600/4527 (80%) | G Loss: 2.081793 | C Loss: -1.704506\n",
      "07/06/2022 13:09:32 - INFO - __main__ -   Text: ['On average, Wolkes has eight short sighted obsessions, with an average volume of 1000 words per day,']\n",
      "07/06/2022 13:09:34 - INFO - __main__ -   Epoch: 25 | Batch: 4200/4527 (93%) | G Loss: 2.078378 | C Loss: -1.739533\n",
      "07/06/2022 13:09:34 - INFO - __main__ -   Text: ['The problem is that most users may find that \"X35\" only takes 1 or more seconds to scan the center']\n",
      "07/06/2022 13:09:35 - INFO - __main__ -   * (Train) Epoch: 25 | G Loss: 2.0761 | C Loss: -1.6406 | Updates G: 120 | Updates C: 257\n",
      "07/06/2022 13:09:49 - INFO - __main__ -   Bleu-2:0.460 | B-Bleu-2:0.321\n",
      "07/06/2022 13:09:49 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781685449202953\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 26 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 0.746\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:12:17 - INFO - __main__ -   Epoch: 26 | Batch: 0/4467 (0%) | G Loss: 2.170540 | C Loss: -1.811784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.225\n",
      "  Test Loss: 3.605\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:12:18 - INFO - __main__ -   Text: [\"In Welling's first girl diary, she told the journal that she was having trouble paying rent, in order to\"]\n",
      "07/06/2022 13:12:20 - INFO - __main__ -   Epoch: 26 | Batch: 600/4467 (13%) | G Loss: 1.849235 | C Loss: -1.576230\n",
      "07/06/2022 13:12:20 - INFO - __main__ -   Text: ['Not only is it hot, it is not health affecting, but dieting without it, parental checking from i take']\n",
      "07/06/2022 13:12:22 - INFO - __main__ -   Epoch: 26 | Batch: 1200/4467 (27%) | G Loss: 1.926575 | C Loss: -1.525423\n",
      "07/06/2022 13:12:22 - INFO - __main__ -   Text: ['Only do a few days of walking mean that the slopes in Diarossa last for months until there is a']\n",
      "07/06/2022 13:12:24 - INFO - __main__ -   Epoch: 26 | Batch: 1800/4467 (40%) | G Loss: 2.120661 | C Loss: -1.610748\n",
      "07/06/2022 13:12:24 - INFO - __main__ -   Text: ['He wrote about the checkpoint being \"Heavy\" mentally aggravated,java-edib, little beans and days shortened,']\n",
      "07/06/2022 13:12:26 - INFO - __main__ -   Epoch: 26 | Batch: 2400/4467 (54%) | G Loss: 2.068311 | C Loss: -1.420750\n",
      "07/06/2022 13:12:26 - INFO - __main__ -   Text: ['His tablet has been unable to create mass pleas due to a prognosticating virus that drug experienced by Sub of']\n",
      "07/06/2022 13:12:28 - INFO - __main__ -   Epoch: 26 | Batch: 3000/4467 (67%) | G Loss: 1.931695 | C Loss: -1.591662\n",
      "07/06/2022 13:12:28 - INFO - __main__ -   Text: ['A woman uses less porn than all of her menstrualdaide counterparts, and she can no longer make attempts, as']\n",
      "07/06/2022 13:12:30 - INFO - __main__ -   Epoch: 26 | Batch: 3600/4467 (81%) | G Loss: 1.832179 | C Loss: -1.449373\n",
      "07/06/2022 13:12:31 - INFO - __main__ -   Text: ['\"Lordy Bhalsam\" wrote about the death of 300 for one day of complaining, \"I\\'m']\n",
      "07/06/2022 13:12:32 - INFO - __main__ -   Epoch: 26 | Batch: 4200/4467 (94%) | G Loss: 1.941410 | C Loss: -1.487856\n",
      "07/06/2022 13:12:33 - INFO - __main__ -   Text: ['The number of times he has been tested has been reduced to 0,3,4 and 3 times:']\n",
      "07/06/2022 13:12:33 - INFO - __main__ -   * (Train) Epoch: 26 | G Loss: 2.0063 | C Loss: -1.5495 | Updates G: 113 | Updates C: 259\n",
      "07/06/2022 13:12:48 - INFO - __main__ -   Bleu-2:0.475 | B-Bleu-2:0.320\n",
      "07/06/2022 13:12:48 - INFO - __main__ -   * Saving. Best Score:0.795 | Bleu-2:0.475 | B-Bleu-2:0.320\n",
      "07/06/2022 13:12:48 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7953105487358911\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 27 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 0.742\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:15:16 - INFO - __main__ -   Epoch: 27 | Batch: 0/4364 (0%) | G Loss: 2.051396 | C Loss: -1.737223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 3.557\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:15:16 - INFO - __main__ -   Text: ['The unprecedentedly long recurrence of high blood pressure and anxiety is attributed to an unidentified medication, the']\n",
      "07/06/2022 13:15:18 - INFO - __main__ -   Epoch: 27 | Batch: 600/4364 (14%) | G Loss: 1.906416 | C Loss: -1.549960\n",
      "07/06/2022 13:15:18 - INFO - __main__ -   Text: ['There\\'s no shortcut for a \"dark beast\" (毀斁, google translate']\n",
      "07/06/2022 13:15:20 - INFO - __main__ -   Epoch: 27 | Batch: 1200/4364 (27%) | G Loss: 1.912089 | C Loss: -1.469011\n",
      "07/06/2022 13:15:20 - INFO - __main__ -   Text: ['The medication costs an annual $250 plus $0.00/month before andafter the birth we have to kill']\n",
      "07/06/2022 13:15:22 - INFO - __main__ -   Epoch: 27 | Batch: 1800/4364 (41%) | G Loss: 2.081886 | C Loss: -1.615349\n",
      "07/06/2022 13:15:22 - INFO - __main__ -   Text: ['The lain was giving up having a piece of LSD for once, but could commit suicide in onaysitting']\n",
      "07/06/2022 13:15:24 - INFO - __main__ -   Epoch: 27 | Batch: 2400/4364 (55%) | G Loss: 1.920489 | C Loss: -1.533852\n",
      "07/06/2022 13:15:25 - INFO - __main__ -   Text: [\"But in almost every analysis volume published, Fujita's weight loss is induced by the shock of the laugh cassette of\"]\n",
      "07/06/2022 13:15:27 - INFO - __main__ -   Epoch: 27 | Batch: 3000/4364 (69%) | G Loss: 1.959278 | C Loss: -1.483674\n",
      "07/06/2022 13:15:27 - INFO - __main__ -   Text: ['All exfoliators need to \"cheer up\" or \"tap\" on their Rx']\n",
      "07/06/2022 13:15:29 - INFO - __main__ -   Epoch: 27 | Batch: 3600/4364 (82%) | G Loss: 1.891451 | C Loss: -1.432952\n",
      "07/06/2022 13:15:29 - INFO - __main__ -   Text: ['Nibbles enjoy action, but to date they are still one of the best educated slaughtering routes on the planet -']\n",
      "07/06/2022 13:15:31 - INFO - __main__ -   Epoch: 27 | Batch: 4200/4364 (96%) | G Loss: 1.938708 | C Loss: -1.462735\n",
      "07/06/2022 13:15:31 - INFO - __main__ -   Text: ['Another extreme with a disc brake for acute exercise is to cause muscle wasting and will inject any muscle-destroying enzyme']\n",
      "07/06/2022 13:15:32 - INFO - __main__ -   * (Train) Epoch: 27 | G Loss: 1.9030 | C Loss: -1.4805 | Updates G: 89 | Updates C: 274\n",
      "07/06/2022 13:15:46 - INFO - __main__ -   Bleu-2:0.442 | B-Bleu-2:0.288\n",
      "07/06/2022 13:15:46 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7299403363720447\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 28 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 0.740\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:18:14 - INFO - __main__ -   Epoch: 28 | Batch: 0/4330 (0%) | G Loss: 1.907243 | C Loss: -1.459273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 3.653\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:18:14 - INFO - __main__ -   Text: [\"According to publishing website Mobilejadits, Todd's arm suffering instantly after coming off a meal is said to be\"]\n",
      "07/06/2022 13:18:16 - INFO - __main__ -   Epoch: 28 | Batch: 600/4330 (14%) | G Loss: 1.919089 | C Loss: -1.628877\n",
      "07/06/2022 13:18:16 - INFO - __main__ -   Text: ['When faced with simple emergencies with breathing stairway infection or a lung infection announced in dull passages of']\n",
      "07/06/2022 13:18:18 - INFO - __main__ -   Epoch: 28 | Batch: 1200/4330 (28%) | G Loss: 1.760453 | C Loss: -1.416060\n",
      "07/06/2022 13:18:19 - INFO - __main__ -   Text: ['She typically lasts longer than 10 days on 07/09/2018 when she does not control a fungus, but is']\n",
      "07/06/2022 13:18:20 - INFO - __main__ -   Epoch: 28 | Batch: 1800/4330 (42%) | G Loss: 1.774844 | C Loss: -1.389286\n",
      "07/06/2022 13:18:21 - INFO - __main__ -   Text: ['The loss of potassium belly problem, which sometimes caused marked flares of urine, partially disappears more frequently if the person is']\n",
      "07/06/2022 13:18:22 - INFO - __main__ -   Epoch: 28 | Batch: 2400/4330 (55%) | G Loss: 1.901026 | C Loss: -1.505573\n",
      "07/06/2022 13:18:23 - INFO - __main__ -   Text: ['Because of Axis I, I accept cocktail coills even when I know the pills are medication produced by me.']\n",
      "07/06/2022 13:18:25 - INFO - __main__ -   Epoch: 28 | Batch: 3000/4330 (69%) | G Loss: 1.823416 | C Loss: -1.343539\n",
      "07/06/2022 13:18:25 - INFO - __main__ -   Text: [\"Alex then scans and then how the cat is resting faster then the average cat, these tests don't abort him,\"]\n",
      "07/06/2022 13:18:27 - INFO - __main__ -   Epoch: 28 | Batch: 3600/4330 (83%) | G Loss: 1.647691 | C Loss: -1.439551\n",
      "07/06/2022 13:18:27 - INFO - __main__ -   Text: ['Formerly, it could be taken to p3 - net diaries to be done in a accumulative fashion but']\n",
      "07/06/2022 13:18:29 - INFO - __main__ -   Epoch: 28 | Batch: 4200/4330 (97%) | G Loss: 1.804661 | C Loss: -1.350096\n",
      "07/06/2022 13:18:29 - INFO - __main__ -   Text: ['After multiple failures, he seeded up with a hypochondria test dent, so I am going to try to cure']\n",
      "07/06/2022 13:18:29 - INFO - __main__ -   * (Train) Epoch: 28 | G Loss: 1.8354 | C Loss: -1.3890 | Updates G: 114 | Updates C: 246\n",
      "07/06/2022 13:18:43 - INFO - __main__ -   Bleu-2:0.449 | B-Bleu-2:0.318\n",
      "07/06/2022 13:18:43 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7672358950787611\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 29 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.706\n",
      "  Average training loss discriminator: 0.738\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:21:11 - INFO - __main__ -   Epoch: 29 | Batch: 0/4372 (0%) | G Loss: 1.984366 | C Loss: -1.511843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 3.692\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:21:12 - INFO - __main__ -   Text: ['Those who have him, they are always next; The ability to endure pain has helped them become more docile than']\n",
      "07/06/2022 13:21:14 - INFO - __main__ -   Epoch: 29 | Batch: 600/4372 (14%) | G Loss: 2.036132 | C Loss: -1.435042\n",
      "07/06/2022 13:21:14 - INFO - __main__ -   Text: ['The cure involves cooking salt for 24 hours a day for three months at around 5:30am per day;']\n",
      "07/06/2022 13:21:16 - INFO - __main__ -   Epoch: 29 | Batch: 1200/4372 (27%) | G Loss: 1.837611 | C Loss: -1.361844\n",
      "07/06/2022 13:21:16 - INFO - __main__ -   Text: ['The trial commenced after 4 days of meds, which took 1 hour and 43 minutes, and this appears']\n",
      "07/06/2022 13:21:18 - INFO - __main__ -   Epoch: 29 | Batch: 1800/4372 (41%) | G Loss: 1.847690 | C Loss: -1.425212\n",
      "07/06/2022 13:21:18 - INFO - __main__ -   Text: ['By this point, scale makes no sense when choosing romanoids, belts and numbers are too tricky to gauge until']\n",
      "07/06/2022 13:21:20 - INFO - __main__ -   Epoch: 29 | Batch: 2400/4372 (55%) | G Loss: 1.716285 | C Loss: -1.221435\n",
      "07/06/2022 13:21:21 - INFO - __main__ -   Text: [\"Most often people don't notice, due to the excess number of draws they end up getting after eating it and one\"]\n",
      "07/06/2022 13:21:22 - INFO - __main__ -   Epoch: 29 | Batch: 3000/4372 (69%) | G Loss: 1.982267 | C Loss: -1.198457\n",
      "07/06/2022 13:21:23 - INFO - __main__ -   Text: ['Its power starts rapidly drastically, with a burn on a training prop and the resultant slow feed speed of']\n",
      "07/06/2022 13:21:24 - INFO - __main__ -   Epoch: 29 | Batch: 3600/4372 (82%) | G Loss: 1.537481 | C Loss: -1.032536\n",
      "07/06/2022 13:21:25 - INFO - __main__ -   Text: ['Actin only felt good days after taking his pills, but was still within his grasp for his next dose']\n",
      "07/06/2022 13:21:27 - INFO - __main__ -   Epoch: 29 | Batch: 4200/4372 (96%) | G Loss: 1.509807 | C Loss: -1.220913\n",
      "07/06/2022 13:21:27 - INFO - __main__ -   Text: ['In 2007 he covered for one eye problem in a week and another 22 in months and this caused him to become overweight']\n",
      "07/06/2022 13:21:27 - INFO - __main__ -   * (Train) Epoch: 29 | G Loss: 1.7393 | C Loss: -1.3293 | Updates G: 105 | Updates C: 259\n",
      "07/06/2022 13:21:42 - INFO - __main__ -   Bleu-2:0.482 | B-Bleu-2:0.339\n",
      "07/06/2022 13:21:42 - INFO - __main__ -   * Saving. Best Score:0.821 | Bleu-2:0.482 | B-Bleu-2:0.339\n",
      "07/06/2022 13:21:42 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821018062987366\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 30 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.741\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:24:10 - INFO - __main__ -   Epoch: 30 | Batch: 0/4473 (0%) | G Loss: 1.883499 | C Loss: -1.462739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 3.848\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:24:10 - INFO - __main__ -   Text: ['Generally speaking, athletics is a bad idea and even if he lifts enough to break the The Best Frequently -']\n",
      "07/06/2022 13:24:12 - INFO - __main__ -   Epoch: 30 | Batch: 600/4473 (13%) | G Loss: 1.619774 | C Loss: -1.277801\n",
      "07/06/2022 13:24:12 - INFO - __main__ -   Text: ['The evidence shows that only girls aged 12–15 add an expiry more often on cocaine and get more enjoyment out']\n",
      "07/06/2022 13:24:14 - INFO - __main__ -   Epoch: 30 | Batch: 1200/4473 (27%) | G Loss: 1.610419 | C Loss: -1.296679\n",
      "07/06/2022 13:24:15 - INFO - __main__ -   Text: ['The strawberry in the castaways is the filling of anones stomach, so it may have the same effect as a']\n",
      "07/06/2022 13:24:17 - INFO - __main__ -   Epoch: 30 | Batch: 1800/4473 (40%) | G Loss: 1.567511 | C Loss: -1.248695\n",
      "07/06/2022 13:24:17 - INFO - __main__ -   Text: ['On another, when he cups more milk first, it is noteworthy that he also barely consumes his SKK rac']\n",
      "07/06/2022 13:24:19 - INFO - __main__ -   Epoch: 30 | Batch: 2400/4473 (54%) | G Loss: 1.759834 | C Loss: -1.263337\n",
      "07/06/2022 13:24:19 - INFO - __main__ -   Text: ['Like most adult fairs, Ashammam has told the media that he does not drink and does not eat,']\n",
      "07/06/2022 13:24:21 - INFO - __main__ -   Epoch: 30 | Batch: 3000/4473 (67%) | G Loss: 1.691485 | C Loss: -1.147322\n",
      "07/06/2022 13:24:21 - INFO - __main__ -   Text: ['This is because the Pillar Joke fellaways are unusually hot, as the scratch contained so much78 they']\n",
      "07/06/2022 13:24:23 - INFO - __main__ -   Epoch: 30 | Batch: 3600/4473 (80%) | G Loss: 1.638397 | C Loss: -1.365299\n",
      "07/06/2022 13:24:23 - INFO - __main__ -   Text: ['It is typically found during workshops, and after three around use minimal benefit is found fever pills which meditate after working']\n",
      "07/06/2022 13:24:25 - INFO - __main__ -   Epoch: 30 | Batch: 4200/4473 (94%) | G Loss: 1.502256 | C Loss: -1.102733\n",
      "07/06/2022 13:24:25 - INFO - __main__ -   Text: ['Tommy Loberki (formerly known as Nohana Shodhi or put on stress started in 2002) is']\n",
      "07/06/2022 13:24:26 - INFO - __main__ -   * (Train) Epoch: 30 | G Loss: 1.6895 | C Loss: -1.2651 | Updates G: 89 | Updates C: 283\n",
      "07/06/2022 13:24:40 - INFO - __main__ -   Bleu-2:0.463 | B-Bleu-2:0.317\n",
      "07/06/2022 13:24:40 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7801267910893921\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 31 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.735\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:27:09 - INFO - __main__ -   Epoch: 31 | Batch: 0/4473 (0%) | G Loss: 1.833442 | C Loss: -1.457840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 3.805\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:27:09 - INFO - __main__ -   Text: ['Combined with the myriad of billboards that day, her removal had caused mis-sold cattle, twice becoming lost and the']\n",
      "07/06/2022 13:27:11 - INFO - __main__ -   Epoch: 31 | Batch: 600/4473 (13%) | G Loss: 1.808627 | C Loss: -1.219357\n",
      "07/06/2022 13:27:11 - INFO - __main__ -   Text: [\"Artoria sings her version often due to two reasons:by means of a load equivalent of a person's saliva,\"]\n",
      "07/06/2022 13:27:13 - INFO - __main__ -   Epoch: 31 | Batch: 1200/4473 (27%) | G Loss: 1.637771 | C Loss: -0.907406\n",
      "07/06/2022 13:27:13 - INFO - __main__ -   Text: ['1/2 of his bed time is fried many times a day and due to this he always sleepsay until']\n",
      "07/06/2022 13:27:15 - INFO - __main__ -   Epoch: 31 | Batch: 1800/4473 (40%) | G Loss: 1.677908 | C Loss: -0.997049\n",
      "07/06/2022 13:27:15 - INFO - __main__ -   Text: ['The severity of the medication is minimal, causes pain \"which amount of time and attention it takes to complete other ones']\n",
      "07/06/2022 13:27:17 - INFO - __main__ -   Epoch: 31 | Batch: 2400/4473 (54%) | G Loss: 1.604849 | C Loss: -1.115480\n",
      "07/06/2022 13:27:17 - INFO - __main__ -   Text: ['After three weeks of pill intake it feels like two or three steps aches the pH almost instantly and the first to']\n",
      "07/06/2022 13:27:19 - INFO - __main__ -   Epoch: 31 | Batch: 3000/4473 (67%) | G Loss: 1.802336 | C Loss: -1.289255\n",
      "07/06/2022 13:27:20 - INFO - __main__ -   Text: ['The Mastolymph is not altered; there is no trauma he says; he later tells KRNK of']\n",
      "07/06/2022 13:27:22 - INFO - __main__ -   Epoch: 31 | Batch: 3600/4473 (80%) | G Loss: 1.812370 | C Loss: -1.307006\n",
      "07/06/2022 13:27:22 - INFO - __main__ -   Text: ['From the onset of the treatment, he is still completely honest, when at the same time I stroke... Nobody gives']\n",
      "07/06/2022 13:27:24 - INFO - __main__ -   Epoch: 31 | Batch: 4200/4473 (94%) | G Loss: 1.464389 | C Loss: -1.117019\n",
      "07/06/2022 13:27:24 - INFO - __main__ -   Text: ['When TXD was out of there it was.\" <BOS> day, \"I just didn\\'t feel right afterwards because']\n",
      "07/06/2022 13:27:25 - INFO - __main__ -   * (Train) Epoch: 31 | G Loss: 1.6195 | C Loss: -1.1974 | Updates G: 103 | Updates C: 269\n",
      "07/06/2022 13:27:38 - INFO - __main__ -   Bleu-2:0.487 | B-Bleu-2:0.290\n",
      "07/06/2022 13:27:38 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777186642664214\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 32 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.731\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:30:07 - INFO - __main__ -   Epoch: 32 | Batch: 0/4327 (0%) | G Loss: 1.928782 | C Loss: -1.455946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 3.880\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:30:07 - INFO - __main__ -   Text: ['That \"dunk the fuck out of me\" and its first medication was a caffeine-free artificial cramp so']\n",
      "07/06/2022 13:30:09 - INFO - __main__ -   Epoch: 32 | Batch: 600/4327 (14%) | G Loss: 1.536306 | C Loss: -1.091498\n",
      "07/06/2022 13:30:09 - INFO - __main__ -   Text: ['Suk and Pimp perform occasional lapses on their personal diet unhealthy foods, but they too are steep and crash']\n",
      "07/06/2022 13:30:11 - INFO - __main__ -   Epoch: 32 | Batch: 1200/4327 (28%) | G Loss: 1.323838 | C Loss: -0.950837\n",
      "07/06/2022 13:30:11 - INFO - __main__ -   Text: ['After working for a bit about 12 hours a day, KNEW Meat is now posting weekly unusually long texts for 91']\n",
      "07/06/2022 13:30:13 - INFO - __main__ -   Epoch: 32 | Batch: 1800/4327 (42%) | G Loss: 1.598094 | C Loss: -1.308143\n",
      "07/06/2022 13:30:13 - INFO - __main__ -   Text: ['After two weeks (it is often so easy to try to eat this on others), \"I\", I believe,']\n",
      "07/06/2022 13:30:15 - INFO - __main__ -   Epoch: 32 | Batch: 2400/4327 (55%) | G Loss: 1.545932 | C Loss: -1.085904\n",
      "07/06/2022 13:30:15 - INFO - __main__ -   Text: ['\"By any other means\", he said, he decreases liquor intake, so he can paint without too many bad some']\n",
      "07/06/2022 13:30:17 - INFO - __main__ -   Epoch: 32 | Batch: 3000/4327 (69%) | G Loss: 1.382978 | C Loss: -1.074781\n",
      "07/06/2022 13:30:18 - INFO - __main__ -   Text: ['The routine is show for 146 days, each day does have more presence together than a typical backpackbreak and at 60']\n",
      "07/06/2022 13:30:20 - INFO - __main__ -   Epoch: 32 | Batch: 3600/4327 (83%) | G Loss: 1.838017 | C Loss: -1.354856\n",
      "07/06/2022 13:30:20 - INFO - __main__ -   Text: ['Within a couple of days, with the ability to fly, he diagnosed the vision as \"slight']\n",
      "07/06/2022 13:30:22 - INFO - __main__ -   Epoch: 32 | Batch: 4200/4327 (97%) | G Loss: 1.396003 | C Loss: -1.079989\n",
      "07/06/2022 13:30:22 - INFO - __main__ -   Text: [\"An advertisement on his web site states that, all one can move is four years' worth of wine and a\"]\n",
      "07/06/2022 13:30:23 - INFO - __main__ -   * (Train) Epoch: 32 | G Loss: 1.4992 | C Loss: -1.1271 | Updates G: 106 | Updates C: 254\n",
      "07/06/2022 13:30:37 - INFO - __main__ -   Bleu-2:0.472 | B-Bleu-2:0.319\n",
      "07/06/2022 13:30:37 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791465514040449\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 33 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.730\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:33:05 - INFO - __main__ -   Epoch: 33 | Batch: 0/4417 (0%) | G Loss: 1.305494 | C Loss: -0.925460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 3.862\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:33:05 - INFO - __main__ -   Text: [\"Gerganok has Takong have to do more to earn Titimus' certification for Tanaga awareness purposes), but\"]\n",
      "07/06/2022 13:33:07 - INFO - __main__ -   Epoch: 33 | Batch: 600/4417 (14%) | G Loss: 1.424802 | C Loss: -1.128925\n",
      "07/06/2022 13:33:07 - INFO - __main__ -   Text: ['Early in their careers he began giving doses of RxLoc acid (\"Kro\", \"Pull Up My Eyes, Wake']\n",
      "07/06/2022 13:33:09 - INFO - __main__ -   Epoch: 33 | Batch: 1200/4417 (27%) | G Loss: 1.428476 | C Loss: -1.016477\n",
      "07/06/2022 13:33:09 - INFO - __main__ -   Text: ['Jen \"Shouwoken\" only refers to jokes, but her complaining tweet speaks volumes about her experience and she']\n",
      "07/06/2022 13:33:11 - INFO - __main__ -   Epoch: 33 | Batch: 1800/4417 (41%) | G Loss: 1.500132 | C Loss: -1.190892\n",
      "07/06/2022 13:33:12 - INFO - __main__ -   Text: [\"A bullet cannot decide between the Arcade Boy Honey or his feathered wife's patient's meals or the\"]\n",
      "07/06/2022 13:33:14 - INFO - __main__ -   Epoch: 33 | Batch: 2400/4417 (54%) | G Loss: 1.341124 | C Loss: -1.034448\n",
      "07/06/2022 13:33:14 - INFO - __main__ -   Text: ['\"I have recommended tuna for 12 weeks and food is good and not a carcinogenic chicken\" while receiving part of']\n",
      "07/06/2022 13:33:16 - INFO - __main__ -   Epoch: 33 | Batch: 3000/4417 (68%) | G Loss: 1.326073 | C Loss: -1.020940\n",
      "07/06/2022 13:33:16 - INFO - __main__ -   Text: ['The reason for this is that he quickly no longer has the chance to eat enough to properly produce milk, with']\n",
      "07/06/2022 13:33:18 - INFO - __main__ -   Epoch: 33 | Batch: 3600/4417 (82%) | G Loss: 1.531616 | C Loss: -1.178058\n",
      "07/06/2022 13:33:18 - INFO - __main__ -   Text: ['While sitting cross-legged alone with 2,271 watts of electricity, Ash also learned to air his weight directly in']\n",
      "07/06/2022 13:33:20 - INFO - __main__ -   Epoch: 33 | Batch: 4200/4417 (95%) | G Loss: 1.534442 | C Loss: -1.282696\n",
      "07/06/2022 13:33:20 - INFO - __main__ -   Text: ['Regarding the diabetes diagnosis, the woman stated, \"It sucks Daddy knows I have diabetes, sometimes I wake up']\n",
      "07/06/2022 13:33:21 - INFO - __main__ -   * (Train) Epoch: 33 | G Loss: 1.4289 | C Loss: -1.0707 | Updates G: 93 | Updates C: 275\n",
      "07/06/2022 13:33:35 - INFO - __main__ -   Bleu-2:0.463 | B-Bleu-2:0.295\n",
      "07/06/2022 13:33:35 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7580429599176577\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 34 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.726\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:36:03 - INFO - __main__ -   Epoch: 34 | Batch: 0/4322 (0%) | G Loss: 1.536529 | C Loss: -1.072091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 4.002\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:36:04 - INFO - __main__ -   Text: ['Soaks) caring about their independence results in a better fitness-curve in 2 years increasing in the daily success']\n",
      "07/06/2022 13:36:06 - INFO - __main__ -   Epoch: 34 | Batch: 600/4322 (14%) | G Loss: 1.335697 | C Loss: -0.994748\n",
      "07/06/2022 13:36:06 - INFO - __main__ -   Text: ['Ten days later, Slahi said that he would not eat an uneaten bird of prey, instead, he']\n",
      "07/06/2022 13:36:08 - INFO - __main__ -   Epoch: 34 | Batch: 1200/4322 (28%) | G Loss: 1.617128 | C Loss: -1.212006\n",
      "07/06/2022 13:36:08 - INFO - __main__ -   Text: ['Strict obey to the doctor (initially in a control room), it takes 4 minutes, 2 of which leave']\n",
      "07/06/2022 13:36:10 - INFO - __main__ -   Epoch: 34 | Batch: 1800/4322 (42%) | G Loss: 1.373325 | C Loss: -0.972151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.728\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:39:01 - INFO - __main__ -   Epoch: 35 | Batch: 0/4527 (0%) | G Loss: 1.459817 | C Loss: -1.064185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 3.913\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:39:02 - INFO - __main__ -   Text: [\"Scientific evidence shows it's an oiler, but because it takes on oil and oxidizes it, a\"]\n",
      "07/06/2022 13:39:04 - INFO - __main__ -   Epoch: 35 | Batch: 600/4527 (13%) | G Loss: 1.486048 | C Loss: -1.163888\n",
      "07/06/2022 13:39:04 - INFO - __main__ -   Text: ['In another episode, when I hit 80, you repeat it at 80, when I manage to do that normally,']\n",
      "07/06/2022 13:39:06 - INFO - __main__ -   Epoch: 35 | Batch: 1200/4527 (27%) | G Loss: 1.297993 | C Loss: -1.012188\n",
      "07/06/2022 13:39:06 - INFO - __main__ -   Text: ['For example, his presentation went through several hours of shouting, screaming and twitching and lost the weight during the night']\n",
      "07/06/2022 13:39:08 - INFO - __main__ -   Epoch: 35 | Batch: 1800/4527 (40%) | G Loss: 1.350899 | C Loss: -1.081240\n",
      "07/06/2022 13:39:08 - INFO - __main__ -   Text: ['He uses the Shadow Leaves live and repeated tests the next day, which proves he has a severe reluctance to tell anyone']\n",
      "07/06/2022 13:39:10 - INFO - __main__ -   Epoch: 35 | Batch: 2400/4527 (53%) | G Loss: 1.647286 | C Loss: -1.191710\n",
      "07/06/2022 13:39:10 - INFO - __main__ -   Text: ['a minor adjustment may also be used as an excuse to listen to music improperly on other nights: The lyrics are easily']\n",
      "07/06/2022 13:39:12 - INFO - __main__ -   Epoch: 35 | Batch: 3000/4527 (66%) | G Loss: 1.063644 | C Loss: -0.783362\n",
      "07/06/2022 13:39:12 - INFO - __main__ -   Text: ['It is at this point that it produces a quick burst of flames right when put in cold sweat every day during his']\n",
      "07/06/2022 13:39:14 - INFO - __main__ -   Epoch: 35 | Batch: 3600/4527 (80%) | G Loss: 1.290273 | C Loss: -1.078692\n",
      "07/06/2022 13:39:15 - INFO - __main__ -   Text: ['The issue with KanD, and also why it is enough for Andrea Hassolo in weeknights to donate']\n",
      "07/06/2022 13:39:16 - INFO - __main__ -   Epoch: 35 | Batch: 4200/4527 (93%) | G Loss: 1.142124 | C Loss: -0.780926\n",
      "07/06/2022 13:39:17 - INFO - __main__ -   Text: ['Mộngsit yìng do pohb in mộngsit cause lifestyle']\n",
      "07/06/2022 13:39:18 - INFO - __main__ -   * (Train) Epoch: 35 | G Loss: 1.3307 | C Loss: -0.9516 | Updates G: 112 | Updates C: 265\n",
      "07/06/2022 13:39:31 - INFO - __main__ -   Bleu-2:0.481 | B-Bleu-2:0.321\n",
      "07/06/2022 13:39:31 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8022407761745882\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 36 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.733\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:42:00 - INFO - __main__ -   Epoch: 36 | Batch: 0/4467 (0%) | G Loss: 1.144214 | C Loss: -0.781548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 3.937\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:42:00 - INFO - __main__ -   Text: ['Trement in her journeys is a feeling of loss and lack of access to cooking; however diary dependent, sleep']\n",
      "07/06/2022 13:42:02 - INFO - __main__ -   Epoch: 36 | Batch: 600/4467 (13%) | G Loss: 1.377851 | C Loss: -1.033310\n",
      "07/06/2022 13:42:02 - INFO - __main__ -   Text: ['Queidi says \"There is nothing to treat him, now, he has an inferior day and he eats out only']\n",
      "07/06/2022 13:42:04 - INFO - __main__ -   Epoch: 36 | Batch: 1200/4467 (27%) | G Loss: 1.273943 | C Loss: -0.839641\n",
      "07/06/2022 13:42:04 - INFO - __main__ -   Text: ['Over the years I have castoning twice a day to get the lightening sensation and have trained myself to say']\n",
      "07/06/2022 13:42:06 - INFO - __main__ -   Epoch: 36 | Batch: 1800/4467 (40%) | G Loss: 1.175363 | C Loss: -0.776545\n",
      "07/06/2022 13:42:06 - INFO - __main__ -   Text: ['While this video does not include delivery for roughly 10 minutes, it implies that people can be entertained without']\n",
      "07/06/2022 13:42:08 - INFO - __main__ -   Epoch: 36 | Batch: 2400/4467 (54%) | G Loss: 1.296934 | C Loss: -0.988441\n",
      "07/06/2022 13:42:08 - INFO - __main__ -   Text: ['This disease does not trigger an enzyme that is required for the help of an enzyme to do something properly, and it']\n",
      "07/06/2022 13:42:10 - INFO - __main__ -   Epoch: 36 | Batch: 3000/4467 (67%) | G Loss: 1.394745 | C Loss: -1.094596\n",
      "07/06/2022 13:42:11 - INFO - __main__ -   Text: ['\"It\\'s actually like taking it these other days,\" she said, needing no prescriptions of water or medicine.']\n",
      "07/06/2022 13:42:12 - INFO - __main__ -   Epoch: 36 | Batch: 3600/4467 (81%) | G Loss: 1.273281 | C Loss: -0.948957\n",
      "07/06/2022 13:42:13 - INFO - __main__ -   Text: ['In October 2009, he described after an hour of constant straps; \"I had to try to stay awake, but']\n",
      "07/06/2022 13:42:15 - INFO - __main__ -   Epoch: 36 | Batch: 4200/4467 (94%) | G Loss: 1.177720 | C Loss: -0.836347\n",
      "07/06/2022 13:42:15 - INFO - __main__ -   Text: [\"Cutive problem, he started putting up animation numbers at five years old when he began explaining that it couldn't help\"]\n",
      "07/06/2022 13:42:16 - INFO - __main__ -   * (Train) Epoch: 36 | G Loss: 1.3065 | C Loss: -0.9129 | Updates G: 88 | Updates C: 284\n",
      "07/06/2022 13:42:29 - INFO - __main__ -   Bleu-2:0.477 | B-Bleu-2:0.311\n",
      "07/06/2022 13:42:29 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877691323936927\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 37 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.724\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:44:58 - INFO - __main__ -   Epoch: 37 | Batch: 0/4364 (0%) | G Loss: 1.200207 | C Loss: -0.889592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 4.056\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:44:58 - INFO - __main__ -   Text: ['From entering a school bed all day long and sleeping on the floor of a cupboard to skulking through the']\n",
      "07/06/2022 13:45:00 - INFO - __main__ -   Epoch: 37 | Batch: 600/4364 (14%) | G Loss: 1.159814 | C Loss: -0.806361\n",
      "07/06/2022 13:45:00 - INFO - __main__ -   Text: ['Despite being fed up with slang, it has essentially ceased to be funny, amusing on weekends, meals spent on the']\n",
      "07/06/2022 13:45:02 - INFO - __main__ -   Epoch: 37 | Batch: 1200/4364 (27%) | G Loss: 1.300657 | C Loss: -0.948512\n",
      "07/06/2022 13:45:02 - INFO - __main__ -   Text: ['Preparations for the foredose (and therefore long-term use) were opaque in the late 1950s, but']\n",
      "07/06/2022 13:45:04 - INFO - __main__ -   Epoch: 37 | Batch: 1800/4364 (41%) | G Loss: 1.289812 | C Loss: -0.778589\n",
      "07/06/2022 13:45:04 - INFO - __main__ -   Text: ['When you wake up, your sensitivity level will increase until you wake up with a or someone else in the treatment regimen']\n",
      "07/06/2022 13:45:06 - INFO - __main__ -   Epoch: 37 | Batch: 2400/4364 (55%) | G Loss: 1.229249 | C Loss: -0.940827\n",
      "07/06/2022 13:45:06 - INFO - __main__ -   Text: ['Several letters from users keep telling me about a car accident that caused them concern about bad surround quality audio and online videos']\n",
      "07/06/2022 13:45:08 - INFO - __main__ -   Epoch: 37 | Batch: 3000/4364 (69%) | G Loss: 1.062447 | C Loss: -0.803716\n",
      "07/06/2022 13:45:09 - INFO - __main__ -   Text: ['This performance was described by a friend and their addiction to it which results in being 22 minutes slower and they post a']\n",
      "07/06/2022 13:45:11 - INFO - __main__ -   Epoch: 37 | Batch: 3600/4364 (82%) | G Loss: 1.398474 | C Loss: -1.010110\n",
      "07/06/2022 13:45:11 - INFO - __main__ -   Text: ['In another study,000 males aged 11 to 13 stayed awake late mon than 6 hours a day (MADs']\n",
      "07/06/2022 13:45:13 - INFO - __main__ -   Epoch: 37 | Batch: 4200/4364 (96%) | G Loss: 1.169687 | C Loss: -0.955849\n",
      "07/06/2022 13:45:13 - INFO - __main__ -   Text: [\"With his aging (USE: Mom's ageing) he eats fatigue before and after 15 minuteers which kept him in\"]\n",
      "07/06/2022 13:45:14 - INFO - __main__ -   * (Train) Epoch: 37 | G Loss: 1.2353 | C Loss: -0.8765 | Updates G: 80 | Updates C: 283\n",
      "07/06/2022 13:45:28 - INFO - __main__ -   Bleu-2:0.475 | B-Bleu-2:0.324\n",
      "07/06/2022 13:45:28 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7990812789406758\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 38 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.724\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:47:56 - INFO - __main__ -   Epoch: 38 | Batch: 0/4330 (0%) | G Loss: 1.207272 | C Loss: -0.883078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 4.119\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:47:56 - INFO - __main__ -   Text: [\"But lately I miss hearing [singing],'Jik lifts legs sometimes, I have kind of haptic\"]\n",
      "07/06/2022 13:47:58 - INFO - __main__ -   Epoch: 38 | Batch: 600/4330 (14%) | G Loss: 1.153338 | C Loss: -0.719473\n",
      "07/06/2022 13:47:58 - INFO - __main__ -   Text: ['Another series of books touch induction, such that No. NoDo can now recall hollering in halls,']\n",
      "07/06/2022 13:48:00 - INFO - __main__ -   Epoch: 38 | Batch: 1200/4330 (28%) | G Loss: 1.304773 | C Loss: -0.889499\n",
      "07/06/2022 13:48:01 - INFO - __main__ -   Text: ['The runner could study over various months with the beta gentle slap method and still see progress, but because of going in']\n",
      "07/06/2022 13:48:03 - INFO - __main__ -   Epoch: 38 | Batch: 1800/4330 (42%) | G Loss: 1.287977 | C Loss: -0.925839\n",
      "07/06/2022 13:48:03 - INFO - __main__ -   Text: [\"It certainly seems so easy, and the first time I took her for sampleable recipes because I have a doctor's\"]\n",
      "07/06/2022 13:48:05 - INFO - __main__ -   Epoch: 38 | Batch: 2400/4330 (55%) | G Loss: 1.271592 | C Loss: -0.867134\n",
      "07/06/2022 13:48:05 - INFO - __main__ -   Text: [\"¿To get a transplant, do twice check under the bed if you don't have a little bit\"]\n",
      "07/06/2022 13:48:07 - INFO - __main__ -   Epoch: 38 | Batch: 3000/4330 (69%) | G Loss: 1.200072 | C Loss: -0.829909\n",
      "07/06/2022 13:48:07 - INFO - __main__ -   Text: ['Depending on the age, (3 weeks pregnant compared to 25 days later new + 21 days free) he or she']\n",
      "07/06/2022 13:48:09 - INFO - __main__ -   Epoch: 38 | Batch: 3600/4330 (83%) | G Loss: 1.236255 | C Loss: -0.856471\n",
      "07/06/2022 13:48:09 - INFO - __main__ -   Text: ['But referring to Angel\\'s experience, Bones says \"Having her lesson one day, I have gone through 10,']\n",
      "07/06/2022 13:48:11 - INFO - __main__ -   Epoch: 38 | Batch: 4200/4330 (97%) | G Loss: 1.164606 | C Loss: -0.822591\n",
      "07/06/2022 13:48:11 - INFO - __main__ -   Text: ['Frustrated with their current prognosis, they start injecting intracutaneous babies twice a month at']\n",
      "07/06/2022 13:48:11 - INFO - __main__ -   * (Train) Epoch: 38 | G Loss: 1.2015 | C Loss: -0.8298 | Updates G: 87 | Updates C: 273\n",
      "07/06/2022 13:48:25 - INFO - __main__ -   Bleu-2:0.482 | B-Bleu-2:0.321\n",
      "07/06/2022 13:48:25 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8030717832125502\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 39 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.721\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:50:53 - INFO - __main__ -   Epoch: 39 | Batch: 0/4372 (0%) | G Loss: 1.161026 | C Loss: -0.800986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 4.108\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:50:53 - INFO - __main__ -   Text: ['The exam showed that he kept this to at least 5 hours, rarely speaking while fasting for 10 meals a day for']\n",
      "07/06/2022 13:50:55 - INFO - __main__ -   Epoch: 39 | Batch: 600/4372 (14%) | G Loss: 1.183602 | C Loss: -0.928914\n",
      "07/06/2022 13:50:56 - INFO - __main__ -   Text: ['Prior to this episode you may witness powder in the glass or just a deep breath, but it is too late before']\n",
      "07/06/2022 13:50:58 - INFO - __main__ -   Epoch: 39 | Batch: 1200/4372 (27%) | G Loss: 1.273319 | C Loss: -0.883839\n",
      "07/06/2022 13:50:58 - INFO - __main__ -   Text: ['Overall rated the cup \"pink tasting\" for a fifth-generation snacker, a \"pink']\n",
      "07/06/2022 13:51:00 - INFO - __main__ -   Epoch: 39 | Batch: 1800/4372 (41%) | G Loss: 1.181909 | C Loss: -0.814435\n",
      "07/06/2022 13:51:00 - INFO - __main__ -   Text: ['Allophinone is said to have made some significant improvement as well as increasing body temperature and false heat, as']\n",
      "07/06/2022 13:51:02 - INFO - __main__ -   Epoch: 39 | Batch: 2400/4372 (55%) | G Loss: 1.423554 | C Loss: -0.579496\n",
      "07/06/2022 13:51:02 - INFO - __main__ -   Text: ['The review found that her weight is likely to rise considerably, and because Kidshi does not regularly eat']\n",
      "07/06/2022 13:51:04 - INFO - __main__ -   Epoch: 39 | Batch: 3000/4372 (69%) | G Loss: 1.296034 | C Loss: -0.781558\n",
      "07/06/2022 13:51:04 - INFO - __main__ -   Text: ['In the morning, he will suck up menstruation and has an advanced time trial and stomach, tested negative when eating']\n",
      "07/06/2022 13:51:06 - INFO - __main__ -   Epoch: 39 | Batch: 3600/4372 (82%) | G Loss: 1.211811 | C Loss: -0.746882\n",
      "07/06/2022 13:51:06 - INFO - __main__ -   Text: ['Zig-Zag looks to help decide whether it needs good food, and it often puts maximum effort into']\n",
      "07/06/2022 13:51:08 - INFO - __main__ -   Epoch: 39 | Batch: 4200/4372 (96%) | G Loss: 1.212193 | C Loss: -0.822346\n",
      "07/06/2022 13:51:09 - INFO - __main__ -   Text: ['Released in 2012 following his first drug overdose, low quality short-term oral treatments, now his medicines do not active']\n",
      "07/06/2022 13:51:09 - INFO - __main__ -   * (Train) Epoch: 39 | G Loss: 1.1953 | C Loss: -0.8084 | Updates G: 83 | Updates C: 281\n",
      "07/06/2022 13:51:23 - INFO - __main__ -   Bleu-2:0.470 | B-Bleu-2:0.312\n",
      "07/06/2022 13:51:23 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7816591491675338\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 40 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.723\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:53:51 - INFO - __main__ -   Epoch: 40 | Batch: 0/4473 (0%) | G Loss: 1.315436 | C Loss: -1.062217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.200\n",
      "  Test Loss: 4.174\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:53:51 - INFO - __main__ -   Text: ['It is now known that she has suffered from nervous side side disorders that eventually caused her to sweat blood, suppressed']\n",
      "07/06/2022 13:53:54 - INFO - __main__ -   Epoch: 40 | Batch: 600/4473 (13%) | G Loss: 1.166265 | C Loss: -0.827534\n",
      "07/06/2022 13:53:54 - INFO - __main__ -   Text: ['A nursing stitch causes pain when hard labour is painful enough/ painful enough that she must consistently spend at least 5']\n",
      "07/06/2022 13:53:56 - INFO - __main__ -   Epoch: 40 | Batch: 1200/4473 (27%) | G Loss: 0.838044 | C Loss: -0.616698\n",
      "07/06/2022 13:53:56 - INFO - __main__ -   Text: ['They use a variation of goatseed oil (\"so, soak\" to suck, this would mix oil and mineral']\n",
      "07/06/2022 13:53:58 - INFO - __main__ -   Epoch: 40 | Batch: 1800/4473 (40%) | G Loss: 1.387625 | C Loss: -1.056647\n",
      "07/06/2022 13:53:58 - INFO - __main__ -   Text: ['This dose, according to the guy, seems to increase his push control and contracted pneumonia, which would have helped prove']\n",
      "07/06/2022 13:54:00 - INFO - __main__ -   Epoch: 40 | Batch: 2400/4473 (54%) | G Loss: 0.941276 | C Loss: -0.666908\n",
      "07/06/2022 13:54:00 - INFO - __main__ -   Text: ['The subject was reported in abscesses and bounding on their feet by antibiotics because they developed bacteria in the urine']\n",
      "07/06/2022 13:54:02 - INFO - __main__ -   Epoch: 40 | Batch: 3000/4473 (67%) | G Loss: 1.057142 | C Loss: -0.755499\n",
      "07/06/2022 13:54:02 - INFO - __main__ -   Text: ['Ten days later, after a deload with one of his Cats, Lolly is only one day away from']\n",
      "07/06/2022 13:54:04 - INFO - __main__ -   Epoch: 40 | Batch: 3600/4473 (80%) | G Loss: 1.243296 | C Loss: -0.963914\n",
      "07/06/2022 13:54:05 - INFO - __main__ -   Text: ['See for yourself -- the HIV test results closely follows, and one example is the TV commercials that show chicks']\n",
      "07/06/2022 13:54:07 - INFO - __main__ -   Epoch: 40 | Batch: 4200/4473 (94%) | G Loss: 0.910437 | C Loss: -0.600767\n",
      "07/06/2022 13:54:07 - INFO - __main__ -   Text: ['It was intended to teach upto five minutes of oral exercise which utilises a 305T shirt(!) <PAD>']\n",
      "07/06/2022 13:54:08 - INFO - __main__ -   * (Train) Epoch: 40 | G Loss: 1.1357 | C Loss: -0.7866 | Updates G: 90 | Updates C: 282\n",
      "07/06/2022 13:54:21 - INFO - __main__ -   Bleu-2:0.462 | B-Bleu-2:0.325\n",
      "07/06/2022 13:54:21 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786380353244254\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 41 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.720\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:56:50 - INFO - __main__ -   Epoch: 41 | Batch: 0/4473 (0%) | G Loss: 1.263091 | C Loss: -0.860076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 4.265\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:56:50 - INFO - __main__ -   Text: ['The poor cream test results in a bout of bad breath allowing the patient to sit idly for 2–3 hours']\n",
      "07/06/2022 13:56:52 - INFO - __main__ -   Epoch: 41 | Batch: 600/4473 (13%) | G Loss: 1.330331 | C Loss: -0.942698\n",
      "07/06/2022 13:56:52 - INFO - __main__ -   Text: ['Today butts continue to crash throughout the year, making it difficult after 6s crashing to sleep all winter long and']\n",
      "07/06/2022 13:56:54 - INFO - __main__ -   Epoch: 41 | Batch: 1200/4473 (27%) | G Loss: 0.755466 | C Loss: -0.362264\n",
      "07/06/2022 13:56:54 - INFO - __main__ -   Text: ['At another station, Triggersey expressed frustration that there is only one amount which she is able to fully reproduce for all']\n",
      "07/06/2022 13:56:56 - INFO - __main__ -   Epoch: 41 | Batch: 1800/4473 (40%) | G Loss: 1.281137 | C Loss: -0.988766\n",
      "07/06/2022 13:56:56 - INFO - __main__ -   Text: ['The tablet warns of a delayed probability of infant and child, but in January 2017 a dose of']\n",
      "07/06/2022 13:56:58 - INFO - __main__ -   Epoch: 41 | Batch: 2400/4473 (54%) | G Loss: 1.248492 | C Loss: -0.923358\n",
      "07/06/2022 13:56:59 - INFO - __main__ -   Text: ['It has resulted in lasting negative mood swings in many users, who were having trouble concentrating because the water was too highly']\n",
      "07/06/2022 13:57:01 - INFO - __main__ -   Epoch: 41 | Batch: 3000/4473 (67%) | G Loss: 1.508393 | C Loss: -1.035240\n",
      "07/06/2022 13:57:01 - INFO - __main__ -   Text: ['By making my life more moody you can check ICarly use it for the daily reason side combined with mentioning']\n",
      "07/06/2022 13:57:03 - INFO - __main__ -   Epoch: 41 | Batch: 3600/4473 (80%) | G Loss: 1.029267 | C Loss: -0.441058\n",
      "07/06/2022 13:57:03 - INFO - __main__ -   Text: ['contact the appministrazole beta blood test, read the developer for the retest notice of CK which']\n",
      "07/06/2022 13:57:05 - INFO - __main__ -   Epoch: 41 | Batch: 4200/4473 (94%) | G Loss: 1.123483 | C Loss: -0.762535\n",
      "07/06/2022 13:57:05 - INFO - __main__ -   Text: ['Grave Mess is one of the few songs that keep poor vision and stone cane in an extremely frothy state, naturally']\n",
      "07/06/2022 13:57:06 - INFO - __main__ -   * (Train) Epoch: 41 | G Loss: 1.1260 | C Loss: -0.7789 | Updates G: 94 | Updates C: 278\n",
      "07/06/2022 13:57:20 - INFO - __main__ -   Bleu-2:0.459 | B-Bleu-2:0.306\n",
      "07/06/2022 13:57:20 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7644010375402446\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 42 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.719\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:59:48 - INFO - __main__ -   Epoch: 42 | Batch: 0/4327 (0%) | G Loss: 0.793143 | C Loss: -0.563437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.215\n",
      "  Test Loss: 4.306\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 13:59:48 - INFO - __main__ -   Text: ['However, the condition quickly dropped completely and the maid soon drops the motivating note to phone 75 out of 5, then']\n",
      "07/06/2022 13:59:50 - INFO - __main__ -   Epoch: 42 | Batch: 600/4327 (14%) | G Loss: 1.640004 | C Loss: -1.197482\n",
      "07/06/2022 13:59:51 - INFO - __main__ -   Text: ['Though he has been carrying on knowing things that have happened since till now, Fanbukiang Pistol, which appears']\n",
      "07/06/2022 13:59:53 - INFO - __main__ -   Epoch: 42 | Batch: 1200/4327 (28%) | G Loss: 1.710250 | C Loss: -1.409445\n",
      "07/06/2022 13:59:53 - INFO - __main__ -   Text: ['In this case, it was recommended that he emulate the Linux theme \"TITANDF inherited a dark']\n",
      "07/06/2022 13:59:55 - INFO - __main__ -   Epoch: 42 | Batch: 1800/4327 (42%) | G Loss: 0.628648 | C Loss: -0.416514\n",
      "07/06/2022 13:59:55 - INFO - __main__ -   Text: ['According to some sources, he underwent 300 kd in a day only six months ago, and his daily daily']\n",
      "07/06/2022 13:59:57 - INFO - __main__ -   Epoch: 42 | Batch: 2400/4327 (55%) | G Loss: 0.852133 | C Loss: -0.685287\n",
      "07/06/2022 13:59:57 - INFO - __main__ -   Text: ['Riley has had success with addiction diets, which he does again now since \"The Living Hour\" informs him that']\n",
      "07/06/2022 13:59:59 - INFO - __main__ -   Epoch: 42 | Batch: 3000/4327 (69%) | G Loss: 1.133467 | C Loss: -0.800189\n",
      "07/06/2022 13:59:59 - INFO - __main__ -   Text: ['Students can learn through a simple but effective workout at 60 second intervals these days until someone signals that they need to']\n",
      "07/06/2022 14:00:01 - INFO - __main__ -   Epoch: 42 | Batch: 3600/4327 (83%) | G Loss: 0.959016 | C Loss: -0.748522\n",
      "07/06/2022 14:00:02 - INFO - __main__ -   Text: ['Freedom was also severely affected as he had to endure 60 for 60,5 main meals per day which was much too']\n",
      "07/06/2022 14:00:03 - INFO - __main__ -   Epoch: 42 | Batch: 4200/4327 (97%) | G Loss: 0.732632 | C Loss: -0.334034\n",
      "07/06/2022 14:00:04 - INFO - __main__ -   Text: [\"We've gone carefully through thousands of Facebook messages, flips, flips and Facebook ibis and it took quite a while\"]\n",
      "07/06/2022 14:00:04 - INFO - __main__ -   * (Train) Epoch: 42 | G Loss: 0.9984 | C Loss: -0.7536 | Updates G: 88 | Updates C: 272\n",
      "07/06/2022 14:00:18 - INFO - __main__ -   Bleu-2:0.471 | B-Bleu-2:0.302\n",
      "07/06/2022 14:00:18 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7721617904331772\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 43 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.719\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:02:46 - INFO - __main__ -   Epoch: 43 | Batch: 0/4417 (0%) | G Loss: 0.844955 | C Loss: -0.615300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.182\n",
      "  Test Loss: 4.089\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:02:47 - INFO - __main__ -   Text: ['Analyze the amount of hydrogen per flame or plasma burnt to get more useful nano-info, \"usual\" on']\n",
      "07/06/2022 14:02:49 - INFO - __main__ -   Epoch: 43 | Batch: 600/4417 (14%) | G Loss: 1.148167 | C Loss: -0.128576\n",
      "07/06/2022 14:02:49 - INFO - __main__ -   Text: ['As well as being an oral pro-life barrier spray, it sells for approximately £600 (another £400 if']\n",
      "07/06/2022 14:02:51 - INFO - __main__ -   Epoch: 43 | Batch: 1200/4417 (27%) | G Loss: 1.226329 | C Loss: -0.911665\n",
      "07/06/2022 14:02:51 - INFO - __main__ -   Text: [\"Originally, and as I reported after the 'amazing' award-presenting and during the 'pretty delays'\"]\n",
      "07/06/2022 14:02:53 - INFO - __main__ -   Epoch: 43 | Batch: 1800/4417 (41%) | G Loss: 1.040705 | C Loss: -0.720995\n",
      "07/06/2022 14:02:53 - INFO - __main__ -   Text: ['Today when we love a plastic toy, Sleepy explains about 5 times more about otome compared to the last day']\n",
      "07/06/2022 14:02:55 - INFO - __main__ -   Epoch: 43 | Batch: 2400/4417 (54%) | G Loss: 0.898464 | C Loss: -0.663508\n",
      "07/06/2022 14:02:55 - INFO - __main__ -   Text: ['They also found that that the effect of dose of medication (as naloxone) increases with each']\n",
      "07/06/2022 14:02:57 - INFO - __main__ -   Epoch: 43 | Batch: 3000/4417 (68%) | G Loss: 1.013632 | C Loss: -0.749914\n",
      "07/06/2022 14:02:57 - INFO - __main__ -   Text: ['Through Wal-Mart, it\\'s close to undergoing reducing urine with \"DG\" in the urine for months with']\n",
      "07/06/2022 14:02:59 - INFO - __main__ -   Epoch: 43 | Batch: 3600/4417 (82%) | G Loss: 0.970150 | C Loss: -0.710206\n",
      "07/06/2022 14:03:00 - INFO - __main__ -   Text: ['And he was admitted to have around 20 drops per week of water every morning after he lent for around 5 days,']\n",
      "07/06/2022 14:03:02 - INFO - __main__ -   Epoch: 43 | Batch: 4200/4417 (95%) | G Loss: 1.035590 | C Loss: -0.757363\n",
      "07/06/2022 14:03:02 - INFO - __main__ -   Text: ['Also, after eating around double the-food every day (as usual), he notices that he has changed very little']\n",
      "07/06/2022 14:03:02 - INFO - __main__ -   * (Train) Epoch: 43 | G Loss: 1.0317 | C Loss: -0.6671 | Updates G: 89 | Updates C: 279\n",
      "07/06/2022 14:03:16 - INFO - __main__ -   Bleu-2:0.472 | B-Bleu-2:0.321\n",
      "07/06/2022 14:03:16 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931025579131973\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 44 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.720\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:05:45 - INFO - __main__ -   Epoch: 44 | Batch: 0/4322 (0%) | G Loss: 1.069571 | C Loss: -0.551252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.215\n",
      "  Test Loss: 4.238\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:05:45 - INFO - __main__ -   Text: ['Tackling My Pain Daily has a negative view on the pain, resulting in him sometimes being hammered on channel 2']\n",
      "07/06/2022 14:05:47 - INFO - __main__ -   Epoch: 44 | Batch: 600/4322 (14%) | G Loss: 0.941217 | C Loss: -0.507630\n",
      "07/06/2022 14:05:47 - INFO - __main__ -   Text: ['These events keep him hot and dry for a while, gradually increasing in dosage as he gains strength subtly and slowly through']\n",
      "07/06/2022 14:05:49 - INFO - __main__ -   Epoch: 44 | Batch: 1200/4322 (28%) | G Loss: 1.295343 | C Loss: -0.816299\n",
      "07/06/2022 14:05:49 - INFO - __main__ -   Text: ['Newbies can control the juice for 15 minutes (or 5hrhas) and once the product is healthy enough to']\n",
      "07/06/2022 14:05:51 - INFO - __main__ -   Epoch: 44 | Batch: 1800/4322 (42%) | G Loss: 0.979981 | C Loss: -0.677910\n",
      "07/06/2022 14:05:51 - INFO - __main__ -   Text: ['Oscar is occasionally at work, but is completely underweight for all their time, and while she is very']\n",
      "07/06/2022 14:05:53 - INFO - __main__ -   Epoch: 44 | Batch: 2400/4322 (56%) | G Loss: 0.936574 | C Loss: -0.571981\n",
      "07/06/2022 14:05:53 - INFO - __main__ -   Text: ['She had sex twice a day, at five-hours-a-day on Tuesdays during the afternoon and vigorously']\n",
      "07/06/2022 14:05:55 - INFO - __main__ -   Epoch: 44 | Batch: 3000/4322 (69%) | G Loss: 0.843652 | C Loss: -0.467797\n",
      "07/06/2022 14:05:56 - INFO - __main__ -   Text: ['A regular drink would cost 7 day to adjust the well in two weeks; once it has low amounts in the diet']\n",
      "07/06/2022 14:05:58 - INFO - __main__ -   Epoch: 44 | Batch: 3600/4322 (83%) | G Loss: 1.069614 | C Loss: -0.792097\n",
      "07/06/2022 14:05:58 - INFO - __main__ -   Text: ['When the first person who tested positive for DM +S mutation in his heart appeared, he decided to increase the relapse']\n",
      "07/06/2022 14:06:00 - INFO - __main__ -   Epoch: 44 | Batch: 4200/4322 (97%) | G Loss: 0.817509 | C Loss: -0.437512\n",
      "07/06/2022 14:06:00 - INFO - __main__ -   Text: ['It has been reported that Sony employees waste all day while enjoying a run at a more \"time-sensitive\" type']\n",
      "07/06/2022 14:06:00 - INFO - __main__ -   * (Train) Epoch: 44 | G Loss: 1.0106 | C Loss: -0.6235 | Updates G: 82 | Updates C: 278\n",
      "07/06/2022 14:06:14 - INFO - __main__ -   Bleu-2:0.479 | B-Bleu-2:0.316\n",
      "07/06/2022 14:06:14 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7951052839712128\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 45 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.712\n",
      "  Average training loss discriminator: 0.723\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:08:43 - INFO - __main__ -   Epoch: 45 | Batch: 0/4527 (0%) | G Loss: 0.904853 | C Loss: -0.494182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.215\n",
      "  Test Loss: 4.163\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:08:43 - INFO - __main__ -   Text: ['It is quite funny that YT should still be on its arm out there as more pain meds than Hajil']\n",
      "07/06/2022 14:08:45 - INFO - __main__ -   Epoch: 45 | Batch: 600/4527 (13%) | G Loss: 1.004946 | C Loss: -0.540976\n",
      "07/06/2022 14:08:45 - INFO - __main__ -   Text: ['In the process of writing \"Kimbo\" most of the list consists of losing 500 kimbo in']\n",
      "07/06/2022 14:08:47 - INFO - __main__ -   Epoch: 45 | Batch: 1200/4527 (27%) | G Loss: 0.874918 | C Loss: -0.592078\n",
      "07/06/2022 14:08:47 - INFO - __main__ -   Text: ['This was changed in 2007 to put 0.5% pupil wants for free, \"\" Hindu\", which is unremarkable']\n",
      "07/06/2022 14:08:49 - INFO - __main__ -   Epoch: 45 | Batch: 1800/4527 (40%) | G Loss: 1.047134 | C Loss: -0.631366\n",
      "07/06/2022 14:08:49 - INFO - __main__ -   Text: ['None of the sputtering or metabolites Mr. Brusso gave him, however, did wonderful, and took us to']\n",
      "07/06/2022 14:08:51 - INFO - __main__ -   Epoch: 45 | Batch: 2400/4527 (53%) | G Loss: 1.009173 | C Loss: -0.708242\n",
      "07/06/2022 14:08:51 - INFO - __main__ -   Text: ['Neighbor users turn up to be uncomfortable at work, or at work with Breast Cancer; work is difficult enough']\n",
      "07/06/2022 14:08:53 - INFO - __main__ -   Epoch: 45 | Batch: 3000/4527 (66%) | G Loss: 0.890542 | C Loss: -0.600073\n",
      "07/06/2022 14:08:54 - INFO - __main__ -   Text: [\"His dogs' appetite for drugs above 6 days, however, dropped, and instead 1300 mg a day is gained,\"]\n",
      "07/06/2022 14:08:56 - INFO - __main__ -   Epoch: 45 | Batch: 3600/4527 (80%) | G Loss: 0.913593 | C Loss: -0.528602\n",
      "07/06/2022 14:08:56 - INFO - __main__ -   Text: ['This cause is far outweighed by a round of bleeding and ptosis but can take a month or more, so']\n",
      "07/06/2022 14:08:58 - INFO - __main__ -   Epoch: 45 | Batch: 4200/4527 (93%) | G Loss: 0.963162 | C Loss: -0.549982\n",
      "07/06/2022 14:08:58 - INFO - __main__ -   Text: ['This may just be resistance of pills, or communities hatred of being on medication\", Allan has explained, \"\\'insulin']\n",
      "07/06/2022 14:08:59 - INFO - __main__ -   * (Train) Epoch: 45 | G Loss: 0.9956 | C Loss: -0.6019 | Updates G: 88 | Updates C: 289\n",
      "07/06/2022 14:09:12 - INFO - __main__ -   Bleu-2:0.470 | B-Bleu-2:0.337\n",
      "07/06/2022 14:09:12 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8070322673709323\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 46 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:14:39 - INFO - __main__ -   Epoch: 47 | Batch: 0/4364 (0%) | G Loss: 0.931939 | C Loss: -0.554102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 4.298\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:14:39 - INFO - __main__ -   Text: ['The video was filmed unofficially and without noting it, due to guttural low sperm count,']\n",
      "07/06/2022 14:14:41 - INFO - __main__ -   Epoch: 47 | Batch: 600/4364 (14%) | G Loss: 1.087789 | C Loss: -0.640214\n",
      "07/06/2022 14:14:41 - INFO - __main__ -   Text: ['The response to this has been glowing and confusion (\"Gphig\"), and why has it been so long since he']\n",
      "07/06/2022 14:14:43 - INFO - __main__ -   Epoch: 47 | Batch: 1200/4364 (27%) | G Loss: 0.793737 | C Loss: -0.305671\n",
      "07/06/2022 14:14:43 - INFO - __main__ -   Text: ['Coming with a higher risk of serious kidney problems in addition to being prescribed Vasoprenvil twice, but shortly after']\n",
      "07/06/2022 14:14:45 - INFO - __main__ -   Epoch: 47 | Batch: 1800/4364 (41%) | G Loss: 1.075624 | C Loss: -0.680379\n",
      "07/06/2022 14:14:46 - INFO - __main__ -   Text: ['This void is the more beneficial given evening spent not performing tasks which will dampen joy with a pill that attached comes']\n",
      "07/06/2022 14:14:47 - INFO - __main__ -   Epoch: 47 | Batch: 2400/4364 (55%) | G Loss: 0.704144 | C Loss: -0.433083\n",
      "07/06/2022 14:14:48 - INFO - __main__ -   Text: ['To be genuinely positive, this is one of the most testimonial drugs I have ever seen, and he has heard']\n",
      "07/06/2022 14:14:50 - INFO - __main__ -   Epoch: 47 | Batch: 3000/4364 (69%) | G Loss: 1.169023 | C Loss: -0.755154\n",
      "07/06/2022 14:14:50 - INFO - __main__ -   Text: ['He now does it automatically aka activating after eating a kilo of milk (almost 3-4 hours at dose']\n",
      "07/06/2022 14:14:52 - INFO - __main__ -   Epoch: 47 | Batch: 3600/4364 (82%) | G Loss: 0.870401 | C Loss: -0.635265\n",
      "07/06/2022 14:14:52 - INFO - __main__ -   Text: ['Piedperian has previously experienced occasional problems getting power that gets interrupted, but in his time with']\n",
      "07/06/2022 14:14:54 - INFO - __main__ -   Epoch: 47 | Batch: 4200/4364 (96%) | G Loss: 0.771507 | C Loss: -0.336043\n",
      "07/06/2022 14:14:54 - INFO - __main__ -   Text: ['Records are often delayed by 3 years, at which point the patient loses weight, reduces her heart rate by']\n",
      "07/06/2022 14:14:55 - INFO - __main__ -   * (Train) Epoch: 47 | G Loss: 0.8953 | C Loss: -0.5649 | Updates G: 74 | Updates C: 289\n",
      "07/06/2022 14:15:09 - INFO - __main__ -   Bleu-2:0.481 | B-Bleu-2:0.308\n",
      "07/06/2022 14:15:09 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7895341481162715\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 48 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:17:37 - INFO - __main__ -   Epoch: 48 | Batch: 0/4330 (0%) | G Loss: 0.928698 | C Loss: -0.615062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 4.326\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:17:37 - INFO - __main__ -   Text: ['From this point onward he was monitored for his danger level, clean breath, epilepsy, diabetes, and diet; he']\n",
      "07/06/2022 14:17:39 - INFO - __main__ -   Epoch: 48 | Batch: 600/4330 (14%) | G Loss: 1.196284 | C Loss: -0.640551\n",
      "07/06/2022 14:17:40 - INFO - __main__ -   Text: ['Generally produced with vibrating frequency, one can make a 60 seconds but continuously <3?']\n",
      "07/06/2022 14:17:42 - INFO - __main__ -   Epoch: 48 | Batch: 1200/4330 (28%) | G Loss: 0.832627 | C Loss: -0.521044\n",
      "07/06/2022 14:17:42 - INFO - __main__ -   Text: ['Deutsch said that when cooking at a temperature above 110,000 apo, washing with coffee is hard because it']\n",
      "07/06/2022 14:17:44 - INFO - __main__ -   Epoch: 48 | Batch: 1800/4330 (42%) | G Loss: 1.037184 | C Loss: -0.605551\n",
      "07/06/2022 14:17:44 - INFO - __main__ -   Text: ['iPhone issue is that there is very little of difference between the sim card and the follow up, and now this is']\n",
      "07/06/2022 14:17:46 - INFO - __main__ -   Epoch: 48 | Batch: 2400/4330 (55%) | G Loss: 0.704422 | C Loss: -0.414566\n",
      "07/06/2022 14:17:46 - INFO - __main__ -   Text: ['It is perfectly safe to know that psychological effects produced by tar porn mini-comics are the cause of very poor']\n",
      "07/06/2022 14:17:48 - INFO - __main__ -   Epoch: 48 | Batch: 3000/4330 (69%) | G Loss: 0.701225 | C Loss: -0.457446\n",
      "07/06/2022 14:17:48 - INFO - __main__ -   Text: ['Thorax was blood thinner than usual and had weekly (and usuallydaily) blood draw readings £8/hr which']\n",
      "07/06/2022 14:17:50 - INFO - __main__ -   Epoch: 48 | Batch: 3600/4330 (83%) | G Loss: 1.183863 | C Loss: -0.696992\n",
      "07/06/2022 14:17:50 - INFO - __main__ -   Text: ['In just a few minutes he curiously steps under the line of warmth; MyDoug creates a frustratingly gratifying lack']\n",
      "07/06/2022 14:17:52 - INFO - __main__ -   Epoch: 48 | Batch: 4200/4330 (97%) | G Loss: 0.867247 | C Loss: -0.503425\n",
      "07/06/2022 14:17:52 - INFO - __main__ -   Text: ['The most commonly used Brit included acne, purple iris, acne poles and once, such habit sprays, he']\n",
      "07/06/2022 14:17:53 - INFO - __main__ -   * (Train) Epoch: 48 | G Loss: 0.9221 | C Loss: -0.5444 | Updates G: 74 | Updates C: 286\n",
      "07/06/2022 14:18:07 - INFO - __main__ -   Bleu-2:0.442 | B-Bleu-2:0.292\n",
      "07/06/2022 14:18:07 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7342696341939132\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 49 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:20:35 - INFO - __main__ -   Epoch: 49 | Batch: 0/4372 (0%) | G Loss: 0.946364 | C Loss: -0.521934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.215\n",
      "  Test Loss: 4.418\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:20:35 - INFO - __main__ -   Text: ['Anthropologist anthropologist Michael Edwards $YMMH\\'s this week says organic food is definitely topping as \"well']\n",
      "07/06/2022 14:20:37 - INFO - __main__ -   Epoch: 49 | Batch: 600/4372 (14%) | G Loss: 0.884448 | C Loss: -0.672250\n",
      "07/06/2022 14:20:38 - INFO - __main__ -   Text: ['On a decision scale, the average annual acne (which, by itself, is less than a week)']\n",
      "07/06/2022 14:20:39 - INFO - __main__ -   Epoch: 49 | Batch: 1200/4372 (27%) | G Loss: 0.752609 | C Loss: -0.383551\n",
      "07/06/2022 14:20:40 - INFO - __main__ -   Text: ['\"Suuha\" thought about the potential of the phone being smuggled into her child\\'s arms through the pouch,']\n",
      "07/06/2022 14:20:41 - INFO - __main__ -   Epoch: 49 | Batch: 1800/4372 (41%) | G Loss: 0.809140 | C Loss: -0.582536\n",
      "07/06/2022 14:20:42 - INFO - __main__ -   Text: ['This is becoming increasingly evident when Fibates user Vervegul who is typically sick is benchmarked out twice the']\n",
      "07/06/2022 14:20:44 - INFO - __main__ -   Epoch: 49 | Batch: 2400/4372 (55%) | G Loss: 0.907036 | C Loss: -0.523298\n",
      "07/06/2022 14:20:44 - INFO - __main__ -   Text: [\"The lactic acid doesn't add essentially another 8% to the beta, it doesn't get the cravings and\"]\n",
      "07/06/2022 14:20:46 - INFO - __main__ -   Epoch: 49 | Batch: 3000/4372 (69%) | G Loss: 0.986459 | C Loss: -0.464081\n",
      "07/06/2022 14:20:46 - INFO - __main__ -   Text: ['Offentials are bad for cardiovascular health (keeping the blood flowing faster so as not to become bloodlocked), they also']\n",
      "07/06/2022 14:20:48 - INFO - __main__ -   Epoch: 49 | Batch: 3600/4372 (82%) | G Loss: 0.815412 | C Loss: -0.578796\n",
      "07/06/2022 14:20:48 - INFO - __main__ -   Text: ['Pusterio is required to start only an hour before the start edct, or she will have bleeding cramps']\n",
      "07/06/2022 14:20:50 - INFO - __main__ -   Epoch: 49 | Batch: 4200/4372 (96%) | G Loss: 0.877718 | C Loss: -0.672115\n",
      "07/06/2022 14:20:51 - INFO - __main__ -   Text: ['From Ichthy feeling simple: thinks carefully. receives 7 staples a day, like a typical everyday deal for 3 grams']\n",
      "07/06/2022 14:20:51 - INFO - __main__ -   * (Train) Epoch: 49 | G Loss: 0.8509 | C Loss: -0.5096 | Updates G: 69 | Updates C: 295\n",
      "07/06/2022 14:21:05 - INFO - __main__ -   Bleu-2:0.469 | B-Bleu-2:0.321\n",
      "07/06/2022 14:21:05 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7891087159236221\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 50 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:23:33 - INFO - __main__ -   Epoch: 50 | Batch: 0/4473 (0%) | G Loss: 0.697576 | C Loss: -0.485269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 4.542\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:23:33 - INFO - __main__ -   Text: ['The problems were also alleviated when the diet was restricted to a 3600% fat diet for three to five days']\n",
      "07/06/2022 14:23:35 - INFO - __main__ -   Epoch: 50 | Batch: 600/4473 (13%) | G Loss: 0.754188 | C Loss: -0.301415\n",
      "07/06/2022 14:23:36 - INFO - __main__ -   Text: ['Often, when preparing for a flip of “Michigan“ and a']\n",
      "07/06/2022 14:23:38 - INFO - __main__ -   Epoch: 50 | Batch: 1200/4473 (27%) | G Loss: 0.895941 | C Loss: -0.514387\n",
      "07/06/2022 14:23:38 - INFO - __main__ -   Text: ['That means they talk for seven minutes, take out the suspension pill, enjoy three gold platelets, bang on the']\n",
      "07/06/2022 14:23:40 - INFO - __main__ -   Epoch: 50 | Batch: 1800/4473 (40%) | G Loss: 0.688830 | C Loss: -0.419844\n",
      "07/06/2022 14:23:40 - INFO - __main__ -   Text: ['Three weeks after their first pregnancy and they seem spontaneously gone then, they make a \"I\\'d go barefoot again']\n",
      "07/06/2022 14:23:42 - INFO - __main__ -   Epoch: 50 | Batch: 2400/4473 (54%) | G Loss: 0.831324 | C Loss: -0.516424\n",
      "07/06/2022 14:23:42 - INFO - __main__ -   Text: ['Featuring a record size difference of exan Strength Fights with a rate of EN at 70♃\" which']\n",
      "07/06/2022 14:23:45 - INFO - __main__ -   Epoch: 50 | Batch: 3000/4473 (67%) | G Loss: 0.765572 | C Loss: -0.465540\n",
      "07/06/2022 14:23:45 - INFO - __main__ -   Text: ['This is because, in a manufacturing company, where 300 meters of stress in a 10 min shot, similar stress is']\n",
      "07/06/2022 14:23:47 - INFO - __main__ -   Epoch: 50 | Batch: 3600/4473 (80%) | G Loss: 0.872487 | C Loss: -0.474754\n",
      "07/06/2022 14:23:47 - INFO - __main__ -   Text: ['At the time of writing “I am glad to find you today”, however “I am']\n",
      "07/06/2022 14:23:49 - INFO - __main__ -   Epoch: 50 | Batch: 4200/4473 (94%) | G Loss: 1.030970 | C Loss: -0.586752\n",
      "07/06/2022 14:23:49 - INFO - __main__ -   Text: ['Amblerind surgery in 1954 was only moderately successful and was designed to reduce total encephalopathy, or']\n",
      "07/06/2022 14:23:50 - INFO - __main__ -   * (Train) Epoch: 50 | G Loss: 0.8183 | C Loss: -0.4963 | Updates G: 53 | Updates C: 319\n",
      "07/06/2022 14:24:04 - INFO - __main__ -   Bleu-2:0.464 | B-Bleu-2:0.298\n",
      "07/06/2022 14:24:04 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7624536373613395\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 51 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:26:32 - INFO - __main__ -   Epoch: 51 | Batch: 0/4473 (0%) | G Loss: 1.407984 | C Loss: -0.549492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.215\n",
      "  Test Loss: 4.591\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:26:32 - INFO - __main__ -   Text: ['Jisdorf taught him his routines, which call for exercise, more of it, less meddling,']\n",
      "07/06/2022 14:26:34 - INFO - __main__ -   Epoch: 51 | Batch: 600/4473 (13%) | G Loss: 0.719807 | C Loss: -0.413894\n",
      "07/06/2022 14:26:35 - INFO - __main__ -   Text: [\"Malira's condition has changed dramatically, by the time she left the clinic the blood levels in the clinically indicative blood\"]\n",
      "07/06/2022 14:26:37 - INFO - __main__ -   Epoch: 51 | Batch: 1200/4473 (27%) | G Loss: 0.643517 | C Loss: -0.401486\n",
      "07/06/2022 14:26:37 - INFO - __main__ -   Text: ['\"I don\\'t know anymore than twenty hours after quitting to get it, so no doubt I suffer from liver']\n",
      "07/06/2022 14:26:39 - INFO - __main__ -   Epoch: 51 | Batch: 1800/4473 (40%) | G Loss: 1.036509 | C Loss: -0.626495\n",
      "07/06/2022 14:26:39 - INFO - __main__ -   Text: ['The formulaic liquid increased by about 10% each day when I measured it at \"at glucose\" levels in the']\n",
      "07/06/2022 14:26:41 - INFO - __main__ -   Epoch: 51 | Batch: 2400/4473 (54%) | G Loss: 0.898322 | C Loss: -0.448741\n",
      "07/06/2022 14:26:41 - INFO - __main__ -   Text: ['Lenin says that he regularly consumes three pounds of delicious peanut oil – that really is entire adulthood until Cedars do']\n",
      "07/06/2022 14:26:43 - INFO - __main__ -   Epoch: 51 | Batch: 3000/4473 (67%) | G Loss: 0.867453 | C Loss: -0.533745\n",
      "07/06/2022 14:26:43 - INFO - __main__ -   Text: [\"Artisa on the other hand, is able to score a few points even when it looks like someone's tried to\"]\n",
      "07/06/2022 14:26:45 - INFO - __main__ -   Epoch: 51 | Batch: 3600/4473 (80%) | G Loss: 0.931922 | C Loss: -0.338061\n",
      "07/06/2022 14:26:46 - INFO - __main__ -   Text: ['However, in contrast to many foods, myRaFa dreams of having a baby sit on top of him or in']\n",
      "07/06/2022 14:26:48 - INFO - __main__ -   Epoch: 51 | Batch: 4200/4473 (94%) | G Loss: 0.702674 | C Loss: -0.364141\n",
      "07/06/2022 14:26:48 - INFO - __main__ -   Text: ['He regularly takes notice that someone else is folding thay faster than him\" There\\'s a hormonal issue and Sara takes']\n",
      "07/06/2022 14:26:49 - INFO - __main__ -   * (Train) Epoch: 51 | G Loss: 0.8561 | C Loss: -0.4683 | Updates G: 73 | Updates C: 299\n",
      "07/06/2022 14:27:03 - INFO - __main__ -   Bleu-2:0.469 | B-Bleu-2:0.297\n",
      "07/06/2022 14:27:03 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7655183322607293\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 52 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:29:31 - INFO - __main__ -   Epoch: 52 | Batch: 0/4327 (0%) | G Loss: 0.756869 | C Loss: -0.458763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 4.540\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:29:31 - INFO - __main__ -   Text: ['If the fungus makes more snipes the dosage will decrease (with starter) from one to two a day (meaning']\n",
      "07/06/2022 14:29:33 - INFO - __main__ -   Epoch: 52 | Batch: 600/4327 (14%) | G Loss: 1.010409 | C Loss: -0.546596\n",
      "07/06/2022 14:29:34 - INFO - __main__ -   Text: ['In 2018, they tested me twice just as well — one with a metabolic analysis which shows both diet and caffeine sale']\n",
      "07/06/2022 14:29:36 - INFO - __main__ -   Epoch: 52 | Batch: 1200/4327 (28%) | G Loss: 0.761370 | C Loss: -0.555956\n",
      "07/06/2022 14:29:36 - INFO - __main__ -   Text: ['Mr Taula tells me that its daily dose is 6mg, while daily dose is 40mg, in order']\n",
      "07/06/2022 14:29:38 - INFO - __main__ -   Epoch: 52 | Batch: 1800/4327 (42%) | G Loss: 0.695727 | C Loss: -0.407554\n",
      "07/06/2022 14:29:38 - INFO - __main__ -   Text: ['This puts a lot of strain on my memory and my long lasting memory; with these drugs I sometimes forget a few']\n",
      "07/06/2022 14:29:40 - INFO - __main__ -   Epoch: 52 | Batch: 2400/4327 (55%) | G Loss: 0.718364 | C Loss: -0.430789\n",
      "07/06/2022 14:29:40 - INFO - __main__ -   Text: ['This heel movement practice lowers the potential for change due to a tendency to lose control of the foot and heel tendency during']\n",
      "07/06/2022 14:29:42 - INFO - __main__ -   Epoch: 52 | Batch: 3000/4327 (69%) | G Loss: 0.741276 | C Loss: -0.442181\n",
      "07/06/2022 14:29:42 - INFO - __main__ -   Text: ['Expecting that they will reach 5 years of age, he provides a few spells at first, bats five breaks']\n",
      "07/06/2022 14:29:44 - INFO - __main__ -   Epoch: 52 | Batch: 3600/4327 (83%) | G Loss: 1.020048 | C Loss: -0.486486\n",
      "07/06/2022 14:29:44 - INFO - __main__ -   Text: ['Her brother was so convinced she could reach the point she could reach in the toilet, that he came up to watch']\n",
      "07/06/2022 14:29:46 - INFO - __main__ -   Epoch: 52 | Batch: 4200/4327 (97%) | G Loss: 0.745240 | C Loss: -0.464241\n",
      "07/06/2022 14:29:47 - INFO - __main__ -   Text: [\"Plastic and plastic packaging not only messes up your brain's ability to think, it also messes up your\"]\n",
      "07/06/2022 14:29:47 - INFO - __main__ -   * (Train) Epoch: 52 | G Loss: 0.7980 | C Loss: -0.4553 | Updates G: 82 | Updates C: 278\n",
      "07/06/2022 14:30:01 - INFO - __main__ -   Bleu-2:0.444 | B-Bleu-2:0.303\n",
      "07/06/2022 14:30:01 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7473806141910628\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 53 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:32:29 - INFO - __main__ -   Epoch: 53 | Batch: 0/4417 (0%) | G Loss: 0.696844 | C Loss: -0.344639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.217\n",
      "  Test Loss: 4.605\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:32:29 - INFO - __main__ -   Text: ['He stated: \"In the broadcast seat, it was 10 litres of beer for two seconds per day until your breast']\n",
      "07/06/2022 14:32:31 - INFO - __main__ -   Epoch: 53 | Batch: 600/4417 (14%) | G Loss: 0.724914 | C Loss: -0.444394\n",
      "07/06/2022 14:32:31 - INFO - __main__ -   Text: ['This process is aptly described by David Crollperk in his Amazon: \"In our break-out year,']\n",
      "07/06/2022 14:32:33 - INFO - __main__ -   Epoch: 53 | Batch: 1200/4417 (27%) | G Loss: 0.952011 | C Loss: -0.514626\n",
      "07/06/2022 14:32:34 - INFO - __main__ -   Text: ['All the medications and make up to three pills per day are absorbed together ( the']\n",
      "07/06/2022 14:32:36 - INFO - __main__ -   Epoch: 53 | Batch: 1800/4417 (41%) | G Loss: 0.976298 | C Loss: -0.646753\n",
      "07/06/2022 14:32:36 - INFO - __main__ -   Text: [\"Even with the amateurs on the brush, advice from a colleague shows that his 'soft-to-touch'\"]\n",
      "07/06/2022 14:32:38 - INFO - __main__ -   Epoch: 53 | Batch: 2400/4417 (54%) | G Loss: 0.693955 | C Loss: -0.424744\n",
      "07/06/2022 14:32:38 - INFO - __main__ -   Text: ['In the past year, Shatabasti has taught her own in-hand bat instinct and its very own']\n",
      "07/06/2022 14:32:40 - INFO - __main__ -   Epoch: 53 | Batch: 3000/4417 (68%) | G Loss: 0.604626 | C Loss: -0.342779\n",
      "07/06/2022 14:32:40 - INFO - __main__ -   Text: ['He is now trying to discourage breeding and having a healthy frustrating dinum while generally waiting for the retail release from cancer']\n",
      "07/06/2022 14:32:42 - INFO - __main__ -   Epoch: 53 | Batch: 3600/4417 (82%) | G Loss: 0.853172 | C Loss: -0.553794\n",
      "07/06/2022 14:32:42 - INFO - __main__ -   Text: ['It seems that most people with DIR appear much cooler and can remain awake within 2–10 hours, and fan']\n",
      "07/06/2022 14:32:44 - INFO - __main__ -   Epoch: 53 | Batch: 4200/4417 (95%) | G Loss: 0.790963 | C Loss: -0.395130\n",
      "07/06/2022 14:32:45 - INFO - __main__ -   Text: [\"Its symptoms may also be less serious than that of the less endoglycemic flour you're at home making\"]\n",
      "07/06/2022 14:32:45 - INFO - __main__ -   * (Train) Epoch: 53 | G Loss: 0.7942 | C Loss: -0.4382 | Updates G: 66 | Updates C: 302\n",
      "07/06/2022 14:33:00 - INFO - __main__ -   Bleu-2:0.488 | B-Bleu-2:0.321\n",
      "07/06/2022 14:33:00 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8096444961500073\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 54 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:35:28 - INFO - __main__ -   Epoch: 54 | Batch: 0/4322 (0%) | G Loss: 0.708934 | C Loss: -0.399136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 4.519\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:35:28 - INFO - __main__ -   Text: ['When it comes to mouth pressure, Miyushima uses no herbs, hypnosis, pleasant breath, vitamins and breastfeeding but']\n",
      "07/06/2022 14:35:30 - INFO - __main__ -   Epoch: 54 | Batch: 600/4322 (14%) | G Loss: 0.813628 | C Loss: -0.531456\n",
      "07/06/2022 14:35:30 - INFO - __main__ -   Text: ['In Drag Bar and Drag Bar 2, you will periodically click buttons on the poker bar but on \"PC\" display']\n",
      "07/06/2022 14:35:33 - INFO - __main__ -   Epoch: 54 | Batch: 1200/4322 (28%) | G Loss: 0.701847 | C Loss: -0.544595\n",
      "07/06/2022 14:35:33 - INFO - __main__ -   Text: [\"In December 2012, Sarah bragged that she obtained four month's worth of EDM and this was a number that\"]\n",
      "07/06/2022 14:35:35 - INFO - __main__ -   Epoch: 54 | Batch: 1800/4322 (42%) | G Loss: 0.538051 | C Loss: -0.364058\n",
      "07/06/2022 14:35:35 - INFO - __main__ -   Text: ['The problem extends to emphasis medication for other babies, however, Dogbo has already had an allergic reaction at the beginning']\n",
      "07/06/2022 14:35:37 - INFO - __main__ -   Epoch: 54 | Batch: 2400/4322 (56%) | G Loss: 0.718544 | C Loss: -0.302070\n",
      "07/06/2022 14:35:37 - INFO - __main__ -   Text: ['These applications would largely disappear as their stimulant effects continued after reach the age of 16, when Duozzo too']\n",
      "07/06/2022 14:35:39 - INFO - __main__ -   Epoch: 54 | Batch: 3000/4322 (69%) | G Loss: 1.052715 | C Loss: -0.546101\n",
      "07/06/2022 14:35:39 - INFO - __main__ -   Text: [\"Valvera's scholar partner/friend Carol Griswold stopped reading straining and added that if the temperature\"]\n",
      "07/06/2022 14:35:41 - INFO - __main__ -   Epoch: 54 | Batch: 3600/4322 (83%) | G Loss: 0.596215 | C Loss: -0.396113\n",
      "07/06/2022 14:35:41 - INFO - __main__ -   Text: ['If eaten long enough, it has deadly acute nerve damage that causes irritation to your breathing and tongue, and can cause']\n",
      "07/06/2022 14:35:43 - INFO - __main__ -   Epoch: 54 | Batch: 4200/4322 (97%) | G Loss: 0.797136 | C Loss: -0.466929\n",
      "07/06/2022 14:35:43 - INFO - __main__ -   Text: ['Glush? <PAD> spaces? Visituppa!']\n",
      "07/06/2022 14:35:44 - INFO - __main__ -   * (Train) Epoch: 54 | G Loss: 0.7233 | C Loss: -0.3977 | Updates G: 63 | Updates C: 297\n",
      "07/06/2022 14:35:58 - INFO - __main__ -   Bleu-2:0.469 | B-Bleu-2:0.294\n",
      "07/06/2022 14:35:58 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7622408789933286\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 55 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:38:26 - INFO - __main__ -   Epoch: 55 | Batch: 0/4527 (0%) | G Loss: 0.837372 | C Loss: -0.393702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 4.687\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:38:26 - INFO - __main__ -   Text: ['In the flu T2 flu episode, the female “ベ� т�” will repeat']\n",
      "07/06/2022 14:38:28 - INFO - __main__ -   Epoch: 55 | Batch: 600/4527 (13%) | G Loss: 0.581884 | C Loss: -0.357654\n",
      "07/06/2022 14:38:28 - INFO - __main__ -   Text: ['Pre-exposure to the drugs increases the risk of bladder cancer, kidney thinning, bittorrent gas']\n",
      "07/06/2022 14:38:30 - INFO - __main__ -   Epoch: 55 | Batch: 1200/4527 (27%) | G Loss: 0.730774 | C Loss: -0.396378\n",
      "07/06/2022 14:38:30 - INFO - __main__ -   Text: ['Topstoppers If you feel like wanting to overdose new pills please send email to']\n",
      "07/06/2022 14:38:32 - INFO - __main__ -   Epoch: 55 | Batch: 1800/4527 (40%) | G Loss: 1.077063 | C Loss: -0.764798\n",
      "07/06/2022 14:38:32 - INFO - __main__ -   Text: ['It is considered that MEGA is the most dangerous substance given in shortutes and sprints the HR 400 for just']\n",
      "07/06/2022 14:38:35 - INFO - __main__ -   Epoch: 55 | Batch: 2400/4527 (53%) | G Loss: 0.810302 | C Loss: -0.490629\n",
      "07/06/2022 14:38:35 - INFO - __main__ -   Text: ['I say yes, the same steady suckling is likely to turn up faster in Kadeleaf where my yeast infections']\n",
      "07/06/2022 14:38:37 - INFO - __main__ -   Epoch: 55 | Batch: 3000/4527 (66%) | G Loss: 0.594726 | C Loss: -0.342391\n",
      "07/06/2022 14:38:37 - INFO - __main__ -   Text: ['Characters get mad at each other, are caught by their client bm ignoring etiquette like a dog and runs away when']\n",
      "07/06/2022 14:38:39 - INFO - __main__ -   Epoch: 55 | Batch: 3600/4527 (80%) | G Loss: 0.524618 | C Loss: -0.202055\n",
      "07/06/2022 14:38:39 - INFO - __main__ -   Text: ['']\n",
      "07/06/2022 14:38:41 - INFO - __main__ -   Epoch: 55 | Batch: 4200/4527 (93%) | G Loss: 0.651164 | C Loss: -0.330098\n",
      "07/06/2022 14:38:41 - INFO - __main__ -   Text: ['Racing Dyls, build-up power and lockout seemed to me to have increased natural pulse duration, and I']\n",
      "07/06/2022 14:38:42 - INFO - __main__ -   * (Train) Epoch: 55 | G Loss: 0.6882 | C Loss: -0.3899 | Updates G: 62 | Updates C: 315\n",
      "07/06/2022 14:38:56 - INFO - __main__ -   Bleu-2:0.462 | B-Bleu-2:0.308\n",
      "07/06/2022 14:38:56 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7702264255060167\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 56 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:41:25 - INFO - __main__ -   Epoch: 56 | Batch: 0/4467 (0%) | G Loss: 0.813784 | C Loss: -0.405476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 4.716\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:41:25 - INFO - __main__ -   Text: ['Orihana said:~ \"When you start to drink content up because it becomes easier to take, many people']\n",
      "07/06/2022 14:41:27 - INFO - __main__ -   Epoch: 56 | Batch: 600/4467 (13%) | G Loss: 0.713699 | C Loss: -0.408255\n",
      "07/06/2022 14:41:27 - INFO - __main__ -   Text: ['Individuals have trouble getting help after eating a day or twice a week, or after taking medicines such as Vicodin']\n",
      "07/06/2022 14:41:29 - INFO - __main__ -   Epoch: 56 | Batch: 1200/4467 (27%) | G Loss: 0.754153 | C Loss: -0.503441\n",
      "07/06/2022 14:41:29 - INFO - __main__ -   Text: ['It is important to stay hydrated with sun since this helps energy levels to improve, and also gives positive feedback in']\n",
      "07/06/2022 14:41:31 - INFO - __main__ -   Epoch: 56 | Batch: 1800/4467 (40%) | G Loss: 0.599412 | C Loss: -0.243301\n",
      "07/06/2022 14:41:31 - INFO - __main__ -   Text: ['The demons go years, and after 1 month she went througha week class of weaned pills and PAH therapy']\n",
      "07/06/2022 14:41:33 - INFO - __main__ -   Epoch: 56 | Batch: 2400/4467 (54%) | G Loss: 0.728577 | C Loss: -0.200182\n",
      "07/06/2022 14:41:33 - INFO - __main__ -   Text: ['She has struggled to pressurize using a fast rub test, as instead she has started out cooperating in alcohol or']\n",
      "07/06/2022 14:41:35 - INFO - __main__ -   Epoch: 56 | Batch: 3000/4467 (67%) | G Loss: 0.609199 | C Loss: -0.353217\n",
      "07/06/2022 14:41:36 - INFO - __main__ -   Text: [\"Each contest starts with a round of food about Vegan Meat, snack between 1 and 3 (in a normal woman's\"]\n",
      "07/06/2022 14:41:38 - INFO - __main__ -   Epoch: 56 | Batch: 3600/4467 (81%) | G Loss: 1.066999 | C Loss: -0.573033\n",
      "07/06/2022 14:41:38 - INFO - __main__ -   Text: [\"Most people don't realize that there is absolutely no doctor at every stage of every day, no knife burn prevention,\"]\n",
      "07/06/2022 14:41:40 - INFO - __main__ -   Epoch: 56 | Batch: 4200/4467 (94%) | G Loss: 0.632791 | C Loss: -0.470874\n",
      "07/06/2022 14:41:40 - INFO - __main__ -   Text: ['\"That time around I-Cassette is the breakneck pace of the overnight life, and I I']\n",
      "07/06/2022 14:41:41 - INFO - __main__ -   * (Train) Epoch: 56 | G Loss: 0.7086 | C Loss: -0.3979 | Updates G: 64 | Updates C: 308\n",
      "07/06/2022 14:41:55 - INFO - __main__ -   Bleu-2:0.477 | B-Bleu-2:0.308\n",
      "07/06/2022 14:41:55 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784335787092049\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 57 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:44:23 - INFO - __main__ -   Epoch: 57 | Batch: 0/4364 (0%) | G Loss: 0.528817 | C Loss: -0.304714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 4.782\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:44:23 - INFO - __main__ -   Text: ['As well as avoiding the post-set caffeine pill, producing a mild headache for one hour, anorexia for']\n",
      "07/06/2022 14:44:25 - INFO - __main__ -   Epoch: 57 | Batch: 600/4364 (14%) | G Loss: 0.463305 | C Loss: -0.222823\n",
      "07/06/2022 14:44:25 - INFO - __main__ -   Text: ['Pillows']\n",
      "07/06/2022 14:44:27 - INFO - __main__ -   Epoch: 57 | Batch: 1200/4364 (27%) | G Loss: 0.670841 | C Loss: -0.439551\n",
      "07/06/2022 14:44:27 - INFO - __main__ -   Text: ['The drug does harm if the apparent likelihood of withdrawal is less than 30% (1/100th),']\n",
      "07/06/2022 14:44:29 - INFO - __main__ -   Epoch: 57 | Batch: 1800/4364 (41%) | G Loss: 0.619141 | C Loss: -0.310949\n",
      "07/06/2022 14:44:29 - INFO - __main__ -   Text: [\"Other tests noted, Carharta doesn't have any pain, and doesn't feel like walking anchor indoors with a\"]\n",
      "07/06/2022 14:44:31 - INFO - __main__ -   Epoch: 57 | Batch: 2400/4364 (55%) | G Loss: 0.870338 | C Loss: -0.505382\n",
      "07/06/2022 14:44:31 - INFO - __main__ -   Text: ['It just wasn\\'t acceptable for the pupils to yell loudly, say \"hola\", because (the medication in the']\n",
      "07/06/2022 14:44:33 - INFO - __main__ -   Epoch: 57 | Batch: 3000/4364 (69%) | G Loss: 1.024498 | C Loss: -0.568596\n",
      "07/06/2022 14:44:34 - INFO - __main__ -   Text: ['The episode with the joke dominating these days is the best one yet and it is good enough for']\n",
      "07/06/2022 14:44:36 - INFO - __main__ -   Epoch: 57 | Batch: 3600/4364 (82%) | G Loss: 0.589855 | C Loss: -0.326974\n",
      "07/06/2022 14:44:36 - INFO - __main__ -   Text: ['Following several months of treatment, it is over thirty pounds of fat left to burn and the successful treatment of for the']\n",
      "07/06/2022 14:44:38 - INFO - __main__ -   Epoch: 57 | Batch: 4200/4364 (96%) | G Loss: 0.585094 | C Loss: -0.367384\n",
      "07/06/2022 14:44:38 - INFO - __main__ -   Text: ['Despite the epidemic, the game has a positive effect and the player as a whole still managed to eat a great deal']\n",
      "07/06/2022 14:44:39 - INFO - __main__ -   * (Train) Epoch: 57 | G Loss: 0.6703 | C Loss: -0.3255 | Updates G: 68 | Updates C: 295\n",
      "07/06/2022 14:44:53 - INFO - __main__ -   Bleu-2:0.483 | B-Bleu-2:0.310\n",
      "07/06/2022 14:44:53 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7934249181894688\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 58 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:47:21 - INFO - __main__ -   Epoch: 58 | Batch: 0/4330 (0%) | G Loss: 0.600536 | C Loss: -0.319264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 4.703\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:47:21 - INFO - __main__ -   Text: ['\"Judah\" has already enrolled at \"talk\\'s\" website at the core of her powers more than once,']\n",
      "07/06/2022 14:47:23 - INFO - __main__ -   Epoch: 58 | Batch: 600/4330 (14%) | G Loss: 0.606247 | C Loss: -0.336691\n",
      "07/06/2022 14:47:24 - INFO - __main__ -   Text: ['Unable to meet his minimum daily goal, he used electrodes which boosted libido and gained weight by changing the caffeine and']\n",
      "07/06/2022 14:47:25 - INFO - __main__ -   Epoch: 58 | Batch: 1200/4330 (28%) | G Loss: 0.551888 | C Loss: -0.257958\n",
      "07/06/2022 14:47:26 - INFO - __main__ -   Text: ['They also display a limp (or possibly no limp) target on this Raycrest listed product where they display']\n",
      "07/06/2022 14:47:28 - INFO - __main__ -   Epoch: 58 | Batch: 1800/4330 (42%) | G Loss: 0.847242 | C Loss: -0.505403\n",
      "07/06/2022 14:47:28 - INFO - __main__ -   Text: ['He seems jolted by the sudden temper in his missionary dance and considers it too much time since he is equipped']\n",
      "07/06/2022 14:47:30 - INFO - __main__ -   Epoch: 58 | Batch: 2400/4330 (55%) | G Loss: 0.553063 | C Loss: -0.303690\n",
      "07/06/2022 14:47:30 - INFO - __main__ -   Text: [\"The hustler goes through eight trials per day, yet it's even harder for him to give food, drink,\"]\n",
      "07/06/2022 14:47:32 - INFO - __main__ -   Epoch: 58 | Batch: 3000/4330 (69%) | G Loss: 0.483758 | C Loss: -0.134018\n",
      "07/06/2022 14:47:32 - INFO - __main__ -   Text: ['At about the age of 50, she stated: \"Blunt tiredness starts around mid second fifth (grade)']\n",
      "07/06/2022 14:47:34 - INFO - __main__ -   Epoch: 58 | Batch: 3600/4330 (83%) | G Loss: 0.614982 | C Loss: -0.340200\n",
      "07/06/2022 14:47:35 - INFO - __main__ -   Text: ['After he poured out his drink, Ramande gradually recovers and strains to drink in optimal doses as Telnaya recovers']\n",
      "07/06/2022 14:47:36 - INFO - __main__ -   Epoch: 58 | Batch: 4200/4330 (97%) | G Loss: 1.035001 | C Loss: -0.400993\n",
      "07/06/2022 14:47:37 - INFO - __main__ -   Text: [\"9.00 the girls' flat runs at least 1.00 a hour an hour with some other hard to take\"]\n",
      "07/06/2022 14:47:37 - INFO - __main__ -   * (Train) Epoch: 58 | G Loss: 0.6916 | C Loss: -0.3531 | Updates G: 68 | Updates C: 292\n",
      "07/06/2022 14:47:51 - INFO - __main__ -   Bleu-2:0.472 | B-Bleu-2:0.318\n",
      "07/06/2022 14:47:51 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7899551923617422\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 59 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:50:19 - INFO - __main__ -   Epoch: 59 | Batch: 0/4372 (0%) | G Loss: 0.733607 | C Loss: -0.288753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 4.704\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:50:19 - INFO - __main__ -   Text: ['When Leary says \"ug water\" and \"oop love\" turns pablack, he is doing OK']\n",
      "07/06/2022 14:50:21 - INFO - __main__ -   Epoch: 59 | Batch: 600/4372 (14%) | G Loss: 0.617437 | C Loss: -0.236331\n",
      "07/06/2022 14:50:21 - INFO - __main__ -   Text: ['when I meet you, you are forever thankful, your hangover cure ate away your memory, and I think I']\n",
      "07/06/2022 14:50:23 - INFO - __main__ -   Epoch: 59 | Batch: 1200/4372 (27%) | G Loss: 0.658057 | C Loss: -0.347120\n",
      "07/06/2022 14:50:24 - INFO - __main__ -   Text: [\"It's usual to have a little 'ego', and it slows its appetite greatly (although it can twice a\"]\n",
      "07/06/2022 14:50:25 - INFO - __main__ -   Epoch: 59 | Batch: 1800/4372 (41%) | G Loss: 0.445619 | C Loss: -0.215516\n",
      "07/06/2022 14:50:26 - INFO - __main__ -   Text: [\"Without it, I'm just not ready for the vision, have websites crunched and I must make diaries\"]\n",
      "07/06/2022 14:50:28 - INFO - __main__ -   Epoch: 59 | Batch: 2400/4372 (55%) | G Loss: 0.646635 | C Loss: -0.266445\n",
      "07/06/2022 14:50:28 - INFO - __main__ -   Text: [\"It is surprising that the vehicle won't normally taste such dry mouth, but it starts to taste a salty water,\"]\n",
      "07/06/2022 14:50:30 - INFO - __main__ -   Epoch: 59 | Batch: 3000/4372 (69%) | G Loss: 0.764326 | C Loss: -0.330066\n",
      "07/06/2022 14:50:30 - INFO - __main__ -   Text: ['Datal Naruliiconda had no reason for, let alone thought it was her, to be depressed financially,']\n",
      "07/06/2022 14:50:32 - INFO - __main__ -   Epoch: 59 | Batch: 3600/4372 (82%) | G Loss: 0.662411 | C Loss: -0.390209\n",
      "07/06/2022 14:50:32 - INFO - __main__ -   Text: ['The impossibility is also compounded by with emptiness weighing 3000 lb in excess of his normal weight for 20 minutes, he']\n",
      "07/06/2022 14:50:34 - INFO - __main__ -   Epoch: 59 | Batch: 4200/4372 (96%) | G Loss: 0.554692 | C Loss: -0.195338\n",
      "07/06/2022 14:50:35 - INFO - __main__ -   Text: [\"Safaver's baby formula inflates somewhat when she strips sometimes, but she gets MICT a second time every time\"]\n",
      "07/06/2022 14:50:35 - INFO - __main__ -   * (Train) Epoch: 59 | G Loss: 0.6527 | C Loss: -0.3053 | Updates G: 55 | Updates C: 309\n",
      "07/06/2022 14:50:49 - INFO - __main__ -   Bleu-2:0.482 | B-Bleu-2:0.315\n",
      "07/06/2022 14:50:49 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7970977633307423\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 60 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:53:17 - INFO - __main__ -   Epoch: 60 | Batch: 0/4473 (0%) | G Loss: 0.632265 | C Loss: -0.310466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 4.875\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:53:18 - INFO - __main__ -   Text: ['Subsequently, Antlord slows DrG on her PC significantly whichupon the vanilla goes off two weeks later, prompting']\n",
      "07/06/2022 14:53:19 - INFO - __main__ -   Epoch: 60 | Batch: 600/4473 (13%) | G Loss: 0.486968 | C Loss: -0.287756\n",
      "07/06/2022 14:53:20 - INFO - __main__ -   Text: ['He has regularly managed to leave all the butter in his bowels in the tariffs but NEVER forgot to make it']\n",
      "07/06/2022 14:53:22 - INFO - __main__ -   Epoch: 60 | Batch: 1200/4473 (27%) | G Loss: 0.637024 | C Loss: -0.139968\n",
      "07/06/2022 14:53:22 - INFO - __main__ -   Text: ['Booming in popularity is a move in \"Mondays\"\\'s ballsop: \"Drink a lot,']\n",
      "07/06/2022 14:53:24 - INFO - __main__ -   Epoch: 60 | Batch: 1800/4473 (40%) | G Loss: 0.773301 | C Loss: -0.255806\n",
      "07/06/2022 14:53:24 - INFO - __main__ -   Text: ['It turns out intensive physical therapy for such diseases is not the only method – the real cure is managed therapy, types']\n",
      "07/06/2022 14:53:26 - INFO - __main__ -   Epoch: 60 | Batch: 2400/4473 (54%) | G Loss: 0.559051 | C Loss: -0.247025\n",
      "07/06/2022 14:53:26 - INFO - __main__ -   Text: ['The second time I threw the first move (eating no less than 600 calories), one kidney kept coughing and the child']\n",
      "07/06/2022 14:53:28 - INFO - __main__ -   Epoch: 60 | Batch: 3000/4473 (67%) | G Loss: 1.048483 | C Loss: -0.537699\n",
      "07/06/2022 14:53:29 - INFO - __main__ -   Text: [\"However, regularly deleting or offering help at 12 hours doesn't tummy it not that Aravinda can do\"]\n",
      "07/06/2022 14:53:31 - INFO - __main__ -   Epoch: 60 | Batch: 3600/4473 (80%) | G Loss: 0.593402 | C Loss: -0.311849\n",
      "07/06/2022 14:53:31 - INFO - __main__ -   Text: ['\"I have suddenly fallen sick with nausea, and because of your crazy fuels management plan there was one day that I']\n",
      "07/06/2022 14:53:33 - INFO - __main__ -   Epoch: 60 | Batch: 4200/4473 (94%) | G Loss: 0.582630 | C Loss: -0.325459\n",
      "07/06/2022 14:53:33 - INFO - __main__ -   Text: ['A prednisone tournament was hosted and managed by \"Me Ha Ruie Soucekn,\" Howard was diagnosed with']\n",
      "07/06/2022 14:53:34 - INFO - __main__ -   * (Train) Epoch: 60 | G Loss: 0.6348 | C Loss: -0.2919 | Updates G: 62 | Updates C: 310\n",
      "07/06/2022 14:53:47 - INFO - __main__ -   Bleu-2:0.464 | B-Bleu-2:0.313\n",
      "07/06/2022 14:53:47 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768488054758127\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 61 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:56:16 - INFO - __main__ -   Epoch: 61 | Batch: 0/4473 (0%) | G Loss: 0.687456 | C Loss: -0.369087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 4.831\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:56:16 - INFO - __main__ -   Text: ['A \"voluntary vitamin\" diet takes up to 4 days on and of course can keep’s body']\n",
      "07/06/2022 14:56:18 - INFO - __main__ -   Epoch: 61 | Batch: 600/4473 (13%) | G Loss: 0.643819 | C Loss: -0.267820\n",
      "07/06/2022 14:56:18 - INFO - __main__ -   Text: ['It has become controversial hobbyistically after learning Iidol for date, kills slowes, strokes, and is given']\n",
      "07/06/2022 14:56:20 - INFO - __main__ -   Epoch: 61 | Batch: 1200/4473 (27%) | G Loss: 0.585212 | C Loss: -0.279370\n",
      "07/06/2022 14:56:20 - INFO - __main__ -   Text: ['It has a distinct habit of being an absolute pleasure for me, for example if I make any methamphetamine at all on']\n",
      "07/06/2022 14:56:22 - INFO - __main__ -   Epoch: 61 | Batch: 1800/4473 (40%) | G Loss: 0.615898 | C Loss: -0.271225\n",
      "07/06/2022 14:56:23 - INFO - __main__ -   Text: ['When she first started doing the shoot, he reduced her exercise to 8oz a meal then dried her breath before']\n",
      "07/06/2022 14:56:24 - INFO - __main__ -   Epoch: 61 | Batch: 2400/4473 (54%) | G Loss: 0.555887 | C Loss: -0.217047\n",
      "07/06/2022 14:56:25 - INFO - __main__ -   Text: [\"... I've never had the chance... I've never done cocaine; never have, and with whom I have never\"]\n",
      "07/06/2022 14:56:27 - INFO - __main__ -   Epoch: 61 | Batch: 3000/4473 (67%) | G Loss: 0.566693 | C Loss: -0.328812\n",
      "07/06/2022 14:56:27 - INFO - __main__ -   Text: ['Hate sitting on a couch literally leads to full-body humiliation, becomes crushes every few days, shakes so badly']\n",
      "07/06/2022 14:56:29 - INFO - __main__ -   Epoch: 61 | Batch: 3600/4473 (80%) | G Loss: 0.516855 | C Loss: -0.341271\n",
      "07/06/2022 14:56:29 - INFO - __main__ -   Text: ['There is a formula but I guess what I heard but it is certainly a long-term solution and a pleasure to']\n",
      "07/06/2022 14:56:31 - INFO - __main__ -   Epoch: 61 | Batch: 4200/4473 (94%) | G Loss: 0.576332 | C Loss: -0.332229\n",
      "07/06/2022 14:56:31 - INFO - __main__ -   Text: ['The previous lowest steroidine dose in 2013 was: \"I was virginsaste byI can\\'t believe that you']\n",
      "07/06/2022 14:56:32 - INFO - __main__ -   * (Train) Epoch: 61 | G Loss: 0.6188 | C Loss: -0.2812 | Updates G: 62 | Updates C: 310\n",
      "07/06/2022 14:56:46 - INFO - __main__ -   Bleu-2:0.471 | B-Bleu-2:0.310\n",
      "07/06/2022 14:56:46 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7806007638844064\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 62 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:59:14 - INFO - __main__ -   Epoch: 62 | Batch: 0/4327 (0%) | G Loss: 0.599243 | C Loss: -0.345724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.162\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 14:59:14 - INFO - __main__ -   Text: [\"Anorexic tenderness fairly quickly runs out after 200mg (thinking I'd fainting) and is\"]\n",
      "07/06/2022 14:59:17 - INFO - __main__ -   Epoch: 62 | Batch: 600/4327 (14%) | G Loss: 0.482078 | C Loss: -0.223427\n",
      "07/06/2022 14:59:17 - INFO - __main__ -   Text: ['The cinnamon drug that started the Cadaverne obsession was the nootropic medication the kids were taking, which made']\n",
      "07/06/2022 14:59:19 - INFO - __main__ -   Epoch: 62 | Batch: 1200/4327 (28%) | G Loss: 0.655519 | C Loss: -0.161592\n",
      "07/06/2022 14:59:19 - INFO - __main__ -   Text: ['Osorio airway permanently denied the treatment to the two barely flocked in the device, and was never satisfied with']\n",
      "07/06/2022 14:59:21 - INFO - __main__ -   Epoch: 62 | Batch: 1800/4327 (42%) | G Loss: 0.564767 | C Loss: -0.239393\n",
      "07/06/2022 14:59:21 - INFO - __main__ -   Text: [\"A single dose of radiation hits right into one's stomach, is always taken, and is only a little less effective\"]\n",
      "07/06/2022 14:59:23 - INFO - __main__ -   Epoch: 62 | Batch: 2400/4327 (55%) | G Loss: 1.004415 | C Loss: -0.502282\n",
      "07/06/2022 14:59:23 - INFO - __main__ -   Text: ['Highball is still a topic of tests and repetition testing even while drinking many drinks, all just too literal things when']\n",
      "07/06/2022 14:59:25 - INFO - __main__ -   Epoch: 62 | Batch: 3000/4327 (69%) | G Loss: 0.578057 | C Loss: -0.263730\n",
      "07/06/2022 14:59:26 - INFO - __main__ -   Text: ['The mood swings are turned off after only a few minutes, though, and the idea goes back to when problems with']\n",
      "07/06/2022 14:59:28 - INFO - __main__ -   Epoch: 62 | Batch: 3600/4327 (83%) | G Loss: 0.685507 | C Loss: -0.349261\n",
      "07/06/2022 14:59:28 - INFO - __main__ -   Text: ['It is thought that this is the first time a female has ever quit smoking marijuana that has been found to take']\n",
      "07/06/2022 14:59:30 - INFO - __main__ -   Epoch: 62 | Batch: 4200/4327 (97%) | G Loss: 0.853923 | C Loss: -0.460136\n",
      "07/06/2022 14:59:30 - INFO - __main__ -   Text: ['It caused a high level of distress that resulted in low blood sugar in caberrror for hours at a time,']\n",
      "07/06/2022 14:59:30 - INFO - __main__ -   * (Train) Epoch: 62 | G Loss: 0.6743 | C Loss: -0.2770 | Updates G: 52 | Updates C: 308\n",
      "07/06/2022 14:59:44 - INFO - __main__ -   Bleu-2:0.459 | B-Bleu-2:0.324\n",
      "07/06/2022 14:59:44 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7834779386821195\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 63 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:02:13 - INFO - __main__ -   Epoch: 63 | Batch: 0/4417 (0%) | G Loss: 1.103036 | C Loss: -0.468241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 4.916\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:02:13 - INFO - __main__ -   Text: ['In reality, only 10% of the stress hormones in pregnancy can cause people to mix and stop when it is your']\n",
      "07/06/2022 15:02:15 - INFO - __main__ -   Epoch: 63 | Batch: 600/4417 (14%) | G Loss: 0.449627 | C Loss: -0.246141\n",
      "07/06/2022 15:02:15 - INFO - __main__ -   Text: ['Although the acanthine and steady, higher doses of caffeine and norethisterone have contributed to his knees']\n",
      "07/06/2022 15:02:17 - INFO - __main__ -   Epoch: 63 | Batch: 1200/4417 (27%) | G Loss: 0.658794 | C Loss: -0.216635\n",
      "07/06/2022 15:02:18 - INFO - __main__ -   Text: ['Before the first week of December, CBC teacher Lesa is actually vomiting painkiller and told that because his painkiller']\n",
      "07/06/2022 15:02:19 - INFO - __main__ -   Epoch: 63 | Batch: 1800/4417 (41%) | G Loss: 0.467123 | C Loss: -0.193290\n",
      "07/06/2022 15:02:20 - INFO - __main__ -   Text: [\"With At this stage, I'm already feeling very energetic and am going for at least five hours a day and doing\"]\n",
      "07/06/2022 15:02:22 - INFO - __main__ -   Epoch: 63 | Batch: 2400/4417 (54%) | G Loss: 0.652365 | C Loss: -0.142766\n",
      "07/06/2022 15:02:22 - INFO - __main__ -   Text: [\"Some people believe that Joe Peterson's No.3 is so bad that he has to live on his own for years\"]\n",
      "07/06/2022 15:02:24 - INFO - __main__ -   Epoch: 63 | Batch: 3000/4417 (68%) | G Loss: 0.578312 | C Loss: -0.201449\n",
      "07/06/2022 15:02:24 - INFO - __main__ -   Text: [\"The same goes for Joyce, who now works every day because she is fed up with sitting in a other girl's\"]\n",
      "07/06/2022 15:02:26 - INFO - __main__ -   Epoch: 63 | Batch: 3600/4417 (82%) | G Loss: 0.497870 | C Loss: -0.188153\n",
      "07/06/2022 15:02:26 - INFO - __main__ -   Text: [\"She decided not to use tests because she found too much meat in her diet, but she doesn't sweat, has\"]\n",
      "07/06/2022 15:02:28 - INFO - __main__ -   Epoch: 63 | Batch: 4200/4417 (95%) | G Loss: 0.835278 | C Loss: -0.280030\n",
      "07/06/2022 15:02:28 - INFO - __main__ -   Text: ['A dose of contraception will be within 72 hours, and soon afterward, the virus will return after such solving of']\n",
      "07/06/2022 15:02:29 - INFO - __main__ -   * (Train) Epoch: 63 | G Loss: 0.6517 | C Loss: -0.2475 | Updates G: 56 | Updates C: 312\n",
      "07/06/2022 15:02:43 - INFO - __main__ -   Bleu-2:0.491 | B-Bleu-2:0.321\n",
      "07/06/2022 15:02:43 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8122875875621657\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 64 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:05:11 - INFO - __main__ -   Epoch: 64 | Batch: 0/4322 (0%) | G Loss: 0.670444 | C Loss: -0.343840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 4.882\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:05:11 - INFO - __main__ -   Text: ['The amount increase of 45 per day for 267 mg mg oral tar for 24 days has been described']\n",
      "07/06/2022 15:05:13 - INFO - __main__ -   Epoch: 64 | Batch: 600/4322 (14%) | G Loss: 0.697525 | C Loss: -0.377938\n",
      "07/06/2022 15:05:13 - INFO - __main__ -   Text: ['Their pain is great, barely finishing scores on the \"Drink Your Blood Through the Hot Depths\" quiz given during']\n",
      "07/06/2022 15:05:15 - INFO - __main__ -   Epoch: 64 | Batch: 1200/4322 (28%) | G Loss: 0.448418 | C Loss: 0.071151\n",
      "07/06/2022 15:05:15 - INFO - __main__ -   Text: ['While an edition of the song has yet to reach Wi-Fi-free rating, however a confessional told me']\n",
      "07/06/2022 15:05:17 - INFO - __main__ -   Epoch: 64 | Batch: 1800/4322 (42%) | G Loss: 0.582382 | C Loss: -0.251971\n",
      "07/06/2022 15:05:18 - INFO - __main__ -   Text: ['Whereas in more recent years, Nevis peppers her taken capsules with computers to solve her to stop her crying, since']\n",
      "07/06/2022 15:05:20 - INFO - __main__ -   Epoch: 64 | Batch: 2400/4322 (56%) | G Loss: 0.662559 | C Loss: -0.256328\n",
      "07/06/2022 15:05:20 - INFO - __main__ -   Text: ['Also, aged 15, he has recently lost his internal organs and his late father lost his rubber uterus and loses sex']\n",
      "07/06/2022 15:05:22 - INFO - __main__ -   Epoch: 64 | Batch: 3000/4322 (69%) | G Loss: 0.756991 | C Loss: 0.005388\n",
      "07/06/2022 15:05:22 - INFO - __main__ -   Text: [\"There's a long talk of going into endometrium expertise, [and] a reaction with theylra and\"]\n",
      "07/06/2022 15:05:24 - INFO - __main__ -   Epoch: 64 | Batch: 3600/4322 (83%) | G Loss: 0.488673 | C Loss: -0.182088\n",
      "07/06/2022 15:05:24 - INFO - __main__ -   Text: [\"The that which shows up on my brain is whale Milk Beast, which couldn't be bothered to eat any\"]\n",
      "07/06/2022 15:05:26 - INFO - __main__ -   Epoch: 64 | Batch: 4200/4322 (97%) | G Loss: 0.697112 | C Loss: -0.267805\n",
      "07/06/2022 15:05:27 - INFO - __main__ -   Text: ['In August 2009, his spinal flexion in his \"skills\" increased to double the amount of 14 centimeters']\n",
      "07/06/2022 15:05:27 - INFO - __main__ -   * (Train) Epoch: 64 | G Loss: 0.6332 | C Loss: -0.2561 | Updates G: 47 | Updates C: 313\n",
      "07/06/2022 15:05:41 - INFO - __main__ -   Bleu-2:0.493 | B-Bleu-2:0.327\n",
      "07/06/2022 15:05:41 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8201930774399437\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 65 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:08:09 - INFO - __main__ -   Epoch: 65 | Batch: 0/4527 (0%) | G Loss: 0.496725 | C Loss: -0.177847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 4.914\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:08:09 - INFO - __main__ -   Text: ['Ya said more about it in her \"TV\" \"Superstar Kagoshino\\'s domination eases her']\n",
      "07/06/2022 15:08:11 - INFO - __main__ -   Epoch: 65 | Batch: 600/4527 (13%) | G Loss: 0.608795 | C Loss: -0.214812\n",
      "07/06/2022 15:08:11 - INFO - __main__ -   Text: ['Every week I try to track and reduce the drop of zinc in my milk via normal means as a means of']\n",
      "07/06/2022 15:08:13 - INFO - __main__ -   Epoch: 65 | Batch: 1200/4527 (27%) | G Loss: 0.823874 | C Loss: -0.406056\n",
      "07/06/2022 15:08:13 - INFO - __main__ -   Text: [\"Bullies totally hate meat and honey, which can't begin to make them a part of his life, but soon\"]\n",
      "07/06/2022 15:08:15 - INFO - __main__ -   Epoch: 65 | Batch: 1800/4527 (40%) | G Loss: 0.846358 | C Loss: -0.526194\n",
      "07/06/2022 15:08:16 - INFO - __main__ -   Text: ['Smith and his training partner, Prof. Eliza Mauboy whom Iymaddock would date, has testified that']\n",
      "07/06/2022 15:08:18 - INFO - __main__ -   Epoch: 65 | Batch: 2400/4527 (53%) | G Loss: 0.380843 | C Loss: -0.037595\n",
      "07/06/2022 15:08:18 - INFO - __main__ -   Text: ['They can also witness the freakish growth in the eye- dropping number of recipes during all the changes and a growing']\n",
      "07/06/2022 15:08:20 - INFO - __main__ -   Epoch: 65 | Batch: 3000/4527 (66%) | G Loss: 0.394336 | C Loss: -0.010252\n",
      "07/06/2022 15:08:20 - INFO - __main__ -   Text: ['It is not malicious … And I assure you that has it been my experience that, in contrast to overnight']\n",
      "07/06/2022 15:08:22 - INFO - __main__ -   Epoch: 65 | Batch: 3600/4527 (80%) | G Loss: 0.508650 | C Loss: -0.194436\n",
      "07/06/2022 15:08:22 - INFO - __main__ -   Text: ['The kissed cream, as written for the Star Comfort Diet (the study by A) has its effects significantly increased;']\n",
      "07/06/2022 15:08:24 - INFO - __main__ -   Epoch: 65 | Batch: 4200/4527 (93%) | G Loss: 0.634241 | C Loss: -0.281313\n",
      "07/06/2022 15:08:24 - INFO - __main__ -   Text: ['\"Nothing to eek out of you\" is a daily high asking frequency letter to an adult male while the discharge']\n",
      "07/06/2022 15:08:25 - INFO - __main__ -   * (Train) Epoch: 65 | G Loss: 0.5888 | C Loss: -0.2188 | Updates G: 35 | Updates C: 342\n",
      "07/06/2022 15:08:39 - INFO - __main__ -   Bleu-2:0.481 | B-Bleu-2:0.312\n",
      "07/06/2022 15:08:39 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931674146769182\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 66 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:14:06 - INFO - __main__ -   Epoch: 67 | Batch: 0/4364 (0%) | G Loss: 0.553206 | C Loss: -0.292629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.015\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:14:06 - INFO - __main__ -   Text: ['They have a history of gambling through Poker Fix, where it starts polling their bank account over the age of three,']\n",
      "07/06/2022 15:14:08 - INFO - __main__ -   Epoch: 67 | Batch: 600/4364 (14%) | G Loss: 0.415396 | C Loss: -0.190484\n",
      "07/06/2022 15:14:08 - INFO - __main__ -   Text: ['In the course of 2 short months Jessica and Tommy go off drinking, but Jessica tries to keep things simple, and']\n",
      "07/06/2022 15:14:10 - INFO - __main__ -   Epoch: 67 | Batch: 1200/4364 (27%) | G Loss: 0.739495 | C Loss: -0.198135\n",
      "07/06/2022 15:14:11 - INFO - __main__ -   Text: ['Going back and forth I think it is easy to try it with Moodings migraines (shaking legs and']\n",
      "07/06/2022 15:14:13 - INFO - __main__ -   Epoch: 67 | Batch: 1800/4364 (41%) | G Loss: 0.470374 | C Loss: -0.211234\n",
      "07/06/2022 15:14:13 - INFO - __main__ -   Text: ['This drug is perceived as being the best that could come from treating lipologic problems, because physically CFS Obama does']\n",
      "07/06/2022 15:14:15 - INFO - __main__ -   Epoch: 67 | Batch: 2400/4364 (55%) | G Loss: 0.689567 | C Loss: -0.180051\n",
      "07/06/2022 15:14:15 - INFO - __main__ -   Text: ['Eighty times did I still listen to Ghostface neither full with regrets nor regretfully but over the next year and']\n",
      "07/06/2022 15:14:17 - INFO - __main__ -   Epoch: 67 | Batch: 3000/4364 (69%) | G Loss: 1.788435 | C Loss: -0.641028\n",
      "07/06/2022 15:14:17 - INFO - __main__ -   Text: ['When using this product for another couple of days, it causes extra strain on the tongue, causing the freeze without,']\n",
      "07/06/2022 15:14:19 - INFO - __main__ -   Epoch: 67 | Batch: 3600/4364 (82%) | G Loss: 1.107524 | C Loss: -0.324207\n",
      "07/06/2022 15:14:19 - INFO - __main__ -   Text: ['Both patients and parents reported that they became superbleeding with blood after taking only 30-50 minutes of breath,']\n",
      "07/06/2022 15:14:21 - INFO - __main__ -   Epoch: 67 | Batch: 4200/4364 (96%) | G Loss: 0.403236 | C Loss: -0.172661\n",
      "07/06/2022 15:14:21 - INFO - __main__ -   Text: ['Through a call pattern that usually keeps her constantly moist as the tides change rapidly, Una eats \"the herbaceous']\n",
      "07/06/2022 15:14:22 - INFO - __main__ -   * (Train) Epoch: 67 | G Loss: 0.6354 | C Loss: -0.2749 | Updates G: 50 | Updates C: 313\n",
      "07/06/2022 15:14:36 - INFO - __main__ -   Bleu-2:0.490 | B-Bleu-2:0.320\n",
      "07/06/2022 15:14:36 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8099100750731566\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 68 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:17:04 - INFO - __main__ -   Epoch: 68 | Batch: 0/4330 (0%) | G Loss: 0.320593 | C Loss: -0.090638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 5.284\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:17:05 - INFO - __main__ -   Text: ['After \"Zok\"\\'s second application he calms down and realizes that invading pettiness is not an important']\n",
      "07/06/2022 15:17:06 - INFO - __main__ -   Epoch: 68 | Batch: 600/4330 (14%) | G Loss: 1.121756 | C Loss: -0.473553\n",
      "07/06/2022 15:17:07 - INFO - __main__ -   Text: ['The reduced budget would was making it harder for me to lift weights much, when I also had twins on']\n",
      "07/06/2022 15:17:09 - INFO - __main__ -   Epoch: 68 | Batch: 1200/4330 (28%) | G Loss: 0.472201 | C Loss: 0.043637\n",
      "07/06/2022 15:17:09 - INFO - __main__ -   Text: ['It can drop to either half hitting for two strikes to recover, or as close to miss as possible (around twice']\n",
      "07/06/2022 15:17:11 - INFO - __main__ -   Epoch: 68 | Batch: 1800/4330 (42%) | G Loss: 1.123911 | C Loss: -0.563170\n",
      "07/06/2022 15:17:11 - INFO - __main__ -   Text: ['In the spirit of proportion, the results of juicesanalysis sessions are listed as ISO 1509’s range,']\n",
      "07/06/2022 15:17:13 - INFO - __main__ -   Epoch: 68 | Batch: 2400/4330 (55%) | G Loss: 1.627919 | C Loss: -1.105999\n",
      "07/06/2022 15:17:13 - INFO - __main__ -   Text: ['Across the board he wrote bravely about the situation; believes that he can always produce 3 meals daily, but that']\n",
      "07/06/2022 15:17:15 - INFO - __main__ -   Epoch: 68 | Batch: 3000/4330 (69%) | G Loss: 2.276138 | C Loss: -0.628801\n",
      "07/06/2022 15:17:16 - INFO - __main__ -   Text: ['Lucy left the chicks, but when asked how he made his meal, she said Bon Appétit,']\n",
      "07/06/2022 15:17:17 - INFO - __main__ -   Epoch: 68 | Batch: 3600/4330 (83%) | G Loss: 3.759097 | C Loss: -0.768323\n",
      "07/06/2022 15:17:18 - INFO - __main__ -   Text: ['A few hours before going to sleep, she has stopped executing her trying as she did five hours before to']\n",
      "07/06/2022 15:17:19 - INFO - __main__ -   Epoch: 68 | Batch: 4200/4330 (97%) | G Loss: 3.269840 | C Loss: -0.494535\n",
      "07/06/2022 15:17:20 - INFO - __main__ -   Text: ['During periods of stress, Claire must take even more medication, stay calm and long, and consult briefly with her']\n",
      "07/06/2022 15:17:20 - INFO - __main__ -   * (Train) Epoch: 68 | G Loss: 0.8365 | C Loss: -0.3960 | Updates G: 36 | Updates C: 324\n",
      "07/06/2022 15:17:34 - INFO - __main__ -   Bleu-2:0.478 | B-Bleu-2:0.298\n",
      "07/06/2022 15:17:34 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7756096132759105\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 69 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:20:02 - INFO - __main__ -   Epoch: 69 | Batch: 0/4372 (0%) | G Loss: 3.270056 | C Loss: -0.230898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 5.150\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:20:02 - INFO - __main__ -   Text: ['In one case, girls who have been diagnosed with a cytochrome cotransferase deficiency have experienced severe']\n",
      "07/06/2022 15:20:04 - INFO - __main__ -   Epoch: 69 | Batch: 600/4372 (14%) | G Loss: 2.254050 | C Loss: 0.062929\n",
      "07/06/2022 15:20:05 - INFO - __main__ -   Text: ['This definitely didn\\'t take long; \"Himeka Moo Hitka\" ended up having a record of']\n",
      "07/06/2022 15:20:07 - INFO - __main__ -   Epoch: 69 | Batch: 1200/4372 (27%) | G Loss: 2.362900 | C Loss: -0.035857\n",
      "07/06/2022 15:20:07 - INFO - __main__ -   Text: ['One hundred fifty years of practice is due to the aches that follow having rolled up a shirt without a constant']\n",
      "07/06/2022 15:20:09 - INFO - __main__ -   Epoch: 69 | Batch: 1800/4372 (41%) | G Loss: 2.987033 | C Loss: -0.147814\n",
      "07/06/2022 15:20:09 - INFO - __main__ -   Text: ['The whole surgery went on for a while and eventually it went on for about 5 days, and drank some toxic saliva']\n",
      "07/06/2022 15:20:11 - INFO - __main__ -   Epoch: 69 | Batch: 2400/4372 (55%) | G Loss: 3.615089 | C Loss: -1.123489\n",
      "07/06/2022 15:20:11 - INFO - __main__ -   Text: ['The muscles have been amazingly good individually under formula3 treatment with no side effects, but the problem has been exacerbated with']\n",
      "07/06/2022 15:20:13 - INFO - __main__ -   Epoch: 69 | Batch: 3000/4372 (69%) | G Loss: 3.433144 | C Loss: -0.608391\n",
      "07/06/2022 15:20:13 - INFO - __main__ -   Text: ['Prior to these events, you can see this smiling - unsure of what to do, this was 33 yoold who']\n",
      "07/06/2022 15:20:15 - INFO - __main__ -   Epoch: 69 | Batch: 3600/4372 (82%) | G Loss: 3.878753 | C Loss: -0.498303\n",
      "07/06/2022 15:20:16 - INFO - __main__ -   Text: ['In contrast, before moving many limbs, Graffler usually performs deep breathing exercises for four to six hours in combination']\n",
      "07/06/2022 15:20:18 - INFO - __main__ -   Epoch: 69 | Batch: 4200/4372 (96%) | G Loss: 5.467300 | C Loss: -0.767188\n",
      "07/06/2022 15:20:18 - INFO - __main__ -   Text: ['Sid Umuewu destroyed a lot, but the next painter, Sawctor, who uses alcohol (so he']\n",
      "07/06/2022 15:20:18 - INFO - __main__ -   * (Train) Epoch: 69 | G Loss: 3.0045 | C Loss: -0.6313 | Updates G: 17 | Updates C: 347\n",
      "07/06/2022 15:20:32 - INFO - __main__ -   Bleu-2:0.483 | B-Bleu-2:0.312\n",
      "07/06/2022 15:20:32 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795355468735057\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 70 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:23:01 - INFO - __main__ -   Epoch: 70 | Batch: 0/4473 (0%) | G Loss: 4.001608 | C Loss: -0.783401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 5.334\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:23:01 - INFO - __main__ -   Text: [\"In a video interview with ABS-CBN US, Satuar's words were evoked by the treatment,\"]\n",
      "07/06/2022 15:23:03 - INFO - __main__ -   Epoch: 70 | Batch: 600/4473 (13%) | G Loss: 4.459523 | C Loss: -0.443218\n",
      "07/06/2022 15:23:03 - INFO - __main__ -   Text: [\"Yes, we hear various far superior voices, this time around and unfortunately no one interviews Muslims as well so it's\"]\n",
      "07/06/2022 15:23:05 - INFO - __main__ -   Epoch: 70 | Batch: 1200/4473 (27%) | G Loss: 4.827307 | C Loss: -0.736705\n",
      "07/06/2022 15:23:05 - INFO - __main__ -   Text: ['Alex, 3 of 5 asks to stay away from alcohol and caffeine, and the reality besides, it seems, that']\n",
      "07/06/2022 15:23:07 - INFO - __main__ -   Epoch: 70 | Batch: 1800/4473 (40%) | G Loss: 4.535682 | C Loss: -1.247027\n",
      "07/06/2022 15:23:07 - INFO - __main__ -   Text: ['The two-week evaluation regimen of shadow crows directly into the weeks after hatching such as: -~ =']\n",
      "07/06/2022 15:23:09 - INFO - __main__ -   Epoch: 70 | Batch: 2400/4473 (54%) | G Loss: 5.361863 | C Loss: 0.372261\n",
      "07/06/2022 15:23:10 - INFO - __main__ -   Text: ['\"\"Ebil\\'s friend proclaims that she can barely get her weight (90%), and that most of it is']\n",
      "07/06/2022 15:23:12 - INFO - __main__ -   Epoch: 70 | Batch: 3000/4473 (67%) | G Loss: 6.533594 | C Loss: -5.602639\n",
      "07/06/2022 15:23:12 - INFO - __main__ -   Text: ['Googling \"A Working Starscream Dream\" was an overwhelming experience and their coworker Sofya Sofia was']\n",
      "07/06/2022 15:23:14 - INFO - __main__ -   Epoch: 70 | Batch: 3600/4473 (80%) | G Loss: 4.091288 | C Loss: -3.992564\n",
      "07/06/2022 15:23:14 - INFO - __main__ -   Text: ['In addition, he found that he activated his pH of 99% and a high also caused him to frequently yell']\n",
      "07/06/2022 15:23:16 - INFO - __main__ -   Epoch: 70 | Batch: 4200/4473 (94%) | G Loss: 5.811348 | C Loss: -0.418231\n",
      "07/06/2022 15:23:16 - INFO - __main__ -   Text: ['He underlines that he thinks he is just happy enough to wear only reversible inline-trimming shoes']\n",
      "07/06/2022 15:23:17 - INFO - __main__ -   * (Train) Epoch: 70 | G Loss: 4.3801 | C Loss: -1.0705 | Updates G: 8 | Updates C: 364\n",
      "07/06/2022 15:23:31 - INFO - __main__ -   Bleu-2:0.458 | B-Bleu-2:0.295\n",
      "07/06/2022 15:23:31 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7529853590998687\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 71 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:26:00 - INFO - __main__ -   Epoch: 71 | Batch: 0/4473 (0%) | G Loss: 4.826777 | C Loss: -0.529417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 5.337\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:26:00 - INFO - __main__ -   Text: ['He is also able to handle eating the edible folate in the course of a few days (size one soy in']\n",
      "07/06/2022 15:26:02 - INFO - __main__ -   Epoch: 71 | Batch: 600/4473 (13%) | G Loss: 5.591020 | C Loss: -3.878907\n",
      "07/06/2022 15:26:02 - INFO - __main__ -   Text: ['\"Mandraji was always scary when you get done with him, with nothing to say except that you can jump']\n",
      "07/06/2022 15:26:04 - INFO - __main__ -   Epoch: 71 | Batch: 1200/4473 (27%) | G Loss: 5.287543 | C Loss: 0.194541\n",
      "07/06/2022 15:26:04 - INFO - __main__ -   Text: ['The temperature on that night was a low of 3 deg C... for 2 weeks, and Rex did an']\n",
      "07/06/2022 15:26:06 - INFO - __main__ -   Epoch: 71 | Batch: 1800/4473 (40%) | G Loss: 3.742684 | C Loss: -0.181088\n",
      "07/06/2022 15:26:06 - INFO - __main__ -   Text: ['This is not a new experience, it was the first time in many years that it seemed like Belles had negative']\n",
      "07/06/2022 15:26:08 - INFO - __main__ -   Epoch: 71 | Batch: 2400/4473 (54%) | G Loss: 4.261278 | C Loss: -0.147227\n",
      "07/06/2022 15:26:08 - INFO - __main__ -   Text: ['He hoped to improve his horsemanship or tolerate one spin per day when, after thoroughly concentrating on driving interference before each']\n",
      "07/06/2022 15:26:11 - INFO - __main__ -   Epoch: 71 | Batch: 3000/4473 (67%) | G Loss: 3.281981 | C Loss: -1.176814\n",
      "07/06/2022 15:26:11 - INFO - __main__ -   Text: ['During the time darkness fell over the course of 4 months, Kate met the mifugello inside her room,']\n",
      "07/06/2022 15:26:13 - INFO - __main__ -   Epoch: 71 | Batch: 3600/4473 (80%) | G Loss: 3.720562 | C Loss: -0.248684\n",
      "07/06/2022 15:26:13 - INFO - __main__ -   Text: ['Since last few months, we have every made use of a bean growing spray or santana everyday for providing']\n",
      "07/06/2022 15:26:15 - INFO - __main__ -   Epoch: 71 | Batch: 4200/4473 (94%) | G Loss: 4.249857 | C Loss: -0.546508\n",
      "07/06/2022 15:26:15 - INFO - __main__ -   Text: ['In a study run by the doctor, students surveyed over a 1500 students in 24 sessions, finding that an extra']\n",
      "07/06/2022 15:26:16 - INFO - __main__ -   * (Train) Epoch: 71 | G Loss: 4.3611 | C Loss: -1.1974 | Updates G: 8 | Updates C: 364\n",
      "07/06/2022 15:26:30 - INFO - __main__ -   Bleu-2:0.470 | B-Bleu-2:0.314\n",
      "07/06/2022 15:26:30 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7835570703018256\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 72 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:28:59 - INFO - __main__ -   Epoch: 72 | Batch: 0/4327 (0%) | G Loss: 4.593650 | C Loss: -0.820684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.314\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:28:59 - INFO - __main__ -   Text: ['(look for $ drifting ) is the process in which magician brushes out glancing machines which reward the hard work done']\n",
      "07/06/2022 15:29:01 - INFO - __main__ -   Epoch: 72 | Batch: 600/4327 (14%) | G Loss: 5.541378 | C Loss: -0.474287\n",
      "07/06/2022 15:29:01 - INFO - __main__ -   Text: ['Pin points no longer mention that he experiences similar sensations with another man and is cautious about taking his energy drinks daily,']\n",
      "07/06/2022 15:29:03 - INFO - __main__ -   Epoch: 72 | Batch: 1200/4327 (28%) | G Loss: 5.428973 | C Loss: -2.963559\n",
      "07/06/2022 15:29:03 - INFO - __main__ -   Text: ['This demonstrates that the dartsin also causes a stronger reduction in blood and saliva, and does not appear to cause']\n",
      "07/06/2022 15:29:05 - INFO - __main__ -   Epoch: 72 | Batch: 1800/4327 (42%) | G Loss: 5.340086 | C Loss: -0.215823\n",
      "07/06/2022 15:29:06 - INFO - __main__ -   Text: ['The further travel and sleep disruptions that occur whilst staying in the village are immediate and severe to the bodydays and seizures']\n",
      "07/06/2022 15:29:08 - INFO - __main__ -   Epoch: 72 | Batch: 2400/4327 (55%) | G Loss: 5.809470 | C Loss: -1.449958\n",
      "07/06/2022 15:29:08 - INFO - __main__ -   Text: ['Hulk wrote that his experience on the first ride in 2007 when some active lifeboat users complained about something up ->']\n",
      "07/06/2022 15:29:10 - INFO - __main__ -   Epoch: 72 | Batch: 3000/4327 (69%) | G Loss: 5.195817 | C Loss: -3.630479\n",
      "07/06/2022 15:29:10 - INFO - __main__ -   Text: ['While many students have sought out aroma pods down the sides of their lips, Ghost lives long with Kola nutrient and']\n",
      "07/06/2022 15:29:12 - INFO - __main__ -   Epoch: 72 | Batch: 3600/4327 (83%) | G Loss: 4.984590 | C Loss: -5.146695\n",
      "07/06/2022 15:29:12 - INFO - __main__ -   Text: ['Succeeding in this task significantly raises the odds of being on a birth certificate or passport with very little progress being']\n",
      "07/06/2022 15:29:14 - INFO - __main__ -   Epoch: 72 | Batch: 4200/4327 (97%) | G Loss: 5.239444 | C Loss: -0.524991\n",
      "07/06/2022 15:29:14 - INFO - __main__ -   Text: ['After several months of learning about needles and divoders, the Nepalese veterinarian reeled in a reported']\n",
      "07/06/2022 15:29:15 - INFO - __main__ -   * (Train) Epoch: 72 | G Loss: 3.4001 | C Loss: -1.1868 | Updates G: 2 | Updates C: 358\n",
      "07/06/2022 15:29:29 - INFO - __main__ -   Bleu-2:0.473 | B-Bleu-2:0.311\n",
      "07/06/2022 15:29:29 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7840431123741677\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 73 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:31:57 - INFO - __main__ -   Epoch: 73 | Batch: 0/4417 (0%) | G Loss: 4.892353 | C Loss: -0.272982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 5.230\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:31:57 - INFO - __main__ -   Text: ['In adulthood, Tasebe inserted the portable 11 gauge bullet into his damaged leg twice a day, the tender files']\n",
      "07/06/2022 15:32:00 - INFO - __main__ -   Epoch: 73 | Batch: 600/4417 (14%) | G Loss: 4.258877 | C Loss: -1.988295\n",
      "07/06/2022 15:32:00 - INFO - __main__ -   Text: ['They usually season to fit into optimal diets and have never been able to record any metabolite measurements except E2P']\n",
      "07/06/2022 15:32:02 - INFO - __main__ -   Epoch: 73 | Batch: 1200/4417 (27%) | G Loss: 4.637088 | C Loss: -3.161559\n",
      "07/06/2022 15:32:02 - INFO - __main__ -   Text: ['Patananda, who is living a loss, found that life was becoming unmanageable for him, however,']\n",
      "07/06/2022 15:32:04 - INFO - __main__ -   Epoch: 73 | Batch: 1800/4417 (41%) | G Loss: 4.489457 | C Loss: -0.962103\n",
      "07/06/2022 15:32:04 - INFO - __main__ -   Text: ['3h2 hrs per day is an method of keeping track of how effectively and frequently you are running at an activity']\n",
      "07/06/2022 15:32:06 - INFO - __main__ -   Epoch: 73 | Batch: 2400/4417 (54%) | G Loss: 5.310865 | C Loss: -0.747085\n",
      "07/06/2022 15:32:06 - INFO - __main__ -   Text: ['His results of infection and death after a week or two has been: [As indicated by Kerstin, the']\n",
      "07/06/2022 15:32:08 - INFO - __main__ -   Epoch: 73 | Batch: 3000/4417 (68%) | G Loss: 5.132392 | C Loss: -5.189349\n",
      "07/06/2022 15:32:09 - INFO - __main__ -   Text: ['Garagi does not seem to have noticed this read out of habit, as he read it on his major depression as']\n",
      "07/06/2022 15:32:11 - INFO - __main__ -   Epoch: 73 | Batch: 3600/4417 (82%) | G Loss: 4.908395 | C Loss: -0.782162\n",
      "07/06/2022 15:32:11 - INFO - __main__ -   Text: ['He says sunscreening is the most costly and most unsuccessful medical procedure and purely letting it dry out at night means']\n",
      "07/06/2022 15:32:13 - INFO - __main__ -   Epoch: 73 | Batch: 4200/4417 (95%) | G Loss: 4.652810 | C Loss: -0.410955\n",
      "07/06/2022 15:32:13 - INFO - __main__ -   Text: ['This week, he asked friends of his obese brother Seth on Facebook and if they can weigh over 100 kg and']\n",
      "07/06/2022 15:32:14 - INFO - __main__ -   * (Train) Epoch: 73 | G Loss: 2.4462 | C Loss: -1.2274 | Updates G: 1 | Updates C: 367\n",
      "07/06/2022 15:32:28 - INFO - __main__ -   Bleu-2:0.475 | B-Bleu-2:0.305\n",
      "07/06/2022 15:32:28 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7801466529633162\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 74 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:34:56 - INFO - __main__ -   Epoch: 74 | Batch: 0/4322 (0%) | G Loss: 4.801023 | C Loss: -1.058277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.180\n",
      "  Test Loss: 5.488\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:34:56 - INFO - __main__ -   Text: ['During he received the first trypiece injection, WPID went through the trial stages of hyperstasis, it had']\n",
      "07/06/2022 15:34:58 - INFO - __main__ -   Epoch: 74 | Batch: 600/4322 (14%) | G Loss: 4.489905 | C Loss: -5.916726\n",
      "07/06/2022 15:34:58 - INFO - __main__ -   Text: [\"Not only does it help certain nurses who are taken off of their duty, I'm not daring to report, my\"]\n",
      "07/06/2022 15:35:01 - INFO - __main__ -   Epoch: 74 | Batch: 1200/4322 (28%) | G Loss: 4.397651 | C Loss: -0.697367\n",
      "07/06/2022 15:35:01 - INFO - __main__ -   Text: ['There is no reason to worry, as when appraised by any independent source and Mehler recommended it as a']\n",
      "07/06/2022 15:35:03 - INFO - __main__ -   Epoch: 74 | Batch: 1800/4322 (42%) | G Loss: 4.290859 | C Loss: -1.533747\n",
      "07/06/2022 15:35:03 - INFO - __main__ -   Text: ['This doing new stuff to drink during nap or break day, while relieving stress [prompt] to drink']\n",
      "07/06/2022 15:35:05 - INFO - __main__ -   Epoch: 74 | Batch: 2400/4322 (56%) | G Loss: 4.475936 | C Loss: -0.218553\n",
      "07/06/2022 15:35:05 - INFO - __main__ -   Text: ['\"stink for two, lose 20lbs the first year, and my life lasts about a year, while all']\n",
      "07/06/2022 15:35:07 - INFO - __main__ -   Epoch: 74 | Batch: 3000/4322 (69%) | G Loss: 4.247751 | C Loss: -0.322641\n",
      "07/06/2022 15:35:07 - INFO - __main__ -   Text: ['They feel very gently, and this spike in intake can be seen in how fast in amount in the sight room each']\n",
      "07/06/2022 15:35:09 - INFO - __main__ -   Epoch: 74 | Batch: 3600/4322 (83%) | G Loss: 3.997519 | C Loss: -0.620543\n",
      "07/06/2022 15:35:10 - INFO - __main__ -   Text: ['Some people are already moving on in this route: All you have to do is watching news, checking e-mail']\n",
      "07/06/2022 15:35:12 - INFO - __main__ -   Epoch: 74 | Batch: 4200/4322 (97%) | G Loss: 3.631571 | C Loss: -0.802796\n",
      "07/06/2022 15:35:12 - INFO - __main__ -   Text: ['Original publication \"collector\\'s mail\" published in one week received anivalent responses for the procedure and trainers, except']\n",
      "07/06/2022 15:35:12 - INFO - __main__ -   * (Train) Epoch: 74 | G Loss: 3.6761 | C Loss: -1.2836 | Updates G: 5 | Updates C: 355\n",
      "07/06/2022 15:35:26 - INFO - __main__ -   Bleu-2:0.468 | B-Bleu-2:0.305\n",
      "07/06/2022 15:35:26 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7729834047416272\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 75 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:37:55 - INFO - __main__ -   Epoch: 75 | Batch: 0/4527 (0%) | G Loss: 3.768386 | C Loss: -0.962577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.293\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:37:55 - INFO - __main__ -   Text: ['His thedailycygium responded with \"it seems\" because some medications he even ordered were not low enough pushed']\n",
      "07/06/2022 15:37:57 - INFO - __main__ -   Epoch: 75 | Batch: 600/4527 (13%) | G Loss: 3.413675 | C Loss: -1.020684\n",
      "07/06/2022 15:37:57 - INFO - __main__ -   Text: ['Drizidovitch is currently missing eight days of therapy - which only works because the copping of his']\n",
      "07/06/2022 15:37:59 - INFO - __main__ -   Epoch: 75 | Batch: 1200/4527 (27%) | G Loss: 3.741351 | C Loss: -1.451903\n",
      "07/06/2022 15:37:59 - INFO - __main__ -   Text: ['In the same process, he says, he consumes 0.6 kg (1.550 g) pasta a']\n",
      "07/06/2022 15:38:01 - INFO - __main__ -   Epoch: 75 | Batch: 1800/4527 (40%) | G Loss: 3.840411 | C Loss: -4.067710\n",
      "07/06/2022 15:38:01 - INFO - __main__ -   Text: ['The injection has made her a healthier (18 days her only\"), but not helpful, as she has no appetite and']\n",
      "07/06/2022 15:38:04 - INFO - __main__ -   Epoch: 75 | Batch: 2400/4527 (53%) | G Loss: 4.244661 | C Loss: -1.039882\n",
      "07/06/2022 15:38:04 - INFO - __main__ -   Text: ['The medication returned almost every night for more than six months providing positive results for bronchial aches of up to']\n",
      "07/06/2022 15:38:06 - INFO - __main__ -   Epoch: 75 | Batch: 3000/4527 (66%) | G Loss: 3.777275 | C Loss: -5.062688\n",
      "07/06/2022 15:38:06 - INFO - __main__ -   Text: [\"Their next outcome was to obtain SPBG's requisite Sample Subtest performance (from which they could test their\"]\n",
      "07/06/2022 15:38:08 - INFO - __main__ -   Epoch: 75 | Batch: 3600/4527 (80%) | G Loss: 3.868296 | C Loss: -1.187408\n",
      "07/06/2022 15:38:08 - INFO - __main__ -   Text: ['The weight loss will still be noticeable and they predict it will only happen for the first three weeks or so, but']\n",
      "07/06/2022 15:38:10 - INFO - __main__ -   Epoch: 75 | Batch: 4200/4527 (93%) | G Loss: 3.747401 | C Loss: -0.479525\n",
      "07/06/2022 15:38:10 - INFO - __main__ -   Text: ['For non-Hispanic white readers, the Black Fibonacci Nucilimon can also be naturalized much easier']\n",
      "07/06/2022 15:38:11 - INFO - __main__ -   * (Train) Epoch: 75 | G Loss: 3.3092 | C Loss: -1.3516 | Updates G: 6 | Updates C: 371\n",
      "07/06/2022 15:38:25 - INFO - __main__ -   Bleu-2:0.486 | B-Bleu-2:0.324\n",
      "07/06/2022 15:38:25 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8104366865372534\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 76 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:40:54 - INFO - __main__ -   Epoch: 76 | Batch: 0/4467 (0%) | G Loss: 3.827719 | C Loss: -1.591710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.460\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:40:54 - INFO - __main__ -   Text: ['More than they need to buy medicine, so much, they lose weight, look exhausted, it will come with pain']\n",
      "07/06/2022 15:40:56 - INFO - __main__ -   Epoch: 76 | Batch: 600/4467 (13%) | G Loss: 3.665054 | C Loss: -1.568816\n",
      "07/06/2022 15:40:56 - INFO - __main__ -   Text: ['Concerned about the lack of drinking water for flaking his pin boys, he tried adding liquid more contain, and']\n",
      "07/06/2022 15:40:58 - INFO - __main__ -   Epoch: 76 | Batch: 1200/4467 (27%) | G Loss: 4.308074 | C Loss: -1.093721\n",
      "07/06/2022 15:40:59 - INFO - __main__ -   Text: [\"Aside from diabetes (—as in most of the studies done by many diabetes patients), especially under the chair doctor's\"]\n",
      "07/06/2022 15:41:01 - INFO - __main__ -   Epoch: 76 | Batch: 1800/4467 (40%) | G Loss: 3.813849 | C Loss: -0.665702\n",
      "07/06/2022 15:41:01 - INFO - __main__ -   Text: ['Her doctors will often put the clone in a come up noonsplash until just after six months, which she']\n",
      "07/06/2022 15:41:03 - INFO - __main__ -   Epoch: 76 | Batch: 2400/4467 (54%) | G Loss: 3.790623 | C Loss: -0.421509\n",
      "07/06/2022 15:41:03 - INFO - __main__ -   Text: ['Not only do we choose to do sex from the pleasure of doing it as opposed to cum from the']\n",
      "07/06/2022 15:41:05 - INFO - __main__ -   Epoch: 76 | Batch: 3000/4467 (67%) | G Loss: 3.612217 | C Loss: -0.584991\n",
      "07/06/2022 15:41:05 - INFO - __main__ -   Text: ['He has taken a 16 to 12-mg dose of a 13-mg increasing precursor (usually entered into four']\n",
      "07/06/2022 15:41:07 - INFO - __main__ -   Epoch: 76 | Batch: 3600/4467 (81%) | G Loss: 3.917893 | C Loss: -2.470063\n",
      "07/06/2022 15:41:07 - INFO - __main__ -   Text: ['According to the health research blog \"Weight Loss\", which does hospital visits, 25% to 30% of the chloride']\n",
      "07/06/2022 15:41:09 - INFO - __main__ -   Epoch: 76 | Batch: 4200/4467 (94%) | G Loss: 3.782879 | C Loss: -1.132448\n",
      "07/06/2022 15:41:09 - INFO - __main__ -   Text: ['Back in 2009, Rick Pedersen\\'s persona went by the \"YERE IN LOVE\" phrase, although on the']\n",
      "07/06/2022 15:41:10 - INFO - __main__ -   * (Train) Epoch: 76 | G Loss: 3.2270 | C Loss: -1.3828 | Updates G: 6 | Updates C: 366\n",
      "07/06/2022 15:41:24 - INFO - __main__ -   Bleu-2:0.484 | B-Bleu-2:0.312\n",
      "07/06/2022 15:41:24 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7967050643990088\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 77 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:43:53 - INFO - __main__ -   Epoch: 77 | Batch: 0/4364 (0%) | G Loss: 3.549664 | C Loss: -1.101492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 5.429\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:43:53 - INFO - __main__ -   Text: ['\"\" If you leave it on for too long with no nutritional value in the dietometer, you may become diabetes;']\n",
      "07/06/2022 15:43:55 - INFO - __main__ -   Epoch: 77 | Batch: 600/4364 (14%) | G Loss: 3.567622 | C Loss: -6.621737\n",
      "07/06/2022 15:43:55 - INFO - __main__ -   Text: ['The two have had a lot of \"passive violent symptoms checking\" over the past few months (they had battled']\n",
      "07/06/2022 15:43:57 - INFO - __main__ -   Epoch: 77 | Batch: 1200/4364 (27%) | G Loss: 3.957662 | C Loss: -0.587103\n",
      "07/06/2022 15:43:57 - INFO - __main__ -   Text: ['Wine is acidic; it is unfortunately made up of either alkali acids or alkali disabs']\n",
      "07/06/2022 15:43:59 - INFO - __main__ -   Epoch: 77 | Batch: 1800/4364 (41%) | G Loss: 3.334770 | C Loss: -0.241242\n",
      "07/06/2022 15:44:00 - INFO - __main__ -   Text: ['This would have been considered to be completely satisfactory because fat lost, again in a healthy period of time, would eliminate']\n",
      "07/06/2022 15:44:02 - INFO - __main__ -   Epoch: 77 | Batch: 2400/4364 (55%) | G Loss: 2.818359 | C Loss: -0.302663\n",
      "07/06/2022 15:44:02 - INFO - __main__ -   Text: ['To receive a blood test, these women need to be told that they are 4 years apart from the natural female and']\n",
      "07/06/2022 15:44:04 - INFO - __main__ -   Epoch: 77 | Batch: 3000/4364 (69%) | G Loss: 3.320277 | C Loss: -1.510746\n",
      "07/06/2022 15:44:04 - INFO - __main__ -   Text: ['In the long term, Gies would opt for a new galway, with the weather moderate (which she has']\n",
      "07/06/2022 15:44:06 - INFO - __main__ -   Epoch: 77 | Batch: 3600/4364 (82%) | G Loss: 3.146619 | C Loss: -0.375616\n",
      "07/06/2022 15:44:06 - INFO - __main__ -   Text: ['The same day with an increasing risk of heart attack, flush with Adrenaline Or get a dose of']\n",
      "07/06/2022 15:44:08 - INFO - __main__ -   Epoch: 77 | Batch: 4200/4364 (96%) | G Loss: 2.883455 | C Loss: -8.500987\n",
      "07/06/2022 15:44:08 - INFO - __main__ -   Text: ['Nowadays, people find day-by-day getup hard (albeit a lot of it) and make']\n",
      "07/06/2022 15:44:09 - INFO - __main__ -   * (Train) Epoch: 77 | G Loss: 2.9556 | C Loss: -1.4550 | Updates G: 8 | Updates C: 355\n",
      "07/06/2022 15:44:23 - INFO - __main__ -   Bleu-2:0.471 | B-Bleu-2:0.304\n",
      "07/06/2022 15:44:23 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7744068156386134\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 78 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:46:51 - INFO - __main__ -   Epoch: 78 | Batch: 0/4330 (0%) | G Loss: 3.308838 | C Loss: -4.736524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.528\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:46:51 - INFO - __main__ -   Text: ['About a month after an eight month exposure, Cohen found out about bronchitis by checking that his lipozyme']\n",
      "07/06/2022 15:46:53 - INFO - __main__ -   Epoch: 78 | Batch: 600/4330 (14%) | G Loss: 3.221216 | C Loss: -0.380310\n",
      "07/06/2022 15:46:54 - INFO - __main__ -   Text: [\"Afterward, the infected woman now receives plus five weeks' hormonal improvements, and a new four-week\"]\n",
      "07/06/2022 15:46:55 - INFO - __main__ -   Epoch: 78 | Batch: 1200/4330 (28%) | G Loss: 3.514722 | C Loss: -0.555087\n",
      "07/06/2022 15:46:56 - INFO - __main__ -   Text: ['He says in regards to the pills: \"I took the 50mg tablets once to get rid of migraine; the']\n",
      "07/06/2022 15:46:57 - INFO - __main__ -   Epoch: 78 | Batch: 1800/4330 (42%) | G Loss: 3.095149 | C Loss: -0.507718\n",
      "07/06/2022 15:46:58 - INFO - __main__ -   Text: ['The symptoms of the flu include the moistness of the air when taking oral antibiotics, and the hindsight of feeling']\n",
      "07/06/2022 15:47:00 - INFO - __main__ -   Epoch: 78 | Batch: 2400/4330 (55%) | G Loss: 2.899942 | C Loss: -1.302772\n",
      "07/06/2022 15:47:00 - INFO - __main__ -   Text: ['× × updated in a temporary way: iStockphoto.net user ( property-sex-hiding: thought']\n",
      "07/06/2022 15:47:02 - INFO - __main__ -   Epoch: 78 | Batch: 3000/4330 (69%) | G Loss: 2.790245 | C Loss: -0.716618\n",
      "07/06/2022 15:47:02 - INFO - __main__ -   Text: ['Engines that boost sleep or nausea can diminish production for the first telomeres and end up being one if a']\n",
      "07/06/2022 15:47:04 - INFO - __main__ -   Epoch: 78 | Batch: 3600/4330 (83%) | G Loss: 2.851536 | C Loss: -0.977111\n",
      "07/06/2022 15:47:04 - INFO - __main__ -   Text: ['From Now On You are a bottle of whisky if you want to recover faster as you get older and found that it']\n",
      "07/06/2022 15:47:06 - INFO - __main__ -   Epoch: 78 | Batch: 4200/4330 (97%) | G Loss: 3.106024 | C Loss: -0.572356\n",
      "07/06/2022 15:47:07 - INFO - __main__ -   Text: ['It just happens to me that when I do things like this, most likely I will not use my years of being']\n",
      "07/06/2022 15:47:07 - INFO - __main__ -   * (Train) Epoch: 78 | G Loss: 2.4134 | C Loss: -1.5016 | Updates G: 4 | Updates C: 356\n",
      "07/06/2022 15:47:21 - INFO - __main__ -   Bleu-2:0.471 | B-Bleu-2:0.309\n",
      "07/06/2022 15:47:21 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7795846681723462\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 79 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:49:49 - INFO - __main__ -   Epoch: 79 | Batch: 0/4372 (0%) | G Loss: 2.586639 | C Loss: -5.638522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.503\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:49:50 - INFO - __main__ -   Text: [\"These days I'm able to support Tracey from where I suppose her parents graduated with a baby blanket that covers my\"]\n",
      "07/06/2022 15:49:52 - INFO - __main__ -   Epoch: 79 | Batch: 600/4372 (14%) | G Loss: 3.103637 | C Loss: -2.118409\n",
      "07/06/2022 15:49:52 - INFO - __main__ -   Text: ['In 2005, she tells me she has developed cloverleaf but only after reports how important it is in her life']\n",
      "07/06/2022 15:49:54 - INFO - __main__ -   Epoch: 79 | Batch: 1200/4372 (27%) | G Loss: 3.081773 | C Loss: -8.423070\n",
      "07/06/2022 15:49:54 - INFO - __main__ -   Text: ['Supercaller takes the drug a minute or so during each consecutive day, suddenly become unconscious; when she goes to']\n",
      "07/06/2022 15:49:56 - INFO - __main__ -   Epoch: 79 | Batch: 1800/4372 (41%) | G Loss: 2.970909 | C Loss: -3.810763\n",
      "07/06/2022 15:49:56 - INFO - __main__ -   Text: ['According to researchers Sheila Conley and Valerie Leven and not recycled by Co., the pills anyone notices are likely to']\n",
      "07/06/2022 15:49:58 - INFO - __main__ -   Epoch: 79 | Batch: 2400/4372 (55%) | G Loss: 3.122534 | C Loss: -1.871206\n",
      "07/06/2022 15:49:58 - INFO - __main__ -   Text: ['For example, NevoMed supports only three patients every year (instead of 10 or 11 patients a year), and']\n",
      "07/06/2022 15:50:00 - INFO - __main__ -   Epoch: 79 | Batch: 3000/4372 (69%) | G Loss: 2.661065 | C Loss: -0.685608\n",
      "07/06/2022 15:50:01 - INFO - __main__ -   Text: ['On the technical level the words death and destruction\" the actor (鬁縿) conveyed are easily']\n",
      "07/06/2022 15:50:03 - INFO - __main__ -   Epoch: 79 | Batch: 3600/4372 (82%) | G Loss: 3.117642 | C Loss: -0.492166\n",
      "07/06/2022 15:50:03 - INFO - __main__ -   Text: ['All weightlifters have a small, pincushionis drive and whereas his best so far has been']\n",
      "07/06/2022 15:50:05 - INFO - __main__ -   Epoch: 79 | Batch: 4200/4372 (96%) | G Loss: 2.754134 | C Loss: -0.896727\n",
      "07/06/2022 15:50:05 - INFO - __main__ -   Text: ['They have learnt just about everything about their cervical spine from the previous attempt, a high temperature can only be used up']\n",
      "07/06/2022 15:50:05 - INFO - __main__ -   * (Train) Epoch: 79 | G Loss: 1.9127 | C Loss: -1.5529 | Updates G: 2 | Updates C: 362\n",
      "07/06/2022 15:50:20 - INFO - __main__ -   Bleu-2:0.457 | B-Bleu-2:0.318\n",
      "07/06/2022 15:50:20 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7750997417032722\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 80 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:52:48 - INFO - __main__ -   Epoch: 80 | Batch: 0/4473 (0%) | G Loss: 2.960250 | C Loss: -2.342412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 5.491\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:52:48 - INFO - __main__ -   Text: ['Officers often refer to the smallest or largest graphical difference in the Dash tutorial; while explaining why it is7,700']\n",
      "07/06/2022 15:52:50 - INFO - __main__ -   Epoch: 80 | Batch: 600/4473 (13%) | G Loss: 2.986803 | C Loss: -0.689272\n",
      "07/06/2022 15:52:50 - INFO - __main__ -   Text: ['The tablet logs 8.9% of the Dash Time with one click (40 hours of it), and he gets']\n",
      "07/06/2022 15:52:52 - INFO - __main__ -   Epoch: 80 | Batch: 1200/4473 (27%) | G Loss: 3.120445 | C Loss: -1.400135\n",
      "07/06/2022 15:52:53 - INFO - __main__ -   Text: ['In spite of this fine publication, she has suffered an appendicitis and has felt the effect of burnout after']\n",
      "07/06/2022 15:52:54 - INFO - __main__ -   Epoch: 80 | Batch: 1800/4473 (40%) | G Loss: 3.057407 | C Loss: -0.678942\n",
      "07/06/2022 15:52:55 - INFO - __main__ -   Text: ['The dosage that is considered the best hormonal contraceptive in the world is ridiculous, due to the weight loss, energy']\n",
      "07/06/2022 15:52:57 - INFO - __main__ -   Epoch: 80 | Batch: 2400/4473 (54%) | G Loss: 2.639979 | C Loss: -0.914168\n",
      "07/06/2022 15:52:57 - INFO - __main__ -   Text: [\"In contrast, the Bradur inbreds day errands with a smile and isn't expecting to achieve an average\"]\n",
      "07/06/2022 15:52:59 - INFO - __main__ -   Epoch: 80 | Batch: 3000/4473 (67%) | G Loss: 2.460129 | C Loss: -1.301353\n",
      "07/06/2022 15:52:59 - INFO - __main__ -   Text: ['By the start as of February 2007 I personally used mobile phone as a reference, wearing well with bass neck muscles,']\n",
      "07/06/2022 15:53:01 - INFO - __main__ -   Epoch: 80 | Batch: 3600/4473 (80%) | G Loss: 2.071509 | C Loss: -0.652301\n",
      "07/06/2022 15:53:01 - INFO - __main__ -   Text: ['In 2011, Munivan told TheJournal.ie that he no longer carries the health counseling protocol after five days due']\n",
      "07/06/2022 15:53:04 - INFO - __main__ -   Epoch: 80 | Batch: 4200/4473 (94%) | G Loss: 1.721366 | C Loss: -1.764563\n",
      "07/06/2022 15:53:04 - INFO - __main__ -   Text: ['But if Jim too, was left removed physically when The Import airs her touch cleanses spells on paper – Instant']\n",
      "07/06/2022 15:53:05 - INFO - __main__ -   * (Train) Epoch: 80 | G Loss: 2.3832 | C Loss: -1.5156 | Updates G: 6 | Updates C: 366\n",
      "07/06/2022 15:53:18 - INFO - __main__ -   Bleu-2:0.461 | B-Bleu-2:0.297\n",
      "07/06/2022 15:53:18 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7574503879378878\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 81 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:55:47 - INFO - __main__ -   Epoch: 81 | Batch: 0/4473 (0%) | G Loss: 1.865711 | C Loss: -0.681801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.185\n",
      "  Test Loss: 5.241\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:55:47 - INFO - __main__ -   Text: ['However, it advised that avoiding a colostomy so that they can only regenerate previous livers prior to']\n",
      "07/06/2022 15:55:49 - INFO - __main__ -   Epoch: 81 | Batch: 600/4473 (13%) | G Loss: 2.542822 | C Loss: -0.419748\n",
      "07/06/2022 15:55:49 - INFO - __main__ -   Text: ['Some women (especially those considering IGH), cannot take the lift after a mental lapse or are over-analyzed']\n",
      "07/06/2022 15:55:51 - INFO - __main__ -   Epoch: 81 | Batch: 1200/4473 (27%) | G Loss: 2.085820 | C Loss: -1.846198\n",
      "07/06/2022 15:55:51 - INFO - __main__ -   Text: ['Interview to be processed accurately is complicated, as the tests take about three hours to complete and before leaving, the young']\n",
      "07/06/2022 15:55:53 - INFO - __main__ -   Epoch: 81 | Batch: 1800/4473 (40%) | G Loss: 1.943767 | C Loss: -0.860697\n",
      "07/06/2022 15:55:54 - INFO - __main__ -   Text: ['A girlfriend noted that she had a couple times cause headaches in this case, but managed to break her teeth while mixing']\n",
      "07/06/2022 15:55:55 - INFO - __main__ -   Epoch: 81 | Batch: 2400/4473 (54%) | G Loss: 2.297997 | C Loss: -0.764420\n",
      "07/06/2022 15:55:56 - INFO - __main__ -   Text: ['It lacks the bowel movements tired-out body throws when eating any kind of GoAlive; normally it is only']\n",
      "07/06/2022 15:55:58 - INFO - __main__ -   Epoch: 81 | Batch: 3000/4473 (67%) | G Loss: 2.440700 | C Loss: -1.455536\n",
      "07/06/2022 15:55:58 - INFO - __main__ -   Text: ['Both men were able to stop the sneezing due to an isolating screen, but initially through the negative feedback']\n",
      "07/06/2022 15:56:00 - INFO - __main__ -   Epoch: 81 | Batch: 3600/4473 (80%) | G Loss: 1.997363 | C Loss: -3.190237\n",
      "07/06/2022 15:56:00 - INFO - __main__ -   Text: ['Now you can wait to pound an urn daily for urine just because of persisting his blood thirst a few days']\n",
      "07/06/2022 15:56:02 - INFO - __main__ -   Epoch: 81 | Batch: 4200/4473 (94%) | G Loss: 2.431096 | C Loss: -0.662703\n",
      "07/06/2022 15:56:02 - INFO - __main__ -   Text: ['On the first day, after eating and weighing 100 grams of mixed nuts when asked \"Go first, make sure you']\n",
      "07/06/2022 15:56:03 - INFO - __main__ -   * (Train) Epoch: 81 | G Loss: 2.0074 | C Loss: -1.5506 | Updates G: 8 | Updates C: 364\n",
      "07/06/2022 15:56:17 - INFO - __main__ -   Bleu-2:0.462 | B-Bleu-2:0.312\n",
      "07/06/2022 15:56:17 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7745877321593013\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 82 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:58:45 - INFO - __main__ -   Epoch: 82 | Batch: 0/4327 (0%) | G Loss: 2.395007 | C Loss: -0.542009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.338\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 15:58:45 - INFO - __main__ -   Text: ['Furthermore, Wedi features relatively mean to moderate dehydration; just over half of the day cares about changing blood sugar as']\n",
      "07/06/2022 15:58:47 - INFO - __main__ -   Epoch: 82 | Batch: 600/4327 (14%) | G Loss: 2.705778 | C Loss: -0.584899\n",
      "07/06/2022 15:58:47 - INFO - __main__ -   Text: ['Many entertainer ads recently, while leaving the restaurant after meals plateau in order to get back, wrote']\n",
      "07/06/2022 15:58:49 - INFO - __main__ -   Epoch: 82 | Batch: 1200/4327 (28%) | G Loss: 2.499647 | C Loss: -0.460088\n",
      "07/06/2022 15:58:50 - INFO - __main__ -   Text: ['Expensively reworked in the service of a distance runner as Krishnakumar had a low body temperature as']\n",
      "07/06/2022 15:58:52 - INFO - __main__ -   Epoch: 82 | Batch: 1800/4327 (42%) | G Loss: 2.290092 | C Loss: -3.475319\n",
      "07/06/2022 15:58:52 - INFO - __main__ -   Text: ['The problem was running continuously and causing short bouts of hyper alert (which was unusually frequent, causing minor dip),']\n",
      "07/06/2022 15:58:54 - INFO - __main__ -   Epoch: 82 | Batch: 2400/4327 (55%) | G Loss: 2.746892 | C Loss: -0.385340\n",
      "07/06/2022 15:58:54 - INFO - __main__ -   Text: ['However, if the next day, when the weight of the meal was going to be fully increased, Ellardo needed']\n",
      "07/06/2022 15:58:56 - INFO - __main__ -   Epoch: 82 | Batch: 3000/4327 (69%) | G Loss: 2.743079 | C Loss: -3.980643\n",
      "07/06/2022 15:58:57 - INFO - __main__ -   Text: ['Called \\'Walpa O Filmi Sahib 2010\\' is a shortcut of \"800 days\\' of unlimited']\n",
      "07/06/2022 15:58:59 - INFO - __main__ -   Epoch: 82 | Batch: 3600/4327 (83%) | G Loss: 2.352917 | C Loss: -0.680542\n",
      "07/06/2022 15:58:59 - INFO - __main__ -   Text: ['The drug is not banned in doctors\\' studies because, after best success with \"The Path\") because of negative reaction']\n",
      "07/06/2022 15:59:01 - INFO - __main__ -   Epoch: 82 | Batch: 4200/4327 (97%) | G Loss: 2.574968 | C Loss: -2.964950\n",
      "07/06/2022 15:59:01 - INFO - __main__ -   Text: ['It takes 17 days for me to be escalated and once I grow up in the Waloka Group (one of']\n",
      "07/06/2022 15:59:01 - INFO - __main__ -   * (Train) Epoch: 82 | G Loss: 2.2802 | C Loss: -1.6068 | Updates G: 10 | Updates C: 350\n",
      "07/06/2022 15:59:15 - INFO - __main__ -   Bleu-2:0.479 | B-Bleu-2:0.307\n",
      "07/06/2022 15:59:15 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7864384955950077\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 83 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:01:44 - INFO - __main__ -   Epoch: 83 | Batch: 0/4417 (0%) | G Loss: 2.476778 | C Loss: -0.458226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.190\n",
      "  Test Loss: 5.092\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:01:44 - INFO - __main__ -   Text: [\"It's helpful to have a green flashlight in Kleion i.e. concentrate only on the front country if you\"]\n",
      "07/06/2022 16:01:46 - INFO - __main__ -   Epoch: 83 | Batch: 600/4417 (14%) | G Loss: 1.950233 | C Loss: -0.471559\n",
      "07/06/2022 16:01:46 - INFO - __main__ -   Text: ['Kraulsigen initially stated that they must \"take care of your teeth\", but the consultation with doctors suggests they take']\n",
      "07/06/2022 16:01:48 - INFO - __main__ -   Epoch: 83 | Batch: 1200/4417 (27%) | G Loss: 1.877306 | C Loss: -0.675939\n",
      "07/06/2022 16:01:48 - INFO - __main__ -   Text: ['In age of caffeine intake, during sleep deprivation, third-hourally affected, Fleming discovered that his pupils suffer from']\n",
      "07/06/2022 16:01:50 - INFO - __main__ -   Epoch: 83 | Batch: 1800/4417 (41%) | G Loss: 1.940711 | C Loss: -0.612897\n",
      "07/06/2022 16:01:51 - INFO - __main__ -   Text: ['\"What I did for 90 percent of my life, nothing else’s happened since before I was introduced to']\n",
      "07/06/2022 16:01:52 - INFO - __main__ -   Epoch: 83 | Batch: 2400/4417 (54%) | G Loss: 2.114457 | C Loss: -0.630168\n",
      "07/06/2022 16:01:53 - INFO - __main__ -   Text: ['Forty-two years after it was release, Antipolo started taking them since my last diet retreated in 1999 to']\n",
      "07/06/2022 16:01:54 - INFO - __main__ -   Epoch: 83 | Batch: 3000/4417 (68%) | G Loss: 2.164340 | C Loss: -0.962411\n",
      "07/06/2022 16:01:55 - INFO - __main__ -   Text: ['The mood worsened once therapy was taken (and this is often where deana dresses as drugs remind her to']\n",
      "07/06/2022 16:01:57 - INFO - __main__ -   Epoch: 83 | Batch: 3600/4417 (82%) | G Loss: 2.350574 | C Loss: -1.208012\n",
      "07/06/2022 16:01:57 - INFO - __main__ -   Text: ['Not only does it suffer from eyelash difficulties lasting over the crowd declamations and complication, it also causes']\n",
      "07/06/2022 16:01:59 - INFO - __main__ -   Epoch: 83 | Batch: 4200/4417 (95%) | G Loss: 2.180816 | C Loss: -4.138071\n",
      "07/06/2022 16:01:59 - INFO - __main__ -   Text: ['He then made that claim in a recent MTV interview where he found out Barnes had lungs because he believed that the capsules']\n",
      "07/06/2022 16:02:00 - INFO - __main__ -   * (Train) Epoch: 83 | G Loss: 1.9042 | C Loss: -1.6310 | Updates G: 17 | Updates C: 351\n",
      "07/06/2022 16:02:14 - INFO - __main__ -   Bleu-2:0.475 | B-Bleu-2:0.307\n",
      "07/06/2022 16:02:14 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817492318313485\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 84 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:04:43 - INFO - __main__ -   Epoch: 84 | Batch: 0/4322 (0%) | G Loss: 2.504087 | C Loss: -2.768497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.660\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:04:43 - INFO - __main__ -   Text: ['He does not seem able to calm down or sleep or heal himself, whereas when he did it, the first words']\n",
      "07/06/2022 16:04:45 - INFO - __main__ -   Epoch: 84 | Batch: 600/4322 (14%) | G Loss: 2.634769 | C Loss: -4.128563\n",
      "07/06/2022 16:04:45 - INFO - __main__ -   Text: ['Criticism hiccitch synchingbut perversely has helped to improve peripheral vision, making a third eye']\n",
      "07/06/2022 16:04:47 - INFO - __main__ -   Epoch: 84 | Batch: 1200/4322 (28%) | G Loss: 2.771128 | C Loss: -0.768347\n",
      "07/06/2022 16:04:47 - INFO - __main__ -   Text: ['He noticed that, while the doctor kept the exact mix Ayurveda needs to take in both semilance']\n",
      "07/06/2022 16:04:49 - INFO - __main__ -   Epoch: 84 | Batch: 1800/4322 (42%) | G Loss: 2.722077 | C Loss: -1.382776\n",
      "07/06/2022 16:04:49 - INFO - __main__ -   Text: ['Adhering lifestyle standards remains the same whether watching TV or not while eating coffee can be blamed for his liver fractured']\n",
      "07/06/2022 16:04:51 - INFO - __main__ -   Epoch: 84 | Batch: 2400/4322 (56%) | G Loss: 2.332523 | C Loss: -0.915294\n",
      "07/06/2022 16:04:52 - INFO - __main__ -   Text: ['On 10 August 2008, SJW\\'s male partner wrote to indicate they will \"never stop smoking and I want to']\n",
      "07/06/2022 16:04:54 - INFO - __main__ -   Epoch: 84 | Batch: 3000/4322 (69%) | G Loss: 1.534269 | C Loss: -0.673214\n",
      "07/06/2022 16:04:54 - INFO - __main__ -   Text: ['In the pre-MRM127 days, the very special treatment that tends to make people more stable in the environment']\n",
      "07/06/2022 16:04:56 - INFO - __main__ -   Epoch: 84 | Batch: 3600/4322 (83%) | G Loss: 1.346172 | C Loss: -1.750131\n",
      "07/06/2022 16:04:56 - INFO - __main__ -   Text: ['Karl is considered the most bulky job and receiving treatment by most means, makes near-sighted dreams of armageddon seem']\n",
      "07/06/2022 16:04:58 - INFO - __main__ -   Epoch: 84 | Batch: 4200/4322 (97%) | G Loss: 1.461271 | C Loss: -1.722212\n",
      "07/06/2022 16:04:58 - INFO - __main__ -   Text: ['RuKaTaP used to see as a kale juice and, once it was released to his patients (\"Targeted']\n",
      "07/06/2022 16:04:59 - INFO - __main__ -   * (Train) Epoch: 84 | G Loss: 1.9876 | C Loss: -1.7531 | Updates G: 15 | Updates C: 345\n",
      "07/06/2022 16:05:13 - INFO - __main__ -   Bleu-2:0.481 | B-Bleu-2:0.317\n",
      "07/06/2022 16:05:13 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7975109565073811\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 85 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:07:41 - INFO - __main__ -   Epoch: 85 | Batch: 0/4527 (0%) | G Loss: 1.272686 | C Loss: -3.992352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.190\n",
      "  Test Loss: 5.264\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:07:41 - INFO - __main__ -   Text: ['In addition to making sex noises during oral sex, Kimota reports that she has had oral sex with 2 bangs']\n",
      "07/06/2022 16:07:43 - INFO - __main__ -   Epoch: 85 | Batch: 600/4527 (13%) | G Loss: 3.107696 | C Loss: -1.421968\n",
      "07/06/2022 16:07:43 - INFO - __main__ -   Text: ['His habit of drinking a full bottle or 300ml, despite his effectiveness only just 10 days earlier, kicks up']\n",
      "07/06/2022 16:07:45 - INFO - __main__ -   Epoch: 85 | Batch: 1200/4527 (27%) | G Loss: 3.982609 | C Loss: -1.038154\n",
      "07/06/2022 16:07:45 - INFO - __main__ -   Text: [\"The patient's symptoms go through afterward, just like the one before, and it takes extremely long to prevent the chill\"]\n",
      "07/06/2022 16:07:48 - INFO - __main__ -   Epoch: 85 | Batch: 1800/4527 (40%) | G Loss: 3.470874 | C Loss: -2.786375\n",
      "07/06/2022 16:07:48 - INFO - __main__ -   Text: ['Agulance then spends three minutes discussing patronizing food with a pride, nifting from tripe pillines']\n",
      "07/06/2022 16:07:50 - INFO - __main__ -   Epoch: 85 | Batch: 2400/4527 (53%) | G Loss: 2.613191 | C Loss: -1.736507\n",
      "07/06/2022 16:07:50 - INFO - __main__ -   Text: [\"Yet I'm attuned to the sound, acclimatized and happy because I'm sure Medicine knows what\"]\n",
      "07/06/2022 16:07:52 - INFO - __main__ -   Epoch: 85 | Batch: 3000/4527 (66%) | G Loss: 1.697592 | C Loss: -1.127700\n",
      "07/06/2022 16:07:52 - INFO - __main__ -   Text: ['They all then get their vaccination, diagnosed with flu and take full sleep, including one topically sick day the other']\n",
      "07/06/2022 16:07:54 - INFO - __main__ -   Epoch: 85 | Batch: 3600/4527 (80%) | G Loss: 1.871880 | C Loss: -1.237795\n",
      "07/06/2022 16:07:54 - INFO - __main__ -   Text: ['My real sonomethings, while not exactly cutting it, it did give me further chances with']\n",
      "07/06/2022 16:07:56 - INFO - __main__ -   Epoch: 85 | Batch: 4200/4527 (93%) | G Loss: 2.011328 | C Loss: -4.451050\n",
      "07/06/2022 16:07:56 - INFO - __main__ -   Text: ['Mezium has also changed anything with it from the aforementioned usage of powdered nectar to SPAN as an']\n",
      "07/06/2022 16:07:57 - INFO - __main__ -   * (Train) Epoch: 85 | G Loss: 1.8321 | C Loss: -1.8545 | Updates G: 19 | Updates C: 358\n",
      "07/06/2022 16:08:11 - INFO - __main__ -   Bleu-2:0.462 | B-Bleu-2:0.332\n",
      "07/06/2022 16:08:11 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7947894482506408\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 86 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:10:40 - INFO - __main__ -   Epoch: 86 | Batch: 0/4467 (0%) | G Loss: 2.034513 | C Loss: -0.649499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.279\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:10:40 - INFO - __main__ -   Text: ['It( Blood pressure pills) is usually harmful to someone, and takes longer than once a day because it is added']\n",
      "07/06/2022 16:10:42 - INFO - __main__ -   Epoch: 86 | Batch: 600/4467 (13%) | G Loss: 2.405900 | C Loss: -1.614829\n",
      "07/06/2022 16:10:42 - INFO - __main__ -   Text: ['It does not start nor drop but is posited telomerase is once every 2–3,000 hours a']\n",
      "07/06/2022 16:10:44 - INFO - __main__ -   Epoch: 86 | Batch: 1200/4467 (27%) | G Loss: 1.724696 | C Loss: -0.785907\n",
      "07/06/2022 16:10:44 - INFO - __main__ -   Text: ['While here, I was able to dry out my lips with one earpiece the morning before because I was using my']\n",
      "07/06/2022 16:10:46 - INFO - __main__ -   Epoch: 86 | Batch: 1800/4467 (40%) | G Loss: 1.804060 | C Loss: -4.334970\n",
      "07/06/2022 16:10:47 - INFO - __main__ -   Text: ['He had run a machine program that is not showing any real elevation gain during running at 7:00pm all the']\n",
      "07/06/2022 16:10:48 - INFO - __main__ -   Epoch: 86 | Batch: 2400/4467 (54%) | G Loss: 2.261190 | C Loss: -7.063373\n",
      "07/06/2022 16:10:49 - INFO - __main__ -   Text: ['First there is the bumps you may experience as an overstating time in relay track time and again in their 1992']\n",
      "07/06/2022 16:10:51 - INFO - __main__ -   Epoch: 86 | Batch: 3000/4467 (67%) | G Loss: 1.832715 | C Loss: -0.546761\n",
      "07/06/2022 16:10:51 - INFO - __main__ -   Text: ['Kassina added that, even after these 2 month studies, she began to show some necrosis and when she looked']\n",
      "07/06/2022 16:10:53 - INFO - __main__ -   Epoch: 86 | Batch: 3600/4467 (81%) | G Loss: 1.904052 | C Loss: -1.796447\n",
      "07/06/2022 16:10:53 - INFO - __main__ -   Text: ['Towards the end of October, Amjadgala used personal photos to write a bio, again exceeding those of others']\n",
      "07/06/2022 16:10:55 - INFO - __main__ -   Epoch: 86 | Batch: 4200/4467 (94%) | G Loss: 1.789242 | C Loss: -0.798121\n",
      "07/06/2022 16:10:55 - INFO - __main__ -   Text: ['On average six weeks went by, a nurse would get in touch with animal cruelty if she looked at a top picture']\n",
      "07/06/2022 16:10:56 - INFO - __main__ -   * (Train) Epoch: 86 | G Loss: 1.7333 | C Loss: -1.8289 | Updates G: 14 | Updates C: 358\n",
      "07/06/2022 16:11:10 - INFO - __main__ -   Bleu-2:0.451 | B-Bleu-2:0.305\n",
      "07/06/2022 16:11:10 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7566639895172902\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 87 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:13:38 - INFO - __main__ -   Epoch: 87 | Batch: 0/4364 (0%) | G Loss: 1.481410 | C Loss: -0.709571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 5.120\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:13:38 - INFO - __main__ -   Text: ['Suppose you imagine your last bet is actually $25 a month which is money you will lose in the next five months']\n",
      "07/06/2022 16:13:40 - INFO - __main__ -   Epoch: 87 | Batch: 600/4364 (14%) | G Loss: 1.146018 | C Loss: -2.217065\n",
      "07/06/2022 16:13:40 - INFO - __main__ -   Text: ['The \\'drama\\' performed by Dr Jaiang\" was this 4(x 15), his best video with']\n",
      "07/06/2022 16:13:42 - INFO - __main__ -   Epoch: 87 | Batch: 1200/4364 (27%) | G Loss: 1.243617 | C Loss: -1.212942\n",
      "07/06/2022 16:13:42 - INFO - __main__ -   Text: [\"Hubbard's observed risqué dog days are often late in the day, altered paleo diet with meme-generated\"]\n",
      "07/06/2022 16:13:44 - INFO - __main__ -   Epoch: 87 | Batch: 1800/4364 (41%) | G Loss: 1.394408 | C Loss: -0.651085\n",
      "07/06/2022 16:13:45 - INFO - __main__ -   Text: ['Similar to trying to attach a shoe to your salary when below three dollars an hour is generally nothing, running late in']\n",
      "07/06/2022 16:13:47 - INFO - __main__ -   Epoch: 87 | Batch: 2400/4364 (55%) | G Loss: 2.395056 | C Loss: -1.459034\n",
      "07/06/2022 16:13:47 - INFO - __main__ -   Text: ['It was also claimed that the video was surprisingly brief and that it vanquished certain symptoms such as blurred vision, high']\n",
      "07/06/2022 16:13:49 - INFO - __main__ -   Epoch: 87 | Batch: 3000/4364 (69%) | G Loss: 2.502356 | C Loss: -4.953349\n",
      "07/06/2022 16:13:49 - INFO - __main__ -   Text: ['According to one study published in Advanced Medical Science last year, 95% of the mucus in normal body is unusually']\n",
      "07/06/2022 16:13:51 - INFO - __main__ -   Epoch: 87 | Batch: 3600/4364 (82%) | G Loss: 2.437210 | C Loss: -1.397557\n",
      "07/06/2022 16:13:51 - INFO - __main__ -   Text: ['Because of the high dependence of the drug it appeared to me that carbunate pills had to be stopped so I']\n",
      "07/06/2022 16:13:53 - INFO - __main__ -   Epoch: 87 | Batch: 4200/4364 (96%) | G Loss: 2.018003 | C Loss: -0.878727\n",
      "07/06/2022 16:13:54 - INFO - __main__ -   Text: ['Often he dances (female strippers include himself on the dance floor can only earn 2 € per hour paid for trance']\n",
      "07/06/2022 16:13:54 - INFO - __main__ -   * (Train) Epoch: 87 | G Loss: 1.5122 | C Loss: -1.8208 | Updates G: 25 | Updates C: 338\n",
      "07/06/2022 16:14:08 - INFO - __main__ -   Bleu-2:0.477 | B-Bleu-2:0.311\n",
      "07/06/2022 16:14:08 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7885306911025647\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 88 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:16:36 - INFO - __main__ -   Epoch: 88 | Batch: 0/4330 (0%) | G Loss: 2.029670 | C Loss: -1.445810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.357\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:16:37 - INFO - __main__ -   Text: ['Disappointed in the software version but happy with the final product because it pushes the retention between Generation 1 and 2 and']\n",
      "07/06/2022 16:16:38 - INFO - __main__ -   Epoch: 88 | Batch: 600/4330 (14%) | G Loss: 1.558958 | C Loss: -5.859989\n",
      "07/06/2022 16:16:39 - INFO - __main__ -   Text: ['Show me how to generate my weekly satisfaction with the hours, hours and minutes, you egotistical loner can']\n",
      "07/06/2022 16:16:41 - INFO - __main__ -   Epoch: 88 | Batch: 1200/4330 (28%) | G Loss: 1.377971 | C Loss: -1.225171\n",
      "07/06/2022 16:16:41 - INFO - __main__ -   Text: [\"In 2015 Bartram's OB claims one week not to eat or drink alcohol, which only thrills her 8\"]\n",
      "07/06/2022 16:16:43 - INFO - __main__ -   Epoch: 88 | Batch: 1800/4330 (42%) | G Loss: 1.134811 | C Loss: -2.445883\n",
      "07/06/2022 16:16:43 - INFO - __main__ -   Text: ['The research revealed that the procedure itself is produced most frequently in the UK and Down syndrome, having to drop every minute']\n",
      "07/06/2022 16:16:45 - INFO - __main__ -   Epoch: 88 | Batch: 2400/4330 (55%) | G Loss: 2.321258 | C Loss: -0.797153\n",
      "07/06/2022 16:16:45 - INFO - __main__ -   Text: ['Memorically saving his paper fares through low hours or slowing him down is actually not enough to get adequate sleep, he']\n",
      "07/06/2022 16:16:47 - INFO - __main__ -   Epoch: 88 | Batch: 3000/4330 (69%) | G Loss: 2.966277 | C Loss: -5.018898\n",
      "07/06/2022 16:16:47 - INFO - __main__ -   Text: ['Kanov also removes the video distracting and it begins decreasing the clicks rate, removing the \"too many irrelevant pants\"']\n",
      "07/06/2022 16:16:49 - INFO - __main__ -   Epoch: 88 | Batch: 3600/4330 (83%) | G Loss: 2.991903 | C Loss: -0.616596\n",
      "07/06/2022 16:16:50 - INFO - __main__ -   Text: ['The reported duration of the procedure is likely to be hours, as Marksazzi says “last for all']\n",
      "07/06/2022 16:16:52 - INFO - __main__ -   Epoch: 88 | Batch: 4200/4330 (97%) | G Loss: 2.403942 | C Loss: -0.800297\n",
      "07/06/2022 16:16:52 - INFO - __main__ -   Text: ['As per Sustaining all opens, her address and IV/V has been exceeded which is potentially']\n",
      "07/06/2022 16:16:52 - INFO - __main__ -   * (Train) Epoch: 88 | G Loss: 1.5532 | C Loss: -1.8326 | Updates G: 13 | Updates C: 347\n",
      "07/06/2022 16:17:06 - INFO - __main__ -   Bleu-2:0.463 | B-Bleu-2:0.300\n",
      "07/06/2022 16:17:06 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7625058037632698\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 89 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:19:35 - INFO - __main__ -   Epoch: 89 | Batch: 0/4372 (0%) | G Loss: 2.253355 | C Loss: -0.768459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 5.397\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:19:35 - INFO - __main__ -   Text: ['He also found that he had to add at least 80% of muscle mass at one hour or less without the']\n",
      "07/06/2022 16:19:37 - INFO - __main__ -   Epoch: 89 | Batch: 600/4372 (14%) | G Loss: 1.841285 | C Loss: -3.350684\n",
      "07/06/2022 16:19:37 - INFO - __main__ -   Text: ['It can sometimes be known that is an eating disorder but when it happens in with ease which is often if the']\n",
      "07/06/2022 16:19:39 - INFO - __main__ -   Epoch: 89 | Batch: 1200/4372 (27%) | G Loss: 0.982716 | C Loss: -0.820739\n",
      "07/06/2022 16:19:39 - INFO - __main__ -   Text: ['The end result came at around 1 hour and 54 minutes when, after gaining a velocity of 48 m/s,']\n",
      "07/06/2022 16:19:41 - INFO - __main__ -   Epoch: 89 | Batch: 1800/4372 (41%) | G Loss: 0.998801 | C Loss: -0.768346\n",
      "07/06/2022 16:19:42 - INFO - __main__ -   Text: ['Cars in a taxi station are deducted 799 behavat sic while in fact,’s cars']\n",
      "07/06/2022 16:19:43 - INFO - __main__ -   Epoch: 89 | Batch: 2400/4372 (55%) | G Loss: 1.708460 | C Loss: -0.684679\n",
      "07/06/2022 16:19:44 - INFO - __main__ -   Text: ['Withdraws from running or yoga can readily occur due to awful boredom, anxiety, boredom, muscle breakdown,']\n",
      "07/06/2022 16:19:46 - INFO - __main__ -   Epoch: 89 | Batch: 3000/4372 (69%) | G Loss: 1.768147 | C Loss: -0.683764\n",
      "07/06/2022 16:19:46 - INFO - __main__ -   Text: ['In another example, sovatoan uses an identical dose that his customers adjust to each other daily, 1 to']\n",
      "07/06/2022 16:19:48 - INFO - __main__ -   Epoch: 89 | Batch: 3600/4372 (82%) | G Loss: 1.562865 | C Loss: -0.755504\n",
      "07/06/2022 16:19:48 - INFO - __main__ -   Text: ['That is, he only used buckwheat wheat for one meal or taking a laxative every two to three']\n",
      "07/06/2022 16:19:50 - INFO - __main__ -   Epoch: 89 | Batch: 4200/4372 (96%) | G Loss: 1.524156 | C Loss: -0.841118\n",
      "07/06/2022 16:19:50 - INFO - __main__ -   Text: ['During this time I would free free up chili syrup from my hand and give it to people who needed it daily,']\n",
      "07/06/2022 16:19:51 - INFO - __main__ -   * (Train) Epoch: 89 | G Loss: 1.3783 | C Loss: -1.8453 | Updates G: 18 | Updates C: 346\n",
      "07/06/2022 16:20:05 - INFO - __main__ -   Bleu-2:0.459 | B-Bleu-2:0.305\n",
      "07/06/2022 16:20:05 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7639143612586378\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 90 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:22:33 - INFO - __main__ -   Epoch: 90 | Batch: 0/4473 (0%) | G Loss: 1.450068 | C Loss: -5.230099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.288\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:22:33 - INFO - __main__ -   Text: ['No stains can be attributed to lack of exercise or only a sudden drop in temperature but there have been a few cases']\n",
      "07/06/2022 16:22:35 - INFO - __main__ -   Epoch: 90 | Batch: 600/4473 (13%) | G Loss: 1.518275 | C Loss: -0.910665\n",
      "07/06/2022 16:22:35 - INFO - __main__ -   Text: ['On 18 June 2017 he was featured in an article in the Bangkok Postist and sharing what the Spletcher cites']\n",
      "07/06/2022 16:22:37 - INFO - __main__ -   Epoch: 90 | Batch: 1200/4473 (27%) | G Loss: 1.307969 | C Loss: -1.982288\n",
      "07/06/2022 16:22:37 - INFO - __main__ -   Text: ['This can be achieved by taking a hard drink, eating a vegan diet, eating a vegan childbath now and leaving']\n",
      "07/06/2022 16:22:39 - INFO - __main__ -   Epoch: 90 | Batch: 1800/4473 (40%) | G Loss: 1.442593 | C Loss: -3.640251\n",
      "07/06/2022 16:22:40 - INFO - __main__ -   Text: ['Eventually, and after suffering severe breast cancer, Bubbles attained human form with a video of 9-10']\n",
      "07/06/2022 16:22:42 - INFO - __main__ -   Epoch: 90 | Batch: 2400/4473 (54%) | G Loss: 1.428495 | C Loss: -1.999850\n",
      "07/06/2022 16:22:42 - INFO - __main__ -   Text: ['They tried a test to determine which stream has changed the shape of their boy right after publishing the results stage, and']\n",
      "07/06/2022 16:22:44 - INFO - __main__ -   Epoch: 90 | Batch: 3000/4473 (67%) | G Loss: 0.994632 | C Loss: -1.476250\n",
      "07/06/2022 16:22:44 - INFO - __main__ -   Text: ['Dark Color isSuvantined byEat and Grab with a picture of him and with 2 bottles Doug 773%']\n",
      "07/06/2022 16:22:46 - INFO - __main__ -   Epoch: 90 | Batch: 3600/4473 (80%) | G Loss: 1.821027 | C Loss: -0.889205\n",
      "07/06/2022 16:22:47 - INFO - __main__ -   Text: ['Aftercatching up their niche, Inkay can wrap up their favourite drink (imagine the 4 stars in the Sports']\n",
      "07/06/2022 16:22:48 - INFO - __main__ -   Epoch: 90 | Batch: 4200/4473 (94%) | G Loss: 2.225342 | C Loss: -1.012344\n",
      "07/06/2022 16:22:49 - INFO - __main__ -   Text: [\"Seen on TV every day in 103 days' time doing typical type 5 muscle curls, showing no sign of fatigue and\"]\n",
      "07/06/2022 16:22:50 - INFO - __main__ -   * (Train) Epoch: 90 | G Loss: 1.3108 | C Loss: -1.7587 | Updates G: 22 | Updates C: 350\n",
      "07/06/2022 16:23:04 - INFO - __main__ -   Bleu-2:0.469 | B-Bleu-2:0.297\n",
      "07/06/2022 16:23:04 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7653255676214941\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 91 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:25:32 - INFO - __main__ -   Epoch: 91 | Batch: 0/4473 (0%) | G Loss: 2.078298 | C Loss: -6.528354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.343\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:25:32 - INFO - __main__ -   Text: ['The next day, after an 8:00 pm snack due to low cortisol and low glucose levels I was told negative']\n",
      "07/06/2022 16:25:34 - INFO - __main__ -   Epoch: 91 | Batch: 600/4473 (13%) | G Loss: 2.094281 | C Loss: -0.874497\n",
      "07/06/2022 16:25:34 - INFO - __main__ -   Text: ['Upon facing this bad experience, Dhagoarz challenges Madhusudan, who does not yet have']\n",
      "07/06/2022 16:25:36 - INFO - __main__ -   Epoch: 91 | Batch: 1200/4473 (27%) | G Loss: 2.248018 | C Loss: -1.842727\n",
      "07/06/2022 16:25:36 - INFO - __main__ -   Text: ['But because of the loss of sweat, treatment may not be progressing any quicker towards morning 8 nines']\n",
      "07/06/2022 16:25:38 - INFO - __main__ -   Epoch: 91 | Batch: 1800/4473 (40%) | G Loss: 2.222855 | C Loss: -1.568256\n",
      "07/06/2022 16:25:38 - INFO - __main__ -   Text: [\"As well as bugs eating 'sinner the output of techno IS>n') which had appeared within the last two\"]\n",
      "07/06/2022 16:25:41 - INFO - __main__ -   Epoch: 91 | Batch: 2400/4473 (54%) | G Loss: 1.337353 | C Loss: -0.954577\n",
      "07/06/2022 16:25:41 - INFO - __main__ -   Text: ['The patientt has reported a threefold decrease in levels of testosterone in their daily history twice a week or twice a']\n",
      "07/06/2022 16:25:43 - INFO - __main__ -   Epoch: 91 | Batch: 3000/4473 (67%) | G Loss: 1.656999 | C Loss: -0.901536\n",
      "07/06/2022 16:25:43 - INFO - __main__ -   Text: ['Until now, this book just recalled a patient who was 365%, but lately in the past weeks care facilities have been']\n",
      "07/06/2022 16:25:45 - INFO - __main__ -   Epoch: 91 | Batch: 3600/4473 (80%) | G Loss: 1.603699 | C Loss: -2.617338\n",
      "07/06/2022 16:25:45 - INFO - __main__ -   Text: ['Since the change in pill dosage in recent days has increased her suicide rate by 11% (adjusted to 12%, -']\n",
      "07/06/2022 16:25:47 - INFO - __main__ -   Epoch: 91 | Batch: 4200/4473 (94%) | G Loss: 1.560833 | C Loss: -0.826809\n",
      "07/06/2022 16:25:48 - INFO - __main__ -   Text: ['The kidneys returned to normal after five more days and after 72 hours on various drugs, the female, Dr.']\n",
      "07/06/2022 16:25:48 - INFO - __main__ -   * (Train) Epoch: 91 | G Loss: 1.4004 | C Loss: -1.7962 | Updates G: 9 | Updates C: 363\n",
      "07/06/2022 16:26:03 - INFO - __main__ -   Bleu-2:0.460 | B-Bleu-2:0.306\n",
      "07/06/2022 16:26:03 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7654523385756375\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 92 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:28:31 - INFO - __main__ -   Epoch: 92 | Batch: 0/4327 (0%) | G Loss: 1.482306 | C Loss: -1.079418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.429\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:28:31 - INFO - __main__ -   Text: ['Face piglets also show cardiac signs in 14s that can also be painful, but are only partially reversible but they']\n",
      "07/06/2022 16:28:33 - INFO - __main__ -   Epoch: 92 | Batch: 600/4327 (14%) | G Loss: 1.630837 | C Loss: -0.720518\n",
      "07/06/2022 16:28:33 - INFO - __main__ -   Text: ['In 2017, the doctor she will now taught has no therapies to work with, only he teaches football pro saying:']\n",
      "07/06/2022 16:28:36 - INFO - __main__ -   Epoch: 92 | Batch: 1200/4327 (28%) | G Loss: 1.675694 | C Loss: -0.672638\n",
      "07/06/2022 16:28:36 - INFO - __main__ -   Text: ['The upcoming season has also shown an onrushing side, as Sydney left the Can, and loudly reported about her']\n",
      "07/06/2022 16:28:38 - INFO - __main__ -   Epoch: 92 | Batch: 1800/4327 (42%) | G Loss: 1.896377 | C Loss: -3.666389\n",
      "07/06/2022 16:28:38 - INFO - __main__ -   Text: ['Woadey did his absolute best to warn of garden beetles and ghost beetles in his setup which included Bernie then sending']\n",
      "07/06/2022 16:28:40 - INFO - __main__ -   Epoch: 92 | Batch: 2400/4327 (55%) | G Loss: 1.466821 | C Loss: -1.017451\n",
      "07/06/2022 16:28:40 - INFO - __main__ -   Text: ['Xinjiao attributed the decrease in IPTV for now (in discussing cycle balance this gives fear, in its search']\n",
      "07/06/2022 16:28:42 - INFO - __main__ -   Epoch: 92 | Batch: 3000/4327 (69%) | G Loss: 1.918573 | C Loss: -1.277435\n",
      "07/06/2022 16:28:42 - INFO - __main__ -   Text: ['He was injured by the broken ball simply because he fell out of the game at the end of the contest and in']\n",
      "07/06/2022 16:28:44 - INFO - __main__ -   Epoch: 92 | Batch: 3600/4327 (83%) | G Loss: 1.461001 | C Loss: -3.071918\n",
      "07/06/2022 16:28:44 - INFO - __main__ -   Text: ['The problem comes from being told that he is overfed and verbally denied milk due to their 64-man diet,']\n",
      "07/06/2022 16:28:46 - INFO - __main__ -   Epoch: 92 | Batch: 4200/4327 (97%) | G Loss: 1.491022 | C Loss: -3.041836\n",
      "07/06/2022 16:28:47 - INFO - __main__ -   Text: ['the egg is good for one month and weighs about 100 g (40 oz), but losing 15% without going in']\n",
      "07/06/2022 16:28:47 - INFO - __main__ -   * (Train) Epoch: 92 | G Loss: 1.3375 | C Loss: -1.8261 | Updates G: 6 | Updates C: 354\n",
      "07/06/2022 16:29:01 - INFO - __main__ -   Bleu-2:0.450 | B-Bleu-2:0.304\n",
      "07/06/2022 16:29:01 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7542279221455301\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 93 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:31:29 - INFO - __main__ -   Epoch: 93 | Batch: 0/4417 (0%) | G Loss: 1.473609 | C Loss: -3.536302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.485\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:31:29 - INFO - __main__ -   Text: ['\"Mostly\" Ii-Hyukup but sometimes Ii-Hyukup is black, but sometimes']\n",
      "07/06/2022 16:31:31 - INFO - __main__ -   Epoch: 93 | Batch: 600/4417 (14%) | G Loss: 0.943699 | C Loss: -0.752693\n",
      "07/06/2022 16:31:32 - INFO - __main__ -   Text: ['After walking quickly through the written list-of-getters, I hoping to complete the marathon task quickly and easily']\n",
      "07/06/2022 16:31:33 - INFO - __main__ -   Epoch: 93 | Batch: 1200/4417 (27%) | G Loss: 1.211521 | C Loss: -0.704620\n",
      "07/06/2022 16:31:34 - INFO - __main__ -   Text: ['Following bile monotonic effect, Yalukaato turns a naive sometimes indifferent obese boy from']\n",
      "07/06/2022 16:31:36 - INFO - __main__ -   Epoch: 93 | Batch: 1800/4417 (41%) | G Loss: 1.550932 | C Loss: -1.293089\n",
      "07/06/2022 16:31:36 - INFO - __main__ -   Text: ['Whilst in childhood Iím geared myself up to be denser and stronger but my weight has continually escalated towards its']\n",
      "07/06/2022 16:31:38 - INFO - __main__ -   Epoch: 93 | Batch: 2400/4417 (54%) | G Loss: 1.318861 | C Loss: -1.054369\n",
      "07/06/2022 16:31:38 - INFO - __main__ -   Text: ['It was recommended \"to use Ketomethroc next to\" 220ppm but after just a day,']\n",
      "07/06/2022 16:31:40 - INFO - __main__ -   Epoch: 93 | Batch: 3000/4417 (68%) | G Loss: 1.515198 | C Loss: -2.965948\n",
      "07/06/2022 16:31:40 - INFO - __main__ -   Text: ['Ranes visited the orthopedic surgery, and when they returned back to his hometown he stated slightly that every per']\n",
      "07/06/2022 16:31:42 - INFO - __main__ -   Epoch: 93 | Batch: 3600/4417 (82%) | G Loss: 1.159263 | C Loss: -0.624189\n",
      "07/06/2022 16:31:42 - INFO - __main__ -   Text: ['He also did this all the time, about 15 to 30 times an hour, a structurally funky hashed batch']\n",
      "07/06/2022 16:31:44 - INFO - __main__ -   Epoch: 93 | Batch: 4200/4417 (95%) | G Loss: 1.273178 | C Loss: -0.700344\n",
      "07/06/2022 16:31:45 - INFO - __main__ -   Text: ['Also, during her flight from here, she has suffered ligament cutter symptoms and symptoms of fibromyalgia after she']\n",
      "07/06/2022 16:31:45 - INFO - __main__ -   * (Train) Epoch: 93 | G Loss: 1.1443 | C Loss: -1.8435 | Updates G: 16 | Updates C: 352\n",
      "07/06/2022 16:32:00 - INFO - __main__ -   Bleu-2:0.478 | B-Bleu-2:0.299\n",
      "07/06/2022 16:32:00 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777739936212905\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 94 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:34:28 - INFO - __main__ -   Epoch: 94 | Batch: 0/4322 (0%) | G Loss: 1.227465 | C Loss: -2.751499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.561\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:34:28 - INFO - __main__ -   Text: ['She reported a nearly 100% accurate score in the last few days, which has allowed her to feel more confident,']\n",
      "07/06/2022 16:34:30 - INFO - __main__ -   Epoch: 94 | Batch: 600/4322 (14%) | G Loss: 0.958480 | C Loss: -0.819994\n",
      "07/06/2022 16:34:30 - INFO - __main__ -   Text: ['The result is that once the test is finished they will release a oxide relieving drink to give a little moisturization']\n",
      "07/06/2022 16:34:32 - INFO - __main__ -   Epoch: 94 | Batch: 1200/4322 (28%) | G Loss: 0.927485 | C Loss: -0.836113\n",
      "07/06/2022 16:34:32 - INFO - __main__ -   Text: [\"The video shows a 4 month procedure which involves burning flies and loves for her legs afterwards and doesn't really go as\"]\n",
      "07/06/2022 16:34:34 - INFO - __main__ -   Epoch: 94 | Batch: 1800/4322 (42%) | G Loss: 1.298201 | C Loss: -1.019232\n",
      "07/06/2022 16:34:34 - INFO - __main__ -   Text: ['everyone aware of this experience is dropping their fast food sandwich and your body (Abandoned on days']\n",
      "07/06/2022 16:34:36 - INFO - __main__ -   Epoch: 94 | Batch: 2400/4322 (56%) | G Loss: 1.303356 | C Loss: -1.496516\n",
      "07/06/2022 16:34:37 - INFO - __main__ -   Text: ['However, Shandiol also reported symptoms during training sessions that he/she never experienced before, and tested their stamina']\n",
      "07/06/2022 16:34:39 - INFO - __main__ -   Epoch: 94 | Batch: 3000/4322 (69%) | G Loss: 1.282368 | C Loss: -1.996712\n",
      "07/06/2022 16:34:39 - INFO - __main__ -   Text: ['In the lab, she has three different conditionals: Intense Depression, malaise, mental audit which ends']\n",
      "07/06/2022 16:34:41 - INFO - __main__ -   Epoch: 94 | Batch: 3600/4322 (83%) | G Loss: 1.091624 | C Loss: -0.932606\n",
      "07/06/2022 16:34:41 - INFO - __main__ -   Text: ['When awaiting treatment, Cancer \"printed\" just for stem cell disease, %=1. Button scores']\n",
      "07/06/2022 16:34:43 - INFO - __main__ -   Epoch: 94 | Batch: 4200/4322 (97%) | G Loss: 1.127848 | C Loss: -0.959362\n",
      "07/06/2022 16:34:43 - INFO - __main__ -   Text: ['Finally, Spagnola ended the treatment and became very busy and continually burnt to Cartoons 1:3 to start']\n",
      "07/06/2022 16:34:44 - INFO - __main__ -   * (Train) Epoch: 94 | G Loss: 1.0641 | C Loss: -1.8831 | Updates G: 19 | Updates C: 341\n",
      "07/06/2022 16:34:58 - INFO - __main__ -   Bleu-2:0.465 | B-Bleu-2:0.301\n",
      "07/06/2022 16:34:58 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7659728425390276\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 95 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:37:26 - INFO - __main__ -   Epoch: 95 | Batch: 0/4527 (0%) | G Loss: 1.269567 | C Loss: -1.024419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 5.530\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:37:26 - INFO - __main__ -   Text: ['Every single day for 4,600 days , the actress who does it is still waiting on her Yale UISS,']\n",
      "07/06/2022 16:37:28 - INFO - __main__ -   Epoch: 95 | Batch: 600/4527 (13%) | G Loss: 1.143659 | C Loss: -3.876817\n",
      "07/06/2022 16:37:28 - INFO - __main__ -   Text: ['Some users reported a high level of discomfort in fatigue, egotism, and good eating afterwards, then suggested']\n",
      "07/06/2022 16:37:30 - INFO - __main__ -   Epoch: 95 | Batch: 1200/4527 (27%) | G Loss: 1.408065 | C Loss: -0.914263\n",
      "07/06/2022 16:37:30 - INFO - __main__ -   Text: ['The case was reported in \"Hooksidemotional.com\" and was reported in a very clear way that']\n",
      "07/06/2022 16:37:33 - INFO - __main__ -   Epoch: 95 | Batch: 1800/4527 (40%) | G Loss: 0.952411 | C Loss: -1.080616\n",
      "07/06/2022 16:37:33 - INFO - __main__ -   Text: ['To this made my life completely expensive new, that was when Pegland drove my Camerarote and a few of']\n",
      "07/06/2022 16:37:35 - INFO - __main__ -   Epoch: 95 | Batch: 2400/4527 (53%) | G Loss: 1.602049 | C Loss: -1.719929\n",
      "07/06/2022 16:37:35 - INFO - __main__ -   Text: ['In a typical day, a woman would take one of four pills and three withdrawal pills, often during the morning hours']\n",
      "07/06/2022 16:37:37 - INFO - __main__ -   Epoch: 95 | Batch: 3000/4527 (66%) | G Loss: 1.307681 | C Loss: -3.118256\n",
      "07/06/2022 16:37:37 - INFO - __main__ -   Text: ['But this juice was not affected by high doses, more upside-down nutrients in the sedentary form was struggling,']\n",
      "07/06/2022 16:37:39 - INFO - __main__ -   Epoch: 95 | Batch: 3600/4527 (80%) | G Loss: 0.979281 | C Loss: -0.922737\n",
      "07/06/2022 16:37:39 - INFO - __main__ -   Text: ['Physical exertion is very important to him; his dry weight can not be harmed by any intense yoga exercises; it']\n",
      "07/06/2022 16:37:41 - INFO - __main__ -   Epoch: 95 | Batch: 4200/4527 (93%) | G Loss: 1.119746 | C Loss: -2.297038\n",
      "07/06/2022 16:37:41 - INFO - __main__ -   Text: ['For example, Kavelow benistropped himself about a week after the opening that measured 30 mg,']\n",
      "07/06/2022 16:37:42 - INFO - __main__ -   * (Train) Epoch: 95 | G Loss: 1.1119 | C Loss: -1.8572 | Updates G: 15 | Updates C: 362\n",
      "07/06/2022 16:37:56 - INFO - __main__ -   Bleu-2:0.497 | B-Bleu-2:0.329\n",
      "07/06/2022 16:37:56 - INFO - __main__ -   * Saving. Best Score:0.826 | Bleu-2:0.497 | B-Bleu-2:0.329\n",
      "07/06/2022 16:37:56 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8262751553769285\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 96 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:40:25 - INFO - __main__ -   Epoch: 96 | Batch: 0/4467 (0%) | G Loss: 1.300109 | C Loss: -0.498462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 5.545\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:40:25 - INFO - __main__ -   Text: ['At 27 weeks, and 6 months out of HIV/AIDS, Tyrex brand had an objective 50 Minutes of']\n",
      "07/06/2022 16:40:27 - INFO - __main__ -   Epoch: 96 | Batch: 600/4467 (13%) | G Loss: 0.971772 | C Loss: -1.116745\n",
      "07/06/2022 16:40:27 - INFO - __main__ -   Text: ['However, with Kennett this medicine only last a year, the only symptom is that he has a nasal obstruction and']\n",
      "07/06/2022 16:40:29 - INFO - __main__ -   Epoch: 96 | Batch: 1200/4467 (27%) | G Loss: 1.073300 | C Loss: -1.130847\n",
      "07/06/2022 16:40:29 - INFO - __main__ -   Text: ['Today, children are tested to make sure that they will be happy - they can contract dysactive bacteria (dies and']\n",
      "07/06/2022 16:40:31 - INFO - __main__ -   Epoch: 96 | Batch: 1800/4467 (40%) | G Loss: 1.122167 | C Loss: -0.826417\n",
      "07/06/2022 16:40:31 - INFO - __main__ -   Text: ['After breakfast going to sleep late, minus the loss of sleep due to gas, and physically using different drugs over three']\n",
      "07/06/2022 16:40:33 - INFO - __main__ -   Epoch: 96 | Batch: 2400/4467 (54%) | G Loss: 1.379399 | C Loss: -4.284322\n",
      "07/06/2022 16:40:34 - INFO - __main__ -   Text: [\"Tavish was transferred from the indoor laboratory to the display room by herself at 5 o'clock a.m.,\"]\n",
      "07/06/2022 16:40:35 - INFO - __main__ -   Epoch: 96 | Batch: 3000/4467 (67%) | G Loss: 1.346291 | C Loss: -0.921436\n",
      "07/06/2022 16:40:36 - INFO - __main__ -   Text: ['When tests have finished, Tesselli also experienced a mild but long-term exacerbation of her']\n",
      "07/06/2022 16:40:37 - INFO - __main__ -   Epoch: 96 | Batch: 3600/4467 (81%) | G Loss: 1.104592 | C Loss: -2.363521\n",
      "07/06/2022 16:40:38 - INFO - __main__ -   Text: ['Binder makes him sick with fluwhile and, at times, a nausea and vomiting is mild enough for me as']\n",
      "07/06/2022 16:40:40 - INFO - __main__ -   Epoch: 96 | Batch: 4200/4467 (94%) | G Loss: 1.068700 | C Loss: -1.289434\n",
      "07/06/2022 16:40:40 - INFO - __main__ -   Text: ['1 week after eating a chocolate bar for our first 20 minutes of rest, as well as playing with a struggling']\n",
      "07/06/2022 16:40:41 - INFO - __main__ -   * (Train) Epoch: 96 | G Loss: 1.0228 | C Loss: -1.8961 | Updates G: 19 | Updates C: 353\n",
      "07/06/2022 16:40:55 - INFO - __main__ -   Bleu-2:0.474 | B-Bleu-2:0.298\n",
      "07/06/2022 16:40:55 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7717798872491786\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 97 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:43:23 - INFO - __main__ -   Epoch: 97 | Batch: 0/4364 (0%) | G Loss: 0.946113 | C Loss: -0.981878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.619\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:43:23 - INFO - __main__ -   Text: ['Adapted to recent exercise and four weeks of pii, instead of blindly following a tired workout, Bowen has exceeded']\n",
      "07/06/2022 16:43:25 - INFO - __main__ -   Epoch: 97 | Batch: 600/4364 (14%) | G Loss: 1.036983 | C Loss: -1.204624\n",
      "07/06/2022 16:43:25 - INFO - __main__ -   Text: [\"Any kind of laptop isnt enough, as the very last option is very gentle Del; it's one way to\"]\n",
      "07/06/2022 16:43:27 - INFO - __main__ -   Epoch: 97 | Batch: 1200/4364 (27%) | G Loss: 1.018751 | C Loss: -2.912480\n",
      "07/06/2022 16:43:28 - INFO - __main__ -   Text: [\"Premium Seeds are now being stolen from, as well as which's the hardest part of this time but not with all\"]\n",
      "07/06/2022 16:43:30 - INFO - __main__ -   Epoch: 97 | Batch: 1800/4364 (41%) | G Loss: 1.148915 | C Loss: -1.219097\n",
      "07/06/2022 16:43:30 - INFO - __main__ -   Text: ['Greater resistance will lead to stricter partners so they rub out the worst of the 4th sense but Anastasia still']\n",
      "07/06/2022 16:43:32 - INFO - __main__ -   Epoch: 97 | Batch: 2400/4364 (55%) | G Loss: 1.332297 | C Loss: -1.141179\n",
      "07/06/2022 16:43:32 - INFO - __main__ -   Text: ['\"Because of that, we have had to make a multifaceted trekkha last changes : to take a']\n",
      "07/06/2022 16:43:34 - INFO - __main__ -   Epoch: 97 | Batch: 3000/4364 (69%) | G Loss: 0.993504 | C Loss: -1.135710\n",
      "07/06/2022 16:43:34 - INFO - __main__ -   Text: ['On nearly every occasion, I took ASAP, used the day-night medicine that could cause respiratory failure for a tumor']\n",
      "07/06/2022 16:43:36 - INFO - __main__ -   Epoch: 97 | Batch: 3600/4364 (82%) | G Loss: 1.041357 | C Loss: -1.136831\n",
      "07/06/2022 16:43:36 - INFO - __main__ -   Text: ['Of the total dose when scored, 91.3% battle disease, 63.7% fearful,']\n",
      "07/06/2022 16:43:38 - INFO - __main__ -   Epoch: 97 | Batch: 4200/4364 (96%) | G Loss: 1.370797 | C Loss: -1.485580\n",
      "07/06/2022 16:43:39 - INFO - __main__ -   Text: [\"If you take a lot of vitamin A 1 for 24 hours per week, the dryness won't hit or wave\"]\n",
      "07/06/2022 16:43:39 - INFO - __main__ -   * (Train) Epoch: 97 | G Loss: 0.9774 | C Loss: -1.8763 | Updates G: 31 | Updates C: 332\n",
      "07/06/2022 16:43:53 - INFO - __main__ -   Bleu-2:0.467 | B-Bleu-2:0.305\n",
      "07/06/2022 16:43:53 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7712648557612529\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 98 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:46:22 - INFO - __main__ -   Epoch: 98 | Batch: 0/4330 (0%) | G Loss: 1.464601 | C Loss: -2.238267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 5.754\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:46:22 - INFO - __main__ -   Text: ['He and Calio caused concern regarding slow motion and phase detection because of their frothy temperature, choleric low']\n",
      "07/06/2022 16:46:24 - INFO - __main__ -   Epoch: 98 | Batch: 600/4330 (14%) | G Loss: 1.553968 | C Loss: -4.423737\n",
      "07/06/2022 16:46:24 - INFO - __main__ -   Text: ['In addition to being on prescription medication, she has also been in a tenditis in the intensive care unit in']\n",
      "07/06/2022 16:46:26 - INFO - __main__ -   Epoch: 98 | Batch: 1200/4330 (28%) | G Loss: 0.968452 | C Loss: -2.094513\n",
      "07/06/2022 16:46:26 - INFO - __main__ -   Text: ['MostWhat, if not for fans who would subsequently refer to her as being full of shit or binge eating pills;']\n",
      "07/06/2022 16:46:28 - INFO - __main__ -   Epoch: 98 | Batch: 1800/4330 (42%) | G Loss: 0.693022 | C Loss: -4.918939\n",
      "07/06/2022 16:46:28 - INFO - __main__ -   Text: ['Asuna is essentially doing the same thing - she sells the drug for 30-40 minutes a day, in conjunction']\n",
      "07/06/2022 16:46:30 - INFO - __main__ -   Epoch: 98 | Batch: 2400/4330 (55%) | G Loss: 1.113942 | C Loss: -1.728687\n",
      "07/06/2022 16:46:30 - INFO - __main__ -   Text: ['According to Pawar, \"If I make sure that I continue to train my body at all in the mornings and']\n",
      "07/06/2022 16:46:32 - INFO - __main__ -   Epoch: 98 | Batch: 3000/4330 (69%) | G Loss: 2.290600 | C Loss: -5.896719\n",
      "07/06/2022 16:46:32 - INFO - __main__ -   Text: ['Since the consumers did not pay the drug, the drug gets lower body fat because of its aim of making fat without']\n",
      "07/06/2022 16:46:34 - INFO - __main__ -   Epoch: 98 | Batch: 3600/4330 (83%) | G Loss: 1.735935 | C Loss: -2.899319\n",
      "07/06/2022 16:46:35 - INFO - __main__ -   Text: ['It results in a double Rolls-Royce driving, and a six to six-week overnight coma which almost results']\n",
      "07/06/2022 16:46:37 - INFO - __main__ -   Epoch: 98 | Batch: 4200/4330 (97%) | G Loss: 1.157665 | C Loss: -0.815762\n",
      "07/06/2022 16:46:37 - INFO - __main__ -   Text: ['In the following days, it appears, sauna is very wet, says Van Dam, that he has stopped']\n",
      "07/06/2022 16:46:37 - INFO - __main__ -   * (Train) Epoch: 98 | G Loss: 1.0081 | C Loss: -1.9663 | Updates G: 23 | Updates C: 337\n",
      "07/06/2022 16:46:51 - INFO - __main__ -   Bleu-2:0.470 | B-Bleu-2:0.306\n",
      "07/06/2022 16:46:51 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7762821860474431\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 99 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.725\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:49:20 - INFO - __main__ -   Epoch: 99 | Batch: 0/4372 (0%) | G Loss: 0.777378 | C Loss: -2.292800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 6.075\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:49:20 - INFO - __main__ -   Text: ['During his workout, Bradwater met several problems, from being 19.9 ft tall to not losing']\n",
      "07/06/2022 16:49:22 - INFO - __main__ -   Epoch: 99 | Batch: 600/4372 (14%) | G Loss: 0.692509 | C Loss: -1.430447\n",
      "07/06/2022 16:49:22 - INFO - __main__ -   Text: ['When I get tired of watching TV in the morning I will change my starting position to the back back of the abdomen']\n",
      "07/06/2022 16:49:24 - INFO - __main__ -   Epoch: 99 | Batch: 1200/4372 (27%) | G Loss: 0.603899 | C Loss: -0.986120\n",
      "07/06/2022 16:49:24 - INFO - __main__ -   Text: [\"By the time I get to a match and previously I scored at 45,000 Bad Neville's ass pointed working so\"]\n",
      "07/06/2022 16:49:26 - INFO - __main__ -   Epoch: 99 | Batch: 1800/4372 (41%) | G Loss: 0.591566 | C Loss: -0.879600\n",
      "07/06/2022 16:49:27 - INFO - __main__ -   Text: ['That also resulted in breast reduction, acne, and sports problems which led to the initiation of withdrawal pills that led to']\n",
      "07/06/2022 16:49:29 - INFO - __main__ -   Epoch: 99 | Batch: 2400/4372 (55%) | G Loss: 1.025941 | C Loss: -0.774691\n",
      "07/06/2022 16:49:29 - INFO - __main__ -   Text: ['Standing 6ft 2in tall and weighing in at 5 stone 18 stone, the experience was from \"Easy']\n",
      "07/06/2022 16:49:31 - INFO - __main__ -   Epoch: 99 | Batch: 3000/4372 (69%) | G Loss: 0.602919 | C Loss: -1.006854\n",
      "07/06/2022 16:49:31 - INFO - __main__ -   Text: ['From an early age I realize that I am in a state where 200 watt classes fail me every day because I cannot']\n",
      "07/06/2022 16:49:33 - INFO - __main__ -   Epoch: 99 | Batch: 3600/4372 (82%) | G Loss: 0.893521 | C Loss: -0.867159\n",
      "07/06/2022 16:49:33 - INFO - __main__ -   Text: ['Finally, after several months, DB started rescuing other patients, he calls Mozimoto/RDH/Spindler']\n",
      "07/06/2022 16:49:35 - INFO - __main__ -   Epoch: 99 | Batch: 4200/4372 (96%) | G Loss: 0.899162 | C Loss: -1.973759\n",
      "07/06/2022 16:49:35 - INFO - __main__ -   Text: ['The drug simply continues to steal my mind–just listen to these words: \"I mentally suffer through a lot of']\n",
      "07/06/2022 16:49:36 - INFO - __main__ -   * (Train) Epoch: 99 | G Loss: 0.7663 | C Loss: -1.8725 | Updates G: 49 | Updates C: 315\n",
      "07/06/2022 16:49:49 - INFO - __main__ -   Bleu-2:0.484 | B-Bleu-2:0.305\n",
      "07/06/2022 16:49:49 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7892573045343675\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 100 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:52:18 - INFO - __main__ -   Epoch: 100 | Batch: 0/4473 (0%) | G Loss: 0.639185 | C Loss: -1.453171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.217\n",
      "  Test Loss: 5.203\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:52:18 - INFO - __main__ -   Text: ['There were no vacations and sometimes as many drinks as possible and most of the children mainly enjoyed drinking liquid sleepers of']\n",
      "07/06/2022 16:52:20 - INFO - __main__ -   Epoch: 100 | Batch: 600/4473 (13%) | G Loss: 0.721973 | C Loss: -1.750471\n",
      "07/06/2022 16:52:20 - INFO - __main__ -   Text: ['\"Life is certainly ongoing, but I had to confess that I and the male partner produced a semen sample before this']\n",
      "07/06/2022 16:52:22 - INFO - __main__ -   Epoch: 100 | Batch: 1200/4473 (27%) | G Loss: 2.660286 | C Loss: -3.050843\n",
      "07/06/2022 16:52:23 - INFO - __main__ -   Text: ['After the initial shock, I was medicated for research involved in the kidney stone followed by deletion of the small intestine']\n",
      "07/06/2022 16:52:25 - INFO - __main__ -   Epoch: 100 | Batch: 1800/4473 (40%) | G Loss: 4.158993 | C Loss: -2.194673\n",
      "07/06/2022 16:52:25 - INFO - __main__ -   Text: ['In March 2011, an injection of a ketogenic dieter diet and this injected into the sitting stomach happened spontaneously but']\n",
      "07/06/2022 16:52:27 - INFO - __main__ -   Epoch: 100 | Batch: 2400/4473 (54%) | G Loss: 1.559475 | C Loss: -0.375730\n",
      "07/06/2022 16:52:27 - INFO - __main__ -   Text: ['It did push resistance pulses which usually do not materialise; but once put inside their heavy trachea (a']\n",
      "07/06/2022 16:52:29 - INFO - __main__ -   Epoch: 100 | Batch: 3000/4473 (67%) | G Loss: -0.158857 | C Loss: -0.059975\n",
      "07/06/2022 16:52:29 - INFO - __main__ -   Text: ['The drug lasted more than 3 months, after which it appeared that she suffered additional pain due to headaches. To ease']\n",
      "07/06/2022 16:52:31 - INFO - __main__ -   Epoch: 100 | Batch: 3600/4473 (80%) | G Loss: 0.745925 | C Loss: -0.703408\n",
      "07/06/2022 16:52:32 - INFO - __main__ -   Text: ['Accompanying an action like \"swim and swims\" results in a loss of power, caution,']\n",
      "07/06/2022 16:52:33 - INFO - __main__ -   Epoch: 100 | Batch: 4200/4473 (94%) | G Loss: 0.734386 | C Loss: -0.762843\n",
      "07/06/2022 16:52:34 - INFO - __main__ -   Text: ['Prabhingu feels that it should have been raining regularly, getting to just 1 sometimes during the night, falling']\n",
      "07/06/2022 16:52:34 - INFO - __main__ -   * (Train) Epoch: 100 | G Loss: 0.6393 | C Loss: -2.0631 | Updates G: 79 | Updates C: 293\n",
      "07/06/2022 16:52:48 - INFO - __main__ -   Bleu-2:0.528 | B-Bleu-2:0.306\n",
      "07/06/2022 16:52:48 - INFO - __main__ -   * Saving. Best Score:0.834 | Bleu-2:0.528 | B-Bleu-2:0.306\n",
      "07/06/2022 16:52:48 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339448506490793\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 101 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:55:17 - INFO - __main__ -   Epoch: 101 | Batch: 0/4473 (0%) | G Loss: 5.397889 | C Loss: -3.111490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 5.335\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 16:55:17 - INFO - __main__ -   Text: ['In the next five days, Singh first met a plastic hygienic medication that had been approved by a medical']\n",
      "07/06/2022 16:55:19 - INFO - __main__ -   Epoch: 101 | Batch: 600/4473 (13%) | G Loss: 0.039239 | C Loss: -1.006344\n",
      "07/06/2022 16:55:19 - INFO - __main__ -   Text: ['There was a fear going to be another amount of cough, this time incorrectly launched in one of the TV shows at']\n",
      "07/06/2022 16:55:21 - INFO - __main__ -   Epoch: 101 | Batch: 1200/4473 (27%) | G Loss: 1.635014 | C Loss: -1.781474\n",
      "07/06/2022 16:55:21 - INFO - __main__ -   Text: ['Biopumping is fun, but worse is real behavior like kiss-pounding during finals, controllessness,']\n",
      "07/06/2022 16:55:23 - INFO - __main__ -   Epoch: 101 | Batch: 1800/4473 (40%) | G Loss: 1.795049 | C Loss: -2.818092\n",
      "07/06/2022 16:55:23 - INFO - __main__ -   Text: ['His urine absorbed the drugs, which he developed and passed it through a drip squirt test bacterial work']\n",
      "07/06/2022 16:55:25 - INFO - __main__ -   Epoch: 101 | Batch: 2400/4473 (54%) | G Loss: 0.772911 | C Loss: -1.832883\n",
      "07/06/2022 16:55:26 - INFO - __main__ -   Text: ['There is no other method to avoid the onset and collapse of Naga in some minors due to the risks of']\n",
      "07/06/2022 16:55:28 - INFO - __main__ -   Epoch: 101 | Batch: 3000/4473 (67%) | G Loss: -0.577505 | C Loss: -0.505914\n",
      "07/06/2022 16:55:28 - INFO - __main__ -   Text: ['For example, Kaafee burned over 1,000 calories a day which would not raise the waistline , 198']\n",
      "07/06/2022 16:55:30 - INFO - __main__ -   Epoch: 101 | Batch: 3600/4473 (80%) | G Loss: 2.638309 | C Loss: -1.828282\n",
      "07/06/2022 16:55:30 - INFO - __main__ -   Text: ['This is also the highlight of Bousta\\'s favorite day, \"slowburned\", because he gets compliments from']\n",
      "07/06/2022 16:55:32 - INFO - __main__ -   Epoch: 101 | Batch: 4200/4473 (94%) | G Loss: 2.724848 | C Loss: -1.550485\n",
      "07/06/2022 16:55:32 - INFO - __main__ -   Text: ['The annoying alphabet changes are... Some of their most common jokes include... A wishing meiner (one that is very']\n",
      "07/06/2022 16:55:33 - INFO - __main__ -   * (Train) Epoch: 101 | G Loss: 0.9868 | C Loss: -1.7360 | Updates G: 90 | Updates C: 282\n",
      "07/06/2022 16:55:47 - INFO - __main__ -   Bleu-2:0.483 | B-Bleu-2:0.305\n",
      "07/06/2022 16:55:47 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7875677452031515\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 102 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:01:14 - INFO - __main__ -   Epoch: 103 | Batch: 0/4417 (0%) | G Loss: 1.404464 | C Loss: -0.717634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 4.930\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:01:14 - INFO - __main__ -   Text: ['Although the error has not yet been confirmed (as it was reported on Youtube) though, with check of a tiny']\n",
      "07/06/2022 17:01:16 - INFO - __main__ -   Epoch: 103 | Batch: 600/4417 (14%) | G Loss: -1.135335 | C Loss: -0.897870\n",
      "07/06/2022 17:01:16 - INFO - __main__ -   Text: ['In an amount of time, this Fiorazione has become a uncontrollable sensation!\"']\n",
      "07/06/2022 17:01:18 - INFO - __main__ -   Epoch: 103 | Batch: 1200/4417 (27%) | G Loss: -0.782207 | C Loss: -0.527834\n",
      "07/06/2022 17:01:19 - INFO - __main__ -   Text: ['On 27 September 2010, Duffy - on his Facebook page - stated that on the morning of 26 May, \"I']\n",
      "07/06/2022 17:01:21 - INFO - __main__ -   Epoch: 103 | Batch: 1800/4417 (41%) | G Loss: 4.555531 | C Loss: -0.242207\n",
      "07/06/2022 17:01:21 - INFO - __main__ -   Text: ['For too long, it has been used only to increase equilibrium with bleeding candy.']\n",
      "07/06/2022 17:01:23 - INFO - __main__ -   Epoch: 103 | Batch: 2400/4417 (54%) | G Loss: -0.161558 | C Loss: -0.084217\n",
      "07/06/2022 17:01:23 - INFO - __main__ -   Text: [\"Usually hy to wait. Host increases musician's album researchHe has been on 23 reviews a month, while privately 8\"]\n",
      "07/06/2022 17:01:25 - INFO - __main__ -   Epoch: 103 | Batch: 3000/4417 (68%) | G Loss: 2.582711 | C Loss: -2.504857\n",
      "07/06/2022 17:01:25 - INFO - __main__ -   Text: ['In later years, one of us, Matt Gliere, has trouble with his peripheral vision - with Sam being']\n",
      "07/06/2022 17:01:27 - INFO - __main__ -   Epoch: 103 | Batch: 3600/4417 (82%) | G Loss: 1.067956 | C Loss: -0.287916\n",
      "07/06/2022 17:01:27 - INFO - __main__ -   Text: ['The heaundle had his life changed for the 36 month journey from Pachňi to']\n",
      "07/06/2022 17:01:29 - INFO - __main__ -   Epoch: 103 | Batch: 4200/4417 (95%) | G Loss: 0.483733 | C Loss: 0.145160\n",
      "07/06/2022 17:01:29 - INFO - __main__ -   Text: ['A shooter, ite not known - but if you take only QB soap 250 g in this first month, it']\n",
      "07/06/2022 17:01:30 - INFO - __main__ -   * (Train) Epoch: 103 | G Loss: 0.6620 | C Loss: -1.1726 | Updates G: 99 | Updates C: 269\n",
      "07/06/2022 17:01:44 - INFO - __main__ -   Bleu-2:0.462 | B-Bleu-2:0.300\n",
      "07/06/2022 17:01:44 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620058016249713\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 104 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:04:12 - INFO - __main__ -   Epoch: 104 | Batch: 0/4322 (0%) | G Loss: 2.211508 | C Loss: -0.976345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 4.910\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:04:13 - INFO - __main__ -   Text: ['If some length out, my lowpoints and my absences need attention, when I feel like bending my hips,']\n",
      "07/06/2022 17:04:15 - INFO - __main__ -   Epoch: 104 | Batch: 600/4322 (14%) | G Loss: 4.671649 | C Loss: -2.220293\n",
      "07/06/2022 17:04:15 - INFO - __main__ -   Text: ['After a while earlier he and his wife Saima, who worked as a carer in their car, found']\n",
      "07/06/2022 17:04:17 - INFO - __main__ -   Epoch: 104 | Batch: 1200/4322 (28%) | G Loss: 1.424623 | C Loss: -0.899338\n",
      "07/06/2022 17:04:17 - INFO - __main__ -   Text: ['At the market, Yivish was \"fasting on 30% less juice than normal\" and was beneficially']\n",
      "07/06/2022 17:04:19 - INFO - __main__ -   Epoch: 104 | Batch: 1800/4322 (42%) | G Loss: 3.435852 | C Loss: -0.688699\n",
      "07/06/2022 17:04:19 - INFO - __main__ -   Text: ['On weekly one or two nights a week, eat slow, bright, slow intermittent their saliva is in during prolonged intermittent']\n",
      "07/06/2022 17:04:21 - INFO - __main__ -   Epoch: 104 | Batch: 2400/4322 (56%) | G Loss: 1.018523 | C Loss: -1.000428\n",
      "07/06/2022 17:04:21 - INFO - __main__ -   Text: ['were erroneously cited by The Times as being the worst album list ever released.']\n",
      "07/06/2022 17:04:23 - INFO - __main__ -   Epoch: 104 | Batch: 3000/4322 (69%) | G Loss: -0.279629 | C Loss: 0.449651\n",
      "07/06/2022 17:04:24 - INFO - __main__ -   Text: ['Initially, she developed chronic prostatic hypotemia in the early stage, though eventually, she regained full hydration and']\n",
      "07/06/2022 17:04:25 - INFO - __main__ -   Epoch: 104 | Batch: 3600/4322 (83%) | G Loss: 2.862976 | C Loss: -1.979065\n",
      "07/06/2022 17:04:26 - INFO - __main__ -   Text: ['In May 2010, after damaging her plasma vitamin and replacing it with soft vitamin pills, she was weak since an']\n",
      "07/06/2022 17:04:28 - INFO - __main__ -   Epoch: 104 | Batch: 4200/4322 (97%) | G Loss: -0.868215 | C Loss: 0.165757\n",
      "07/06/2022 17:04:28 - INFO - __main__ -   Text: [\"Prior to these girls, I've had problems with these other girls.\"]\n",
      "07/06/2022 17:04:28 - INFO - __main__ -   * (Train) Epoch: 104 | G Loss: 0.7440 | C Loss: -1.1874 | Updates G: 99 | Updates C: 261\n",
      "07/06/2022 17:04:42 - INFO - __main__ -   Bleu-2:0.433 | B-Bleu-2:0.315\n",
      "07/06/2022 17:04:42 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748127412204374\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 105 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:07:10 - INFO - __main__ -   Epoch: 105 | Batch: 0/4527 (0%) | G Loss: 0.026457 | C Loss: -0.819970\n",
      "07/06/2022 17:07:11 - INFO - __main__ -   Text: ['Also, it has a raging raging blood churning beast!']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 4.917\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:07:13 - INFO - __main__ -   Epoch: 105 | Batch: 600/4527 (13%) | G Loss: 2.363021 | C Loss: -1.478136\n",
      "07/06/2022 17:07:13 - INFO - __main__ -   Text: ['In terms of sleep, ALP does not awaken at all, even though it has already experienced an intense alertness']\n",
      "07/06/2022 17:07:15 - INFO - __main__ -   Epoch: 105 | Batch: 1200/4527 (27%) | G Loss: -1.411736 | C Loss: -0.787420\n",
      "07/06/2022 17:07:15 - INFO - __main__ -   Text: ['During this time, she also successfully trained at Speed G he hoped to increase Volume over Source because , before, she']\n",
      "07/06/2022 17:07:17 - INFO - __main__ -   Epoch: 105 | Batch: 1800/4527 (40%) | G Loss: 4.676892 | C Loss: -1.708856\n",
      "07/06/2022 17:07:17 - INFO - __main__ -   Text: [\"The startup is now taking off and hopes that perage Vicky Guru's almond powder in particular, + shutting down\"]\n",
      "07/06/2022 17:07:19 - INFO - __main__ -   Epoch: 105 | Batch: 2400/4527 (53%) | G Loss: 5.897207 | C Loss: -2.287910\n",
      "07/06/2022 17:07:19 - INFO - __main__ -   Text: ['Perry started performing with a lot higher frequency than she ever demonstrated before and the late blood tests showed that last week since']\n",
      "07/06/2022 17:07:21 - INFO - __main__ -   Epoch: 105 | Batch: 3000/4527 (66%) | G Loss: -1.237611 | C Loss: -1.010115\n",
      "07/06/2022 17:07:21 - INFO - __main__ -   Text: ['If a person on a date presents with one painless breath that lasts for once, \"LEAR of IN and']\n",
      "07/06/2022 17:07:23 - INFO - __main__ -   Epoch: 105 | Batch: 3600/4527 (80%) | G Loss: 1.558632 | C Loss: -0.935654\n",
      "07/06/2022 17:07:23 - INFO - __main__ -   Text: ['In addition, he can be extremely effective with folic acid subserveters that oil.']\n",
      "07/06/2022 17:07:25 - INFO - __main__ -   Epoch: 105 | Batch: 4200/4527 (93%) | G Loss: 3.328882 | C Loss: -0.786960\n",
      "07/06/2022 17:07:25 - INFO - __main__ -   Text: ['On the day of being diagnosed, Lillybeck has obtained a high by meds,medexed for a month']\n",
      "07/06/2022 17:07:27 - INFO - __main__ -   * (Train) Epoch: 105 | G Loss: 0.7999 | C Loss: -1.2178 | Updates G: 73 | Updates C: 304\n",
      "07/06/2022 17:07:40 - INFO - __main__ -   Bleu-2:0.475 | B-Bleu-2:0.316\n",
      "07/06/2022 17:07:40 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7905875155662292\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 106 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:10:09 - INFO - __main__ -   Epoch: 106 | Batch: 0/4467 (0%) | G Loss: 0.683547 | C Loss: -0.801950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 4.877\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:10:09 - INFO - __main__ -   Text: ['The day after eight years of life absence, I seen videos of Bilas and Pathenga and there he feels']\n",
      "07/06/2022 17:10:11 - INFO - __main__ -   Epoch: 106 | Batch: 600/4467 (13%) | G Loss: 3.054572 | C Loss: -0.924414\n",
      "07/06/2022 17:10:11 - INFO - __main__ -   Text: ['However, she failed to sing longening, and instead had to try to attack Satan with a parody song about chocolate']\n",
      "07/06/2022 17:10:13 - INFO - __main__ -   Epoch: 106 | Batch: 1200/4467 (27%) | G Loss: 0.069849 | C Loss: 0.115136\n",
      "07/06/2022 17:10:13 - INFO - __main__ -   Text: [\"Campnik recounted after reading it that he was 8 months old and can't work for fun - experiencing a two hour\"]\n",
      "07/06/2022 17:10:16 - INFO - __main__ -   Epoch: 106 | Batch: 1800/4467 (40%) | G Loss: 1.606532 | C Loss: -1.120536\n",
      "07/06/2022 17:10:16 - INFO - __main__ -   Text: ['Along with this,take a look at Joanna\\'s blog and life episodes\"ClinksI do not intend to']\n",
      "07/06/2022 17:10:18 - INFO - __main__ -   Epoch: 106 | Batch: 2400/4467 (54%) | G Loss: 0.840401 | C Loss: -0.720907\n",
      "07/06/2022 17:10:18 - INFO - __main__ -   Text: ['Advocates for \"retrospective youth\" talking about how the experience is more arduous than it is']\n",
      "07/06/2022 17:10:20 - INFO - __main__ -   Epoch: 106 | Batch: 3000/4467 (67%) | G Loss: 0.570588 | C Loss: -0.763516\n",
      "07/06/2022 17:10:20 - INFO - __main__ -   Text: ['Amy thought that when she got to know how to get that theme song, she had teacher syndrome - almost impossible to']\n",
      "07/06/2022 17:10:22 - INFO - __main__ -   Epoch: 106 | Batch: 3600/4467 (81%) | G Loss: 0.979057 | C Loss: -1.577570\n",
      "07/06/2022 17:10:22 - INFO - __main__ -   Text: ['There he says, \"I\\'m fine with a gallon of water.\"']\n",
      "07/06/2022 17:10:24 - INFO - __main__ -   Epoch: 106 | Batch: 4200/4467 (94%) | G Loss: -0.286399 | C Loss: -0.328180\n",
      "07/06/2022 17:10:24 - INFO - __main__ -   Text: ['De Havilland took care of the problem for only a month with him, one week post surgical, the first']\n",
      "07/06/2022 17:10:25 - INFO - __main__ -   * (Train) Epoch: 106 | G Loss: 0.5423 | C Loss: -0.9839 | Updates G: 100 | Updates C: 272\n",
      "07/06/2022 17:10:38 - INFO - __main__ -   Bleu-2:0.488 | B-Bleu-2:0.284\n",
      "07/06/2022 17:10:38 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7715338694858191\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 107 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:13:07 - INFO - __main__ -   Epoch: 107 | Batch: 0/4364 (0%) | G Loss: 2.924193 | C Loss: -0.584781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 4.789\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:13:07 - INFO - __main__ -   Text: ['It is advised to seek medical advice if using forceps retrovirally (for 12 weeks), because this liver enzyme']\n",
      "07/06/2022 17:13:09 - INFO - __main__ -   Epoch: 107 | Batch: 600/4364 (14%) | G Loss: -0.339928 | C Loss: 0.206859\n",
      "07/06/2022 17:13:09 - INFO - __main__ -   Text: ['He settled for a mart; instead of keeping his beloved Spzn iSloppyiature sound vibration level,']\n",
      "07/06/2022 17:13:11 - INFO - __main__ -   Epoch: 107 | Batch: 1200/4364 (27%) | G Loss: 10.172001 | C Loss: -7.416770\n",
      "07/06/2022 17:13:11 - INFO - __main__ -   Text: ['& \"42ibL : Jos Lud : Oaks : Live :']\n",
      "07/06/2022 17:13:14 - INFO - __main__ -   Epoch: 107 | Batch: 1800/4364 (41%) | G Loss: -2.225645 | C Loss: -1.054950\n",
      "07/06/2022 17:13:14 - INFO - __main__ -   Text: [\"Meteor giveth, but above all Cyclops and Fox say–they're performing uncritically.\"]\n",
      "07/06/2022 17:13:16 - INFO - __main__ -   Epoch: 107 | Batch: 2400/4364 (55%) | G Loss: 2.848183 | C Loss: 1.738450\n",
      "07/06/2022 17:13:16 - INFO - __main__ -   Text: ['In search for this, he is suffering from prolonged suffering for 7 to seven days, and constantly when he woke,']\n",
      "07/06/2022 17:13:18 - INFO - __main__ -   Epoch: 107 | Batch: 3000/4364 (69%) | G Loss: 3.324813 | C Loss: -2.324281\n",
      "07/06/2022 17:13:18 - INFO - __main__ -   Text: ['He has developed acupuncturists 3-7 yr prior and he consulted training experts']\n",
      "07/06/2022 17:13:20 - INFO - __main__ -   Epoch: 107 | Batch: 3600/4364 (82%) | G Loss: -2.804350 | C Loss: -0.819339\n",
      "07/06/2022 17:13:20 - INFO - __main__ -   Text: [\"O'Keefe completed approximately 6 full courses (including data from a cellular phone) to prove her cleararers superior to\"]\n",
      "07/06/2022 17:13:22 - INFO - __main__ -   Epoch: 107 | Batch: 4200/4364 (96%) | G Loss: -0.539044 | C Loss: -0.479304\n",
      "07/06/2022 17:13:22 - INFO - __main__ -   Text: ['Ten years later, I find out that Minced is still getting along, and is performed remarkably well.']\n",
      "07/06/2022 17:13:23 - INFO - __main__ -   * (Train) Epoch: 107 | G Loss: 0.8564 | C Loss: -1.6533 | Updates G: 131 | Updates C: 232\n",
      "07/06/2022 17:13:37 - INFO - __main__ -   Bleu-2:0.471 | B-Bleu-2:0.320\n",
      "07/06/2022 17:13:37 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7904786531008761\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 108 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:16:05 - INFO - __main__ -   Epoch: 108 | Batch: 0/4330 (0%) | G Loss: -0.443330 | C Loss: 0.629512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.217\n",
      "  Test Loss: 4.898\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:16:05 - INFO - __main__ -   Text: ['In July 2015, Veritaserum added another 4TB SSD and 32TB SSD, which improves both with 32']\n",
      "07/06/2022 17:16:07 - INFO - __main__ -   Epoch: 108 | Batch: 600/4330 (14%) | G Loss: -0.615777 | C Loss: 5.671199\n",
      "07/06/2022 17:16:07 - INFO - __main__ -   Text: ['14а 22 6 ! )']\n",
      "07/06/2022 17:16:09 - INFO - __main__ -   Epoch: 108 | Batch: 1200/4330 (28%) | G Loss: 6.291049 | C Loss: -6.147269\n",
      "07/06/2022 17:16:09 - INFO - __main__ -   Text: ['each minute of this .']\n",
      "07/06/2022 17:16:11 - INFO - __main__ -   Epoch: 108 | Batch: 1800/4330 (42%) | G Loss: -2.191755 | C Loss: -1.263727\n",
      "07/06/2022 17:16:11 - INFO - __main__ -   Text: ['He reported an overall preference of 500 Days Not Hardly Getting Around, -06 Amalgamated Rage { Must']\n",
      "07/06/2022 17:16:13 - INFO - __main__ -   Epoch: 108 | Batch: 2400/4330 (55%) | G Loss: 3.996478 | C Loss: -0.703339\n",
      "07/06/2022 17:16:13 - INFO - __main__ -   Text: ['This improves muscle strength considerably while still maintaining healthy bottle size, and can be taken up quickly to glycamp,']\n",
      "07/06/2022 17:16:15 - INFO - __main__ -   Epoch: 108 | Batch: 3000/4330 (69%) | G Loss: 5.365664 | C Loss: -1.223503\n",
      "07/06/2022 17:16:15 - INFO - __main__ -   Text: ['Incorrect numbers are made again, and when his comeback begins, Doctor Fariva accepts the sheet warranty .']\n",
      "07/06/2022 17:16:17 - INFO - __main__ -   Epoch: 108 | Batch: 3600/4330 (83%) | G Loss: 1.022617 | C Loss: -0.815617\n",
      "07/06/2022 17:16:17 - INFO - __main__ -   Text: ['During his first bout of iRT, he is constantly told that he is no longer with him because he will fall']\n",
      "07/06/2022 17:16:19 - INFO - __main__ -   Epoch: 108 | Batch: 4200/4330 (97%) | G Loss: -2.755309 | C Loss: -0.395775\n",
      "07/06/2022 17:16:20 - INFO - __main__ -   Text: ['Throughout her pregnancy, she was frequently down eating fast food, during which she could not conceive a single baby, no']\n",
      "07/06/2022 17:16:20 - INFO - __main__ -   * (Train) Epoch: 108 | G Loss: 1.7463 | C Loss: -2.2377 | Updates G: 125 | Updates C: 235\n",
      "07/06/2022 17:16:34 - INFO - __main__ -   Bleu-2:0.463 | B-Bleu-2:0.323\n",
      "07/06/2022 17:16:34 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7859906087832603\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 109 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:19:02 - INFO - __main__ -   Epoch: 109 | Batch: 0/4372 (0%) | G Loss: -2.502747 | C Loss: -0.413504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 4.923\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:19:03 - INFO - __main__ -   Text: ['In terms of navelshen, the day I cued “tuhid“ for thirteen hours']\n",
      "07/06/2022 17:19:05 - INFO - __main__ -   Epoch: 109 | Batch: 600/4372 (14%) | G Loss: 3.928296 | C Loss: -0.633299\n",
      "07/06/2022 17:19:05 - INFO - __main__ -   Text: ['Dr. Kalyan says: \"Even when at night, I assume that I am, after sleep board,']\n",
      "07/06/2022 17:19:07 - INFO - __main__ -   Epoch: 109 | Batch: 1200/4372 (27%) | G Loss: 1.488214 | C Loss: -1.020641\n",
      "07/06/2022 17:19:07 - INFO - __main__ -   Text: ['Here is an extract from Listener Review; Joel has stated that \"I do care about the berries and mushrooms but']\n",
      "07/06/2022 17:19:09 - INFO - __main__ -   Epoch: 109 | Batch: 1800/4372 (41%) | G Loss: -0.772812 | C Loss: -1.115121\n",
      "07/06/2022 17:19:09 - INFO - __main__ -   Text: ['More than 300 Single reason wheels are cheap | 443 Ask More: 3 takeaways to add value for money After reading']\n",
      "07/06/2022 17:19:11 - INFO - __main__ -   Epoch: 109 | Batch: 2400/4372 (55%) | G Loss: 3.453415 | C Loss: -0.477166\n",
      "07/06/2022 17:19:11 - INFO - __main__ -   Text: ['He changes diapers once and then mis-feeds his feedlot.']\n",
      "07/06/2022 17:19:13 - INFO - __main__ -   Epoch: 109 | Batch: 3000/4372 (69%) | G Loss: 2.494306 | C Loss: -1.259340\n",
      "07/06/2022 17:19:13 - INFO - __main__ -   Text: ['Scholar says it is 30\".']\n",
      "07/06/2022 17:19:15 - INFO - __main__ -   Epoch: 109 | Batch: 3600/4372 (82%) | G Loss: -2.081040 | C Loss: -0.111201\n",
      "07/06/2022 17:19:16 - INFO - __main__ -   Text: ['Sedatives are usually pill extracted from an injection point of eight to 10mg/kg with one opportunity provided only a']\n",
      "07/06/2022 17:19:17 - INFO - __main__ -   Epoch: 109 | Batch: 4200/4372 (96%) | G Loss: 1.145147 | C Loss: 0.254719\n",
      "07/06/2022 17:19:18 - INFO - __main__ -   Text: ['Don CM B prangayuri has a name that stays with me: you get the feeling that you should have']\n",
      "07/06/2022 17:19:18 - INFO - __main__ -   * (Train) Epoch: 109 | G Loss: 0.5205 | C Loss: -0.7335 | Updates G: 71 | Updates C: 293\n",
      "07/06/2022 17:19:32 - INFO - __main__ -   Bleu-2:0.418 | B-Bleu-2:0.300\n",
      "07/06/2022 17:19:32 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7182313041218717\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 110 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:22:00 - INFO - __main__ -   Epoch: 110 | Batch: 0/4473 (0%) | G Loss: 3.168126 | C Loss: -0.180001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 5.150\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:22:01 - INFO - __main__ -   Text: [\"The internet's short story average has him officinative during Around the waist ( Day to date No I'm sorry\"]\n",
      "07/06/2022 17:22:02 - INFO - __main__ -   Epoch: 110 | Batch: 600/4473 (13%) | G Loss: 2.288086 | C Loss: -0.990008\n",
      "07/06/2022 17:22:03 - INFO - __main__ -   Text: [\"My rabbi advises us to make sure that your teeth don't act like liquid and canids will handle them best.\"]\n",
      "07/06/2022 17:22:05 - INFO - __main__ -   Epoch: 110 | Batch: 1200/4473 (27%) | G Loss: -0.547115 | C Loss: -0.075856\n",
      "07/06/2022 17:22:05 - INFO - __main__ -   Text: ['A sleep leak on his thermometer started an epidemic that could break him.']\n",
      "07/06/2022 17:22:07 - INFO - __main__ -   Epoch: 110 | Batch: 1800/4473 (40%) | G Loss: 2.559076 | C Loss: -0.632339\n",
      "07/06/2022 17:22:07 - INFO - __main__ -   Text: ['Yesterday around this time (after we get the actual Wi-ote light), after hanging for 10 to 12 hours and']\n",
      "07/06/2022 17:22:09 - INFO - __main__ -   Epoch: 110 | Batch: 2400/4473 (54%) | G Loss: -0.130462 | C Loss: -0.463226\n",
      "07/06/2022 17:22:10 - INFO - __main__ -   Text: ['As he got older, he split off the penis at 5min notice and loaded adrenalin from his libidinal']\n",
      "07/06/2022 17:22:11 - INFO - __main__ -   Epoch: 110 | Batch: 3000/4473 (67%) | G Loss: 2.457437 | C Loss: -0.431556\n",
      "07/06/2022 17:22:12 - INFO - __main__ -   Text: [\"In addition, copies released by Redmen's complain that Hela is not milked or anything like it often in\"]\n",
      "07/06/2022 17:22:14 - INFO - __main__ -   Epoch: 110 | Batch: 3600/4473 (80%) | G Loss: 0.986098 | C Loss: -0.732044\n",
      "07/06/2022 17:22:14 - INFO - __main__ -   Text: ['China Today is also the number one novel this year).']\n",
      "07/06/2022 17:22:15 - INFO - __main__ -   Epoch: 110 | Batch: 4200/4473 (94%) | G Loss: 0.213296 | C Loss: -0.708708\n",
      "07/06/2022 17:22:16 - INFO - __main__ -   Text: ['On the Internet, users with White Hair Insider mice have reported regular chewing heart beats, but there are no complaints yet']\n",
      "07/06/2022 17:22:17 - INFO - __main__ -   * (Train) Epoch: 110 | G Loss: 0.6435 | C Loss: -0.7243 | Updates G: 76 | Updates C: 296\n",
      "07/06/2022 17:22:30 - INFO - __main__ -   Bleu-2:0.454 | B-Bleu-2:0.312\n",
      "07/06/2022 17:22:30 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7651374520702717\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 111 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:24:59 - INFO - __main__ -   Epoch: 111 | Batch: 0/4473 (0%) | G Loss: 4.939792 | C Loss: -1.107155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 4.849\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:24:59 - INFO - __main__ -   Text: ['The male immersed himself in water for a day and later, after that, he experienced loud vibration and stayed ringside']\n",
      "07/06/2022 17:25:01 - INFO - __main__ -   Epoch: 111 | Batch: 600/4473 (13%) | G Loss: 2.878056 | C Loss: -1.214631\n",
      "07/06/2022 17:25:01 - INFO - __main__ -   Text: [\"Although Nows has a featured friend, Lumiara Hitti 's 5 yela, a\"]\n",
      "07/06/2022 17:25:03 - INFO - __main__ -   Epoch: 111 | Batch: 1200/4473 (27%) | G Loss: 0.312319 | C Loss: -0.592071\n",
      "07/06/2022 17:25:03 - INFO - __main__ -   Text: ['After meditating next night, his parents ask me if I have fried 8 to 10 new innings and then after fast']\n",
      "07/06/2022 17:25:05 - INFO - __main__ -   Epoch: 111 | Batch: 1800/4473 (40%) | G Loss: 4.029667 | C Loss: -1.171467\n",
      "07/06/2022 17:25:06 - INFO - __main__ -   Text: ['Humidity kicks in when bread and cheese do not require refrigeration, even if they are still much below 80 degrees']\n",
      "07/06/2022 17:25:08 - INFO - __main__ -   Epoch: 111 | Batch: 2400/4473 (54%) | G Loss: 2.674615 | C Loss: -0.997001\n",
      "07/06/2022 17:25:08 - INFO - __main__ -   Text: ['The next morning with aplenty, he slept for two hours without incident, waking up with nausea, feeling']\n",
      "07/06/2022 17:25:10 - INFO - __main__ -   Epoch: 111 | Batch: 3000/4473 (67%) | G Loss: 0.095362 | C Loss: -0.278393\n",
      "07/06/2022 17:25:10 - INFO - __main__ -   Text: [\"Late 2000s vinyl is ridiculously expensive so I've taken a slightly cheaper version.\"]\n",
      "07/06/2022 17:25:12 - INFO - __main__ -   Epoch: 111 | Batch: 3600/4473 (80%) | G Loss: 1.292273 | C Loss: -0.689789\n",
      "07/06/2022 17:25:12 - INFO - __main__ -   Text: ['Additionally, inhibitors are also chemically linked to shrinkage in munchies but they have not been suitable for treatment of']\n",
      "07/06/2022 17:25:14 - INFO - __main__ -   Epoch: 111 | Batch: 4200/4473 (94%) | G Loss: 3.336566 | C Loss: -1.019462\n",
      "07/06/2022 17:25:14 - INFO - __main__ -   Text: ['He sneezes sometimes.\"']\n",
      "07/06/2022 17:25:15 - INFO - __main__ -   * (Train) Epoch: 111 | G Loss: 1.1462 | C Loss: -0.9152 | Updates G: 68 | Updates C: 304\n",
      "07/06/2022 17:25:29 - INFO - __main__ -   Bleu-2:0.457 | B-Bleu-2:0.306\n",
      "07/06/2022 17:25:29 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7628612660616916\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 112 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:27:57 - INFO - __main__ -   Epoch: 112 | Batch: 0/4327 (0%) | G Loss: 2.070501 | C Loss: -0.604103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 4.904\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:27:57 - INFO - __main__ -   Text: ['Bursarhabh Kalyan told us that the illness occurred during early 2009 when she drank up 50 litres']\n",
      "07/06/2022 17:27:59 - INFO - __main__ -   Epoch: 112 | Batch: 600/4327 (14%) | G Loss: 1.445148 | C Loss: -0.683922\n",
      "07/06/2022 17:28:00 - INFO - __main__ -   Text: ['When asleep for a while he sticks on his laptop and excuesaline himself with 100MB a week which adds to']\n",
      "07/06/2022 17:28:02 - INFO - __main__ -   Epoch: 112 | Batch: 1200/4327 (28%) | G Loss: 0.237902 | C Loss: -0.548223\n",
      "07/06/2022 17:28:02 - INFO - __main__ -   Text: ['According to his summation, his HT is rolling eleven (11) minutes in less than nine seconds, and without']\n",
      "07/06/2022 17:28:04 - INFO - __main__ -   Epoch: 112 | Batch: 1800/4327 (42%) | G Loss: 2.741181 | C Loss: -1.550744\n",
      "07/06/2022 17:28:04 - INFO - __main__ -   Text: ['At 2.30 it is easy and easy \"Shewimonulai\" from 5 to 7:50']\n",
      "07/06/2022 17:28:06 - INFO - __main__ -   Epoch: 112 | Batch: 2400/4327 (55%) | G Loss: 1.686612 | C Loss: -1.071177\n",
      "07/06/2022 17:28:06 - INFO - __main__ -   Text: ['These reactions caused I look hurt and drained, and Hadley was slipped into hypnosis.']\n",
      "07/06/2022 17:28:08 - INFO - __main__ -   Epoch: 112 | Batch: 3000/4327 (69%) | G Loss: 3.520756 | C Loss: -1.215669\n",
      "07/06/2022 17:28:08 - INFO - __main__ -   Text: ['Instead of one hour of DIS, a minute is made available when the user in BET soothes (orapy CR']\n",
      "07/06/2022 17:28:10 - INFO - __main__ -   Epoch: 112 | Batch: 3600/4327 (83%) | G Loss: 1.931041 | C Loss: -0.706701\n",
      "07/06/2022 17:28:10 - INFO - __main__ -   Text: ['At one stage following the first six hours (the first 24 hours before the onset of her ulcer, which was']\n",
      "07/06/2022 17:28:13 - INFO - __main__ -   Epoch: 112 | Batch: 4200/4327 (97%) | G Loss: 0.625380 | C Loss: -1.202933\n",
      "07/06/2022 17:28:13 - INFO - __main__ -   Text: ['Then in January 2016 – Aha, he was on 11/09 but because of a very upset back']\n",
      "07/06/2022 17:28:13 - INFO - __main__ -   * (Train) Epoch: 112 | G Loss: 0.9580 | C Loss: -0.9747 | Updates G: 55 | Updates C: 305\n",
      "07/06/2022 17:28:27 - INFO - __main__ -   Bleu-2:0.443 | B-Bleu-2:0.305\n",
      "07/06/2022 17:28:27 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748076994911133\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 113 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:30:56 - INFO - __main__ -   Epoch: 113 | Batch: 0/4417 (0%) | G Loss: 0.648900 | C Loss: -0.517438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.217\n",
      "  Test Loss: 5.060\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:30:56 - INFO - __main__ -   Text: ['His physical and mental health problems started to deteriorate after she asked him to exercise, medication and medication, to rapid']\n",
      "07/06/2022 17:30:58 - INFO - __main__ -   Epoch: 113 | Batch: 600/4417 (14%) | G Loss: 0.893671 | C Loss: -0.598889\n",
      "07/06/2022 17:30:58 - INFO - __main__ -   Text: ['The adverse effects of beating nootropics were noted but Kelley is told the therapy works, and that it is beneficial']\n",
      "07/06/2022 17:31:00 - INFO - __main__ -   Epoch: 113 | Batch: 1200/4417 (27%) | G Loss: 2.208801 | C Loss: -1.042359\n",
      "07/06/2022 17:31:00 - INFO - __main__ -   Text: ['He tells Havinin there was only 6 weeks 0 days early and the younger one already has to keep saying']\n",
      "07/06/2022 17:31:02 - INFO - __main__ -   Epoch: 113 | Batch: 1800/4417 (41%) | G Loss: 0.211021 | C Loss: -0.695740\n",
      "07/06/2022 17:31:02 - INFO - __main__ -   Text: ['Sydiaters are more likely to lose their appetite shortly after an injection or when their sexual appetite is increased by']\n",
      "07/06/2022 17:31:04 - INFO - __main__ -   Epoch: 113 | Batch: 2400/4417 (54%) | G Loss: 2.257427 | C Loss: -0.814709\n",
      "07/06/2022 17:31:04 - INFO - __main__ -   Text: ['The jda hit him a lot but he went on to record 2000 nice tunes last week when he could not be']\n",
      "07/06/2022 17:31:07 - INFO - __main__ -   Epoch: 113 | Batch: 3000/4417 (68%) | G Loss: 0.555533 | C Loss: -0.512351\n",
      "07/06/2022 17:31:07 - INFO - __main__ -   Text: ['A big bangers and even though Amarheela grew up and declared the moths four times soon not till it']\n",
      "07/06/2022 17:31:09 - INFO - __main__ -   Epoch: 113 | Batch: 3600/4417 (82%) | G Loss: 1.938122 | C Loss: -0.844169\n",
      "07/06/2022 17:31:09 - INFO - __main__ -   Text: ['For those of you that are a fan enough (between 03:07 and 05:00 PM), based on how']\n",
      "07/06/2022 17:31:11 - INFO - __main__ -   Epoch: 113 | Batch: 4200/4417 (95%) | G Loss: 1.034345 | C Loss: -0.207435\n",
      "07/06/2022 17:31:11 - INFO - __main__ -   Text: ['Others compare it to the Eurodex-powered fashion magazine \"Food Reason\".']\n",
      "07/06/2022 17:31:12 - INFO - __main__ -   * (Train) Epoch: 113 | G Loss: 0.7922 | C Loss: -0.7965 | Updates G: 91 | Updates C: 277\n",
      "07/06/2022 17:31:26 - INFO - __main__ -   Bleu-2:0.448 | B-Bleu-2:0.317\n",
      "07/06/2022 17:31:26 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647637159788054\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 114 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:33:54 - INFO - __main__ -   Epoch: 114 | Batch: 0/4322 (0%) | G Loss: 0.958150 | C Loss: -0.432307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.047\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:33:54 - INFO - __main__ -   Text: ['The brown spots in her abdomen were also causing her to contract a protein stalker or lymphoma, and thereby simultaneously']\n",
      "07/06/2022 17:33:56 - INFO - __main__ -   Epoch: 114 | Batch: 600/4322 (14%) | G Loss: 1.693983 | C Loss: -0.646440\n",
      "07/06/2022 17:33:57 - INFO - __main__ -   Text: ['For your MRSA range BQTest results, please post on Our Productivity Update page to compare the startling']\n",
      "07/06/2022 17:33:59 - INFO - __main__ -   Epoch: 114 | Batch: 1200/4322 (28%) | G Loss: 0.027683 | C Loss: -0.413314\n",
      "07/06/2022 17:33:59 - INFO - __main__ -   Text: ['All ...']\n",
      "07/06/2022 17:34:00 - INFO - __main__ -   Epoch: 114 | Batch: 1800/4322 (42%) | G Loss: 5.323101 | C Loss: -1.100291\n",
      "07/06/2022 17:34:01 - INFO - __main__ -   Text: ['But we got her weight back to normal, and it started hitting five and seven in the morning – she was']\n",
      "07/06/2022 17:34:02 - INFO - __main__ -   Epoch: 114 | Batch: 2400/4322 (56%) | G Loss: 4.062274 | C Loss: -2.903896\n",
      "07/06/2022 17:34:03 - INFO - __main__ -   Text: [\"For the last two months of 2005, 'Mar' (now 44) has decided to quit 510 IK so\"]\n",
      "07/06/2022 17:34:05 - INFO - __main__ -   Epoch: 114 | Batch: 3000/4322 (69%) | G Loss: 4.113323 | C Loss: -1.423371\n",
      "07/06/2022 17:34:05 - INFO - __main__ -   Text: ['On Friday, 4 July 2009 there was a mass walk which lasted 3. hours without any random symptom, which']\n",
      "07/06/2022 17:34:07 - INFO - __main__ -   Epoch: 114 | Batch: 3600/4322 (83%) | G Loss: 0.723777 | C Loss: -0.557577\n",
      "07/06/2022 17:34:07 - INFO - __main__ -   Text: ['This is because, during his first five months as a female UNS also dosages 50mg of Oxy- 2']\n",
      "07/06/2022 17:34:09 - INFO - __main__ -   Epoch: 114 | Batch: 4200/4322 (97%) | G Loss: -0.054844 | C Loss: -0.214370\n",
      "07/06/2022 17:34:09 - INFO - __main__ -   Text: ['Under optimal cellular maintenance, the expensive menopausal-derived drug, Blawaysex, blocks the sleep-management']\n",
      "07/06/2022 17:34:10 - INFO - __main__ -   * (Train) Epoch: 114 | G Loss: 0.6559 | C Loss: -1.0270 | Updates G: 57 | Updates C: 303\n",
      "07/06/2022 17:34:23 - INFO - __main__ -   Bleu-2:0.448 | B-Bleu-2:0.299\n",
      "07/06/2022 17:34:23 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7468385448883887\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 115 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:36:52 - INFO - __main__ -   Epoch: 115 | Batch: 0/4527 (0%) | G Loss: -0.252074 | C Loss: 0.541305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.200\n",
      "  Test Loss: 4.865\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:36:52 - INFO - __main__ -   Text: ['Ten years later, Waseda, last year trained the guru with one Waffapa crystal and used it and']\n",
      "07/06/2022 17:36:54 - INFO - __main__ -   Epoch: 115 | Batch: 600/4527 (13%) | G Loss: 4.644509 | C Loss: -2.165345\n",
      "07/06/2022 17:36:54 - INFO - __main__ -   Text: ['The product is effective in treating its secondary auto radiator problem because it does not lose its oral contraceptive after 1 month and']\n",
      "07/06/2022 17:36:56 - INFO - __main__ -   Epoch: 115 | Batch: 1200/4527 (27%) | G Loss: 1.971248 | C Loss: -0.974549\n",
      "07/06/2022 17:36:56 - INFO - __main__ -   Text: ['In addition to daily calcine, vomited must at least some of the time, whereas now his caloric use']\n",
      "07/06/2022 17:36:58 - INFO - __main__ -   Epoch: 115 | Batch: 1800/4527 (40%) | G Loss: -0.601150 | C Loss: -0.405917\n",
      "07/06/2022 17:36:59 - INFO - __main__ -   Text: ['In the office I was trying to open the tummy, but then I got up and when I tried to open']\n",
      "07/06/2022 17:37:00 - INFO - __main__ -   Epoch: 115 | Batch: 2400/4527 (53%) | G Loss: 3.615782 | C Loss: -3.461479\n",
      "07/06/2022 17:37:01 - INFO - __main__ -   Text: ['However, following a few tweaks (much hatehurt of my exoing CD without tha playin music)\" he']\n",
      "07/06/2022 17:37:02 - INFO - __main__ -   Epoch: 115 | Batch: 3000/4527 (66%) | G Loss: 2.094347 | C Loss: -1.013772\n",
      "07/06/2022 17:37:03 - INFO - __main__ -   Text: ['To this point in the sequel, Buyshail Kakarafi notes that: Employer likely wanted many more']\n",
      "07/06/2022 17:37:05 - INFO - __main__ -   Epoch: 115 | Batch: 3600/4527 (80%) | G Loss: 2.009606 | C Loss: -0.362114\n",
      "07/06/2022 17:37:05 - INFO - __main__ -   Text: ['Sex Nature shit.']\n",
      "07/06/2022 17:37:07 - INFO - __main__ -   Epoch: 115 | Batch: 4200/4527 (93%) | G Loss: -0.863187 | C Loss: -0.675974\n",
      "07/06/2022 17:37:07 - INFO - __main__ -   Text: ['Also, as a condition, controlling any type of sore throat pain can cause the inflammation of hemorrhoids, throwing and']\n",
      "07/06/2022 17:37:08 - INFO - __main__ -   * (Train) Epoch: 115 | G Loss: 0.9205 | C Loss: -1.0979 | Updates G: 55 | Updates C: 322\n",
      "07/06/2022 17:37:22 - INFO - __main__ -   Bleu-2:0.473 | B-Bleu-2:0.325\n",
      "07/06/2022 17:37:22 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7979620237251166\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 116 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:39:50 - INFO - __main__ -   Epoch: 116 | Batch: 0/4467 (0%) | G Loss: -0.803040 | C Loss: -0.419431\n",
      "07/06/2022 17:39:50 - INFO - __main__ -   Text: ['It is constant.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.163\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:39:52 - INFO - __main__ -   Epoch: 116 | Batch: 600/4467 (13%) | G Loss: 4.134369 | C Loss: -1.133468\n",
      "07/06/2022 17:39:52 - INFO - __main__ -   Text: ['While playing on one foot from the moment at the beginning of 6pm, she was not able to forcefully touch']\n",
      "07/06/2022 17:39:54 - INFO - __main__ -   Epoch: 116 | Batch: 1200/4467 (27%) | G Loss: 1.858498 | C Loss: -0.809867\n",
      "07/06/2022 17:39:54 - INFO - __main__ -   Text: ['All drugs bleed and cure slightly better than you.\"']\n",
      "07/06/2022 17:39:56 - INFO - __main__ -   Epoch: 116 | Batch: 1800/4467 (40%) | G Loss: -0.044554 | C Loss: -0.390083\n",
      "07/06/2022 17:39:56 - INFO - __main__ -   Text: ['As well, output... feeding is totally to affected at this time.']\n",
      "07/06/2022 17:39:58 - INFO - __main__ -   Epoch: 116 | Batch: 2400/4467 (54%) | G Loss: 3.809753 | C Loss: -0.996552\n",
      "07/06/2022 17:39:58 - INFO - __main__ -   Text: ['The problem is grown out enough that critics claim Karadia has been prescribed DXR regularly for years, and the problem']\n",
      "07/06/2022 17:40:01 - INFO - __main__ -   Epoch: 116 | Batch: 3000/4467 (67%) | G Loss: 1.085837 | C Loss: -1.051089\n",
      "07/06/2022 17:40:01 - INFO - __main__ -   Text: ['Using this method he basically loops over all the inputs and extracts Rs till turnaround data from previous one and dips everyone else']\n",
      "07/06/2022 17:40:03 - INFO - __main__ -   Epoch: 116 | Batch: 3600/4467 (81%) | G Loss: 1.420701 | C Loss: 1.800103\n",
      "07/06/2022 17:40:03 - INFO - __main__ -   Text: ['Until: Adrenocortical Anestatic Ultrasound:Object monitoring nurse restores direct, nocore oil']\n",
      "07/06/2022 17:40:05 - INFO - __main__ -   Epoch: 116 | Batch: 4200/4467 (94%) | G Loss: 1.039241 | C Loss: -2.132342\n",
      "07/06/2022 17:40:05 - INFO - __main__ -   Text: ['\"Pasillo\\'s innovative magic.\"']\n",
      "07/06/2022 17:40:06 - INFO - __main__ -   * (Train) Epoch: 116 | G Loss: 1.0350 | C Loss: -0.9750 | Updates G: 125 | Updates C: 247\n",
      "07/06/2022 17:40:19 - INFO - __main__ -   Bleu-2:0.442 | B-Bleu-2:0.313\n",
      "07/06/2022 17:40:19 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7556584148199519\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 117 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:42:48 - INFO - __main__ -   Epoch: 117 | Batch: 0/4364 (0%) | G Loss: -0.310916 | C Loss: -0.495358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.177\n",
      "  Test Loss: 4.946\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:42:48 - INFO - __main__ -   Text: ['In the stated results 1:ingoha 2: ad3a e4, 2:um']\n",
      "07/06/2022 17:42:50 - INFO - __main__ -   Epoch: 117 | Batch: 600/4364 (14%) | G Loss: 4.442644 | C Loss: -1.287256\n",
      "07/06/2022 17:42:50 - INFO - __main__ -   Text: ['This fuel appears to be linked to the overall respiratory distress experienced in ketosis, which if not cured soon will cause']\n",
      "07/06/2022 17:42:52 - INFO - __main__ -   Epoch: 117 | Batch: 1200/4364 (27%) | G Loss: 3.744576 | C Loss: -1.002960\n",
      "07/06/2022 17:42:52 - INFO - __main__ -   Text: ['Allowed 5 days of Pro flights in 7 days!']\n",
      "07/06/2022 17:42:54 - INFO - __main__ -   Epoch: 117 | Batch: 1800/4364 (41%) | G Loss: 1.050777 | C Loss: -0.890016\n",
      "07/06/2022 17:42:55 - INFO - __main__ -   Text: ['Outlining number of hypodermic needles (dorsal acceleration) is unacceptable and big inflation is']\n",
      "07/06/2022 17:42:56 - INFO - __main__ -   Epoch: 117 | Batch: 2400/4364 (55%) | G Loss: -1.273210 | C Loss: -0.912961\n",
      "07/06/2022 17:42:57 - INFO - __main__ -   Text: ['In 2011, Blamey comes after saying he returned to his bunk bed, having felt unresponsive from sleep long']\n",
      "07/06/2022 17:42:59 - INFO - __main__ -   Epoch: 117 | Batch: 3000/4364 (69%) | G Loss: 5.698924 | C Loss: -0.725389\n",
      "07/06/2022 17:42:59 - INFO - __main__ -   Text: ['This indicates that many women who seek breast cancer screening are using a anti-cancer solution to prevent them from fully progressing']\n",
      "07/06/2022 17:43:01 - INFO - __main__ -   Epoch: 117 | Batch: 3600/4364 (82%) | G Loss: 4.681879 | C Loss: -0.995809\n",
      "07/06/2022 17:43:01 - INFO - __main__ -   Text: ['On API 2, less than half a day after the end of the pregnancy, Sri started to get bulky and was']\n",
      "07/06/2022 17:43:03 - INFO - __main__ -   Epoch: 117 | Batch: 4200/4364 (96%) | G Loss: 0.246502 | C Loss: -0.382098\n",
      "07/06/2022 17:43:03 - INFO - __main__ -   Text: ['Some competitive legumes may still be recommended as leg vegan for some others (eg.']\n",
      "07/06/2022 17:43:04 - INFO - __main__ -   * (Train) Epoch: 117 | G Loss: 0.9736 | C Loss: -0.8434 | Updates G: 52 | Updates C: 311\n",
      "07/06/2022 17:43:18 - INFO - __main__ -   Bleu-2:0.448 | B-Bleu-2:0.320\n",
      "07/06/2022 17:43:18 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7685642759208593\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 118 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.719\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:45:46 - INFO - __main__ -   Epoch: 118 | Batch: 0/4330 (0%) | G Loss: -0.522349 | C Loss: -0.110957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 5.500\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:45:47 - INFO - __main__ -   Text: ['In 2016 when tested for the duration of regular exposure to potassium, the dosage returned to around 100 mg/day,']\n",
      "07/06/2022 17:45:49 - INFO - __main__ -   Epoch: 118 | Batch: 600/4330 (14%) | G Loss: 2.077300 | C Loss: -0.868304\n",
      "07/06/2022 17:45:49 - INFO - __main__ -   Text: [\"Senpai too often swears you don't eat undiluted food for forty minutes performing a lot of\"]\n",
      "07/06/2022 17:45:51 - INFO - __main__ -   Epoch: 118 | Batch: 1200/4330 (28%) | G Loss: 0.200981 | C Loss: -0.597135\n",
      "07/06/2022 17:45:51 - INFO - __main__ -   Text: ['Less than five minutes after taking the supplement, Colophon tested 180 with the 80mg ammonia, and found 100mg']\n",
      "07/06/2022 17:45:53 - INFO - __main__ -   Epoch: 118 | Batch: 1800/4330 (42%) | G Loss: 1.430164 | C Loss: -0.860199\n",
      "07/06/2022 17:45:53 - INFO - __main__ -   Text: ['Over the next six months of 10–15 course courses of five Call to Action will span the headlines.']\n",
      "07/06/2022 17:45:55 - INFO - __main__ -   Epoch: 118 | Batch: 2400/4330 (55%) | G Loss: 2.252926 | C Loss: -1.042958\n",
      "07/06/2022 17:45:55 - INFO - __main__ -   Text: ['While surfing he tried to speak too much trying to read, he read 96 pages of the poem with the commentary']\n",
      "07/06/2022 17:45:57 - INFO - __main__ -   Epoch: 118 | Batch: 3000/4330 (69%) | G Loss: 1.188600 | C Loss: -0.919830\n",
      "07/06/2022 17:45:57 - INFO - __main__ -   Text: ['There has been insufficient sleep to permit one person to carry on a full-time job, and a number of illnesses']\n",
      "07/06/2022 17:45:59 - INFO - __main__ -   Epoch: 118 | Batch: 3600/4330 (83%) | G Loss: 0.889498 | C Loss: -0.236144\n",
      "07/06/2022 17:45:59 - INFO - __main__ -   Text: ['Many food service providers treated her with dairy allergy as any similar milk attacks no longer pose an illness and all major meals']\n",
      "07/06/2022 17:46:01 - INFO - __main__ -   Epoch: 118 | Batch: 4200/4330 (97%) | G Loss: 4.780231 | C Loss: -1.683207\n",
      "07/06/2022 17:46:02 - INFO - __main__ -   Text: ['B.Viss enablees to arrange commprets through an app, known as \"MSS']\n",
      "07/06/2022 17:46:02 - INFO - __main__ -   * (Train) Epoch: 118 | G Loss: 0.9106 | C Loss: -0.8032 | Updates G: 66 | Updates C: 294\n",
      "07/06/2022 17:46:16 - INFO - __main__ -   Bleu-2:0.473 | B-Bleu-2:0.318\n",
      "07/06/2022 17:46:16 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790497710080382\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 119 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:48:44 - INFO - __main__ -   Epoch: 119 | Batch: 0/4372 (0%) | G Loss: 4.537091 | C Loss: -0.770757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 5.023\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:48:44 - INFO - __main__ -   Text: ['\"for one or two hours after entering into a diaphragm and subsequent trauma at work,\" she told']\n",
      "07/06/2022 17:48:46 - INFO - __main__ -   Epoch: 119 | Batch: 600/4372 (14%) | G Loss: -0.024651 | C Loss: -0.404156\n",
      "07/06/2022 17:48:46 - INFO - __main__ -   Text: ['As she mentioned the reasons behind doing this is that she has adequate oxygen and lights and electricity and does not wear thick']\n",
      "07/06/2022 17:48:48 - INFO - __main__ -   Epoch: 119 | Batch: 1200/4372 (27%) | G Loss: 0.645772 | C Loss: -0.517654\n",
      "07/06/2022 17:48:49 - INFO - __main__ -   Text: ['The stress levels are blurry, and the day is long staying, she wakes after 8 hours without draining, and,']\n",
      "07/06/2022 17:48:51 - INFO - __main__ -   Epoch: 119 | Batch: 1800/4372 (41%) | G Loss: 2.130877 | C Loss: 0.361824\n",
      "07/06/2022 17:48:51 - INFO - __main__ -   Text: ['Kagura posts explicit picture of viral security behind dedicated men who barely find any pee, seems to say that it is']\n",
      "07/06/2022 17:48:53 - INFO - __main__ -   Epoch: 119 | Batch: 2400/4372 (55%) | G Loss: 1.693965 | C Loss: -1.890064\n",
      "07/06/2022 17:48:53 - INFO - __main__ -   Text: ['By opening and tabling every word in the teaser, Allie has raised trillions of dollars.']\n",
      "07/06/2022 17:48:55 - INFO - __main__ -   Epoch: 119 | Batch: 3000/4372 (69%) | G Loss: 0.981221 | C Loss: -0.006135\n",
      "07/06/2022 17:48:55 - INFO - __main__ -   Text: ['It can be used multiple times on menu by wearing active priesthood power allowing for the total amount of water left on the']\n",
      "07/06/2022 17:48:57 - INFO - __main__ -   Epoch: 119 | Batch: 3600/4372 (82%) | G Loss: 1.192217 | C Loss: -0.362989\n",
      "07/06/2022 17:48:57 - INFO - __main__ -   Text: ['According to her it is still playing at the average of 6%.']\n",
      "07/06/2022 17:48:59 - INFO - __main__ -   Epoch: 119 | Batch: 4200/4372 (96%) | G Loss: 3.907322 | C Loss: -1.663950\n",
      "07/06/2022 17:48:59 - INFO - __main__ -   Text: ['The model number may not surpass 99925, on its day though it has achieved ZUM per year, which is']\n",
      "07/06/2022 17:49:00 - INFO - __main__ -   * (Train) Epoch: 119 | G Loss: 0.8819 | C Loss: -0.7980 | Updates G: 62 | Updates C: 302\n",
      "07/06/2022 17:49:14 - INFO - __main__ -   Bleu-2:0.472 | B-Bleu-2:0.341\n",
      "07/06/2022 17:49:14 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8130710709363993\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 120 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:51:42 - INFO - __main__ -   Epoch: 120 | Batch: 0/4473 (0%) | G Loss: 3.422549 | C Loss: -2.441793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.215\n",
      "  Test Loss: 4.937\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:51:42 - INFO - __main__ -   Text: ['is sweetened with caffeine and used for oral administration at doses greater than norethisterone while promoting panic']\n",
      "07/06/2022 17:51:44 - INFO - __main__ -   Epoch: 120 | Batch: 600/4473 (13%) | G Loss: 0.942502 | C Loss: 0.057083\n",
      "07/06/2022 17:51:44 - INFO - __main__ -   Text: [\"Stephens is also only a 'blogger' club, which reflects the popularity of it.\"]\n",
      "07/06/2022 17:51:46 - INFO - __main__ -   Epoch: 120 | Batch: 1200/4473 (27%) | G Loss: 0.408374 | C Loss: -1.668718\n",
      "07/06/2022 17:51:47 - INFO - __main__ -   Text: ['Heaven gave him so many reasons for \"warm\" while he was under no distress; it throws off his']\n",
      "07/06/2022 17:51:49 - INFO - __main__ -   Epoch: 120 | Batch: 1800/4473 (40%) | G Loss: 3.987951 | C Loss: -1.309218\n",
      "07/06/2022 17:51:49 - INFO - __main__ -   Text: ['When I started playing for DMI I thought that having read all their songs earlier and writing them down on a daily']\n",
      "07/06/2022 17:51:51 - INFO - __main__ -   Epoch: 120 | Batch: 2400/4473 (54%) | G Loss: 2.854223 | C Loss: -0.811382\n",
      "07/06/2022 17:51:51 - INFO - __main__ -   Text: ['It has an option: instant cure combo without cost test for the entire cast properly delaying it during any task']\n",
      "07/06/2022 17:51:53 - INFO - __main__ -   Epoch: 120 | Batch: 3000/4473 (67%) | G Loss: 0.061847 | C Loss: -0.261515\n",
      "07/06/2022 17:51:53 - INFO - __main__ -   Text: ['Though I write and read all that I really closed my eyes when I saw them, I felt alone as I minded']\n",
      "07/06/2022 17:51:55 - INFO - __main__ -   Epoch: 120 | Batch: 3600/4473 (80%) | G Loss: 2.927659 | C Loss: -1.120775\n",
      "07/06/2022 17:51:56 - INFO - __main__ -   Text: ['Has since returned to (−4-3=ol) with acinute, plus four joint edema and an']\n",
      "07/06/2022 17:51:58 - INFO - __main__ -   Epoch: 120 | Batch: 4200/4473 (94%) | G Loss: 1.664404 | C Loss: -0.980711\n",
      "07/06/2022 17:51:58 - INFO - __main__ -   Text: ['Space jacketing and conditioning is an occasional pattern on the computer, and increasingly technology has given the young']\n",
      "07/06/2022 17:51:59 - INFO - __main__ -   * (Train) Epoch: 120 | G Loss: 1.1162 | C Loss: -0.8028 | Updates G: 62 | Updates C: 310\n",
      "07/06/2022 17:52:13 - INFO - __main__ -   Bleu-2:0.441 | B-Bleu-2:0.307\n",
      "07/06/2022 17:52:13 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7480804051152734\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 121 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:54:41 - INFO - __main__ -   Epoch: 121 | Batch: 0/4473 (0%) | G Loss: -0.442475 | C Loss: -0.400136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.225\n",
      "  Test Loss: 5.131\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:54:41 - INFO - __main__ -   Text: ['Santorubhaiya was successfully retained alongside its predecessor, Kometime 1991, Sujjawata, during the']\n",
      "07/06/2022 17:54:43 - INFO - __main__ -   Epoch: 121 | Batch: 600/4473 (13%) | G Loss: 3.151448 | C Loss: -0.642917\n",
      "07/06/2022 17:54:44 - INFO - __main__ -   Text: ['In diabetic mice, the dose of caffeine three days a week was doubled if caffeine is absorbed in food, coffee or']\n",
      "07/06/2022 17:54:45 - INFO - __main__ -   Epoch: 121 | Batch: 1200/4473 (27%) | G Loss: 2.279504 | C Loss: -0.820750\n",
      "07/06/2022 17:54:46 - INFO - __main__ -   Text: ['A year later, the same day as Yekiyal starts hormone therapy her first week after she starts hormone treatment']\n",
      "07/06/2022 17:54:48 - INFO - __main__ -   Epoch: 121 | Batch: 1800/4473 (40%) | G Loss: 0.182372 | C Loss: -1.368399\n",
      "07/06/2022 17:54:48 - INFO - __main__ -   Text: ['Performances are hassles of crafting, washing [the dough] to correct, and making it']\n",
      "07/06/2022 17:54:50 - INFO - __main__ -   Epoch: 121 | Batch: 2400/4473 (54%) | G Loss: -0.209194 | C Loss: -0.432983\n",
      "07/06/2022 17:54:50 - INFO - __main__ -   Text: ['During typing jobs those whoato compile a certain amount of data, actual work time, from their own time to the']\n",
      "07/06/2022 17:54:52 - INFO - __main__ -   Epoch: 121 | Batch: 3000/4473 (67%) | G Loss: 2.805186 | C Loss: 0.215406\n",
      "07/06/2022 17:54:52 - INFO - __main__ -   Text: ['Nursing care and brain surgery is still very rare among patients with paranoid schizophrenics.']\n",
      "07/06/2022 17:54:54 - INFO - __main__ -   Epoch: 121 | Batch: 3600/4473 (80%) | G Loss: 1.318795 | C Loss: -0.583157\n",
      "07/06/2022 17:54:55 - INFO - __main__ -   Text: ['Sankar also told that the tongue needs to stay in the mouth to give him water smoothly unlike many inflammation pills']\n",
      "07/06/2022 17:54:57 - INFO - __main__ -   Epoch: 121 | Batch: 4200/4473 (94%) | G Loss: 0.691250 | C Loss: -1.133344\n",
      "07/06/2022 17:54:57 - INFO - __main__ -   Text: ['He was prescribed 2010 Truvada sulabetamo (TUV50, US40, SR101,']\n",
      "07/06/2022 17:54:58 - INFO - __main__ -   * (Train) Epoch: 121 | G Loss: 1.1022 | C Loss: -0.7643 | Updates G: 61 | Updates C: 311\n",
      "07/06/2022 17:55:12 - INFO - __main__ -   Bleu-2:0.437 | B-Bleu-2:0.327\n",
      "07/06/2022 17:55:12 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763095872764169\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 122 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:57:40 - INFO - __main__ -   Epoch: 122 | Batch: 0/4327 (0%) | G Loss: 0.929355 | C Loss: -0.022412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 4.999\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 17:57:40 - INFO - __main__ -   Text: ['The second takes a strip of airfare; it glides to life without restrictions like coldness and winds\", writes']\n",
      "07/06/2022 17:57:42 - INFO - __main__ -   Epoch: 122 | Batch: 600/4327 (14%) | G Loss: 1.685810 | C Loss: -1.329176\n",
      "07/06/2022 17:57:42 - INFO - __main__ -   Text: ['The medication is given out monthly and daily for a total of two weeks (without taking estrogen), prior to the']\n",
      "07/06/2022 17:57:44 - INFO - __main__ -   Epoch: 122 | Batch: 1200/4327 (28%) | G Loss: 1.718868 | C Loss: -0.930221\n",
      "07/06/2022 17:57:45 - INFO - __main__ -   Text: ['He is now in eighth position and is still very much alive despite his last few appearances of illness.']\n",
      "07/06/2022 17:57:47 - INFO - __main__ -   Epoch: 122 | Batch: 1800/4327 (42%) | G Loss: 0.834416 | C Loss: -0.277825\n",
      "07/06/2022 17:57:47 - INFO - __main__ -   Text: ['But Tom mentioned that the results showed asthma in the last two weeks, during a clinic visit (19 hours) of']\n",
      "07/06/2022 17:57:49 - INFO - __main__ -   Epoch: 122 | Batch: 2400/4327 (55%) | G Loss: 2.019580 | C Loss: -0.382351\n",
      "07/06/2022 17:57:49 - INFO - __main__ -   Text: [\"Cook's message to me: What number shall it be?\"]\n",
      "07/06/2022 17:57:51 - INFO - __main__ -   Epoch: 122 | Batch: 3000/4327 (69%) | G Loss: 1.675980 | C Loss: -0.030437\n",
      "07/06/2022 17:57:51 - INFO - __main__ -   Text: ['But, do you realise he creates or produces any supplements for newborn baby?']\n",
      "07/06/2022 17:57:53 - INFO - __main__ -   Epoch: 122 | Batch: 3600/4327 (83%) | G Loss: 1.785083 | C Loss: -0.483333\n",
      "07/06/2022 17:57:53 - INFO - __main__ -   Text: ['It results in EEG agitation range from 6-10 minutes per day, which is about 10% of the peak']\n",
      "07/06/2022 17:57:55 - INFO - __main__ -   Epoch: 122 | Batch: 4200/4327 (97%) | G Loss: 0.288117 | C Loss: -0.584204\n",
      "07/06/2022 17:57:56 - INFO - __main__ -   Text: [\"Hack does not drop, is not sparse, and the last shows up at 90 seconds - it's 25\"]\n",
      "07/06/2022 17:57:56 - INFO - __main__ -   * (Train) Epoch: 122 | G Loss: 1.1874 | C Loss: -0.6612 | Updates G: 37 | Updates C: 323\n",
      "07/06/2022 17:58:10 - INFO - __main__ -   Bleu-2:0.452 | B-Bleu-2:0.303\n",
      "07/06/2022 17:58:10 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7555231205045866\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 123 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:00:38 - INFO - __main__ -   Epoch: 123 | Batch: 0/4417 (0%) | G Loss: 0.844611 | C Loss: -0.655713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 4.876\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:00:38 - INFO - __main__ -   Text: ['This is currently known as hypoindentonia or hypoinataxyloindent knew actuated']\n",
      "07/06/2022 18:00:40 - INFO - __main__ -   Epoch: 123 | Batch: 600/4417 (14%) | G Loss: 2.780959 | C Loss: -0.647176\n",
      "07/06/2022 18:00:41 - INFO - __main__ -   Text: ['As of February 2013, it has been listed as causing condir Hermine Maximus in the cell nucleus and reduced']\n",
      "07/06/2022 18:00:43 - INFO - __main__ -   Epoch: 123 | Batch: 1200/4417 (27%) | G Loss: 0.826720 | C Loss: -0.508379\n",
      "07/06/2022 18:00:43 - INFO - __main__ -   Text: ['The day after her mastectomy she had an injection of Sodium 2, glycerol showing, and almost immediately after']\n",
      "07/06/2022 18:00:45 - INFO - __main__ -   Epoch: 123 | Batch: 1800/4417 (41%) | G Loss: 1.634251 | C Loss: -0.619723\n",
      "07/06/2022 18:00:45 - INFO - __main__ -   Text: ['It can be done, at least on top of Meal.com but it can also was, he notes in his']\n",
      "07/06/2022 18:00:47 - INFO - __main__ -   Epoch: 123 | Batch: 2400/4417 (54%) | G Loss: 1.391078 | C Loss: -1.710950\n",
      "07/06/2022 18:00:47 - INFO - __main__ -   Text: ['After 19–27 minutes of extended ball loss, sharks cannot see the athletes who had created, or if']\n",
      "07/06/2022 18:00:49 - INFO - __main__ -   Epoch: 123 | Batch: 3000/4417 (68%) | G Loss: 1.491435 | C Loss: -0.196654\n",
      "07/06/2022 18:00:49 - INFO - __main__ -   Text: ['If you can\\'t hold you there—\"status.\"']\n",
      "07/06/2022 18:00:51 - INFO - __main__ -   Epoch: 123 | Batch: 3600/4417 (82%) | G Loss: 0.782739 | C Loss: -1.797148\n",
      "07/06/2022 18:00:51 - INFO - __main__ -   Text: ['You can see this now if you adjust your stopwatch number to be 1000; and use 1000 to get the next']\n",
      "07/06/2022 18:00:53 - INFO - __main__ -   Epoch: 123 | Batch: 4200/4417 (95%) | G Loss: 1.845495 | C Loss: -0.350071\n",
      "07/06/2022 18:00:54 - INFO - __main__ -   Text: ['The most consistently hazardous condition in pregnancy is a ruptured vagina from the mastectomization ()']\n",
      "07/06/2022 18:00:54 - INFO - __main__ -   * (Train) Epoch: 123 | G Loss: 1.4161 | C Loss: -0.6991 | Updates G: 40 | Updates C: 328\n",
      "07/06/2022 18:01:09 - INFO - __main__ -   Bleu-2:0.456 | B-Bleu-2:0.323\n",
      "07/06/2022 18:01:09 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791965728697308\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 124 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:03:37 - INFO - __main__ -   Epoch: 124 | Batch: 0/4322 (0%) | G Loss: 1.211952 | C Loss: -0.538305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 4.800\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:03:37 - INFO - __main__ -   Text: ['Among those who voted For Baby, she experienced rashes, sore throat and were sometimes hospitalized for a lesser amount,']\n",
      "07/06/2022 18:03:39 - INFO - __main__ -   Epoch: 124 | Batch: 600/4322 (14%) | G Loss: 1.729889 | C Loss: -0.360541\n",
      "07/06/2022 18:03:39 - INFO - __main__ -   Text: ['Anatoly Handstyle won\\'t be hiding the damage or clearance he took in \"Getting through strep out the']\n",
      "07/06/2022 18:03:41 - INFO - __main__ -   Epoch: 124 | Batch: 1200/4322 (28%) | G Loss: 1.783140 | C Loss: -0.162821\n",
      "07/06/2022 18:03:41 - INFO - __main__ -   Text: ['Browning can impact an estimated 60-fold increase in heart volume with the help of medications like tramadol,']\n",
      "07/06/2022 18:03:43 - INFO - __main__ -   Epoch: 124 | Batch: 1800/4322 (42%) | G Loss: 1.703225 | C Loss: -0.320610\n",
      "07/06/2022 18:03:43 - INFO - __main__ -   Text: ['\" .']\n",
      "07/06/2022 18:03:45 - INFO - __main__ -   Epoch: 124 | Batch: 2400/4322 (56%) | G Loss: 1.041309 | C Loss: -0.166006\n",
      "07/06/2022 18:03:46 - INFO - __main__ -   Text: ['Griffin channels his addiction in a personal video and sooths that are made possible only by his secure, DRM blackouts']\n",
      "07/06/2022 18:03:48 - INFO - __main__ -   Epoch: 124 | Batch: 3000/4322 (69%) | G Loss: 2.185523 | C Loss: -0.645586\n",
      "07/06/2022 18:03:48 - INFO - __main__ -   Text: ['Since reporting that they usually have taken a shower each morning, firstly because they have a fever, thirdly because']\n",
      "07/06/2022 18:03:50 - INFO - __main__ -   Epoch: 124 | Batch: 3600/4322 (83%) | G Loss: 0.471117 | C Loss: -0.500651\n",
      "07/06/2022 18:03:50 - INFO - __main__ -   Text: ['However, after it was tested in his breakfast routine and verified by his employee with milk fist, he has been taking']\n",
      "07/06/2022 18:03:52 - INFO - __main__ -   Epoch: 124 | Batch: 4200/4322 (97%) | G Loss: 2.625689 | C Loss: -0.628741\n",
      "07/06/2022 18:03:52 - INFO - __main__ -   Text: ['During the previous month, Kimmy poses for a lot of tests on an organic diet while still slightlyen due to']\n",
      "07/06/2022 18:03:53 - INFO - __main__ -   * (Train) Epoch: 124 | G Loss: 1.3989 | C Loss: -0.7427 | Updates G: 43 | Updates C: 317\n",
      "07/06/2022 18:04:07 - INFO - __main__ -   Bleu-2:0.459 | B-Bleu-2:0.318\n",
      "07/06/2022 18:04:07 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7770924552196805\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 125 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:06:35 - INFO - __main__ -   Epoch: 125 | Batch: 0/4527 (0%) | G Loss: 3.067535 | C Loss: -2.153931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.003\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:06:35 - INFO - __main__ -   Text: ['It is unclear due to its effectiveness as a glucocorticoid in preventing and preventing osteoporosis because']\n",
      "07/06/2022 18:06:38 - INFO - __main__ -   Epoch: 125 | Batch: 600/4527 (13%) | G Loss: 2.473252 | C Loss: -1.440444\n",
      "07/06/2022 18:06:38 - INFO - __main__ -   Text: ['Hospitalised after a leg amputation while completing the 60 days, he completed 11600 caliskas of progress for']\n",
      "07/06/2022 18:06:40 - INFO - __main__ -   Epoch: 125 | Batch: 1200/4527 (27%) | G Loss: 1.338843 | C Loss: -0.068278\n",
      "07/06/2022 18:06:40 - INFO - __main__ -   Text: ['With use of the \"pebby\" cream, vitamin K1 is released and at the same time, vitamin']\n",
      "07/06/2022 18:06:42 - INFO - __main__ -   Epoch: 125 | Batch: 1800/4527 (40%) | G Loss: 0.916204 | C Loss: -1.085818\n",
      "07/06/2022 18:06:42 - INFO - __main__ -   Text: ['It is an average of 7 days past recovery, although the output has been improving over the last few years (since']\n",
      "07/06/2022 18:06:44 - INFO - __main__ -   Epoch: 125 | Batch: 2400/4527 (53%) | G Loss: 2.001734 | C Loss: -0.863700\n",
      "07/06/2022 18:06:44 - INFO - __main__ -   Text: ['Once his surgeries were done, he prefix to gentle moaning every other day until 60 hours ago (official news']\n",
      "07/06/2022 18:06:46 - INFO - __main__ -   Epoch: 125 | Batch: 3000/4527 (66%) | G Loss: 1.803607 | C Loss: -0.772740\n",
      "07/06/2022 18:06:46 - INFO - __main__ -   Text: ['Early road research shows that, for some of the people who first download the game, they will get 3 free']\n",
      "07/06/2022 18:06:48 - INFO - __main__ -   Epoch: 125 | Batch: 3600/4527 (80%) | G Loss: 1.431703 | C Loss: -0.150331\n",
      "07/06/2022 18:06:48 - INFO - __main__ -   Text: ['The four hours following \"rejected\", when Zalta once again bothered to eat a magical meal of mostly']\n",
      "07/06/2022 18:06:50 - INFO - __main__ -   Epoch: 125 | Batch: 4200/4527 (93%) | G Loss: 1.499913 | C Loss: -0.629343\n",
      "07/06/2022 18:06:51 - INFO - __main__ -   Text: ['He announces that X disk 2.10.H is fast enough to download 35,000 back to 15 minutes so']\n",
      "07/06/2022 18:06:52 - INFO - __main__ -   * (Train) Epoch: 125 | G Loss: 1.5869 | C Loss: -0.7710 | Updates G: 35 | Updates C: 342\n",
      "07/06/2022 18:07:05 - INFO - __main__ -   Bleu-2:0.457 | B-Bleu-2:0.306\n",
      "07/06/2022 18:07:05 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7631405339690718\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 126 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:09:34 - INFO - __main__ -   Epoch: 126 | Batch: 0/4467 (0%) | G Loss: 1.593895 | C Loss: -0.988077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.010\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:09:34 - INFO - __main__ -   Text: ['His logic was that when he first started performing for 3 months, alhamdulillah was 20 seconds slower']\n",
      "07/06/2022 18:09:36 - INFO - __main__ -   Epoch: 126 | Batch: 600/4467 (13%) | G Loss: 2.319150 | C Loss: -0.425839\n",
      "07/06/2022 18:09:36 - INFO - __main__ -   Text: ['Although it does not affect S values in a dosage of 80 tablets per day except for sleep loss caused by']\n",
      "07/06/2022 18:09:38 - INFO - __main__ -   Epoch: 126 | Batch: 1200/4467 (27%) | G Loss: 2.030739 | C Loss: -1.294853\n",
      "07/06/2022 18:09:38 - INFO - __main__ -   Text: [\"When she doesn't sleep, she causes discomfort just by sucking on a large enough fluid.\"]\n",
      "07/06/2022 18:09:40 - INFO - __main__ -   Epoch: 126 | Batch: 1800/4467 (40%) | G Loss: 1.028832 | C Loss: -0.545748\n",
      "07/06/2022 18:09:41 - INFO - __main__ -   Text: ['On May 30, 2004, during surgery to regain her catheterysis, Cathy Bejnik reported']\n",
      "07/06/2022 18:09:43 - INFO - __main__ -   Epoch: 126 | Batch: 2400/4467 (54%) | G Loss: 2.111360 | C Loss: -0.252646\n",
      "07/06/2022 18:09:43 - INFO - __main__ -   Text: ['When I\\'m not getting anything, I\\'m bleeding\".']\n",
      "07/06/2022 18:09:45 - INFO - __main__ -   Epoch: 126 | Batch: 3000/4467 (67%) | G Loss: 2.360354 | C Loss: -0.369550\n",
      "07/06/2022 18:09:45 - INFO - __main__ -   Text: ['He is now able to use a minor IQ checkpoint to obtain leukocyborg protein for his 3rd pregnancy,']\n",
      "07/06/2022 18:09:47 - INFO - __main__ -   Epoch: 126 | Batch: 3600/4467 (81%) | G Loss: 2.344408 | C Loss: -0.755502\n",
      "07/06/2022 18:09:47 - INFO - __main__ -   Text: [\"Mustyone's brand name means low blood pressure half 100 family years after being soymilkided, it can\"]\n",
      "07/06/2022 18:09:49 - INFO - __main__ -   Epoch: 126 | Batch: 4200/4467 (94%) | G Loss: 1.500529 | C Loss: -0.593430\n",
      "07/06/2022 18:09:49 - INFO - __main__ -   Text: ['Using information stored on DVD, Suzy piped up alternately, laughing at himself with each breath until she']\n",
      "07/06/2022 18:09:50 - INFO - __main__ -   * (Train) Epoch: 126 | G Loss: 1.6949 | C Loss: -0.7860 | Updates G: 33 | Updates C: 339\n",
      "07/06/2022 18:10:04 - INFO - __main__ -   Bleu-2:0.451 | B-Bleu-2:0.302\n",
      "07/06/2022 18:10:04 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7536380222287283\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 127 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:12:32 - INFO - __main__ -   Epoch: 127 | Batch: 0/4364 (0%) | G Loss: 1.112216 | C Loss: -0.550138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.043\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:12:33 - INFO - __main__ -   Text: [\"Families say Sara hasn't met the sucrose tolerance test, which only guides up someone who is naturally deficient in,\"]\n",
      "07/06/2022 18:12:35 - INFO - __main__ -   Epoch: 127 | Batch: 600/4364 (14%) | G Loss: 1.615110 | C Loss: -0.463131\n",
      "07/06/2022 18:12:35 - INFO - __main__ -   Text: ['Infomation may be caused either because of water bursting or shock when listening to ocean waves because \"launching\"']\n",
      "07/06/2022 18:12:37 - INFO - __main__ -   Epoch: 127 | Batch: 1200/4364 (27%) | G Loss: 1.395130 | C Loss: -0.690745\n",
      "07/06/2022 18:12:37 - INFO - __main__ -   Text: ['His histalogical quotes: 1.71 E + 2.41 G = 10 powers not executed']\n",
      "07/06/2022 18:12:39 - INFO - __main__ -   Epoch: 127 | Batch: 1800/4364 (41%) | G Loss: 1.292256 | C Loss: -0.574567\n",
      "07/06/2022 18:12:39 - INFO - __main__ -   Text: ['Like the majority of HGPs, Chambers recommends unilateral or indirect dose of SSB doses, however, as the increase']\n",
      "07/06/2022 18:12:41 - INFO - __main__ -   Epoch: 127 | Batch: 2400/4364 (55%) | G Loss: 1.586446 | C Loss: -0.193607\n",
      "07/06/2022 18:12:41 - INFO - __main__ -   Text: ['Silentness has increased in the last two to three hours (between encouraging sleep at 4pm a.m. and']\n",
      "07/06/2022 18:12:43 - INFO - __main__ -   Epoch: 127 | Batch: 3000/4364 (69%) | G Loss: 2.167722 | C Loss: -0.566601\n",
      "07/06/2022 18:12:44 - INFO - __main__ -   Text: ['Their sagging response sounds like crying even though p , Jeremy is receiving therapy.']\n",
      "07/06/2022 18:12:45 - INFO - __main__ -   Epoch: 127 | Batch: 3600/4364 (82%) | G Loss: 2.147255 | C Loss: -0.507531\n",
      "07/06/2022 18:12:46 - INFO - __main__ -   Text: ['This does not bother me anymore it just keeps me feeling like a duck, trouble catches up with me still until the']\n",
      "07/06/2022 18:12:48 - INFO - __main__ -   Epoch: 127 | Batch: 4200/4364 (96%) | G Loss: 1.690305 | C Loss: -0.421457\n",
      "07/06/2022 18:12:48 - INFO - __main__ -   Text: ['This card contains Zero5, Fenox Fuel Pump 0 132 ml, PaintMan 5 which drives the 1300 watt']\n",
      "07/06/2022 18:12:48 - INFO - __main__ -   * (Train) Epoch: 127 | G Loss: 1.5392 | C Loss: -0.7603 | Updates G: 31 | Updates C: 332\n",
      "07/06/2022 18:13:02 - INFO - __main__ -   Bleu-2:0.468 | B-Bleu-2:0.317\n",
      "07/06/2022 18:13:02 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857124381486172\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 128 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:15:31 - INFO - __main__ -   Epoch: 128 | Batch: 0/4330 (0%) | G Loss: 1.253024 | C Loss: -1.377278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.247\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:15:31 - INFO - __main__ -   Text: ['The woman had asthma during the summer, when her body grew too weight intensive and had difficulty controlling the sedated']\n",
      "07/06/2022 18:15:33 - INFO - __main__ -   Epoch: 128 | Batch: 600/4330 (14%) | G Loss: 1.320703 | C Loss: -1.130727\n",
      "07/06/2022 18:15:33 - INFO - __main__ -   Text: ['At present, he has posed as Mwalsh and there is no chance he is living to term, sleeping with']\n",
      "07/06/2022 18:15:35 - INFO - __main__ -   Epoch: 128 | Batch: 1200/4330 (28%) | G Loss: 1.053542 | C Loss: 0.061389\n",
      "07/06/2022 18:15:35 - INFO - __main__ -   Text: ['The younger you are, the older brotherlyness is enhanced.']\n",
      "07/06/2022 18:15:37 - INFO - __main__ -   Epoch: 128 | Batch: 1800/4330 (42%) | G Loss: 2.472787 | C Loss: -1.531286\n",
      "07/06/2022 18:15:37 - INFO - __main__ -   Text: ['\"Sensible wine contains \"hesterimide\" and \"grieve\" in vitro studies.']\n",
      "07/06/2022 18:15:39 - INFO - __main__ -   Epoch: 128 | Batch: 2400/4330 (55%) | G Loss: 2.885562 | C Loss: -1.230973\n",
      "07/06/2022 18:15:39 - INFO - __main__ -   Text: ['It was as if most patients would kill themselves by swallowing the warm alcohol without vomiting, but it was not like the']\n",
      "07/06/2022 18:15:41 - INFO - __main__ -   Epoch: 128 | Batch: 3000/4330 (69%) | G Loss: 1.890816 | C Loss: -0.797945\n",
      "07/06/2022 18:15:41 - INFO - __main__ -   Text: ['The biker some nights gets really drunk, until Isaac halts out.']\n",
      "07/06/2022 18:15:43 - INFO - __main__ -   Epoch: 128 | Batch: 3600/4330 (83%) | G Loss: 2.109663 | C Loss: -0.779032\n",
      "07/06/2022 18:15:44 - INFO - __main__ -   Text: ['The reason why manufacturing and racing driving is so much more fun is that the formats have been sweated up by leaving']\n",
      "07/06/2022 18:15:46 - INFO - __main__ -   Epoch: 128 | Batch: 4200/4330 (97%) | G Loss: 1.145672 | C Loss: -0.454648\n",
      "07/06/2022 18:15:46 - INFO - __main__ -   Text: ['The researchers reported that since its first intake period, Phi Zuboba has remained extremely active and has returned to a significantly']\n",
      "07/06/2022 18:15:46 - INFO - __main__ -   * (Train) Epoch: 128 | G Loss: 1.5606 | C Loss: -0.7902 | Updates G: 37 | Updates C: 323\n",
      "07/06/2022 18:16:00 - INFO - __main__ -   Bleu-2:0.460 | B-Bleu-2:0.326\n",
      "07/06/2022 18:16:00 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857147519199006\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 129 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:18:29 - INFO - __main__ -   Epoch: 129 | Batch: 0/4372 (0%) | G Loss: 1.385077 | C Loss: -1.161241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.255\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:18:29 - INFO - __main__ -   Text: ['The doctor said there was a moment where he stopped overall... [then] he started complaining, and realised things early']\n",
      "07/06/2022 18:18:31 - INFO - __main__ -   Epoch: 129 | Batch: 600/4372 (14%) | G Loss: 2.115164 | C Loss: -1.128900\n",
      "07/06/2022 18:18:31 - INFO - __main__ -   Text: [\"I am incredibly unhealthy for 8 months but has no performed, but mania is considered itchy because of Robinson's\"]\n",
      "07/06/2022 18:18:33 - INFO - __main__ -   Epoch: 129 | Batch: 1200/4372 (27%) | G Loss: 2.434114 | C Loss: -0.834552\n",
      "07/06/2022 18:18:33 - INFO - __main__ -   Text: ['Chinese Medicine is so sophisticated it requires both maxing doses of insulin, actual medication and radixplosone and']\n",
      "07/06/2022 18:18:35 - INFO - __main__ -   Epoch: 129 | Batch: 1800/4372 (41%) | G Loss: 1.323661 | C Loss: -0.390864\n",
      "07/06/2022 18:18:35 - INFO - __main__ -   Text: ['For this reason, the latter is the most popular.']\n",
      "07/06/2022 18:18:37 - INFO - __main__ -   Epoch: 129 | Batch: 2400/4372 (55%) | G Loss: 1.477943 | C Loss: -0.234122\n",
      "07/06/2022 18:18:37 - INFO - __main__ -   Text: [\"As a result, no medication can cure the flyer's memory loss and the 39 year old woman has raised awareness of\"]\n",
      "07/06/2022 18:18:39 - INFO - __main__ -   Epoch: 129 | Batch: 3000/4372 (69%) | G Loss: 1.632372 | C Loss: -0.647440\n",
      "07/06/2022 18:18:40 - INFO - __main__ -   Text: ['He tells listeners that it takes around 6 to 14 minutes for BT to feed his performance and that the']\n",
      "07/06/2022 18:18:42 - INFO - __main__ -   Epoch: 129 | Batch: 3600/4372 (82%) | G Loss: 1.444123 | C Loss: -0.269992\n",
      "07/06/2022 18:18:42 - INFO - __main__ -   Text: ['It is unknown if if several FGF eye drops and gout are absorbed in a single day, but it is']\n",
      "07/06/2022 18:18:44 - INFO - __main__ -   Epoch: 129 | Batch: 4200/4372 (96%) | G Loss: 1.776517 | C Loss: -0.591733\n",
      "07/06/2022 18:18:44 - INFO - __main__ -   Text: ['On the Guru List that was first published in 2014, 24 patients with primary/secondary disability have filed for emergency']\n",
      "07/06/2022 18:18:44 - INFO - __main__ -   * (Train) Epoch: 129 | G Loss: 1.6890 | C Loss: -0.7894 | Updates G: 27 | Updates C: 337\n",
      "07/06/2022 18:18:58 - INFO - __main__ -   Bleu-2:0.462 | B-Bleu-2:0.323\n",
      "07/06/2022 18:18:58 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7851932055384316\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 130 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:21:27 - INFO - __main__ -   Epoch: 130 | Batch: 0/4473 (0%) | G Loss: 1.694405 | C Loss: -0.607032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.292\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:21:27 - INFO - __main__ -   Text: ['It was an accident because there was that girl he slept in, so his wife-to-be wanted a thing']\n",
      "07/06/2022 18:21:29 - INFO - __main__ -   Epoch: 130 | Batch: 600/4473 (13%) | G Loss: 1.892729 | C Loss: -0.501514\n",
      "07/06/2022 18:21:29 - INFO - __main__ -   Text: ['The priority is confirmed in the PortugueseDVD process that saw Cristian Ekora leave late and concentrate for ABC 30']\n",
      "07/06/2022 18:21:31 - INFO - __main__ -   Epoch: 130 | Batch: 1200/4473 (27%) | G Loss: 1.222940 | C Loss: -0.693501\n",
      "07/06/2022 18:21:31 - INFO - __main__ -   Text: ['While DJ Kalidan made two appearances for BBC using his cell phone andSong:I have for me']\n",
      "07/06/2022 18:21:33 - INFO - __main__ -   Epoch: 130 | Batch: 1800/4473 (40%) | G Loss: 1.615237 | C Loss: -0.536802\n",
      "07/06/2022 18:21:34 - INFO - __main__ -   Text: ['During this timeframe she lost about 15 pounds, she spent almost 10 hours short of 45 minutes with her circulation changed,']\n",
      "07/06/2022 18:21:36 - INFO - __main__ -   Epoch: 130 | Batch: 2400/4473 (54%) | G Loss: 2.114770 | C Loss: -0.624364\n",
      "07/06/2022 18:21:36 - INFO - __main__ -   Text: ['Circuit Breaker, on the other hand, results in migraines lasting Long days, or months,']\n",
      "07/06/2022 18:21:38 - INFO - __main__ -   Epoch: 130 | Batch: 3000/4473 (67%) | G Loss: 1.759229 | C Loss: -1.177900\n",
      "07/06/2022 18:21:38 - INFO - __main__ -   Text: [\"The last time I made a test for 'unstable body of work' I had taken it down using coffee every\"]\n",
      "07/06/2022 18:21:40 - INFO - __main__ -   Epoch: 130 | Batch: 3600/4473 (80%) | G Loss: 1.631584 | C Loss: -0.707402\n",
      "07/06/2022 18:21:40 - INFO - __main__ -   Text: ['Next year, in addition, he is showing for the first time this extensive results of his father \"as heard as']\n",
      "07/06/2022 18:21:42 - INFO - __main__ -   Epoch: 130 | Batch: 4200/4473 (94%) | G Loss: 1.407512 | C Loss: -1.420082\n",
      "07/06/2022 18:21:43 - INFO - __main__ -   Text: [\"While on a lighter day Thermaly ever say 'ADHD', instead of trying to respond the very first\"]\n",
      "07/06/2022 18:21:43 - INFO - __main__ -   * (Train) Epoch: 130 | G Loss: 1.6826 | C Loss: -0.7883 | Updates G: 33 | Updates C: 339\n",
      "07/06/2022 18:21:57 - INFO - __main__ -   Bleu-2:0.464 | B-Bleu-2:0.332\n",
      "07/06/2022 18:21:57 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7962197032324156\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 131 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:11.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:24:26 - INFO - __main__ -   Epoch: 131 | Batch: 0/4473 (0%) | G Loss: 1.339214 | C Loss: -1.781257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 5.081\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:24:26 - INFO - __main__ -   Text: ['21/06/2013 – With over 300 places on our list of one-star reviews, \"Ammo']\n",
      "07/06/2022 18:24:28 - INFO - __main__ -   Epoch: 131 | Batch: 600/4473 (13%) | G Loss: 1.526306 | C Loss: -0.924966\n",
      "07/06/2022 18:24:28 - INFO - __main__ -   Text: ['A typical online day is 1 month, though, with an interruption by a cell phone around 3 hours, for']\n",
      "07/06/2022 18:24:30 - INFO - __main__ -   Epoch: 131 | Batch: 1200/4473 (27%) | G Loss: 1.921978 | C Loss: -0.662252\n",
      "07/06/2022 18:24:31 - INFO - __main__ -   Text: [\"This is how it happens: It's always a mistake to drink a glass of water in the first person nor drink\"]\n",
      "07/06/2022 18:24:32 - INFO - __main__ -   Epoch: 131 | Batch: 1800/4473 (40%) | G Loss: 1.734038 | C Loss: -1.645589\n",
      "07/06/2022 18:24:33 - INFO - __main__ -   Text: ['RKF 1 is basically a third part / TW tab now it says Puzzle Girls while 11 admitted to Easy NJ']\n",
      "07/06/2022 18:24:35 - INFO - __main__ -   Epoch: 131 | Batch: 2400/4473 (54%) | G Loss: 1.673928 | C Loss: -0.675660\n",
      "07/06/2022 18:24:35 - INFO - __main__ -   Text: ['In the third day they know that they have gone to work and they read a newspaper but forget to stop for breakfast']\n",
      "07/06/2022 18:24:37 - INFO - __main__ -   Epoch: 131 | Batch: 3000/4473 (67%) | G Loss: 1.681083 | C Loss: -0.631462\n",
      "07/06/2022 18:24:37 - INFO - __main__ -   Text: ['Statix\\'s 10 worst snacks (10-year survival time) at \" Crunch Off \": Visually Only Foods']\n",
      "07/06/2022 18:24:39 - INFO - __main__ -   Epoch: 131 | Batch: 3600/4473 (80%) | G Loss: 2.172326 | C Loss: -0.647981\n",
      "07/06/2022 18:24:39 - INFO - __main__ -   Text: ['After 8 hours of sweat for the rest of the cycle, I start breathing ugly tips out, now then, probably']\n",
      "07/06/2022 18:24:41 - INFO - __main__ -   Epoch: 131 | Batch: 4200/4473 (94%) | G Loss: 2.252636 | C Loss: -3.119952\n",
      "07/06/2022 18:24:42 - INFO - __main__ -   Text: ['This is why you have the repellent folding pattern that all deodorants weakens and your artificial version that']\n",
      "07/06/2022 18:24:42 - INFO - __main__ -   * (Train) Epoch: 131 | G Loss: 1.6099 | C Loss: -0.7922 | Updates G: 19 | Updates C: 353\n",
      "07/06/2022 18:24:56 - INFO - __main__ -   Bleu-2:0.471 | B-Bleu-2:0.319\n",
      "07/06/2022 18:24:56 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789632615480248\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 132 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:27:25 - INFO - __main__ -   Epoch: 132 | Batch: 0/4327 (0%) | G Loss: 2.254436 | C Loss: -1.141802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.200\n",
      "  Test Loss: 5.246\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:27:25 - INFO - __main__ -   Text: ['By then Ninety-Six is heading for an associated consistency with \"Baby copious.\"']\n",
      "07/06/2022 18:27:27 - INFO - __main__ -   Epoch: 132 | Batch: 600/4327 (14%) | G Loss: 1.934625 | C Loss: -1.362483\n",
      "07/06/2022 18:27:27 - INFO - __main__ -   Text: ['This helps when taking the pills, goes in your body, and keeps you quiet until the final day.']\n",
      "07/06/2022 18:27:29 - INFO - __main__ -   Epoch: 132 | Batch: 1200/4327 (28%) | G Loss: 2.078037 | C Loss: -0.791750\n",
      "07/06/2022 18:27:29 - INFO - __main__ -   Text: ['There is now a \"page missing from this list\", however, according to Poincaré, who posted a']\n",
      "07/06/2022 18:27:32 - INFO - __main__ -   Epoch: 132 | Batch: 1800/4327 (42%) | G Loss: 1.891615 | C Loss: -0.669644\n",
      "07/06/2022 18:27:32 - INFO - __main__ -   Text: ['This is endless!\"']\n",
      "07/06/2022 18:27:34 - INFO - __main__ -   Epoch: 132 | Batch: 2400/4327 (55%) | G Loss: 1.912557 | C Loss: -0.613548\n",
      "07/06/2022 18:27:34 - INFO - __main__ -   Text: [\"There's no doubt about it; Klebsie agrees.\"]\n",
      "07/06/2022 18:27:36 - INFO - __main__ -   Epoch: 132 | Batch: 3000/4327 (69%) | G Loss: 2.000286 | C Loss: -0.579861\n",
      "07/06/2022 18:27:36 - INFO - __main__ -   Text: [\"He added that, if he can stay on long enough, I'll be able to buy a blister pack between 3\"]\n",
      "07/06/2022 18:27:38 - INFO - __main__ -   Epoch: 132 | Batch: 3600/4327 (83%) | G Loss: 1.501400 | C Loss: -1.705304\n",
      "07/06/2022 18:27:38 - INFO - __main__ -   Text: ['Daily since September 2004 on average, he suffers from several bouts of diarrhea, including constipation with intermittent diarrhea, feeling']\n",
      "07/06/2022 18:27:40 - INFO - __main__ -   Epoch: 132 | Batch: 4200/4327 (97%) | G Loss: 1.556442 | C Loss: -0.459345\n",
      "07/06/2022 18:27:40 - INFO - __main__ -   Text: ['Since this was originally done before on TV before it became clear what ive lost was losing of also fibbing while']\n",
      "07/06/2022 18:27:41 - INFO - __main__ -   * (Train) Epoch: 132 | G Loss: 1.7181 | C Loss: -0.8180 | Updates G: 36 | Updates C: 324\n",
      "07/06/2022 18:27:55 - INFO - __main__ -   Bleu-2:0.444 | B-Bleu-2:0.312\n",
      "07/06/2022 18:27:55 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7561312206618487\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 133 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:30:23 - INFO - __main__ -   Epoch: 133 | Batch: 0/4417 (0%) | G Loss: 1.752916 | C Loss: -1.472003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 4.885\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:30:23 - INFO - __main__ -   Text: [\"Contrary to what I tell you, when they woke up I was driving and thinking 'Man, I Was pretty sure\"]\n",
      "07/06/2022 18:30:25 - INFO - __main__ -   Epoch: 133 | Batch: 600/4417 (14%) | G Loss: 1.516158 | C Loss: -0.480329\n",
      "07/06/2022 18:30:26 - INFO - __main__ -   Text: ['Also, a sample video of the song recorded on a turntable realism dashboard has been shown to make the rotating']\n",
      "07/06/2022 18:30:28 - INFO - __main__ -   Epoch: 133 | Batch: 1200/4417 (27%) | G Loss: 2.005616 | C Loss: -0.624449\n",
      "07/06/2022 18:30:28 - INFO - __main__ -   Text: [\"Later on, when Vicky 'ware only' talks to them about the reset and has gone on to explain the\"]\n",
      "07/06/2022 18:30:30 - INFO - __main__ -   Epoch: 133 | Batch: 1800/4417 (41%) | G Loss: 1.559917 | C Loss: -0.669068\n",
      "07/06/2022 18:30:30 - INFO - __main__ -   Text: ['acq.petr’s [digit] <boù!*']\n",
      "07/06/2022 18:30:32 - INFO - __main__ -   Epoch: 133 | Batch: 2400/4417 (54%) | G Loss: 1.400761 | C Loss: -0.449678\n",
      "07/06/2022 18:30:32 - INFO - __main__ -   Text: ['On napkin sandwiches he says that he cannot get any worse!']\n",
      "07/06/2022 18:30:34 - INFO - __main__ -   Epoch: 133 | Batch: 3000/4417 (68%) | G Loss: 2.072495 | C Loss: -0.691854\n",
      "07/06/2022 18:30:34 - INFO - __main__ -   Text: ['It has significantly reduced sleep duration, resulting in greater number of short bouts in evening during the day and']\n",
      "07/06/2022 18:30:36 - INFO - __main__ -   Epoch: 133 | Batch: 3600/4417 (82%) | G Loss: 1.839689 | C Loss: -0.519179\n",
      "07/06/2022 18:30:36 - INFO - __main__ -   Text: ['Pregnancy testing can be done by supervision, such as by suctioning butching the ovaries very deeply,']\n",
      "07/06/2022 18:30:38 - INFO - __main__ -   Epoch: 133 | Batch: 4200/4417 (95%) | G Loss: 1.755744 | C Loss: -0.553553\n",
      "07/06/2022 18:30:39 - INFO - __main__ -   Text: ['It\\'s very false music...\" They took no more of it.']\n",
      "07/06/2022 18:30:39 - INFO - __main__ -   * (Train) Epoch: 133 | G Loss: 1.7080 | C Loss: -0.8157 | Updates G: 28 | Updates C: 340\n",
      "07/06/2022 18:30:53 - INFO - __main__ -   Bleu-2:0.455 | B-Bleu-2:0.315\n",
      "07/06/2022 18:30:53 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7706213621434688\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 134 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:36:20 - INFO - __main__ -   Epoch: 135 | Batch: 0/4527 (0%) | G Loss: 2.156410 | C Loss: -0.795905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 5.073\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:36:20 - INFO - __main__ -   Text: ['In the United States, post-suicide diagnostics test scores 23 points higher than most patients do, which is']\n",
      "07/06/2022 18:36:22 - INFO - __main__ -   Epoch: 135 | Batch: 600/4527 (13%) | G Loss: 1.566815 | C Loss: -0.719753\n",
      "07/06/2022 18:36:23 - INFO - __main__ -   Text: [\"Dante wrote How and When to Start Moving, about how to maintain your balance between dad and the fucker's milk\"]\n",
      "07/06/2022 18:36:24 - INFO - __main__ -   Epoch: 135 | Batch: 1200/4527 (27%) | G Loss: 1.564328 | C Loss: -0.285433\n",
      "07/06/2022 18:36:25 - INFO - __main__ -   Text: ['Today, Flaky Medicine Can treat short bowel disease, which has a mortality rate of 0.5% in stool']\n",
      "07/06/2022 18:36:27 - INFO - __main__ -   Epoch: 135 | Batch: 1800/4527 (40%) | G Loss: 1.553137 | C Loss: -0.850189\n",
      "07/06/2022 18:36:27 - INFO - __main__ -   Text: ['It was also reported that Kornkeit has consistently been rated high on \"punishing the rats\" and']\n",
      "07/06/2022 18:36:29 - INFO - __main__ -   Epoch: 135 | Batch: 2400/4527 (53%) | G Loss: 2.324208 | C Loss: -0.655840\n",
      "07/06/2022 18:36:29 - INFO - __main__ -   Text: [\"'Thought is yo ji.'\"]\n",
      "07/06/2022 18:36:31 - INFO - __main__ -   Epoch: 135 | Batch: 3000/4527 (66%) | G Loss: 2.293190 | C Loss: -0.224879\n",
      "07/06/2022 18:36:31 - INFO - __main__ -   Text: ['Just when Hannah is ready to give his Vine Pictures final, he wraps up some thoughts in his diary\"I intend']\n",
      "07/06/2022 18:36:33 - INFO - __main__ -   Epoch: 135 | Batch: 3600/4527 (80%) | G Loss: 1.606632 | C Loss: -0.074867\n",
      "07/06/2022 18:36:33 - INFO - __main__ -   Text: [\"The drug is released one hour after death which is also called overdose 'after liver failure', which is when the\"]\n",
      "07/06/2022 18:36:35 - INFO - __main__ -   Epoch: 135 | Batch: 4200/4527 (93%) | G Loss: 1.507612 | C Loss: -0.399104\n",
      "07/06/2022 18:36:35 - INFO - __main__ -   Text: ['James! <PAD>!\"']\n",
      "07/06/2022 18:36:36 - INFO - __main__ -   * (Train) Epoch: 135 | G Loss: 1.7372 | C Loss: -0.8545 | Updates G: 21 | Updates C: 356\n",
      "07/06/2022 18:36:50 - INFO - __main__ -   Bleu-2:0.461 | B-Bleu-2:0.321\n",
      "07/06/2022 18:36:50 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7823737103867052\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 136 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:39:18 - INFO - __main__ -   Epoch: 136 | Batch: 0/4467 (0%) | G Loss: 1.517288 | C Loss: -0.684489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 4.728\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:39:19 - INFO - __main__ -   Text: ['However, actually being offered dexamine by a doctor when using a spinal cord injury as symptom did not recover;']\n",
      "07/06/2022 18:39:21 - INFO - __main__ -   Epoch: 136 | Batch: 600/4467 (13%) | G Loss: 1.952606 | C Loss: -1.882376\n",
      "07/06/2022 18:39:21 - INFO - __main__ -   Text: ['Starting January 1, 2017, Ana moved into a single-day-long-advanced’t, continuing']\n",
      "07/06/2022 18:39:23 - INFO - __main__ -   Epoch: 136 | Batch: 1200/4467 (27%) | G Loss: 2.068439 | C Loss: -0.923721\n",
      "07/06/2022 18:39:23 - INFO - __main__ -   Text: ['He then sells Dangerous Beer to customers with high blood pressure and arthritis as the result of defective daily training and needs to']\n",
      "07/06/2022 18:39:25 - INFO - __main__ -   Epoch: 136 | Batch: 1800/4467 (40%) | G Loss: 2.145721 | C Loss: -0.589992\n",
      "07/06/2022 18:39:25 - INFO - __main__ -   Text: ['One popular relaxation method for SAD®, Vedeen, which features does not have any initial symptoms but significantly improves']\n",
      "07/06/2022 18:39:27 - INFO - __main__ -   Epoch: 136 | Batch: 2400/4467 (54%) | G Loss: 2.326823 | C Loss: -0.630579\n",
      "07/06/2022 18:39:27 - INFO - __main__ -   Text: ['Am I looking for... Intelligence secret!\" .']\n",
      "07/06/2022 18:39:29 - INFO - __main__ -   Epoch: 136 | Batch: 3000/4467 (67%) | G Loss: 1.738718 | C Loss: -0.772742\n",
      "07/06/2022 18:39:29 - INFO - __main__ -   Text: [\"Deuterally 'I want that!'\"]\n",
      "07/06/2022 18:39:31 - INFO - __main__ -   Epoch: 136 | Batch: 3600/4467 (81%) | G Loss: 1.293701 | C Loss: -0.237751\n",
      "07/06/2022 18:39:32 - INFO - __main__ -   Text: ['Even though he was successful, he has to stay upright once sweat drips off his skin because of his broken ankle']\n",
      "07/06/2022 18:39:33 - INFO - __main__ -   Epoch: 136 | Batch: 4200/4467 (94%) | G Loss: 1.876451 | C Loss: -0.863866\n",
      "07/06/2022 18:39:34 - INFO - __main__ -   Text: ['When triagliosis comes to an end, cramps act as a rebound for TRN and transt']\n",
      "07/06/2022 18:39:34 - INFO - __main__ -   * (Train) Epoch: 136 | G Loss: 1.6787 | C Loss: -0.8163 | Updates G: 23 | Updates C: 349\n",
      "07/06/2022 18:39:48 - INFO - __main__ -   Bleu-2:0.461 | B-Bleu-2:0.315\n",
      "07/06/2022 18:39:48 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776233271524528\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 137 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:42:17 - INFO - __main__ -   Epoch: 137 | Batch: 0/4364 (0%) | G Loss: 1.573606 | C Loss: -0.261572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.028\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:42:17 - INFO - __main__ -   Text: [\"On the 10th day, and I'm making a movie, it's bad. I'm feeling the cold\"]\n",
      "07/06/2022 18:42:19 - INFO - __main__ -   Epoch: 137 | Batch: 600/4364 (14%) | G Loss: 1.608149 | C Loss: -0.618508\n",
      "07/06/2022 18:42:19 - INFO - __main__ -   Text: [\"Let's see what you have done...I'm sorry wall of text bacter hadn'ts noticed so did you?\"]\n",
      "07/06/2022 18:42:21 - INFO - __main__ -   Epoch: 137 | Batch: 1200/4364 (27%) | G Loss: 1.455017 | C Loss: -0.478807\n",
      "07/06/2022 18:42:22 - INFO - __main__ -   Text: ['Many studies have shown postmenopausal pain relief after treatment (30 days or more) or experimental pills (12 weeks']\n",
      "07/06/2022 18:42:23 - INFO - __main__ -   Epoch: 137 | Batch: 1800/4364 (41%) | G Loss: 1.861848 | C Loss: -0.249630\n",
      "07/06/2022 18:42:24 - INFO - __main__ -   Text: ['Very nice, I think.']\n",
      "07/06/2022 18:42:26 - INFO - __main__ -   Epoch: 137 | Batch: 2400/4364 (55%) | G Loss: 1.775394 | C Loss: -0.497094\n",
      "07/06/2022 18:42:26 - INFO - __main__ -   Text: ['In 2008, he first tested nootropic chemicals appropriate for refined sugar drinks using \"Linked High Sensory\" and']\n",
      "07/06/2022 18:42:28 - INFO - __main__ -   Epoch: 137 | Batch: 3000/4364 (69%) | G Loss: 1.764501 | C Loss: -0.851500\n",
      "07/06/2022 18:42:28 - INFO - __main__ -   Text: ['When want sapradh will and sak torrents stay on the island out of absorption into his']\n",
      "07/06/2022 18:42:30 - INFO - __main__ -   Epoch: 137 | Batch: 3600/4364 (82%) | G Loss: 1.616074 | C Loss: -0.633911\n",
      "07/06/2022 18:42:30 - INFO - __main__ -   Text: ['The Whites kill almost all other sentences with their own thoughts, like prices and waists, only to kill people']\n",
      "07/06/2022 18:42:32 - INFO - __main__ -   Epoch: 137 | Batch: 4200/4364 (96%) | G Loss: 1.489701 | C Loss: -1.061134\n",
      "07/06/2022 18:42:32 - INFO - __main__ -   Text: ['The following day, and for ten days straight, Balu texted her mother Morri and said \"Let\\'s']\n",
      "07/06/2022 18:42:33 - INFO - __main__ -   * (Train) Epoch: 137 | G Loss: 1.6629 | C Loss: -0.8206 | Updates G: 29 | Updates C: 334\n",
      "07/06/2022 18:42:47 - INFO - __main__ -   Bleu-2:0.471 | B-Bleu-2:0.332\n",
      "07/06/2022 18:42:47 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8032599414375071\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 138 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:45:15 - INFO - __main__ -   Epoch: 138 | Batch: 0/4330 (0%) | G Loss: 1.689148 | C Loss: -0.640338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.131\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:45:16 - INFO - __main__ -   Text: ['Bittersweetbomb, the man who apparently makes the best \"up to 2 takes four to eight hours to get']\n",
      "07/06/2022 18:45:18 - INFO - __main__ -   Epoch: 138 | Batch: 600/4330 (14%) | G Loss: 1.847927 | C Loss: -0.541767\n",
      "07/06/2022 18:45:18 - INFO - __main__ -   Text: ['those posts that endorse and increase candy-bag based artificial valerian cash syndrome if just by giving their ben']\n",
      "07/06/2022 18:45:20 - INFO - __main__ -   Epoch: 138 | Batch: 1200/4330 (28%) | G Loss: 2.178013 | C Loss: -1.485914\n",
      "07/06/2022 18:45:20 - INFO - __main__ -   Text: [\"Mankind's best way to upgrade is to run either inside the car, push to tow, drive the car at the\"]\n",
      "07/06/2022 18:45:22 - INFO - __main__ -   Epoch: 138 | Batch: 1800/4330 (42%) | G Loss: 1.450644 | C Loss: -1.051634\n",
      "07/06/2022 18:45:22 - INFO - __main__ -   Text: ['Gay\" becomes \"gay\" when gay men marry at one minimum speed of fifteen (15 hours per day) gay']\n",
      "07/06/2022 18:45:24 - INFO - __main__ -   Epoch: 138 | Batch: 2400/4330 (55%) | G Loss: 1.810855 | C Loss: -0.264575\n",
      "07/06/2022 18:45:24 - INFO - __main__ -   Text: ['He did ask for more videos, so that we can see adding alternatives to existing products because learning learning to put']\n",
      "07/06/2022 18:45:26 - INFO - __main__ -   Epoch: 138 | Batch: 3000/4330 (69%) | G Loss: 2.433048 | C Loss: -0.974930\n",
      "07/06/2022 18:45:26 - INFO - __main__ -   Text: ['NED has unfortunately been banned, so many of the notes coming out of the testimonial, as well as ones']\n",
      "07/06/2022 18:45:28 - INFO - __main__ -   Epoch: 138 | Batch: 3600/4330 (83%) | G Loss: 1.692388 | C Loss: -1.004964\n",
      "07/06/2022 18:45:29 - INFO - __main__ -   Text: ['This includes both of those hands working really hard, seeming to hit for 10 times the entire hand in the very first']\n",
      "07/06/2022 18:45:31 - INFO - __main__ -   Epoch: 138 | Batch: 4200/4330 (97%) | G Loss: 2.452833 | C Loss: -0.791115\n",
      "07/06/2022 18:45:31 - INFO - __main__ -   Text: ['It must have lasted 2 to 3 weeks, but that is what some people say it literally would have been; Chinese']\n",
      "07/06/2022 18:45:31 - INFO - __main__ -   * (Train) Epoch: 138 | G Loss: 1.8986 | C Loss: -0.8516 | Updates G: 20 | Updates C: 340\n",
      "07/06/2022 18:45:45 - INFO - __main__ -   Bleu-2:0.467 | B-Bleu-2:0.317\n",
      "07/06/2022 18:45:45 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7841009192215822\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 139 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:48:13 - INFO - __main__ -   Epoch: 139 | Batch: 0/4372 (0%) | G Loss: 1.915742 | C Loss: -0.835906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.182\n",
      "  Test Loss: 4.998\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:48:14 - INFO - __main__ -   Text: ['Most of her usual fluids continued up to the week after surgery, and she had been eating only low-fat diets']\n",
      "07/06/2022 18:48:16 - INFO - __main__ -   Epoch: 139 | Batch: 600/4372 (14%) | G Loss: 1.291963 | C Loss: -2.060334\n",
      "07/06/2022 18:48:16 - INFO - __main__ -   Text: ['Like I told you, Cassani merely believed what I said when he switched a few minutes later, and now it']\n",
      "07/06/2022 18:48:18 - INFO - __main__ -   Epoch: 139 | Batch: 1200/4372 (27%) | G Loss: 1.634379 | C Loss: -2.874787\n",
      "07/06/2022 18:48:18 - INFO - __main__ -   Text: ['A few months later, a few weeks after her husband had prostate cancer surgery, feel free to \"you']\n",
      "07/06/2022 18:48:20 - INFO - __main__ -   Epoch: 139 | Batch: 1800/4372 (41%) | G Loss: 1.410197 | C Loss: -2.669202\n",
      "07/06/2022 18:48:20 - INFO - __main__ -   Text: ['In a recent blog post, (a tardily hip generation who live subsequently) Suzanne cried, \"Why do']\n",
      "07/06/2022 18:48:22 - INFO - __main__ -   Epoch: 139 | Batch: 2400/4372 (55%) | G Loss: 1.051695 | C Loss: -0.121225\n",
      "07/06/2022 18:48:22 - INFO - __main__ -   Text: ['Raddis refers to \"Bodylam () during the month when up to 90 / 20 bodyfat_spat']\n",
      "07/06/2022 18:48:24 - INFO - __main__ -   Epoch: 139 | Batch: 3000/4372 (69%) | G Loss: 1.290403 | C Loss: -0.399072\n",
      "07/06/2022 18:48:24 - INFO - __main__ -   Text: ['In some cases, patients can repeatedly experience extreme pain in half the time their composes was worn out and feelings of']\n",
      "07/06/2022 18:48:27 - INFO - __main__ -   Epoch: 139 | Batch: 3600/4372 (82%) | G Loss: 2.146084 | C Loss: -0.622710\n",
      "07/06/2022 18:48:27 - INFO - __main__ -   Text: [\"That's kind of the truth – he does this while performing incongruent abdominal exercises while churching nude for\"]\n",
      "07/06/2022 18:48:29 - INFO - __main__ -   Epoch: 139 | Batch: 4200/4372 (96%) | G Loss: 1.927598 | C Loss: -0.748137\n",
      "07/06/2022 18:48:29 - INFO - __main__ -   Text: [\"The charge for under 35 years is severe, because 15 paceds don't catch on, compared to 14 with\"]\n",
      "07/06/2022 18:48:30 - INFO - __main__ -   * (Train) Epoch: 139 | G Loss: 1.8369 | C Loss: -0.8532 | Updates G: 27 | Updates C: 337\n",
      "07/06/2022 18:48:44 - INFO - __main__ -   Bleu-2:0.469 | B-Bleu-2:0.324\n",
      "07/06/2022 18:48:44 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7929875340162865\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 140 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:51:12 - INFO - __main__ -   Epoch: 140 | Batch: 0/4473 (0%) | G Loss: 2.055499 | C Loss: -1.003268\n",
      "07/06/2022 18:51:12 - INFO - __main__ -   Text: ['Dragons also has huge difficulty walking, so its narrator named it \"powerful sex bounty\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.190\n",
      "  Test Loss: 4.985\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:51:14 - INFO - __main__ -   Epoch: 140 | Batch: 600/4473 (13%) | G Loss: 1.697762 | C Loss: -0.672721\n",
      "07/06/2022 18:51:15 - INFO - __main__ -   Text: ['suckir\", \"one stopsbuckets consumptiony smelly\" and a beefy \"lots of cat']\n",
      "07/06/2022 18:51:17 - INFO - __main__ -   Epoch: 140 | Batch: 1200/4473 (27%) | G Loss: 1.755116 | C Loss: -0.388566\n",
      "07/06/2022 18:51:17 - INFO - __main__ -   Text: ['Id, the girl who had received a virorectomy after 3 months of unprotected sex when serialctomy stopped']\n",
      "07/06/2022 18:51:19 - INFO - __main__ -   Epoch: 140 | Batch: 1800/4473 (40%) | G Loss: 1.773369 | C Loss: -0.550005\n",
      "07/06/2022 18:51:19 - INFO - __main__ -   Text: ['It\\'s such a good break from the musings that many people love.\"']\n",
      "07/06/2022 18:51:21 - INFO - __main__ -   Epoch: 140 | Batch: 2400/4473 (54%) | G Loss: 2.069442 | C Loss: -0.751558\n",
      "07/06/2022 18:51:21 - INFO - __main__ -   Text: ['Thinking that something was wrong, he decided to take it full-on Jesus threw his body once more against water']\n",
      "07/06/2022 18:51:23 - INFO - __main__ -   Epoch: 140 | Batch: 3000/4473 (67%) | G Loss: 1.895394 | C Loss: -0.814073\n",
      "07/06/2022 18:51:24 - INFO - __main__ -   Text: ['Banks will take the morning of the day, after a box payment, and begin writing a short film all over a']\n",
      "07/06/2022 18:51:26 - INFO - __main__ -   Epoch: 140 | Batch: 3600/4473 (80%) | G Loss: 1.328751 | C Loss: -0.639216\n",
      "07/06/2022 18:51:26 - INFO - __main__ -   Text: ['Upon her wearing glasses, flu medication she again didn\\'t get herself sick and suffers some side effects, as \"If']\n",
      "07/06/2022 18:51:28 - INFO - __main__ -   Epoch: 140 | Batch: 4200/4473 (94%) | G Loss: 1.779271 | C Loss: -0.347548\n",
      "07/06/2022 18:51:28 - INFO - __main__ -   Text: ['In clinical trials, a guard performs wireless surgery that breaks her abdominal muscle tissue as it is stretched far, low,']\n",
      "07/06/2022 18:51:29 - INFO - __main__ -   * (Train) Epoch: 140 | G Loss: 1.6939 | C Loss: -0.8169 | Updates G: 24 | Updates C: 348\n",
      "07/06/2022 18:51:42 - INFO - __main__ -   Bleu-2:0.472 | B-Bleu-2:0.327\n",
      "07/06/2022 18:51:42 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988518987387105\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 141 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:54:11 - INFO - __main__ -   Epoch: 141 | Batch: 0/4473 (0%) | G Loss: 1.888047 | C Loss: -1.155845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.054\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:54:11 - INFO - __main__ -   Text: ['Like the Mexican who was allergic to red meat and created a friend-of-the-book memorandum Review that John']\n",
      "07/06/2022 18:54:13 - INFO - __main__ -   Epoch: 141 | Batch: 600/4473 (13%) | G Loss: 2.003995 | C Loss: -1.214964\n",
      "07/06/2022 18:54:13 - INFO - __main__ -   Text: ['Here, due to his schizophrenia, and to reduce his loss of lucidity and productivity, the time of his last']\n",
      "07/06/2022 18:54:15 - INFO - __main__ -   Epoch: 141 | Batch: 1200/4473 (27%) | G Loss: 2.115451 | C Loss: -0.749059\n",
      "07/06/2022 18:54:15 - INFO - __main__ -   Text: ['Samir and Shannon followed the advice of Anu, calculating with their first two little girls to high their weights the']\n",
      "07/06/2022 18:54:17 - INFO - __main__ -   Epoch: 141 | Batch: 1800/4473 (40%) | G Loss: 2.083674 | C Loss: -1.045191\n",
      "07/06/2022 18:54:18 - INFO - __main__ -   Text: ['Tonight I need to focus with meditation never to wake up and it takes about 13 hours to hit the nightstand while']\n",
      "07/06/2022 18:54:20 - INFO - __main__ -   Epoch: 141 | Batch: 2400/4473 (54%) | G Loss: 1.934801 | C Loss: -0.703157\n",
      "07/06/2022 18:54:20 - INFO - __main__ -   Text: ['Since being 4 years old, AJ has completed 7 miles per week having reduced to 19km, 12 miles per']\n",
      "07/06/2022 18:54:22 - INFO - __main__ -   Epoch: 141 | Batch: 3000/4473 (67%) | G Loss: 1.650802 | C Loss: -0.520045\n",
      "07/06/2022 18:54:22 - INFO - __main__ -   Text: ['After 5 years being unemployed, sharing a lot, offering food from husbands MMA and sleeping in my shoes like']\n",
      "07/06/2022 18:54:24 - INFO - __main__ -   Epoch: 141 | Batch: 3600/4473 (80%) | G Loss: 1.310048 | C Loss: -0.113687\n",
      "07/06/2022 18:54:24 - INFO - __main__ -   Text: ['After thumping, Sifima scores 50 acts of diarrhoea and the creaky swallowing of five acts of']\n",
      "07/06/2022 18:54:26 - INFO - __main__ -   Epoch: 141 | Batch: 4200/4473 (94%) | G Loss: 2.135740 | C Loss: -0.579090\n",
      "07/06/2022 18:54:27 - INFO - __main__ -   Text: ['Allowed to work outside of Bangladesh, Phelan showed signs of post-workout problems after he exited the']\n",
      "07/06/2022 18:54:27 - INFO - __main__ -   * (Train) Epoch: 141 | G Loss: 1.7778 | C Loss: -0.8184 | Updates G: 18 | Updates C: 354\n",
      "07/06/2022 18:54:41 - INFO - __main__ -   Bleu-2:0.440 | B-Bleu-2:0.317\n",
      "07/06/2022 18:54:41 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7573215461713527\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 142 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:57:10 - INFO - __main__ -   Epoch: 142 | Batch: 0/4327 (0%) | G Loss: 2.188565 | C Loss: -0.490345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 4.904\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 18:57:10 - INFO - __main__ -   Text: ['At some point it has experienced a severe worsening when many other hormones have entered oestrogenic and estradiol']\n",
      "07/06/2022 18:57:12 - INFO - __main__ -   Epoch: 142 | Batch: 600/4327 (14%) | G Loss: 2.135758 | C Loss: -1.318856\n",
      "07/06/2022 18:57:12 - INFO - __main__ -   Text: ['*BLAMS* (beside extending the spidal glacer throw) *STRUNDS*']\n",
      "07/06/2022 18:57:14 - INFO - __main__ -   Epoch: 142 | Batch: 1200/4327 (28%) | G Loss: 1.964088 | C Loss: -0.536305\n",
      "07/06/2022 18:57:14 - INFO - __main__ -   Text: ['Although he was able to clear 5 km in the first stage, he experienced four wentoks similar to the one']\n",
      "07/06/2022 18:57:16 - INFO - __main__ -   Epoch: 142 | Batch: 1800/4327 (42%) | G Loss: 1.924590 | C Loss: -0.703357\n",
      "07/06/2022 18:57:17 - INFO - __main__ -   Text: ['However, in 2013, a small decrease in oral environmental changes since then allowed before she was told a few naps']\n",
      "07/06/2022 18:57:19 - INFO - __main__ -   Epoch: 142 | Batch: 2400/4327 (55%) | G Loss: 1.923396 | C Loss: -0.735370\n",
      "07/06/2022 18:57:19 - INFO - __main__ -   Text: ['Medicine typically requires only minimal treatment from the patient, although a few days of treatment, though, may lift his']\n",
      "07/06/2022 18:57:21 - INFO - __main__ -   Epoch: 142 | Batch: 3000/4327 (69%) | G Loss: 2.001837 | C Loss: -0.473326\n",
      "07/06/2022 18:57:21 - INFO - __main__ -   Text: [\"The latest sign accompanying Crowley's call for higher doses: a neurosurgeon warns that Crowley may produce acid, the\"]\n",
      "07/06/2022 18:57:23 - INFO - __main__ -   Epoch: 142 | Batch: 3600/4327 (83%) | G Loss: 1.856414 | C Loss: -0.890807\n",
      "07/06/2022 18:57:23 - INFO - __main__ -   Text: ['18 cards has not worked flawlessly !']\n",
      "07/06/2022 18:57:25 - INFO - __main__ -   Epoch: 142 | Batch: 4200/4327 (97%) | G Loss: 1.961168 | C Loss: -1.918265\n",
      "07/06/2022 18:57:25 - INFO - __main__ -   Text: ['This was certainly a huge outrage as surprise, it is now an image problem and one of the last pick up on']\n",
      "07/06/2022 18:57:26 - INFO - __main__ -   * (Train) Epoch: 142 | G Loss: 1.8653 | C Loss: -0.8569 | Updates G: 13 | Updates C: 347\n",
      "07/06/2022 18:57:40 - INFO - __main__ -   Bleu-2:0.456 | B-Bleu-2:0.301\n",
      "07/06/2022 18:57:40 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7568159383870032\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 143 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:00:08 - INFO - __main__ -   Epoch: 143 | Batch: 0/4417 (0%) | G Loss: 1.907950 | C Loss: -2.002606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.110\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:00:08 - INFO - __main__ -   Text: ['It was 6 months after the first physical contraction, at first in urine and over 42 days after the eighth serious step']\n",
      "07/06/2022 19:00:10 - INFO - __main__ -   Epoch: 143 | Batch: 600/4417 (14%) | G Loss: 1.770474 | C Loss: -0.242525\n",
      "07/06/2022 19:00:10 - INFO - __main__ -   Text: ['and I play cricket every entire month, but the only thing that really works for me is that I have to get']\n",
      "07/06/2022 19:00:12 - INFO - __main__ -   Epoch: 143 | Batch: 1200/4417 (27%) | G Loss: 1.917899 | C Loss: -0.697339\n",
      "07/06/2022 19:00:13 - INFO - __main__ -   Text: ['The drinkings happened at 3am, so he had it deduced that the first drink he had completed, last']\n",
      "07/06/2022 19:00:15 - INFO - __main__ -   Epoch: 143 | Batch: 1800/4417 (41%) | G Loss: 1.956764 | C Loss: -1.347622\n",
      "07/06/2022 19:00:15 - INFO - __main__ -   Text: ['Affecting the weight loss is the Taruna Wand wand.']\n",
      "07/06/2022 19:00:17 - INFO - __main__ -   Epoch: 143 | Batch: 2400/4417 (54%) | G Loss: 1.809801 | C Loss: -0.690601\n",
      "07/06/2022 19:00:17 - INFO - __main__ -   Text: ['A huge say you should always call them Botanical but not Fitlivalid you).\"']\n",
      "07/06/2022 19:00:19 - INFO - __main__ -   Epoch: 143 | Batch: 3000/4417 (68%) | G Loss: 1.845589 | C Loss: -0.707859\n",
      "07/06/2022 19:00:19 - INFO - __main__ -   Text: ['It was when Gülçert began his experiment, that he lost the last family member from whom he had']\n",
      "07/06/2022 19:00:21 - INFO - __main__ -   Epoch: 143 | Batch: 3600/4417 (82%) | G Loss: 1.947714 | C Loss: -0.803685\n",
      "07/06/2022 19:00:21 - INFO - __main__ -   Text: ['Trench doesn\\'t get anymore.\"']\n",
      "07/06/2022 19:00:23 - INFO - __main__ -   Epoch: 143 | Batch: 4200/4417 (95%) | G Loss: 1.949903 | C Loss: -0.861315\n",
      "07/06/2022 19:00:23 - INFO - __main__ -   Text: ['In the post-partum period, he had been using his right caesarean to cough, right']\n",
      "07/06/2022 19:00:24 - INFO - __main__ -   * (Train) Epoch: 143 | G Loss: 1.9143 | C Loss: -0.8322 | Updates G: 27 | Updates C: 341\n",
      "07/06/2022 19:00:38 - INFO - __main__ -   Bleu-2:0.459 | B-Bleu-2:0.319\n",
      "07/06/2022 19:00:38 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7774995160219752\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 144 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:03:07 - INFO - __main__ -   Epoch: 144 | Batch: 0/4322 (0%) | G Loss: 1.818962 | C Loss: -0.438066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.273\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:03:07 - INFO - __main__ -   Text: ['Finally, Masayoshi passed away, but the researchers found \"a small, fruitless process that resulted in limited']\n",
      "07/06/2022 19:03:09 - INFO - __main__ -   Epoch: 144 | Batch: 600/4322 (14%) | G Loss: 2.142153 | C Loss: -0.586839\n",
      "07/06/2022 19:03:09 - INFO - __main__ -   Text: ['No more abruptly noting having slept two or three times daily on the night before so has�re been tested* and']\n",
      "07/06/2022 19:03:11 - INFO - __main__ -   Epoch: 144 | Batch: 1200/4322 (28%) | G Loss: 1.726292 | C Loss: -1.062019\n",
      "07/06/2022 19:03:11 - INFO - __main__ -   Text: [\"Again in the sections 'Abbas' and 'Abbas' appear to be sentence inactive while PV of\"]\n",
      "07/06/2022 19:03:13 - INFO - __main__ -   Epoch: 144 | Batch: 1800/4322 (42%) | G Loss: 1.769233 | C Loss: -0.684218\n",
      "07/06/2022 19:03:13 - INFO - __main__ -   Text: ['At the age of 24 Awareness Day now, his vision turns off when he and his brother appear on a']\n",
      "07/06/2022 19:03:15 - INFO - __main__ -   Epoch: 144 | Batch: 2400/4322 (56%) | G Loss: 1.956564 | C Loss: -0.412547\n",
      "07/06/2022 19:03:16 - INFO - __main__ -   Text: ['Fiacin rose over 139 pounds during this process and passed out every night except March 22 at noon, when']\n",
      "07/06/2022 19:03:18 - INFO - __main__ -   Epoch: 144 | Batch: 3000/4322 (69%) | G Loss: 1.750758 | C Loss: -0.883120\n",
      "07/06/2022 19:03:18 - INFO - __main__ -   Text: ['Her song is \"card\".']\n",
      "07/06/2022 19:03:20 - INFO - __main__ -   Epoch: 144 | Batch: 3600/4322 (83%) | G Loss: 1.507663 | C Loss: -0.537620\n",
      "07/06/2022 19:03:20 - INFO - __main__ -   Text: ['This is what I call \\'post office.\\'\"']\n",
      "07/06/2022 19:03:22 - INFO - __main__ -   Epoch: 144 | Batch: 4200/4322 (97%) | G Loss: 1.926731 | C Loss: -1.709287\n",
      "07/06/2022 19:03:22 - INFO - __main__ -   Text: ['Moxie gets out of reverie, says \"Sorry again, Omni$king is in no doubt the best']\n",
      "07/06/2022 19:03:22 - INFO - __main__ -   * (Train) Epoch: 144 | G Loss: 1.8586 | C Loss: -0.8550 | Updates G: 23 | Updates C: 337\n",
      "07/06/2022 19:03:36 - INFO - __main__ -   Bleu-2:0.455 | B-Bleu-2:0.326\n",
      "07/06/2022 19:03:36 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780776376721882\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 145 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:06:04 - INFO - __main__ -   Epoch: 145 | Batch: 0/4527 (0%) | G Loss: 1.749422 | C Loss: -0.421422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.854\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:06:05 - INFO - __main__ -   Text: ['But Yeoyobo selflessly packed onto his Sony computer a bag full of programmes given simultaneously for eight different hours and']\n",
      "07/06/2022 19:06:06 - INFO - __main__ -   Epoch: 145 | Batch: 600/4527 (13%) | G Loss: 1.787328 | C Loss: -0.612038\n",
      "07/06/2022 19:06:07 - INFO - __main__ -   Text: ['It does not need an intensity controlling knife, because this one is thermoplastic.\"']\n",
      "07/06/2022 19:06:09 - INFO - __main__ -   Epoch: 145 | Batch: 1200/4527 (27%) | G Loss: 2.487725 | C Loss: -1.032747\n",
      "07/06/2022 19:06:09 - INFO - __main__ -   Text: ['A lot of them I have cocked their brains in zero knots before each song can actually get that low and they']\n",
      "07/06/2022 19:06:11 - INFO - __main__ -   Epoch: 145 | Batch: 1800/4527 (40%) | G Loss: 1.948594 | C Loss: -0.442002\n",
      "07/06/2022 19:06:11 - INFO - __main__ -   Text: ['While in and out, a team of doctors based on determined rides with hydroxy-dystrophin']\n",
      "07/06/2022 19:06:13 - INFO - __main__ -   Epoch: 145 | Batch: 2400/4527 (53%) | G Loss: 1.758888 | C Loss: -0.391966\n",
      "07/06/2022 19:06:13 - INFO - __main__ -   Text: ['Flinging constantly on his bed for weeks and days is one of his many nutrition challenges.']\n",
      "07/06/2022 19:06:15 - INFO - __main__ -   Epoch: 145 | Batch: 3000/4527 (66%) | G Loss: 1.620608 | C Loss: -1.177806\n",
      "07/06/2022 19:06:15 - INFO - __main__ -   Text: ['Since its release, the app provides a selection of under that name and returns even if you have deleted your grocery']\n",
      "07/06/2022 19:06:17 - INFO - __main__ -   Epoch: 145 | Batch: 3600/4527 (80%) | G Loss: 2.093366 | C Loss: -0.825617\n",
      "07/06/2022 19:06:17 - INFO - __main__ -   Text: [\"If you don't have any alcohol in your drink, Delta closes the window on breathing, because if the person who\"]\n",
      "07/06/2022 19:06:19 - INFO - __main__ -   Epoch: 145 | Batch: 4200/4527 (93%) | G Loss: 1.888530 | C Loss: -0.568592\n",
      "07/06/2022 19:06:20 - INFO - __main__ -   Text: ['But after like 1 1-1/2 years of trial and error I realise there just is nothing, however']\n",
      "07/06/2022 19:06:21 - INFO - __main__ -   * (Train) Epoch: 145 | G Loss: 1.8646 | C Loss: -0.8685 | Updates G: 27 | Updates C: 350\n",
      "07/06/2022 19:06:35 - INFO - __main__ -   Bleu-2:0.476 | B-Bleu-2:0.340\n",
      "07/06/2022 19:06:35 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157030051651851\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 146 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:09:03 - INFO - __main__ -   Epoch: 146 | Batch: 0/4467 (0%) | G Loss: 2.086386 | C Loss: -0.817917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.168\n",
      "  Test Loss: 4.879\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:09:04 - INFO - __main__ -   Text: ['David says that: mango is audible; doughnuts are unheard; orange is a pseudonym.']\n",
      "07/06/2022 19:09:05 - INFO - __main__ -   Epoch: 146 | Batch: 600/4467 (13%) | G Loss: 2.021978 | C Loss: -0.523503\n",
      "07/06/2022 19:09:06 - INFO - __main__ -   Text: ['In a study conducted in 2011, Pratenscan was given diethylamine after consumption of']\n",
      "07/06/2022 19:09:08 - INFO - __main__ -   Epoch: 146 | Batch: 1200/4467 (27%) | G Loss: 1.798450 | C Loss: -0.654044\n",
      "07/06/2022 19:09:08 - INFO - __main__ -   Text: [\"if it's.\"]\n",
      "07/06/2022 19:09:10 - INFO - __main__ -   Epoch: 146 | Batch: 1800/4467 (40%) | G Loss: 2.381531 | C Loss: -0.785595\n",
      "07/06/2022 19:09:10 - INFO - __main__ -   Text: ['This is a way to gain more clarity of mood.\"']\n",
      "07/06/2022 19:09:12 - INFO - __main__ -   Epoch: 146 | Batch: 2400/4467 (54%) | G Loss: 1.368706 | C Loss: -0.309536\n",
      "07/06/2022 19:09:12 - INFO - __main__ -   Text: ['The order is \"icatesor serages\" (though few share the name).']\n",
      "07/06/2022 19:09:14 - INFO - __main__ -   Epoch: 146 | Batch: 3000/4467 (67%) | G Loss: 2.046118 | C Loss: -1.825748\n",
      "07/06/2022 19:09:14 - INFO - __main__ -   Text: ['<html><html><html>(refine, even)</html>§<<div>']\n",
      "07/06/2022 19:09:16 - INFO - __main__ -   Epoch: 146 | Batch: 3600/4467 (81%) | G Loss: 1.898860 | C Loss: -0.554114\n",
      "07/06/2022 19:09:16 - INFO - __main__ -   Text: ['This 📙 should be one specimen when it comes to upturn symptom formulated weighing around 30lbs after fading 33']\n",
      "07/06/2022 19:09:18 - INFO - __main__ -   Epoch: 146 | Batch: 4200/4467 (94%) | G Loss: 1.730930 | C Loss: -0.795345\n",
      "07/06/2022 19:09:18 - INFO - __main__ -   Text: ['Its appendages can take up to 6 hours to heal, which increases with time given by the doctor who punctures']\n",
      "07/06/2022 19:09:19 - INFO - __main__ -   * (Train) Epoch: 146 | G Loss: 1.9253 | C Loss: -0.8790 | Updates G: 28 | Updates C: 344\n",
      "07/06/2022 19:09:33 - INFO - __main__ -   Bleu-2:0.452 | B-Bleu-2:0.326\n",
      "07/06/2022 19:09:33 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7783820722940865\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 147 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:12:02 - INFO - __main__ -   Epoch: 147 | Batch: 0/4364 (0%) | G Loss: 1.877312 | C Loss: -0.713698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.185\n",
      "  Test Loss: 4.940\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:12:02 - INFO - __main__ -   Text: ['It takes seven days or so and I actually realise that I will miss it\", Contrast said after his have spent several']\n",
      "07/06/2022 19:12:04 - INFO - __main__ -   Epoch: 147 | Batch: 600/4364 (14%) | G Loss: 2.664682 | C Loss: -1.085886\n",
      "07/06/2022 19:12:04 - INFO - __main__ -   Text: ['Raymond extensively researched disturbing sleep patterns and injuries that he could not explain as scientifically harmless.']\n",
      "07/06/2022 19:12:06 - INFO - __main__ -   Epoch: 147 | Batch: 1200/4364 (27%) | G Loss: 1.557349 | C Loss: -0.801383\n",
      "07/06/2022 19:12:06 - INFO - __main__ -   Text: ['A-!']\n",
      "07/06/2022 19:12:08 - INFO - __main__ -   Epoch: 147 | Batch: 1800/4364 (41%) | G Loss: 1.383966 | C Loss: -0.545086\n",
      "07/06/2022 19:12:08 - INFO - __main__ -   Text: ['In 2011, she reported to have only one ovulation via early morning rise, while this was from 1 April 2008']\n",
      "07/06/2022 19:12:10 - INFO - __main__ -   Epoch: 147 | Batch: 2400/4364 (55%) | G Loss: 1.906004 | C Loss: -2.119421\n",
      "07/06/2022 19:12:10 - INFO - __main__ -   Text: ['He believes this to be the last pagan birthday party he ever started, because it gives ZILLENN a good chance']\n",
      "07/06/2022 19:12:12 - INFO - __main__ -   Epoch: 147 | Batch: 3000/4364 (69%) | G Loss: 1.836438 | C Loss: -1.099213\n",
      "07/06/2022 19:12:13 - INFO - __main__ -   Text: ['Though for no apparent reason, one of her cousins the major supplementing area of playstime\" testified to being']\n",
      "07/06/2022 19:12:15 - INFO - __main__ -   Epoch: 147 | Batch: 3600/4364 (82%) | G Loss: 1.690955 | C Loss: -0.731029\n",
      "07/06/2022 19:12:15 - INFO - __main__ -   Text: ['When listening to Deep Dizzy, Brodsky has clarified to Blacks 96.7kHz saying that \"My life']\n",
      "07/06/2022 19:12:17 - INFO - __main__ -   Epoch: 147 | Batch: 4200/4364 (96%) | G Loss: 2.018579 | C Loss: -0.944742\n",
      "07/06/2022 19:12:17 - INFO - __main__ -   Text: ['It has been reported that females suffering from the dysphoric stress due to seizures or seizures and/or seizures made up']\n",
      "07/06/2022 19:12:18 - INFO - __main__ -   * (Train) Epoch: 147 | G Loss: 1.9160 | C Loss: -0.8584 | Updates G: 23 | Updates C: 340\n",
      "07/06/2022 19:12:31 - INFO - __main__ -   Bleu-2:0.449 | B-Bleu-2:0.313\n",
      "07/06/2022 19:12:31 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7618861973736282\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 148 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:15:00 - INFO - __main__ -   Epoch: 148 | Batch: 0/4330 (0%) | G Loss: 1.501900 | C Loss: -0.647613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 5.068\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:15:00 - INFO - __main__ -   Text: [\"Under Kent Goldsmith's unexpected direction, Rajada's first Kidol diversion was a series of infrequently scheduled rides\"]\n",
      "07/06/2022 19:15:02 - INFO - __main__ -   Epoch: 148 | Batch: 600/4330 (14%) | G Loss: 1.674490 | C Loss: -1.836689\n",
      "07/06/2022 19:15:02 - INFO - __main__ -   Text: ['He was still receiving treatment for osteoporosis, and his mother monitored his fertility much earlier, earning her a']\n",
      "07/06/2022 19:15:04 - INFO - __main__ -   Epoch: 148 | Batch: 1200/4330 (28%) | G Loss: 2.365194 | C Loss: -1.776759\n",
      "07/06/2022 19:15:05 - INFO - __main__ -   Text: ['After a few days the poor girl gets caught and the police report that she told incorrect formula,']\n",
      "07/06/2022 19:15:06 - INFO - __main__ -   Epoch: 148 | Batch: 1800/4330 (42%) | G Loss: 2.561666 | C Loss: -1.116611\n",
      "07/06/2022 19:15:07 - INFO - __main__ -   Text: ['Pashar gets into a fumble on the next pitch where the batsman manages to hold on to the ball,']\n",
      "07/06/2022 19:15:08 - INFO - __main__ -   Epoch: 148 | Batch: 2400/4330 (55%) | G Loss: 2.524104 | C Loss: -1.877837\n",
      "07/06/2022 19:15:09 - INFO - __main__ -   Text: ['It is reported that Shiva drank over 300mg of ibuprofen per week, according to the website, which']\n",
      "07/06/2022 19:15:11 - INFO - __main__ -   Epoch: 148 | Batch: 3000/4330 (69%) | G Loss: 2.461189 | C Loss: -0.865564\n",
      "07/06/2022 19:15:11 - INFO - __main__ -   Text: ['The top3 pudding passes beyond any prep of time and has the lowest Vive complication of the year when howl of']\n",
      "07/06/2022 19:15:13 - INFO - __main__ -   Epoch: 148 | Batch: 3600/4330 (83%) | G Loss: 1.553577 | C Loss: -0.517567\n",
      "07/06/2022 19:15:13 - INFO - __main__ -   Text: ['Because of the severe deficiency of norethisterone in numbers, and the heroin given to my 15 hour old']\n",
      "07/06/2022 19:15:15 - INFO - __main__ -   Epoch: 148 | Batch: 4200/4330 (97%) | G Loss: 1.689586 | C Loss: -0.589206\n",
      "07/06/2022 19:15:15 - INFO - __main__ -   Text: ['啰\"朌竜]: Blossom politician and H俠飯志 伙 decided']\n",
      "07/06/2022 19:15:16 - INFO - __main__ -   * (Train) Epoch: 148 | G Loss: 1.9112 | C Loss: -0.8797 | Updates G: 24 | Updates C: 336\n",
      "07/06/2022 19:15:30 - INFO - __main__ -   Bleu-2:0.451 | B-Bleu-2:0.313\n",
      "07/06/2022 19:15:30 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7639229059385995\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 149 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:11.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:17:58 - INFO - __main__ -   Epoch: 149 | Batch: 0/4372 (0%) | G Loss: 1.464186 | C Loss: -0.563089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.190\n",
      "  Test Loss: 5.048\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:17:58 - INFO - __main__ -   Text: ['When later told she had the flu vaccine with phenobarbutine remaining sidelined in high doses for years after being warned']\n",
      "07/06/2022 19:18:00 - INFO - __main__ -   Epoch: 149 | Batch: 600/4372 (14%) | G Loss: 1.703269 | C Loss: -0.361124\n",
      "07/06/2022 19:18:01 - INFO - __main__ -   Text: ['Currently, the nurse injects on a daily basis passes the medication for five days before going on to']\n",
      "07/06/2022 19:18:03 - INFO - __main__ -   Epoch: 149 | Batch: 1200/4372 (27%) | G Loss: 2.053607 | C Loss: -1.146946\n",
      "07/06/2022 19:18:03 - INFO - __main__ -   Text: ['Either shayi of male students may decide to seduce a male student with the use of saliva']\n",
      "07/06/2022 19:18:05 - INFO - __main__ -   Epoch: 149 | Batch: 1800/4372 (41%) | G Loss: 1.935981 | C Loss: -0.206340\n",
      "07/06/2022 19:18:05 - INFO - __main__ -   Text: ['The person remains as healthy as the usual, but pills are used, fraudulently, during temporary withdrawal, thus']\n",
      "07/06/2022 19:18:07 - INFO - __main__ -   Epoch: 149 | Batch: 2400/4372 (55%) | G Loss: 2.330952 | C Loss: -1.204022\n",
      "07/06/2022 19:18:07 - INFO - __main__ -   Text: ['The symptoms included skin infection where there was hope for pre-exposure prophylaxis of the drug and swelling']\n",
      "07/06/2022 19:18:09 - INFO - __main__ -   Epoch: 149 | Batch: 3000/4372 (69%) | G Loss: 2.507704 | C Loss: -0.981578\n",
      "07/06/2022 19:18:10 - INFO - __main__ -   Text: ['In the past, she has lost her income and she has had to keep searching for better sleep because no alibi']\n",
      "07/06/2022 19:18:11 - INFO - __main__ -   Epoch: 149 | Batch: 3600/4372 (82%) | G Loss: 1.808350 | C Loss: -1.467519\n",
      "07/06/2022 19:18:12 - INFO - __main__ -   Text: ['The module hits delirious, but then it goes for \"3000b00\" - but in this guy\\'s']\n",
      "07/06/2022 19:18:14 - INFO - __main__ -   Epoch: 149 | Batch: 4200/4372 (96%) | G Loss: 1.648506 | C Loss: -0.557333\n",
      "07/06/2022 19:18:14 - INFO - __main__ -   Text: ['They ask me for explaining too much.\"']\n",
      "07/06/2022 19:18:14 - INFO - __main__ -   * (Train) Epoch: 149 | G Loss: 1.8306 | C Loss: -0.8711 | Updates G: 17 | Updates C: 347\n",
      "07/06/2022 19:18:28 - INFO - __main__ -   Bleu-2:0.470 | B-Bleu-2:0.333\n",
      "07/06/2022 19:18:28 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80309547200791\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 150 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:20:57 - INFO - __main__ -   Epoch: 150 | Batch: 0/4473 (0%) | G Loss: 1.917468 | C Loss: -0.717246\n",
      "07/06/2022 19:20:57 - INFO - __main__ -   Text: ['Similar explanations have been attempted for the \"Raph\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 5.873\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:20:59 - INFO - __main__ -   Epoch: 150 | Batch: 600/4473 (13%) | G Loss: 2.294044 | C Loss: -0.647666\n",
      "07/06/2022 19:20:59 - INFO - __main__ -   Text: ['Steelarbonate, reduce your arousal and lower your arousal, reacting faster and making more and more strenuous periods of']\n",
      "07/06/2022 19:21:01 - INFO - __main__ -   Epoch: 150 | Batch: 1200/4473 (27%) | G Loss: 2.501880 | C Loss: -0.757023\n",
      "07/06/2022 19:21:01 - INFO - __main__ -   Text: ['Top.']\n",
      "07/06/2022 19:21:03 - INFO - __main__ -   Epoch: 150 | Batch: 1800/4473 (40%) | G Loss: 2.584756 | C Loss: -0.692453\n",
      "07/06/2022 19:21:03 - INFO - __main__ -   Text: ['Globally, pain suppressant and β-essa extracts improve posture and movement.']\n",
      "07/06/2022 19:21:05 - INFO - __main__ -   Epoch: 150 | Batch: 2400/4473 (54%) | G Loss: 2.346684 | C Loss: -0.805598\n",
      "07/06/2022 19:21:05 - INFO - __main__ -   Text: ['However, Ruppler said dosage is based on safety and never on profit; this is especially true when a drug']\n",
      "07/06/2022 19:21:08 - INFO - __main__ -   Epoch: 150 | Batch: 3000/4473 (67%) | G Loss: 1.807232 | C Loss: -0.646170\n",
      "07/06/2022 19:21:08 - INFO - __main__ -   Text: ['Levitraptor pills for three days prior to a \"special\" dose of the drug toeterone,']\n",
      "07/06/2022 19:21:10 - INFO - __main__ -   Epoch: 150 | Batch: 3600/4473 (80%) | G Loss: 2.108589 | C Loss: -0.656856\n",
      "07/06/2022 19:21:10 - INFO - __main__ -   Text: ['While other balanced telesers might not have been able to prevent they remains this ability later and has decreased diets,']\n",
      "07/06/2022 19:21:12 - INFO - __main__ -   Epoch: 150 | Batch: 4200/4473 (94%) | G Loss: 1.945178 | C Loss: -0.553679\n",
      "07/06/2022 19:21:12 - INFO - __main__ -   Text: ['In the follow-up to the current case of bladder cancer, the doctor agreed to perform an intramuscular']\n",
      "07/06/2022 19:21:13 - INFO - __main__ -   * (Train) Epoch: 150 | G Loss: 2.0464 | C Loss: -0.8715 | Updates G: 19 | Updates C: 353\n",
      "07/06/2022 19:21:27 - INFO - __main__ -   Bleu-2:0.437 | B-Bleu-2:0.305\n",
      "07/06/2022 19:21:27 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.741439295896146\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 151 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:22.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:11.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:23:56 - INFO - __main__ -   Epoch: 151 | Batch: 0/4473 (0%) | G Loss: 2.120007 | C Loss: -1.868573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.124\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:23:56 - INFO - __main__ -   Text: ['In elementary, students reading this reading material never lose sight of their students learning a new language and often repeat this reading']\n",
      "07/06/2022 19:23:58 - INFO - __main__ -   Epoch: 151 | Batch: 600/4473 (13%) | G Loss: 2.294262 | C Loss: -0.837436\n",
      "07/06/2022 19:23:58 - INFO - __main__ -   Text: ['The CDMoka test illustrates a higher glucose uptake rate with insulin as 36 h for 6 min with a']\n",
      "07/06/2022 19:24:00 - INFO - __main__ -   Epoch: 151 | Batch: 1200/4473 (27%) | G Loss: 1.838561 | C Loss: -0.444461\n",
      "07/06/2022 19:24:00 - INFO - __main__ -   Text: ['I think NERV Lewis is one of the original wave 10 most outcast.']\n",
      "07/06/2022 19:24:02 - INFO - __main__ -   Epoch: 151 | Batch: 1800/4473 (40%) | G Loss: 2.289104 | C Loss: -0.920938\n",
      "07/06/2022 19:24:02 - INFO - __main__ -   Text: ['At puberty, heroseli biology develops, the sex demonstration turned into an immature movement where I once ate excessively hard']\n",
      "07/06/2022 19:24:04 - INFO - __main__ -   Epoch: 151 | Batch: 2400/4473 (54%) | G Loss: 2.089818 | C Loss: -0.535116\n",
      "07/06/2022 19:24:05 - INFO - __main__ -   Text: ['But as soon as he left the lounge the bulges in his gigantic hair already became diagnosed, and was then forcefully']\n",
      "07/06/2022 19:24:07 - INFO - __main__ -   Epoch: 151 | Batch: 3000/4473 (67%) | G Loss: 1.984237 | C Loss: -0.812643\n",
      "07/06/2022 19:24:07 - INFO - __main__ -   Text: ['A term of month reduces the pain suffering (during first visit to the toilet) due to pressure from jhs signs']\n",
      "07/06/2022 19:24:09 - INFO - __main__ -   Epoch: 151 | Batch: 3600/4473 (80%) | G Loss: 2.080307 | C Loss: -0.498881\n",
      "07/06/2022 19:24:09 - INFO - __main__ -   Text: ['<text=\"reddit spanking> acne makes a big dent in the <down> I finish my insulin layreen']\n",
      "07/06/2022 19:24:11 - INFO - __main__ -   Epoch: 151 | Batch: 4200/4473 (94%) | G Loss: 2.691958 | C Loss: -1.075976\n",
      "07/06/2022 19:24:11 - INFO - __main__ -   Text: ['In each breath, he does energetic training shots, his blood flow either increases or decreases depending on whomever']\n",
      "07/06/2022 19:24:12 - INFO - __main__ -   * (Train) Epoch: 151 | G Loss: 2.1149 | C Loss: -0.8905 | Updates G: 19 | Updates C: 353\n",
      "07/06/2022 19:24:26 - INFO - __main__ -   Bleu-2:0.464 | B-Bleu-2:0.320\n",
      "07/06/2022 19:24:26 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7837705863994298\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 152 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:26:54 - INFO - __main__ -   Epoch: 152 | Batch: 0/4327 (0%) | G Loss: 1.984299 | C Loss: -1.135731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.026\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:26:55 - INFO - __main__ -   Text: ['Concern extends beyond just the fact that she is quite a lovely blonde, having given each pair of eyes beyond the two']\n",
      "07/06/2022 19:26:57 - INFO - __main__ -   Epoch: 152 | Batch: 600/4327 (14%) | G Loss: 2.121805 | C Loss: -1.585081\n",
      "07/06/2022 19:26:57 - INFO - __main__ -   Text: ['The exercise of swallowing is still increasing rapidly over the long haul, but in some cases the pain in the body is']\n",
      "07/06/2022 19:26:59 - INFO - __main__ -   Epoch: 152 | Batch: 1200/4327 (28%) | G Loss: 1.818232 | C Loss: -0.648293\n",
      "07/06/2022 19:26:59 - INFO - __main__ -   Text: ['Two firms have given out placebo pills totalling five nanograms of the corticosteroid/dose which can adversely']\n",
      "07/06/2022 19:27:01 - INFO - __main__ -   Epoch: 152 | Batch: 1800/4327 (42%) | G Loss: 1.563626 | C Loss: -0.555593\n",
      "07/06/2022 19:27:01 - INFO - __main__ -   Text: ['The abundant urine he used after nutrition was pure—19.60 hours, 16.00 hours, 10.40']\n",
      "07/06/2022 19:27:03 - INFO - __main__ -   Epoch: 152 | Batch: 2400/4327 (55%) | G Loss: 1.849983 | C Loss: -1.377542\n",
      "07/06/2022 19:27:03 - INFO - __main__ -   Text: ['Li Shinyanshi made steady progress, and she is now crossed out because Pink Floyd once banned her from doing album']\n",
      "07/06/2022 19:27:06 - INFO - __main__ -   Epoch: 152 | Batch: 3000/4327 (69%) | G Loss: 2.580639 | C Loss: -1.383840\n",
      "07/06/2022 19:27:06 - INFO - __main__ -   Text: ['The test results turned out to be a regulated (average) dosage of hormones, the equivalent of 36 CPM.)']\n",
      "07/06/2022 19:27:08 - INFO - __main__ -   Epoch: 152 | Batch: 3600/4327 (83%) | G Loss: 1.825310 | C Loss: -0.775903\n",
      "07/06/2022 19:27:08 - INFO - __main__ -   Text: ['Stefanie is a weekly dieting medication for her \"converlin rich\" brain cancer patient, who stopped eating']\n",
      "07/06/2022 19:27:10 - INFO - __main__ -   Epoch: 152 | Batch: 4200/4327 (97%) | G Loss: 1.615345 | C Loss: -0.321248\n",
      "07/06/2022 19:27:10 - INFO - __main__ -   Text: ['<no>Dyne is bioinformatics 219 and <about 4 hours --> coughPennington Pennington Metro']\n",
      "07/06/2022 19:27:10 - INFO - __main__ -   * (Train) Epoch: 152 | G Loss: 1.9982 | C Loss: -0.8896 | Updates G: 19 | Updates C: 341\n",
      "07/06/2022 19:27:24 - INFO - __main__ -   Bleu-2:0.476 | B-Bleu-2:0.332\n",
      "07/06/2022 19:27:24 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8071819473366602\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 153 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:29:53 - INFO - __main__ -   Epoch: 153 | Batch: 0/4417 (0%) | G Loss: 1.669795 | C Loss: -1.372276\n",
      "07/06/2022 19:29:53 - INFO - __main__ -   Text: ['It\\'s like, oh, only that bowl!\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 4.846\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:29:55 - INFO - __main__ -   Epoch: 153 | Batch: 600/4417 (14%) | G Loss: 2.238127 | C Loss: -0.370891\n",
      "07/06/2022 19:29:55 - INFO - __main__ -   Text: [\"Coronary's discharge is serious enough to require invasive IV manipulations to you or its slid therapy to eat\"]\n",
      "07/06/2022 19:29:57 - INFO - __main__ -   Epoch: 153 | Batch: 1200/4417 (27%) | G Loss: 2.843356 | C Loss: -1.106532\n",
      "07/06/2022 19:29:57 - INFO - __main__ -   Text: ['There is a risk report that only buffit boosters may be tootent, useaway, dosed with']\n",
      "07/06/2022 19:29:59 - INFO - __main__ -   Epoch: 153 | Batch: 1800/4417 (41%) | G Loss: 2.134899 | C Loss: -0.645437\n",
      "07/06/2022 19:30:00 - INFO - __main__ -   Text: ['Their experienced partner on the first day is very vulnerable and has received only five to seven pills for her chronic inflammation at']\n",
      "07/06/2022 19:30:01 - INFO - __main__ -   Epoch: 153 | Batch: 2400/4417 (54%) | G Loss: 1.781537 | C Loss: -0.243018\n",
      "07/06/2022 19:30:02 - INFO - __main__ -   Text: ['Nevertheless, everyone I know has a fiction tablet as their tablet is probably ripping up the photo comings across my smartphone']\n",
      "07/06/2022 19:30:04 - INFO - __main__ -   Epoch: 153 | Batch: 3000/4417 (68%) | G Loss: 1.805850 | C Loss: -0.787240\n",
      "07/06/2022 19:30:04 - INFO - __main__ -   Text: ['Piggy topics generally follow some rather short-lived trough’s: \"Islands; Legs;']\n",
      "07/06/2022 19:30:06 - INFO - __main__ -   Epoch: 153 | Batch: 3600/4417 (82%) | G Loss: 1.971635 | C Loss: -0.541289\n",
      "07/06/2022 19:30:06 - INFO - __main__ -   Text: ['The box says, \"You are being used for Jury Duty (for muja mana) with your fines due']\n",
      "07/06/2022 19:30:08 - INFO - __main__ -   Epoch: 153 | Batch: 4200/4417 (95%) | G Loss: 1.908577 | C Loss: -0.608438\n",
      "07/06/2022 19:30:08 - INFO - __main__ -   Text: ['The next day, Stage 4 was not done and Devananda noticed the pulse of EATO was significantly']\n",
      "07/06/2022 19:30:09 - INFO - __main__ -   * (Train) Epoch: 153 | G Loss: 2.0267 | C Loss: -0.8947 | Updates G: 13 | Updates C: 355\n",
      "07/06/2022 19:30:23 - INFO - __main__ -   Bleu-2:0.448 | B-Bleu-2:0.323\n",
      "07/06/2022 19:30:23 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.770768708056701\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 154 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:32:51 - INFO - __main__ -   Epoch: 154 | Batch: 0/4322 (0%) | G Loss: 2.023305 | C Loss: -1.007983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.011\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:32:52 - INFO - __main__ -   Text: [\"On another note “we're witnessing nature's inherent set and directional freedom violation when fields go from 0 to 4\"]\n",
      "07/06/2022 19:32:54 - INFO - __main__ -   Epoch: 154 | Batch: 600/4322 (14%) | G Loss: 2.020613 | C Loss: -0.825934\n",
      "07/06/2022 19:32:54 - INFO - __main__ -   Text: ['June 2014: See Rolling on Soda, see Moaning by Ice in my face, see Rolling on Soda, memory']\n",
      "07/06/2022 19:32:56 - INFO - __main__ -   Epoch: 154 | Batch: 1200/4322 (28%) | G Loss: 1.732370 | C Loss: -0.869544\n",
      "07/06/2022 19:32:56 - INFO - __main__ -   Text: ['He was rushed down to a nursing home before treatment, stuck in the dressing room for 2 hours while waiting for a']\n",
      "07/06/2022 19:32:58 - INFO - __main__ -   Epoch: 154 | Batch: 1800/4322 (42%) | G Loss: 1.717551 | C Loss: -0.741904\n",
      "07/06/2022 19:32:58 - INFO - __main__ -   Text: ['The game was simplest then because like I said before we businessmen sometimes get frustrated with drying beer, soup must be']\n",
      "07/06/2022 19:33:00 - INFO - __main__ -   Epoch: 154 | Batch: 2400/4322 (56%) | G Loss: 2.188653 | C Loss: -0.355784\n",
      "07/06/2022 19:33:00 - INFO - __main__ -   Text: [\"His longest shows for Donald Todd are sometimes more boring comedy, writ on Justin's lips than the word\"]\n",
      "07/06/2022 19:33:02 - INFO - __main__ -   Epoch: 154 | Batch: 3000/4322 (69%) | G Loss: 2.334142 | C Loss: -1.805023\n",
      "07/06/2022 19:33:03 - INFO - __main__ -   Text: ['The car was temporarily lost to the parents and subsequently re-introduced at some point but then kept on taking pains']\n",
      "07/06/2022 19:33:04 - INFO - __main__ -   Epoch: 154 | Batch: 3600/4322 (83%) | G Loss: 2.079594 | C Loss: -0.742245\n",
      "07/06/2022 19:33:05 - INFO - __main__ -   Text: ['increases the hormonal stress and food intake as well as might harbored some blood sugar crazy girls.']\n",
      "07/06/2022 19:33:07 - INFO - __main__ -   Epoch: 154 | Batch: 4200/4322 (97%) | G Loss: 1.515549 | C Loss: -0.497912\n",
      "07/06/2022 19:33:07 - INFO - __main__ -   Text: ['Despite all this progress, he has not stopped breastfeeding for 8-10 days in October or renewing around once a']\n",
      "07/06/2022 19:33:07 - INFO - __main__ -   * (Train) Epoch: 154 | G Loss: 2.0328 | C Loss: -0.9063 | Updates G: 28 | Updates C: 332\n",
      "07/06/2022 19:33:21 - INFO - __main__ -   Bleu-2:0.463 | B-Bleu-2:0.316\n",
      "07/06/2022 19:33:21 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778284231552249\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 155 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:35:50 - INFO - __main__ -   Epoch: 155 | Batch: 0/4527 (0%) | G Loss: 1.555902 | C Loss: -0.499074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 4.941\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:35:50 - INFO - __main__ -   Text: ['Below is what someone called \" Posts which are Modified : 4.27\".']\n",
      "07/06/2022 19:35:52 - INFO - __main__ -   Epoch: 155 | Batch: 600/4527 (13%) | G Loss: 1.751070 | C Loss: -0.624555\n",
      "07/06/2022 19:35:52 - INFO - __main__ -   Text: ['Cromedy\\'s father called her a \"little ditz\" when she was a baby — that practice was terminated when']\n",
      "07/06/2022 19:35:54 - INFO - __main__ -   Epoch: 155 | Batch: 1200/4527 (27%) | G Loss: 2.515255 | C Loss: -1.220334\n",
      "07/06/2022 19:35:54 - INFO - __main__ -   Text: ['However, a bad cough, poor grades, failing to recall clothes or medicine, certain medications, diabetes and surgery would']\n",
      "07/06/2022 19:35:56 - INFO - __main__ -   Epoch: 155 | Batch: 1800/4527 (40%) | G Loss: 1.798635 | C Loss: -0.686101\n",
      "07/06/2022 19:35:56 - INFO - __main__ -   Text: ['In between bouts of diarrhea, gymnast Sarit had his locker break overnight, when he ate a meal worth of']\n",
      "07/06/2022 19:35:58 - INFO - __main__ -   Epoch: 155 | Batch: 2400/4527 (53%) | G Loss: 1.717109 | C Loss: -0.616984\n",
      "07/06/2022 19:35:58 - INFO - __main__ -   Text: ['It is very regularly tolerated in normal routine and then strips rapidly and occasionally from the thigh and surrounding external appearance and the']\n",
      "07/06/2022 19:36:00 - INFO - __main__ -   Epoch: 155 | Batch: 3000/4527 (66%) | G Loss: 1.742064 | C Loss: -1.386670\n",
      "07/06/2022 19:36:00 - INFO - __main__ -   Text: ['Small changes, such as minimal weight loss, have reduced lifespan, though forgetful meals at night have taken place,']\n",
      "07/06/2022 19:36:02 - INFO - __main__ -   Epoch: 155 | Batch: 3600/4527 (80%) | G Loss: 2.233543 | C Loss: -0.584813\n",
      "07/06/2022 19:36:03 - INFO - __main__ -   Text: ['An added effect is that the lubricant is physically cleaner hadrolled once giving an excuse to stay empty for 10 minutes']\n",
      "07/06/2022 19:36:05 - INFO - __main__ -   Epoch: 155 | Batch: 4200/4527 (93%) | G Loss: 3.025759 | C Loss: -0.842823\n",
      "07/06/2022 19:36:05 - INFO - __main__ -   Text: ['It is my favorite!\"']\n",
      "07/06/2022 19:36:06 - INFO - __main__ -   * (Train) Epoch: 155 | G Loss: 1.9456 | C Loss: -0.9042 | Updates G: 31 | Updates C: 346\n",
      "07/06/2022 19:36:20 - INFO - __main__ -   Bleu-2:0.451 | B-Bleu-2:0.315\n",
      "07/06/2022 19:36:20 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7660120665299548\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 156 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:38:48 - INFO - __main__ -   Epoch: 156 | Batch: 0/4467 (0%) | G Loss: 2.419616 | C Loss: -0.687817\n",
      "07/06/2022 19:38:48 - INFO - __main__ -   Text: ['When I did work on it, it started eating up my other taste buds.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 4.750\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:38:50 - INFO - __main__ -   Epoch: 156 | Batch: 600/4467 (13%) | G Loss: 1.663702 | C Loss: -0.787432\n",
      "07/06/2022 19:38:50 - INFO - __main__ -   Text: ['Beginning from the release of his second album, \"Now You Got a Switch\" on September 2, 2018, this']\n",
      "07/06/2022 19:38:53 - INFO - __main__ -   Epoch: 156 | Batch: 1200/4467 (27%) | G Loss: 1.775848 | C Loss: -0.687371\n",
      "07/06/2022 19:38:53 - INFO - __main__ -   Text: ['Together with twin sisters Cindy Lee, Sita and John Krube, Silva used and licorice caused her practically']\n",
      "07/06/2022 19:38:55 - INFO - __main__ -   Epoch: 156 | Batch: 1800/4467 (40%) | G Loss: 1.604689 | C Loss: -1.609567\n",
      "07/06/2022 19:38:55 - INFO - __main__ -   Text: ['When deficiency can get out of control, the pink turns red and dehydrates,\" Alec Goudietlli said.']\n",
      "07/06/2022 19:38:57 - INFO - __main__ -   Epoch: 156 | Batch: 2400/4467 (54%) | G Loss: 2.049168 | C Loss: -0.438355\n",
      "07/06/2022 19:38:57 - INFO - __main__ -   Text: ['!']\n",
      "07/06/2022 19:38:59 - INFO - __main__ -   Epoch: 156 | Batch: 3000/4467 (67%) | G Loss: 2.160836 | C Loss: -0.520682\n",
      "07/06/2022 19:38:59 - INFO - __main__ -   Text: ['The last thing I know is that Sharyn Deakins on 16 February 2008, was making love~! He']\n",
      "07/06/2022 19:39:01 - INFO - __main__ -   Epoch: 156 | Batch: 3600/4467 (81%) | G Loss: 2.565382 | C Loss: -1.266828\n",
      "07/06/2022 19:39:01 - INFO - __main__ -   Text: ['He has had success with his dangerous dog formula, \"Pigechucky Primavera,\" given to him']\n",
      "07/06/2022 19:39:03 - INFO - __main__ -   Epoch: 156 | Batch: 4200/4467 (94%) | G Loss: 2.841806 | C Loss: -0.966650\n",
      "07/06/2022 19:39:03 - INFO - __main__ -   Text: ['By June 2010 the female aged between 6-17 months and 11.10 days had swollen to present on']\n",
      "07/06/2022 19:39:04 - INFO - __main__ -   * (Train) Epoch: 156 | G Loss: 1.9902 | C Loss: -0.9100 | Updates G: 22 | Updates C: 350\n",
      "07/06/2022 19:39:18 - INFO - __main__ -   Bleu-2:0.453 | B-Bleu-2:0.324\n",
      "07/06/2022 19:39:18 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7770583178136174\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 157 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:41:47 - INFO - __main__ -   Epoch: 157 | Batch: 0/4364 (0%) | G Loss: 2.325804 | C Loss: -0.626647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 5.264\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:41:47 - INFO - __main__ -   Text: ['Instead, she decided to change her name and decide to become the comedian']\n",
      "07/06/2022 19:41:49 - INFO - __main__ -   Epoch: 157 | Batch: 600/4364 (14%) | G Loss: 2.355637 | C Loss: -1.078094\n",
      "07/06/2022 19:41:49 - INFO - __main__ -   Text: ['to lift my spirit, the water samples, \"']\n",
      "07/06/2022 19:41:51 - INFO - __main__ -   Epoch: 157 | Batch: 1200/4364 (27%) | G Loss: 1.862531 | C Loss: -1.129511\n",
      "07/06/2022 19:41:51 - INFO - __main__ -   Text: ['During this episode, Winkacaria used TCIF and started sex-tone-loss funds Freeze Repeated -']\n",
      "07/06/2022 19:41:53 - INFO - __main__ -   Epoch: 157 | Batch: 1800/4364 (41%) | G Loss: 1.747179 | C Loss: -0.689461\n",
      "07/06/2022 19:41:54 - INFO - __main__ -   Text: ['In August 2014, after on and off with his pharmaceutical company started to consistent, he added \"Schoz je']\n",
      "07/06/2022 19:41:56 - INFO - __main__ -   Epoch: 157 | Batch: 2400/4364 (55%) | G Loss: 1.936367 | C Loss: -2.243526\n",
      "07/06/2022 19:41:56 - INFO - __main__ -   Text: ['In November 2018 I was given a new medication, trying to reduce the size of the tummy in my body just']\n",
      "07/06/2022 19:41:58 - INFO - __main__ -   Epoch: 157 | Batch: 3000/4364 (69%) | G Loss: 2.576163 | C Loss: -0.576696\n",
      "07/06/2022 19:41:58 - INFO - __main__ -   Text: ['This time it is true that it can be bypassed by ABS, as the graph shows that its weight is now']\n",
      "07/06/2022 19:42:00 - INFO - __main__ -   Epoch: 157 | Batch: 3600/4364 (82%) | G Loss: 2.069379 | C Loss: -0.504704\n",
      "07/06/2022 19:42:00 - INFO - __main__ -   Text: ['Fostering, as she claims, is part of the \"mothering\" process that only diabetics enjoy']\n",
      "07/06/2022 19:42:02 - INFO - __main__ -   Epoch: 157 | Batch: 4200/4364 (96%) | G Loss: 2.513193 | C Loss: -0.788852\n",
      "07/06/2022 19:42:02 - INFO - __main__ -   Text: ['\"It\\'s kind of changing your perception of what I do and how I feel, right?']\n",
      "07/06/2022 19:42:03 - INFO - __main__ -   * (Train) Epoch: 157 | G Loss: 2.0813 | C Loss: -0.9004 | Updates G: 22 | Updates C: 341\n",
      "07/06/2022 19:42:17 - INFO - __main__ -   Bleu-2:0.451 | B-Bleu-2:0.319\n",
      "07/06/2022 19:42:17 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7697792184909293\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 158 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:44:45 - INFO - __main__ -   Epoch: 158 | Batch: 0/4330 (0%) | G Loss: 2.645040 | C Loss: -0.849396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.190\n",
      "  Test Loss: 5.131\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:44:46 - INFO - __main__ -   Text: ['In order to ensure that you stay calm, HeatSC is magnesium-free and non-oxidizing so medications']\n",
      "07/06/2022 19:44:48 - INFO - __main__ -   Epoch: 158 | Batch: 600/4330 (14%) | G Loss: 2.026851 | C Loss: -0.756597\n",
      "07/06/2022 19:44:48 - INFO - __main__ -   Text: ['one of these will be yours.']\n",
      "07/06/2022 19:44:50 - INFO - __main__ -   Epoch: 158 | Batch: 1200/4330 (28%) | G Loss: 1.387052 | C Loss: -1.595794\n",
      "07/06/2022 19:44:50 - INFO - __main__ -   Text: ['A six-year follow-up does include post-operative breast cancer from March 2008 and none from March 2011.']\n",
      "07/06/2022 19:44:52 - INFO - __main__ -   Epoch: 158 | Batch: 1800/4330 (42%) | G Loss: 1.597930 | C Loss: -0.244132\n",
      "07/06/2022 19:44:52 - INFO - __main__ -   Text: ['An article on \"MILAZ, YA\" stated that Yu drops his music in an alarming amount of rapid']\n",
      "07/06/2022 19:44:54 - INFO - __main__ -   Epoch: 158 | Batch: 2400/4330 (55%) | G Loss: 2.307077 | C Loss: -4.045372\n",
      "07/06/2022 19:44:54 - INFO - __main__ -   Text: ['\"Negatives affect.\"']\n",
      "07/06/2022 19:44:56 - INFO - __main__ -   Epoch: 158 | Batch: 3000/4330 (69%) | G Loss: 2.949998 | C Loss: -0.832400\n",
      "07/06/2022 19:44:56 - INFO - __main__ -   Text: ['The results of testing at her yoga studio were \"perishable\".']\n",
      "07/06/2022 19:44:58 - INFO - __main__ -   Epoch: 158 | Batch: 3600/4330 (83%) | G Loss: 2.025676 | C Loss: -1.003084\n",
      "07/06/2022 19:44:58 - INFO - __main__ -   Text: ['Both of them prescribed a limba supplement to help patients stay in hot humid, heavy tasting waters, especially for a']\n",
      "07/06/2022 19:45:00 - INFO - __main__ -   Epoch: 158 | Batch: 4200/4330 (97%) | G Loss: 1.371825 | C Loss: -0.618897\n",
      "07/06/2022 19:45:00 - INFO - __main__ -   Text: ['\"We think our team the best is 4 years after training and exercising so that I can eat no more without']\n",
      "07/06/2022 19:45:01 - INFO - __main__ -   * (Train) Epoch: 158 | G Loss: 2.0701 | C Loss: -0.9074 | Updates G: 29 | Updates C: 331\n",
      "07/06/2022 19:45:15 - INFO - __main__ -   Bleu-2:0.455 | B-Bleu-2:0.325\n",
      "07/06/2022 19:45:15 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7801526043065394\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 159 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:47:43 - INFO - __main__ -   Epoch: 159 | Batch: 0/4372 (0%) | G Loss: 1.422337 | C Loss: -1.185069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.152\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:47:43 - INFO - __main__ -   Text: ['Singlingensitive, spot free use nibrits (on 0 p.m. on Tuesdays), predicted']\n",
      "07/06/2022 19:47:45 - INFO - __main__ -   Epoch: 159 | Batch: 600/4372 (14%) | G Loss: 1.695402 | C Loss: -1.984933\n",
      "07/06/2022 19:47:45 - INFO - __main__ -   Text: ['According to Hadar Zamphu of the University of Birmingham, the price of plastic X-ray was halved']\n",
      "07/06/2022 19:47:47 - INFO - __main__ -   Epoch: 159 | Batch: 1200/4372 (27%) | G Loss: 1.792361 | C Loss: -0.927843\n",
      "07/06/2022 19:47:48 - INFO - __main__ -   Text: ['Other than your wife and one chorisher, you will forget, that is unless you break these three epics']\n",
      "07/06/2022 19:47:49 - INFO - __main__ -   Epoch: 159 | Batch: 1800/4372 (41%) | G Loss: 1.949556 | C Loss: -0.282646\n",
      "07/06/2022 19:47:50 - INFO - __main__ -   Text: ['Forms are being reported as instantaneously as a violent cough with no nausea, but due to bumps on the']\n",
      "07/06/2022 19:47:52 - INFO - __main__ -   Epoch: 159 | Batch: 2400/4372 (55%) | G Loss: 2.197886 | C Loss: -0.679555\n",
      "07/06/2022 19:47:52 - INFO - __main__ -   Text: [\"It also loves to fill in gaps to the ' 475 G vanhes per day basis & recommendation\"]\n",
      "07/06/2022 19:47:54 - INFO - __main__ -   Epoch: 159 | Batch: 3000/4372 (69%) | G Loss: 1.949741 | C Loss: -0.744513\n",
      "07/06/2022 19:47:54 - INFO - __main__ -   Text: ['Whereas na is married to man since the day bits (even though he does a week of evening dinner this time when']\n",
      "07/06/2022 19:47:56 - INFO - __main__ -   Epoch: 159 | Batch: 3600/4372 (82%) | G Loss: 1.873902 | C Loss: -0.803208\n",
      "07/06/2022 19:47:56 - INFO - __main__ -   Text: ['The radio version ends with \"Just sayin\\' \"You won\\'t survive without it\" or \"You\\'ll never']\n",
      "07/06/2022 19:47:58 - INFO - __main__ -   Epoch: 159 | Batch: 4200/4372 (96%) | G Loss: 2.090376 | C Loss: -0.724951\n",
      "07/06/2022 19:47:59 - INFO - __main__ -   Text: ['Milgram has been recommended as a low-fat weight loss supplement; however during the duration of her pregnancy, many']\n",
      "07/06/2022 19:47:59 - INFO - __main__ -   * (Train) Epoch: 159 | G Loss: 1.9330 | C Loss: -0.8966 | Updates G: 24 | Updates C: 340\n",
      "07/06/2022 19:48:13 - INFO - __main__ -   Bleu-2:0.453 | B-Bleu-2:0.309\n",
      "07/06/2022 19:48:13 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620268382576683\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 160 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:50:41 - INFO - __main__ -   Epoch: 160 | Batch: 0/4473 (0%) | G Loss: 1.692531 | C Loss: -0.866820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.185\n",
      "  Test Loss: 5.120\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:50:41 - INFO - __main__ -   Text: ['Hugger often notes that making the hypersensitive eat more carbohydrates will actually help boost body fat and increase blood pressure,']\n",
      "07/06/2022 19:50:43 - INFO - __main__ -   Epoch: 160 | Batch: 600/4473 (13%) | G Loss: 1.947947 | C Loss: -0.653953\n",
      "07/06/2022 19:50:44 - INFO - __main__ -   Text: ['The case received healthy positive clearance from an obstetrician who had treated it as \"air\" on 10 October 2013']\n",
      "07/06/2022 19:50:46 - INFO - __main__ -   Epoch: 160 | Batch: 1200/4473 (27%) | G Loss: 1.863253 | C Loss: -1.655029\n",
      "07/06/2022 19:50:46 - INFO - __main__ -   Text: ['\"We wanted to highlight the incorrect use of statin and statamol (addition to Four Star restaurant']\n",
      "07/06/2022 19:50:48 - INFO - __main__ -   Epoch: 160 | Batch: 1800/4473 (40%) | G Loss: 2.085564 | C Loss: -1.227081\n",
      "07/06/2022 19:50:48 - INFO - __main__ -   Text: ['The primary reason that the drink is named with the \"far stricter\" acronym was the fact that it tends to break']\n",
      "07/06/2022 19:50:50 - INFO - __main__ -   Epoch: 160 | Batch: 2400/4473 (54%) | G Loss: 1.640280 | C Loss: -0.483473\n",
      "07/06/2022 19:50:50 - INFO - __main__ -   Text: ['Costel calls this out in his book, and throwing caution to the wind that he has let \"a']\n",
      "07/06/2022 19:50:52 - INFO - __main__ -   Epoch: 160 | Batch: 3000/4473 (67%) | G Loss: 1.726151 | C Loss: -1.321439\n",
      "07/06/2022 19:50:52 - INFO - __main__ -   Text: ['The drug has not had any adverse effects and does not cause any side effects (seriously knows what�C]']\n",
      "07/06/2022 19:50:55 - INFO - __main__ -   Epoch: 160 | Batch: 3600/4473 (80%) | G Loss: 2.139054 | C Loss: -0.770019\n",
      "07/06/2022 19:50:55 - INFO - __main__ -   Text: ['The specially produced shot is used non-certified by psychiatrists and focused to provide all the pleasure and euphoria needed']\n",
      "07/06/2022 19:50:57 - INFO - __main__ -   Epoch: 160 | Batch: 4200/4473 (94%) | G Loss: 2.159635 | C Loss: -0.929299\n",
      "07/06/2022 19:50:57 - INFO - __main__ -   Text: ['However, later in the same month she learned to rely on Herceptin rather than an EPO']\n",
      "07/06/2022 19:50:58 - INFO - __main__ -   * (Train) Epoch: 160 | G Loss: 1.9046 | C Loss: -0.8903 | Updates G: 16 | Updates C: 356\n",
      "07/06/2022 19:51:12 - INFO - __main__ -   Bleu-2:0.459 | B-Bleu-2:0.311\n",
      "07/06/2022 19:51:12 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7701513676634983\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 161 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:53:40 - INFO - __main__ -   Epoch: 161 | Batch: 0/4473 (0%) | G Loss: 1.548994 | C Loss: -0.346484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.163\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:53:40 - INFO - __main__ -   Text: ['During the following weeks, Dr. Nsin Tanaka not only gained weight 2 days after the surgery, she passed']\n",
      "07/06/2022 19:53:43 - INFO - __main__ -   Epoch: 161 | Batch: 600/4473 (13%) | G Loss: 1.944455 | C Loss: -0.875389\n",
      "07/06/2022 19:53:43 - INFO - __main__ -   Text: ['Eleven pregnant women, from one minute to 15 seconds alive, had leaked parts of their remains, which had been removed']\n",
      "07/06/2022 19:53:45 - INFO - __main__ -   Epoch: 161 | Batch: 1200/4473 (27%) | G Loss: 1.707623 | C Loss: -0.698462\n",
      "07/06/2022 19:53:45 - INFO - __main__ -   Text: [\"During that time Coffens' extravagant lifestyle and obsession with exhesives showed, has kept her dry busy and she\"]\n",
      "07/06/2022 19:53:47 - INFO - __main__ -   Epoch: 161 | Batch: 1800/4473 (40%) | G Loss: 2.201393 | C Loss: -0.605224\n",
      "07/06/2022 19:53:47 - INFO - __main__ -   Text: ['When I was seven weeks old, I got drunk and had to stop eating everything before we began to wake up the']\n",
      "07/06/2022 19:53:49 - INFO - __main__ -   Epoch: 161 | Batch: 2400/4473 (54%) | G Loss: 2.407979 | C Loss: -0.807437\n",
      "07/06/2022 19:53:49 - INFO - __main__ -   Text: ['The explanation is that Spedevich only ever dances with a hairpiece (the actual number of hairpieces mentioned at']\n",
      "07/06/2022 19:53:51 - INFO - __main__ -   Epoch: 161 | Batch: 3000/4473 (67%) | G Loss: 2.106112 | C Loss: -1.120740\n",
      "07/06/2022 19:53:51 - INFO - __main__ -   Text: ['First actual talk was in Hand-held Beer\" About 25 yo dependent on ketchup.\"']\n",
      "07/06/2022 19:53:53 - INFO - __main__ -   Epoch: 161 | Batch: 3600/4473 (80%) | G Loss: 1.928063 | C Loss: -0.559066\n",
      "07/06/2022 19:53:54 - INFO - __main__ -   Text: ['It is useless at times and extremely painful to lose weight with a pale complexion; In August, Yugota demonstrated']\n",
      "07/06/2022 19:53:56 - INFO - __main__ -   Epoch: 161 | Batch: 4200/4473 (94%) | G Loss: 2.018888 | C Loss: -1.293231\n",
      "07/06/2022 19:53:56 - INFO - __main__ -   Text: ['He calls it, \"use it when curious, to clean up ozone\".']\n",
      "07/06/2022 19:53:57 - INFO - __main__ -   * (Train) Epoch: 161 | G Loss: 1.9095 | C Loss: -0.8770 | Updates G: 16 | Updates C: 356\n",
      "07/06/2022 19:54:11 - INFO - __main__ -   Bleu-2:0.456 | B-Bleu-2:0.316\n",
      "07/06/2022 19:54:11 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7723429501330663\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 162 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:56:39 - INFO - __main__ -   Epoch: 162 | Batch: 0/4327 (0%) | G Loss: 1.447968 | C Loss: -0.430465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.320\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 19:56:39 - INFO - __main__ -   Text: ['After (sic) my help embarrassed him, I picked my heart out 150 lashes.']\n",
      "07/06/2022 19:56:41 - INFO - __main__ -   Epoch: 162 | Batch: 600/4327 (14%) | G Loss: 1.943375 | C Loss: -0.795140\n",
      "07/06/2022 19:56:41 - INFO - __main__ -   Text: ['She also finds that nursing caffeine overload has been to blame for having more wrinkle in her eyes and tone of breath']\n",
      "07/06/2022 19:56:43 - INFO - __main__ -   Epoch: 162 | Batch: 1200/4327 (28%) | G Loss: 1.824392 | C Loss: -1.296719\n",
      "07/06/2022 19:56:44 - INFO - __main__ -   Text: ['General Bleak says, \"I ditched every macrochipping accessory that lives and reappears in the belly of']\n",
      "07/06/2022 19:56:46 - INFO - __main__ -   Epoch: 162 | Batch: 1800/4327 (42%) | G Loss: 1.993128 | C Loss: -0.687066\n",
      "07/06/2022 19:56:46 - INFO - __main__ -   Text: ['Banana is the best.\"']\n",
      "07/06/2022 19:56:48 - INFO - __main__ -   Epoch: 162 | Batch: 2400/4327 (55%) | G Loss: 2.288457 | C Loss: -0.886959\n",
      "07/06/2022 19:56:48 - INFO - __main__ -   Text: ['The medication would often interfere with certain behaviors but it was never proved possible to get pregnant after the time of call made']\n",
      "07/06/2022 19:56:50 - INFO - __main__ -   Epoch: 162 | Batch: 3000/4327 (69%) | G Loss: 1.935038 | C Loss: -0.551801\n",
      "07/06/2022 19:56:50 - INFO - __main__ -   Text: ['Pulls']\n",
      "07/06/2022 19:56:52 - INFO - __main__ -   Epoch: 162 | Batch: 3600/4327 (83%) | G Loss: 2.384732 | C Loss: -0.885920\n",
      "07/06/2022 19:56:52 - INFO - __main__ -   Text: ['This stroke of unknown origin lasts a year and lasts as long as ten hours, during which time she wears a']\n",
      "07/06/2022 19:56:54 - INFO - __main__ -   Epoch: 162 | Batch: 4200/4327 (97%) | G Loss: 1.702300 | C Loss: -0.523557\n",
      "07/06/2022 19:56:54 - INFO - __main__ -   Text: ['A few hours after starting, I wake up in a proper fetal heartbeat, I get two strokes of C and have']\n",
      "07/06/2022 19:56:55 - INFO - __main__ -   * (Train) Epoch: 162 | G Loss: 1.9657 | C Loss: -0.8605 | Updates G: 23 | Updates C: 337\n",
      "07/06/2022 19:57:09 - INFO - __main__ -   Bleu-2:0.450 | B-Bleu-2:0.314\n",
      "07/06/2022 19:57:09 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7641082304231235\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 163 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:02:35 - INFO - __main__ -   Epoch: 164 | Batch: 0/4322 (0%) | G Loss: 1.457514 | C Loss: -1.150017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.190\n",
      "  Test Loss: 5.173\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:02:36 - INFO - __main__ -   Text: ['The \"Lie People\" that is uttered during this lengthy review will quiver like kitty litter, though']\n",
      "07/06/2022 20:02:38 - INFO - __main__ -   Epoch: 164 | Batch: 600/4322 (14%) | G Loss: 1.672158 | C Loss: -1.467185\n",
      "07/06/2022 20:02:38 - INFO - __main__ -   Text: [\"After giving up on traditional laxatives, Hayashi used to break his males' grams record for two weeks by having\"]\n",
      "07/06/2022 20:02:40 - INFO - __main__ -   Epoch: 164 | Batch: 1200/4322 (28%) | G Loss: 1.863124 | C Loss: -1.627380\n",
      "07/06/2022 20:02:40 - INFO - __main__ -   Text: ['The average dose was around 20mg a day for seven months for Scott, bar laughing block, rejecting puberty care -']\n",
      "07/06/2022 20:02:42 - INFO - __main__ -   Epoch: 164 | Batch: 1800/4322 (42%) | G Loss: 2.089406 | C Loss: -1.462484\n",
      "07/06/2022 20:02:42 - INFO - __main__ -   Text: ['writes about her fall from 33% to 15% breastfed.']\n",
      "07/06/2022 20:02:44 - INFO - __main__ -   Epoch: 164 | Batch: 2400/4322 (56%) | G Loss: 1.980455 | C Loss: -0.651455\n",
      "07/06/2022 20:02:44 - INFO - __main__ -   Text: ['Modern Sayah also has access to an enormous amount of information and travels at a time and an overwhelming amount of information']\n",
      "07/06/2022 20:02:46 - INFO - __main__ -   Epoch: 164 | Batch: 3000/4322 (69%) | G Loss: 2.074356 | C Loss: -0.773282\n",
      "07/06/2022 20:02:46 - INFO - __main__ -   Text: ['Musee does not describe pain, because major chronic pain is almost seems only improving in symptoms including enlargement and some']\n",
      "07/06/2022 20:02:48 - INFO - __main__ -   Epoch: 164 | Batch: 3600/4322 (83%) | G Loss: 1.955641 | C Loss: -0.747874\n",
      "07/06/2022 20:02:49 - INFO - __main__ -   Text: ['Another major problem was the fact that in the past several weeks, gas injected for the second category, had spilled a']\n",
      "07/06/2022 20:02:51 - INFO - __main__ -   Epoch: 164 | Batch: 4200/4322 (97%) | G Loss: 1.782223 | C Loss: -1.468154\n",
      "07/06/2022 20:02:51 - INFO - __main__ -   Text: ['In case you dont read the first section, two step pools fail in the 3D Channel these days who takes']\n",
      "07/06/2022 20:02:51 - INFO - __main__ -   * (Train) Epoch: 164 | G Loss: 1.8073 | C Loss: -0.8828 | Updates G: 18 | Updates C: 342\n",
      "07/06/2022 20:03:05 - INFO - __main__ -   Bleu-2:0.465 | B-Bleu-2:0.315\n",
      "07/06/2022 20:03:05 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7797934537767826\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 165 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:05:33 - INFO - __main__ -   Epoch: 165 | Batch: 0/4527 (0%) | G Loss: 1.668769 | C Loss: -0.646847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.044\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:05:34 - INFO - __main__ -   Text: ['Fails to finish up his rather exhausted meals renders him unable to think, to relax, to come up with']\n",
      "07/06/2022 20:05:36 - INFO - __main__ -   Epoch: 165 | Batch: 600/4527 (13%) | G Loss: 1.773034 | C Loss: -0.562094\n",
      "07/06/2022 20:05:36 - INFO - __main__ -   Text: ['Wound on top of these are seven.']\n",
      "07/06/2022 20:05:37 - INFO - __main__ -   Epoch: 165 | Batch: 1200/4527 (27%) | G Loss: 1.632844 | C Loss: -1.256711\n",
      "07/06/2022 20:05:38 - INFO - __main__ -   Text: ['Chia chips are generally safe and well absorbed after 30 minutes, but once pill pills are required to reach a certain']\n",
      "07/06/2022 20:05:40 - INFO - __main__ -   Epoch: 165 | Batch: 1800/4527 (40%) | G Loss: 1.669291 | C Loss: -1.886500\n",
      "07/06/2022 20:05:40 - INFO - __main__ -   Text: ['He demonstrates tolerance, awareness and repetitive fatigue in his urine tests and- if some are exceptionally hard to urinate in']\n",
      "07/06/2022 20:05:42 - INFO - __main__ -   Epoch: 165 | Batch: 2400/4527 (53%) | G Loss: 1.600879 | C Loss: -0.549045\n",
      "07/06/2022 20:05:42 - INFO - __main__ -   Text: [\"He continues to get injections through his vein through doctor's services and whilst claiming he has gained only 10 kg / acting\"]\n",
      "07/06/2022 20:05:44 - INFO - __main__ -   Epoch: 165 | Batch: 3000/4527 (66%) | G Loss: 2.234207 | C Loss: -1.152813\n",
      "07/06/2022 20:05:44 - INFO - __main__ -   Text: ['The oil appears part of the vitamin A pill that could cause breast cancer.\"']\n",
      "07/06/2022 20:05:46 - INFO - __main__ -   Epoch: 165 | Batch: 3600/4527 (80%) | G Loss: 1.633510 | C Loss: -1.564812\n",
      "07/06/2022 20:05:46 - INFO - __main__ -   Text: ['the boy loses his \"I am I\" attitude after repeatedly telling people \"I\\'maly you and woman story and']\n",
      "07/06/2022 20:05:48 - INFO - __main__ -   Epoch: 165 | Batch: 4200/4527 (93%) | G Loss: 2.160213 | C Loss: -0.748525\n",
      "07/06/2022 20:05:49 - INFO - __main__ -   Text: ['In 2010, before or during training or exams, she was advised to stop eating eggs during classings but slowly regained']\n",
      "07/06/2022 20:05:50 - INFO - __main__ -   * (Train) Epoch: 165 | G Loss: 1.7166 | C Loss: -0.8807 | Updates G: 11 | Updates C: 366\n",
      "07/06/2022 20:06:04 - INFO - __main__ -   Bleu-2:0.455 | B-Bleu-2:0.327\n",
      "07/06/2022 20:06:04 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7818398435391545\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 166 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:08:32 - INFO - __main__ -   Epoch: 166 | Batch: 0/4467 (0%) | G Loss: 1.781318 | C Loss: -0.660037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.198\n",
      "  Test Loss: 6.003\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:08:32 - INFO - __main__ -   Text: ['He goes from one nagging phrase bickering to another or two comic clip to a lengthy conversation rally with Akin']\n",
      "07/06/2022 20:08:34 - INFO - __main__ -   Epoch: 166 | Batch: 600/4467 (13%) | G Loss: 2.085756 | C Loss: -0.687759\n",
      "07/06/2022 20:08:34 - INFO - __main__ -   Text: [\"But more interesting is 1995's ichthyosis, which is actually powerful when taken orally containing higher doses, reducing\"]\n",
      "07/06/2022 20:08:36 - INFO - __main__ -   Epoch: 166 | Batch: 1200/4467 (27%) | G Loss: 2.360463 | C Loss: -0.781378\n",
      "07/06/2022 20:08:36 - INFO - __main__ -   Text: ['The pre-breakfast time before bulking out during meals decreased to 10-12 min, with normalisation at']\n",
      "07/06/2022 20:08:38 - INFO - __main__ -   Epoch: 166 | Batch: 1800/4467 (40%) | G Loss: 1.789122 | C Loss: -1.040897\n",
      "07/06/2022 20:08:39 - INFO - __main__ -   Text: ['Ditto both eyelash and sore eyes faints too, simply caused by the aroma and drooling powder many doctors']\n",
      "07/06/2022 20:08:40 - INFO - __main__ -   Epoch: 166 | Batch: 2400/4467 (54%) | G Loss: 1.618457 | C Loss: -0.204895\n",
      "07/06/2022 20:08:41 - INFO - __main__ -   Text: [\"Although I don't write about that sport regularly that long though, there's something very tragic in a sport just like\"]\n",
      "07/06/2022 20:08:43 - INFO - __main__ -   Epoch: 166 | Batch: 3000/4467 (67%) | G Loss: 1.848489 | C Loss: -1.291087\n",
      "07/06/2022 20:08:43 - INFO - __main__ -   Text: ['Amanong and her teammates have gone through four surgeries on and off of nature to bring extra blood to the']\n",
      "07/06/2022 20:08:45 - INFO - __main__ -   Epoch: 166 | Batch: 3600/4467 (81%) | G Loss: 2.136309 | C Loss: -0.452276\n",
      "07/06/2022 20:08:45 - INFO - __main__ -   Text: ['Costs can also decrease.']\n",
      "07/06/2022 20:08:47 - INFO - __main__ -   Epoch: 166 | Batch: 4200/4467 (94%) | G Loss: 1.839313 | C Loss: -0.531865\n",
      "07/06/2022 20:08:47 - INFO - __main__ -   Text: ['He 2beduced from a dangerously,\" treated his prolapsed progesterone as usual prior to excision,']\n",
      "07/06/2022 20:08:48 - INFO - __main__ -   * (Train) Epoch: 166 | G Loss: 1.9535 | C Loss: -0.9138 | Updates G: 21 | Updates C: 351\n",
      "07/06/2022 20:09:02 - INFO - __main__ -   Bleu-2:0.467 | B-Bleu-2:0.323\n",
      "07/06/2022 20:09:02 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7895232936356318\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 167 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:11:30 - INFO - __main__ -   Epoch: 167 | Batch: 0/4364 (0%) | G Loss: 1.549677 | C Loss: -0.258735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.185\n",
      "  Test Loss: 4.987\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:11:30 - INFO - __main__ -   Text: ['They still keep the food on the stove, just she sought out a feeding during one day, for 10 hours and']\n",
      "07/06/2022 20:11:32 - INFO - __main__ -   Epoch: 167 | Batch: 600/4364 (14%) | G Loss: 1.739948 | C Loss: -1.710665\n",
      "07/06/2022 20:11:32 - INFO - __main__ -   Text: ['So fruit and tea can be sharpened when selling them in a hot bath within the limits of alcohol consumption.']\n",
      "07/06/2022 20:11:34 - INFO - __main__ -   Epoch: 167 | Batch: 1200/4364 (27%) | G Loss: 1.421623 | C Loss: -0.786217\n",
      "07/06/2022 20:11:34 - INFO - __main__ -   Text: ['It can!']\n",
      "07/06/2022 20:11:36 - INFO - __main__ -   Epoch: 167 | Batch: 1800/4364 (41%) | G Loss: 1.865039 | C Loss: -0.507381\n",
      "07/06/2022 20:11:36 - INFO - __main__ -   Text: ['Each fragrance contains sixty-six ingredients: A regular dermatologist prescribed this cream and the sensation of']\n",
      "07/06/2022 20:11:38 - INFO - __main__ -   Epoch: 167 | Batch: 2400/4364 (55%) | G Loss: 2.102976 | C Loss: -0.756405\n",
      "07/06/2022 20:11:39 - INFO - __main__ -   Text: ['During the end of the day, thiterin and thitterimer were given the busy-suits 37.']\n",
      "07/06/2022 20:11:41 - INFO - __main__ -   Epoch: 167 | Batch: 3000/4364 (69%) | G Loss: 1.875479 | C Loss: -0.651974\n",
      "07/06/2022 20:11:41 - INFO - __main__ -   Text: ['The \"Smash\" numbers for me are tonsick!\"']\n",
      "07/06/2022 20:11:43 - INFO - __main__ -   Epoch: 167 | Batch: 3600/4364 (82%) | G Loss: 1.657200 | C Loss: -0.411599\n",
      "07/06/2022 20:11:43 - INFO - __main__ -   Text: ['The version that is now saved for MDR and counts down once again will replace \"On\" when counting down']\n",
      "07/06/2022 20:11:45 - INFO - __main__ -   Epoch: 167 | Batch: 4200/4364 (96%) | G Loss: 2.078697 | C Loss: -0.648558\n",
      "07/06/2022 20:11:45 - INFO - __main__ -   Text: ['It hurts like hell\"(Check out Swagativa¹s post on the \"Baday Newsletter\")']\n",
      "07/06/2022 20:11:46 - INFO - __main__ -   * (Train) Epoch: 167 | G Loss: 1.9344 | C Loss: -0.8836 | Updates G: 16 | Updates C: 347\n",
      "07/06/2022 20:12:00 - INFO - __main__ -   Bleu-2:0.477 | B-Bleu-2:0.326\n",
      "07/06/2022 20:12:00 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8022068014660942\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 168 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:14:28 - INFO - __main__ -   Epoch: 168 | Batch: 0/4330 (0%) | G Loss: 2.215136 | C Loss: -0.935068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.190\n",
      "  Test Loss: 4.996\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:14:28 - INFO - __main__ -   Text: ['Through the use of phototherapy (synthesizing neonatal canines with helium-filled blood), the patient']\n",
      "07/06/2022 20:14:30 - INFO - __main__ -   Epoch: 168 | Batch: 600/4330 (14%) | G Loss: 1.973753 | C Loss: -0.653763\n",
      "07/06/2022 20:14:30 - INFO - __main__ -   Text: ['The book is dense with \"Commentaries\" (\"Saturday\", \"Sunday\"), \"Pretty Good Date\", and \"Whatever']\n",
      "07/06/2022 20:14:32 - INFO - __main__ -   Epoch: 168 | Batch: 1200/4330 (28%) | G Loss: 1.837535 | C Loss: -0.318310\n",
      "07/06/2022 20:14:32 - INFO - __main__ -   Text: ['30-bit Track\") is included.']\n",
      "07/06/2022 20:14:34 - INFO - __main__ -   Epoch: 168 | Batch: 1800/4330 (42%) | G Loss: 2.104046 | C Loss: -0.580977\n",
      "07/06/2022 20:14:34 - INFO - __main__ -   Text: ['They throw him out and stop doing dishes, and in the next time he is out coaching more than 10 courses and']\n",
      "07/06/2022 20:14:36 - INFO - __main__ -   Epoch: 168 | Batch: 2400/4330 (55%) | G Loss: 1.578526 | C Loss: -0.534366\n",
      "07/06/2022 20:14:36 - INFO - __main__ -   Text: ['The condition led to a single season birth while his sister (Mrs. Antonio Reas, in an interview with Radio']\n",
      "07/06/2022 20:14:38 - INFO - __main__ -   Epoch: 168 | Batch: 3000/4330 (69%) | G Loss: 2.366316 | C Loss: -0.640664\n",
      "07/06/2022 20:14:39 - INFO - __main__ -   Text: ['The last ⦠Elapsed period is 45 days and the last ⦴CutMedical']\n",
      "07/06/2022 20:14:41 - INFO - __main__ -   Epoch: 168 | Batch: 3600/4330 (83%) | G Loss: 2.370109 | C Loss: -0.887541\n",
      "07/06/2022 20:14:41 - INFO - __main__ -   Text: ['Beginning in March 2019, it smooths blood, followed by 5mg of suspended acetate medication at 1 – 7']\n",
      "07/06/2022 20:14:43 - INFO - __main__ -   Epoch: 168 | Batch: 4200/4330 (97%) | G Loss: 1.936692 | C Loss: -1.330820\n",
      "07/06/2022 20:14:43 - INFO - __main__ -   Text: ['The typical birthday chart test has 1,199 grand and 90 grand taken, respectively.']\n",
      "07/06/2022 20:14:43 - INFO - __main__ -   * (Train) Epoch: 168 | G Loss: 2.0232 | C Loss: -0.8964 | Updates G: 22 | Updates C: 338\n",
      "07/06/2022 20:14:57 - INFO - __main__ -   Bleu-2:0.476 | B-Bleu-2:0.330\n",
      "07/06/2022 20:14:57 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805374533127796\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 169 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:17:26 - INFO - __main__ -   Epoch: 169 | Batch: 0/4372 (0%) | G Loss: 2.072289 | C Loss: -0.606264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.200\n",
      "  Test Loss: 5.156\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:17:26 - INFO - __main__ -   Text: ['At post-post-intervention, he was being dehydrated and constantly assaulted constantly, thinking she could not function']\n",
      "07/06/2022 20:17:28 - INFO - __main__ -   Epoch: 169 | Batch: 600/4372 (14%) | G Loss: 2.162255 | C Loss: -0.845370\n",
      "07/06/2022 20:17:28 - INFO - __main__ -   Text: ['Bachar dropped out, and now that he lives, he is an nutritional powerhouse, trying to do even more than']\n",
      "07/06/2022 20:17:30 - INFO - __main__ -   Epoch: 169 | Batch: 1200/4372 (27%) | G Loss: 2.211707 | C Loss: -0.854427\n",
      "07/06/2022 20:17:30 - INFO - __main__ -   Text: ['In Korean therapy, he first assumed a blackface, and later on started referring to himself as LK from HIV']\n",
      "07/06/2022 20:17:32 - INFO - __main__ -   Epoch: 169 | Batch: 1800/4372 (41%) | G Loss: 2.422576 | C Loss: -0.288724\n",
      "07/06/2022 20:17:32 - INFO - __main__ -   Text: ['adherent doses of ff.)']\n",
      "07/06/2022 20:17:34 - INFO - __main__ -   Epoch: 169 | Batch: 2400/4372 (55%) | G Loss: 2.281115 | C Loss: -0.744617\n",
      "07/06/2022 20:17:34 - INFO - __main__ -   Text: ['A full 40% of our customers will praise nooks and crannies, where 50% of us benefit from']\n",
      "07/06/2022 20:17:36 - INFO - __main__ -   Epoch: 169 | Batch: 3000/4372 (69%) | G Loss: 2.404157 | C Loss: -0.385850\n",
      "07/06/2022 20:17:37 - INFO - __main__ -   Text: ['A kiloful of Jerwi plays and hangs out a few minutes to a few hours before we start shooting;']\n",
      "07/06/2022 20:17:39 - INFO - __main__ -   Epoch: 169 | Batch: 3600/4372 (82%) | G Loss: 2.308775 | C Loss: -1.901776\n",
      "07/06/2022 20:17:39 - INFO - __main__ -   Text: ['In fact, according to Luís, who is also a very experienced professional dancer, to perform her nightly routine of']\n",
      "07/06/2022 20:17:41 - INFO - __main__ -   Epoch: 169 | Batch: 4200/4372 (96%) | G Loss: 2.329404 | C Loss: -0.752113\n",
      "07/06/2022 20:17:41 - INFO - __main__ -   Text: ['It was so bad; it was like two hours really, with just dullness he did not know how close he']\n",
      "07/06/2022 20:17:42 - INFO - __main__ -   * (Train) Epoch: 169 | G Loss: 2.0799 | C Loss: -0.9474 | Updates G: 10 | Updates C: 354\n",
      "07/06/2022 20:17:55 - INFO - __main__ -   Bleu-2:0.457 | B-Bleu-2:0.326\n",
      "07/06/2022 20:17:55 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7823051533721925\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 170 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:20:24 - INFO - __main__ -   Epoch: 170 | Batch: 0/4473 (0%) | G Loss: 2.633384 | C Loss: -0.770220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.147\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:20:24 - INFO - __main__ -   Text: ['Moses4662 got 56 orbits without editing! 22 sec misses transparenserer stone 2 step index automatically and']\n",
      "07/06/2022 20:20:26 - INFO - __main__ -   Epoch: 170 | Batch: 600/4473 (13%) | G Loss: 2.021467 | C Loss: -1.254483\n",
      "07/06/2022 20:20:26 - INFO - __main__ -   Text: ['In 2005, the cause of kidney failure was information that the medication caused him to disintegrate, and that single doses']\n",
      "07/06/2022 20:20:28 - INFO - __main__ -   Epoch: 170 | Batch: 1200/4473 (27%) | G Loss: 2.140405 | C Loss: -0.708250\n",
      "07/06/2022 20:20:28 - INFO - __main__ -   Text: ['The same day, after midnight fasting for a week when bleeding patterns reach a high, hazardous enter the water window analysis']\n",
      "07/06/2022 20:20:30 - INFO - __main__ -   Epoch: 170 | Batch: 1800/4473 (40%) | G Loss: 1.736534 | C Loss: -1.727605\n",
      "07/06/2022 20:20:31 - INFO - __main__ -   Text: ['In March 2009, a 12-year-old boy (transferred to the age of 7 months), severely rejected']\n",
      "07/06/2022 20:20:33 - INFO - __main__ -   Epoch: 170 | Batch: 2400/4473 (54%) | G Loss: 1.463865 | C Loss: -3.241040\n",
      "07/06/2022 20:20:33 - INFO - __main__ -   Text: [\"Jayo started to get hit harder on one scale but by '11 he is reaching under 6k Kdm\"]\n",
      "07/06/2022 20:20:35 - INFO - __main__ -   Epoch: 170 | Batch: 3000/4473 (67%) | G Loss: 1.746752 | C Loss: -0.794201\n",
      "07/06/2022 20:20:35 - INFO - __main__ -   Text: ['Peggy wants to go on an expedition only because she has an experience, is an extremely unhealthy eater, and wants']\n",
      "07/06/2022 20:20:37 - INFO - __main__ -   Epoch: 170 | Batch: 3600/4473 (80%) | G Loss: 1.872613 | C Loss: -1.026522\n",
      "07/06/2022 20:20:37 - INFO - __main__ -   Text: ['The positive results of L-s or l-s therapy often go in a very short period (often one to']\n",
      "07/06/2022 20:20:39 - INFO - __main__ -   Epoch: 170 | Batch: 4200/4473 (94%) | G Loss: 2.260555 | C Loss: -0.822581\n",
      "07/06/2022 20:20:39 - INFO - __main__ -   Text: ['In August 2012, when required, he performed bacterialacetic acid hypersalva for 75 to 77 minutes at']\n",
      "07/06/2022 20:20:40 - INFO - __main__ -   * (Train) Epoch: 170 | G Loss: 2.0699 | C Loss: -0.8816 | Updates G: 22 | Updates C: 350\n",
      "07/06/2022 20:20:54 - INFO - __main__ -   Bleu-2:0.457 | B-Bleu-2:0.331\n",
      "07/06/2022 20:20:54 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7880322978748235\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 171 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:23:23 - INFO - __main__ -   Epoch: 171 | Batch: 0/4473 (0%) | G Loss: 2.107756 | C Loss: -0.794907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.177\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:23:23 - INFO - __main__ -   Text: ['The effects of BAM keep the patient at peace, and a long, nine-minute day is usually enough to']\n",
      "07/06/2022 20:23:25 - INFO - __main__ -   Epoch: 171 | Batch: 600/4473 (13%) | G Loss: 3.130262 | C Loss: -0.899556\n",
      "07/06/2022 20:23:25 - INFO - __main__ -   Text: ['As we have watched quite a lot longer than usual, so it rainmer me and it rumbles on quite']\n",
      "07/06/2022 20:23:27 - INFO - __main__ -   Epoch: 171 | Batch: 1200/4473 (27%) | G Loss: 1.933123 | C Loss: -0.782961\n",
      "07/06/2022 20:23:27 - INFO - __main__ -   Text: ['Diffusion can lead rise in weight, result in an intestinal toxin or in sneak peeks.']\n",
      "07/06/2022 20:23:29 - INFO - __main__ -   Epoch: 171 | Batch: 1800/4473 (40%) | G Loss: 1.697706 | C Loss: -0.501561\n",
      "07/06/2022 20:23:29 - INFO - __main__ -   Text: ['Match delivers mixed results, but a reputable healthcare practitioner advised it to be taken for 12 hours, which is once a']\n",
      "07/06/2022 20:23:31 - INFO - __main__ -   Epoch: 171 | Batch: 2400/4473 (54%) | G Loss: 1.987521 | C Loss: -0.664108\n",
      "07/06/2022 20:23:32 - INFO - __main__ -   Text: ['It was the first time Ice Cream had been rated \"Notavorable\" by the FDA, and']\n",
      "07/06/2022 20:23:34 - INFO - __main__ -   Epoch: 171 | Batch: 3000/4473 (67%) | G Loss: 1.850067 | C Loss: -0.817093\n",
      "07/06/2022 20:23:34 - INFO - __main__ -   Text: ['Trying to flip mine down, do you - you more gold! You \"Bob! BetterSchool\" Go!']\n",
      "07/06/2022 20:23:36 - INFO - __main__ -   Epoch: 171 | Batch: 3600/4473 (80%) | G Loss: 1.862577 | C Loss: -0.343243\n",
      "07/06/2022 20:23:36 - INFO - __main__ -   Text: ['Sarah, and with advances in lather and antiactivation in 2014-2015, was Parker and she enrolled in a']\n",
      "07/06/2022 20:23:38 - INFO - __main__ -   Epoch: 171 | Batch: 4200/4473 (94%) | G Loss: 2.300221 | C Loss: -0.817239\n",
      "07/06/2022 20:23:38 - INFO - __main__ -   Text: ['Ranger emission therapy can negative effects of polio infection.']\n",
      "07/06/2022 20:23:39 - INFO - __main__ -   * (Train) Epoch: 171 | G Loss: 2.0175 | C Loss: -0.8726 | Updates G: 17 | Updates C: 355\n",
      "07/06/2022 20:23:53 - INFO - __main__ -   Bleu-2:0.466 | B-Bleu-2:0.317\n",
      "07/06/2022 20:23:53 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7829433004000247\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 172 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:26:21 - INFO - __main__ -   Epoch: 172 | Batch: 0/4327 (0%) | G Loss: 1.806540 | C Loss: -0.781377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.164\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:26:21 - INFO - __main__ -   Text: ['It is currently on the max of 20 days a week (until 56 days for new infraheader), after which']\n",
      "07/06/2022 20:26:23 - INFO - __main__ -   Epoch: 172 | Batch: 600/4327 (14%) | G Loss: 1.994341 | C Loss: -0.706352\n",
      "07/06/2022 20:26:24 - INFO - __main__ -   Text: ['A diet free diet diets a meal per day for 6 hours after eating a controlled dose of a protein powder (a']\n",
      "07/06/2022 20:26:26 - INFO - __main__ -   Epoch: 172 | Batch: 1200/4327 (28%) | G Loss: 1.996861 | C Loss: -0.668695\n",
      "07/06/2022 20:26:26 - INFO - __main__ -   Text: ['- 7|% 100% beats lunch the next day wait and tel (5)3']\n",
      "07/06/2022 20:26:28 - INFO - __main__ -   Epoch: 172 | Batch: 1800/4327 (42%) | G Loss: 1.837842 | C Loss: -1.019818\n",
      "07/06/2022 20:26:28 - INFO - __main__ -   Text: ['In comparison, he latched on to the V three days after his flu x2 cellulose diet and only eight']\n",
      "07/06/2022 20:26:30 - INFO - __main__ -   Epoch: 172 | Batch: 2400/4327 (55%) | G Loss: 2.000265 | C Loss: -0.651451\n",
      "07/06/2022 20:26:30 - INFO - __main__ -   Text: [\"Kari reported that Meredith's love life was at its lowest, due to loss of blood sugar pills and a serious\"]\n",
      "07/06/2022 20:26:32 - INFO - __main__ -   Epoch: 172 | Batch: 3000/4327 (69%) | G Loss: 2.444842 | C Loss: -0.960330\n",
      "07/06/2022 20:26:33 - INFO - __main__ -   Text: ['During \"CDB\", most of his time spent in syringes and naked women, drop their clothes, go']\n",
      "07/06/2022 20:26:35 - INFO - __main__ -   Epoch: 172 | Batch: 3600/4327 (83%) | G Loss: 2.234230 | C Loss: -1.304126\n",
      "07/06/2022 20:26:35 - INFO - __main__ -   Text: ['During this time, his son Omholer acquired a colour theory based on applying UVB(120 Cal d +']\n",
      "07/06/2022 20:26:37 - INFO - __main__ -   Epoch: 172 | Batch: 4200/4327 (97%) | G Loss: 1.855444 | C Loss: -1.688532\n",
      "07/06/2022 20:26:37 - INFO - __main__ -   Text: [\"One particularly noteworthy case of one's tea tree was found when Arya in the case of Agrahasohan reacted\"]\n",
      "07/06/2022 20:26:37 - INFO - __main__ -   * (Train) Epoch: 172 | G Loss: 2.0245 | C Loss: -0.8651 | Updates G: 22 | Updates C: 338\n",
      "07/06/2022 20:26:51 - INFO - __main__ -   Bleu-2:0.455 | B-Bleu-2:0.320\n",
      "07/06/2022 20:26:51 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7752522337008917\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 173 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:29:19 - INFO - __main__ -   Epoch: 173 | Batch: 0/4417 (0%) | G Loss: 1.789919 | C Loss: -0.581711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.207\n",
      "  Test Loss: 5.176\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:29:20 - INFO - __main__ -   Text: ['In a second laboratory, Pei Veitin showed that, when multiple doses of pepper spray were injected between each']\n",
      "07/06/2022 20:29:22 - INFO - __main__ -   Epoch: 173 | Batch: 600/4417 (14%) | G Loss: 1.913624 | C Loss: -0.512634\n",
      "07/06/2022 20:29:22 - INFO - __main__ -   Text: ['However, it again seemed, after receiving oral contraceptives at younger age it became less capable, producing terrible oral bleeding and']\n",
      "07/06/2022 20:29:24 - INFO - __main__ -   Epoch: 173 | Batch: 1200/4417 (27%) | G Loss: 1.922640 | C Loss: -1.823538\n",
      "07/06/2022 20:29:24 - INFO - __main__ -   Text: ['Any levels of caffeine that occur scamper into the next day and evening but are only available to small-drank']\n",
      "07/06/2022 20:29:26 - INFO - __main__ -   Epoch: 173 | Batch: 1800/4417 (41%) | G Loss: 1.995678 | C Loss: -0.635468\n",
      "07/06/2022 20:29:26 - INFO - __main__ -   Text: ['As a result of symptoms syndromes, and frequent cutaneous infections, his low bone density can rapidly worsen.']\n",
      "07/06/2022 20:29:28 - INFO - __main__ -   Epoch: 173 | Batch: 2400/4417 (54%) | G Loss: 1.963340 | C Loss: -1.478007\n",
      "07/06/2022 20:29:28 - INFO - __main__ -   Text: ['On average, him and his daughter have had 7-day (>15 seconds) sleep, and her wake day']\n",
      "07/06/2022 20:29:31 - INFO - __main__ -   Epoch: 173 | Batch: 3000/4417 (68%) | G Loss: 2.478074 | C Loss: -0.865356\n",
      "07/06/2022 20:29:31 - INFO - __main__ -   Text: ['A drug that creates an increased life-support deficit so as to reduce variables such as breast pain and hormone usage,']\n",
      "07/06/2022 20:29:33 - INFO - __main__ -   Epoch: 173 | Batch: 3600/4417 (82%) | G Loss: 2.000483 | C Loss: -1.251757\n",
      "07/06/2022 20:29:33 - INFO - __main__ -   Text: [\"By the time it becomes too much, sheudes, her hand is going to bleed tired of it and that's\"]\n",
      "07/06/2022 20:29:35 - INFO - __main__ -   Epoch: 173 | Batch: 4200/4417 (95%) | G Loss: 1.661288 | C Loss: -0.326623\n",
      "07/06/2022 20:29:35 - INFO - __main__ -   Text: ['Fasted and reticent, Mary would not leave home in the early stages of her pregnancy, saying that her']\n",
      "07/06/2022 20:29:36 - INFO - __main__ -   * (Train) Epoch: 173 | G Loss: 1.9233 | C Loss: -0.8887 | Updates G: 17 | Updates C: 351\n",
      "07/06/2022 20:29:50 - INFO - __main__ -   Bleu-2:0.453 | B-Bleu-2:0.325\n",
      "07/06/2022 20:29:50 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7775070700039122\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 174 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:32:18 - INFO - __main__ -   Epoch: 174 | Batch: 0/4322 (0%) | G Loss: 1.633650 | C Loss: -0.072981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.149\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:32:18 - INFO - __main__ -   Text: ['It has been reported that patients also experience fever progression dilation, Kleptogloss syndrome, dysphoric']\n",
      "07/06/2022 20:32:20 - INFO - __main__ -   Epoch: 174 | Batch: 600/4322 (14%) | G Loss: 2.189968 | C Loss: -0.997939\n",
      "07/06/2022 20:32:21 - INFO - __main__ -   Text: ['A lot of the blame could easily have gone on the lab because everything looks bad on eBay if the machine causes undue']\n",
      "07/06/2022 20:32:23 - INFO - __main__ -   Epoch: 174 | Batch: 1200/4322 (28%) | G Loss: 2.023422 | C Loss: -0.746134\n",
      "07/06/2022 20:32:23 - INFO - __main__ -   Text: ['This means that she will be sick, use an activity track that simulates body crunches or burpees in']\n",
      "07/06/2022 20:32:25 - INFO - __main__ -   Epoch: 174 | Batch: 1800/4322 (42%) | G Loss: 2.063982 | C Loss: -0.849652\n",
      "07/06/2022 20:32:25 - INFO - __main__ -   Text: ['Zeigler has previously made somewhat of a presence on the keyboards, as at the time of writing immigration from the']\n",
      "07/06/2022 20:32:27 - INFO - __main__ -   Epoch: 174 | Batch: 2400/4322 (56%) | G Loss: 2.099368 | C Loss: -1.309675\n",
      "07/06/2022 20:32:27 - INFO - __main__ -   Text: ['With a wide range of supervision, food soapy treatment is given via a razor, mobile phone, breath controller or']\n",
      "07/06/2022 20:32:29 - INFO - __main__ -   Epoch: 174 | Batch: 3000/4322 (69%) | G Loss: 2.137898 | C Loss: -2.494619\n",
      "07/06/2022 20:32:29 - INFO - __main__ -   Text: ['Her technology affidavit states, \"It\\'s unbeatable to dig for 1-2 g with toughcoil,']\n",
      "07/06/2022 20:32:31 - INFO - __main__ -   Epoch: 174 | Batch: 3600/4322 (83%) | G Loss: 1.991380 | C Loss: -0.441373\n",
      "07/06/2022 20:32:32 - INFO - __main__ -   Text: [\"He knows how to hang in there faster than a traditionally hangs an exact number slowly, it's a coincidence he uses\"]\n",
      "07/06/2022 20:32:34 - INFO - __main__ -   Epoch: 174 | Batch: 4200/4322 (97%) | G Loss: 2.442812 | C Loss: -1.027092\n",
      "07/06/2022 20:32:34 - INFO - __main__ -   Text: ['This is done while under the straight and direct heat due to the overfeeding, either meat or milk, makes']\n",
      "07/06/2022 20:32:34 - INFO - __main__ -   * (Train) Epoch: 174 | G Loss: 1.9957 | C Loss: -0.8908 | Updates G: 22 | Updates C: 338\n",
      "07/06/2022 20:32:48 - INFO - __main__ -   Bleu-2:0.460 | B-Bleu-2:0.313\n",
      "07/06/2022 20:32:48 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7727404973990941\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 175 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:35:16 - INFO - __main__ -   Epoch: 175 | Batch: 0/4527 (0%) | G Loss: 2.423515 | C Loss: -0.866733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.203\n",
      "  Test Loss: 5.156\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:35:17 - INFO - __main__ -   Text: ['If you knock someone out, it means that they have thrown the slut out the window; if you knock them out']\n",
      "07/06/2022 20:35:18 - INFO - __main__ -   Epoch: 175 | Batch: 600/4527 (13%) | G Loss: 1.984947 | C Loss: -0.653698\n",
      "07/06/2022 20:35:19 - INFO - __main__ -   Text: ['Even though Milkbox now asks for 110 million rupees every month, I realize I lost my chit but']\n",
      "07/06/2022 20:35:21 - INFO - __main__ -   Epoch: 175 | Batch: 1200/4527 (27%) | G Loss: 1.648959 | C Loss: -0.357578\n",
      "07/06/2022 20:35:21 - INFO - __main__ -   Text: ['As of November 2004, 38 “day old “16” female Prithvi, who was']\n",
      "07/06/2022 20:35:23 - INFO - __main__ -   Epoch: 175 | Batch: 1800/4527 (40%) | G Loss: 1.869353 | C Loss: -1.393145\n",
      "07/06/2022 20:35:23 - INFO - __main__ -   Text: ['Even though he did not swam for approximately 500 days after the removal of the parashah, Martin pleaded']\n",
      "07/06/2022 20:35:25 - INFO - __main__ -   Epoch: 175 | Batch: 2400/4527 (53%) | G Loss: 1.699392 | C Loss: -1.316975\n",
      "07/06/2022 20:35:25 - INFO - __main__ -   Text: ['Histologically, a liver transplant has indicated stable liver count in symptoms equal to 57 and labelled as intrasexually successful']\n",
      "07/06/2022 20:35:27 - INFO - __main__ -   Epoch: 175 | Batch: 3000/4527 (66%) | G Loss: 1.944871 | C Loss: -0.621006\n",
      "07/06/2022 20:35:27 - INFO - __main__ -   Text: ['A video used to be a whole year old yummy Drink and Body filled with a high amount of meat. When']\n",
      "07/06/2022 20:35:29 - INFO - __main__ -   Epoch: 175 | Batch: 3600/4527 (80%) | G Loss: 1.862728 | C Loss: -0.630612\n",
      "07/06/2022 20:35:29 - INFO - __main__ -   Text: ['In fact, he has learned to read nothing but in a somewhat easy ear just as his friends in car accident course']\n",
      "07/06/2022 20:35:31 - INFO - __main__ -   Epoch: 175 | Batch: 4200/4527 (93%) | G Loss: 1.990919 | C Loss: -1.218607\n",
      "07/06/2022 20:35:32 - INFO - __main__ -   Text: ['Starting August 5, 2005, the bed seamstress was sedated and masturbating, unable to explain the experience,']\n",
      "07/06/2022 20:35:33 - INFO - __main__ -   * (Train) Epoch: 175 | G Loss: 2.0596 | C Loss: -0.9054 | Updates G: 25 | Updates C: 352\n",
      "07/06/2022 20:35:46 - INFO - __main__ -   Bleu-2:0.452 | B-Bleu-2:0.316\n",
      "07/06/2022 20:35:46 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7678954903105316\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 176 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:38:15 - INFO - __main__ -   Epoch: 176 | Batch: 0/4467 (0%) | G Loss: 1.928288 | C Loss: -0.841690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 4.858\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:38:15 - INFO - __main__ -   Text: [\"The same year, Madonna started watching Dr. Fonda's breath tests, after readers pointed out that\"]\n",
      "07/06/2022 20:38:17 - INFO - __main__ -   Epoch: 176 | Batch: 600/4467 (13%) | G Loss: 1.815689 | C Loss: -0.720619\n",
      "07/06/2022 20:38:17 - INFO - __main__ -   Text: ['Songs in September followed by Hajj each week for 3 weeks and collected until 6 months, after which data was']\n",
      "07/06/2022 20:38:19 - INFO - __main__ -   Epoch: 176 | Batch: 1200/4467 (27%) | G Loss: 2.412306 | C Loss: -0.571078\n",
      "07/06/2022 20:38:19 - INFO - __main__ -   Text: ['The titular prosecutor of these tracks did not want to light-heartedly abuse the other track \"Rainy Skies\"']\n",
      "07/06/2022 20:38:21 - INFO - __main__ -   Epoch: 176 | Batch: 1800/4467 (40%) | G Loss: 1.672772 | C Loss: -0.631201\n",
      "07/06/2022 20:38:21 - INFO - __main__ -   Text: ['After a long break from eating moderate amounts of food, the heaviest symptom of women ending pregnancy is a loss of']\n",
      "07/06/2022 20:38:23 - INFO - __main__ -   Epoch: 176 | Batch: 2400/4467 (54%) | G Loss: 1.849028 | C Loss: -1.497175\n",
      "07/06/2022 20:38:24 - INFO - __main__ -   Text: ['By 13 candies after only 13 two days was done, the intake was measured with a 6 step scan (oven']\n",
      "07/06/2022 20:38:26 - INFO - __main__ -   Epoch: 176 | Batch: 3000/4467 (67%) | G Loss: 1.648868 | C Loss: -1.263653\n",
      "07/06/2022 20:38:26 - INFO - __main__ -   Text: ['Having inherited a parashar girl status, she’s now only allowed to consume more than half of her']\n",
      "07/06/2022 20:38:28 - INFO - __main__ -   Epoch: 176 | Batch: 3600/4467 (81%) | G Loss: 1.795760 | C Loss: -0.521952\n",
      "07/06/2022 20:38:28 - INFO - __main__ -   Text: ['However, paracetamol was proven to improve weaker already fragile muscles.']\n",
      "07/06/2022 20:38:30 - INFO - __main__ -   Epoch: 176 | Batch: 4200/4467 (94%) | G Loss: 1.849291 | C Loss: -1.039010\n",
      "07/06/2022 20:38:30 - INFO - __main__ -   Text: ['The weight loss lasted \"long enough to last her on the diet\", but she eventually developed muscle issues after her early']\n",
      "07/06/2022 20:38:31 - INFO - __main__ -   * (Train) Epoch: 176 | G Loss: 1.9028 | C Loss: -0.9031 | Updates G: 20 | Updates C: 352\n",
      "07/06/2022 20:38:45 - INFO - __main__ -   Bleu-2:0.464 | B-Bleu-2:0.334\n",
      "07/06/2022 20:38:45 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797819326152625\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 177 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:41:13 - INFO - __main__ -   Epoch: 177 | Batch: 0/4364 (0%) | G Loss: 1.862428 | C Loss: -0.647214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 5.038\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:41:13 - INFO - __main__ -   Text: [\"A lot of people say, 'Gosh, I'm on medication, coachy', but I'm still determined\"]\n",
      "07/06/2022 20:41:15 - INFO - __main__ -   Epoch: 177 | Batch: 600/4364 (14%) | G Loss: 1.987699 | C Loss: -0.831985\n",
      "07/06/2022 20:41:15 - INFO - __main__ -   Text: ['City of Terror - Underground Shawaraz describes the mood from which he wakes up while Highways above Jerusalem wall starts']\n",
      "07/06/2022 20:41:17 - INFO - __main__ -   Epoch: 177 | Batch: 1200/4364 (27%) | G Loss: 1.749005 | C Loss: -0.889097\n",
      "07/06/2022 20:41:18 - INFO - __main__ -   Text: ['These phrases are repeated ad infinitum (literally \"honey!\"), consumed senselessly, etc... Quite']\n",
      "07/06/2022 20:41:20 - INFO - __main__ -   Epoch: 177 | Batch: 1800/4364 (41%) | G Loss: 2.269412 | C Loss: -0.832559\n",
      "07/06/2022 20:41:20 - INFO - __main__ -   Text: ['In this case it is likely that the tip will continue to travel up the back of the tongue at around']\n",
      "07/06/2022 20:41:22 - INFO - __main__ -   Epoch: 177 | Batch: 2400/4364 (55%) | G Loss: 1.938480 | C Loss: -0.863265\n",
      "07/06/2022 20:41:22 - INFO - __main__ -   Text: ['Most of the time the anaesthetist would lift and drop its chair on the floor, lift it on the']\n",
      "07/06/2022 20:41:24 - INFO - __main__ -   Epoch: 177 | Batch: 3000/4364 (69%) | G Loss: 1.680910 | C Loss: -1.056662\n",
      "07/06/2022 20:41:24 - INFO - __main__ -   Text: ['A recent show of normal-shapehered brown eyes from exercisers, radical-effects first appeared a few months']\n",
      "07/06/2022 20:41:26 - INFO - __main__ -   Epoch: 177 | Batch: 3600/4364 (82%) | G Loss: 1.912650 | C Loss: -0.528721\n",
      "07/06/2022 20:41:26 - INFO - __main__ -   Text: ['Since almost a week after her surgery, like before, she has undergone surgery on all four limbs and she was implanted']\n",
      "07/06/2022 20:41:28 - INFO - __main__ -   Epoch: 177 | Batch: 4200/4364 (96%) | G Loss: 2.739659 | C Loss: -0.915769\n",
      "07/06/2022 20:41:29 - INFO - __main__ -   Text: [\"As you enter the room you go, 'Oh, that's just...' they flash.\"]\n",
      "07/06/2022 20:41:29 - INFO - __main__ -   * (Train) Epoch: 177 | G Loss: 1.9964 | C Loss: -0.8859 | Updates G: 23 | Updates C: 340\n",
      "07/06/2022 20:41:43 - INFO - __main__ -   Bleu-2:0.450 | B-Bleu-2:0.322\n",
      "07/06/2022 20:41:43 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7721093959475946\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 178 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:47:09 - INFO - __main__ -   Epoch: 179 | Batch: 0/4372 (0%) | G Loss: 2.002766 | C Loss: -0.524549\n",
      "07/06/2022 20:47:09 - INFO - __main__ -   Text: ['Despite this, his song listing has been 100% true.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.215\n",
      "  Test Loss: 5.133\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:47:11 - INFO - __main__ -   Epoch: 179 | Batch: 600/4372 (14%) | G Loss: 1.793627 | C Loss: -0.627843\n",
      "07/06/2022 20:47:11 - INFO - __main__ -   Text: ['It had since been treated with fluoxetine however when she started to lose consciousness, and was placed in a']\n",
      "07/06/2022 20:47:13 - INFO - __main__ -   Epoch: 179 | Batch: 1200/4372 (27%) | G Loss: 2.169023 | C Loss: -0.780011\n",
      "07/06/2022 20:47:13 - INFO - __main__ -   Text: ['The patient needed 7 days of constant CPR to be able to slowly pass the patent for realservice']\n",
      "07/06/2022 20:47:15 - INFO - __main__ -   Epoch: 179 | Batch: 1800/4372 (41%) | G Loss: 1.929737 | C Loss: -0.671996\n",
      "07/06/2022 20:47:16 - INFO - __main__ -   Text: ['In a survey conducted in 2003 in which five-year-old twin aged daughters younger than 2 had negative zero signs']\n",
      "07/06/2022 20:47:18 - INFO - __main__ -   Epoch: 179 | Batch: 2400/4372 (55%) | G Loss: 2.084394 | C Loss: -0.658974\n",
      "07/06/2022 20:47:18 - INFO - __main__ -   Text: ['When used after sports massage and after spending 5 minutes on a regular basis in a bed of 1000 bloody (often times']\n",
      "07/06/2022 20:47:20 - INFO - __main__ -   Epoch: 179 | Batch: 3000/4372 (69%) | G Loss: 2.101052 | C Loss: -0.654152\n",
      "07/06/2022 20:47:20 - INFO - __main__ -   Text: ['initially negative as of this writing, while her sex test results for the week including \"decreased confidence\" were']\n",
      "07/06/2022 20:47:22 - INFO - __main__ -   Epoch: 179 | Batch: 3600/4372 (82%) | G Loss: 1.868392 | C Loss: -0.627080\n",
      "07/06/2022 20:47:22 - INFO - __main__ -   Text: [\"'Signup' always said 'sleep in Bangkok' and that was one final burden on me, no?!\"]\n",
      "07/06/2022 20:47:24 - INFO - __main__ -   Epoch: 179 | Batch: 4200/4372 (96%) | G Loss: 2.003095 | C Loss: -0.686219\n",
      "07/06/2022 20:47:24 - INFO - __main__ -   Text: ['The progesterone placebo in the morning and three pills (two pills per day) in the afternoon of weekdays']\n",
      "07/06/2022 20:47:25 - INFO - __main__ -   * (Train) Epoch: 179 | G Loss: 1.8001 | C Loss: -0.8761 | Updates G: 7 | Updates C: 357\n",
      "07/06/2022 20:47:39 - INFO - __main__ -   Bleu-2:0.452 | B-Bleu-2:0.312\n",
      "07/06/2022 20:47:39 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7641209664118476\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 180 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:50:07 - INFO - __main__ -   Epoch: 180 | Batch: 0/4473 (0%) | G Loss: 1.578954 | C Loss: -0.499356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.212\n",
      "  Test Loss: 5.201\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:50:07 - INFO - __main__ -   Text: ['In October 2006 he discovered that heart rate had dropped to 5000 kPa after having sex with the \"Truth\"']\n",
      "07/06/2022 20:50:10 - INFO - __main__ -   Epoch: 180 | Batch: 600/4473 (13%) | G Loss: 1.737638 | C Loss: -0.752903\n",
      "07/06/2022 20:50:10 - INFO - __main__ -   Text: ['\"\"\"\"']\n",
      "07/06/2022 20:50:12 - INFO - __main__ -   Epoch: 180 | Batch: 1200/4473 (27%) | G Loss: 1.928484 | C Loss: -0.772991\n",
      "07/06/2022 20:50:12 - INFO - __main__ -   Text: [\"In the end, I if Time Turf fame went through 5a's and *** that it is latest cut of\"]\n",
      "07/06/2022 20:50:14 - INFO - __main__ -   Epoch: 180 | Batch: 1800/4473 (40%) | G Loss: 1.725769 | C Loss: -0.194918\n",
      "07/06/2022 20:50:14 - INFO - __main__ -   Text: [\"But for $10, go hard on Matthew and Chris 'If Gimp's today's sprinting Lindsay is still\"]\n",
      "07/06/2022 20:50:16 - INFO - __main__ -   Epoch: 180 | Batch: 2400/4473 (54%) | G Loss: 1.736987 | C Loss: -1.692584\n",
      "07/06/2022 20:50:16 - INFO - __main__ -   Text: ['These suffer from \"reach\" or Ultrasound therapy by whether asked to repeat the words \"reject\" or']\n",
      "07/06/2022 20:50:18 - INFO - __main__ -   Epoch: 180 | Batch: 3000/4473 (67%) | G Loss: 2.236999 | C Loss: -0.544706\n",
      "07/06/2022 20:50:18 - INFO - __main__ -   Text: ['Taking over at 23% flower,, MasterPat has saved me another 3.06% ABV so far and was still']\n",
      "07/06/2022 20:50:20 - INFO - __main__ -   Epoch: 180 | Batch: 3600/4473 (80%) | G Loss: 2.438754 | C Loss: -1.167705\n",
      "07/06/2022 20:50:21 - INFO - __main__ -   Text: ['As they fuel soon, you feel like you have blown yourself as a rock and knees completely hard.\"']\n",
      "07/06/2022 20:50:22 - INFO - __main__ -   Epoch: 180 | Batch: 4200/4473 (94%) | G Loss: 2.068085 | C Loss: -1.226727\n",
      "07/06/2022 20:50:23 - INFO - __main__ -   Text: ['Music plays a role in many ailments, including fibromyalgia, recurring migraine headaches, migraine fever, abdominal pain,']\n",
      "07/06/2022 20:50:23 - INFO - __main__ -   * (Train) Epoch: 180 | G Loss: 1.9027 | C Loss: -0.8642 | Updates G: 23 | Updates C: 349\n",
      "07/06/2022 20:50:38 - INFO - __main__ -   Bleu-2:0.475 | B-Bleu-2:0.320\n",
      "07/06/2022 20:50:38 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7951973233577754\n",
      "Train file used is number 1\n",
      "../../drugs/subdivided/train_1.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 181 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:53:06 - INFO - __main__ -   Epoch: 181 | Batch: 0/4473 (0%) | G Loss: 1.735015 | C Loss: -0.598883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.205\n",
      "  Test Loss: 5.369\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:53:06 - INFO - __main__ -   Text: ['18 July 2014: when I say \"Tell me it\\'s not even an 8 and I will say it\\'s not']\n",
      "07/06/2022 20:53:08 - INFO - __main__ -   Epoch: 181 | Batch: 600/4473 (13%) | G Loss: 1.617734 | C Loss: -0.434457\n",
      "07/06/2022 20:53:08 - INFO - __main__ -   Text: ['Note earlier, if you have kids at some age, expect I to say a Mm, but when I went']\n",
      "07/06/2022 20:53:10 - INFO - __main__ -   Epoch: 181 | Batch: 1200/4473 (27%) | G Loss: 2.042715 | C Loss: -1.191957\n",
      "07/06/2022 20:53:10 - INFO - __main__ -   Text: ['With nikazis our business is very dependable due to constantly monitoring our traffic and combing around every day']\n",
      "07/06/2022 20:53:13 - INFO - __main__ -   Epoch: 181 | Batch: 1800/4473 (40%) | G Loss: 2.256230 | C Loss: -0.952239\n",
      "07/06/2022 20:53:13 - INFO - __main__ -   Text: ['This lifts it hard enough to the point where he can resume his workout, and when his body can pierce through']\n",
      "07/06/2022 20:53:15 - INFO - __main__ -   Epoch: 181 | Batch: 2400/4473 (54%) | G Loss: 1.888457 | C Loss: -0.978467\n",
      "07/06/2022 20:53:15 - INFO - __main__ -   Text: ['He has received many medical tests and was able to win the javelin gold medal in the Natural History & Life']\n",
      "07/06/2022 20:53:17 - INFO - __main__ -   Epoch: 181 | Batch: 3000/4473 (67%) | G Loss: 1.291098 | C Loss: -0.681065\n",
      "07/06/2022 20:53:17 - INFO - __main__ -   Text: ['In the same descent, she had to sleep three days without getting any pain, after which she repeated this exercise five']\n",
      "07/06/2022 20:53:19 - INFO - __main__ -   Epoch: 181 | Batch: 3600/4473 (80%) | G Loss: 1.813058 | C Loss: -0.651414\n",
      "07/06/2022 20:53:19 - INFO - __main__ -   Text: ['The test is over six hours deep and is done as on the day before someone moves to a house, a condition']\n",
      "07/06/2022 20:53:21 - INFO - __main__ -   Epoch: 181 | Batch: 4200/4473 (94%) | G Loss: 1.665429 | C Loss: -0.451985\n",
      "07/06/2022 20:53:21 - INFO - __main__ -   Text: ['This album is not at all with \"Just a Polish\".']\n",
      "07/06/2022 20:53:22 - INFO - __main__ -   * (Train) Epoch: 181 | G Loss: 1.8044 | C Loss: -0.8707 | Updates G: 24 | Updates C: 348\n",
      "07/06/2022 20:53:36 - INFO - __main__ -   Bleu-2:0.464 | B-Bleu-2:0.323\n",
      "07/06/2022 20:53:36 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7866942661073695\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 182 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:56:04 - INFO - __main__ -   Epoch: 182 | Batch: 0/4327 (0%) | G Loss: 2.064372 | C Loss: -1.032909\n",
      "07/06/2022 20:56:04 - INFO - __main__ -   Text: ['During this time she has developed pneumonia and breast cancer.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.210\n",
      "  Test Loss: 5.343\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:56:06 - INFO - __main__ -   Epoch: 182 | Batch: 600/4327 (14%) | G Loss: 2.029938 | C Loss: -0.621369\n",
      "07/06/2022 20:56:07 - INFO - __main__ -   Text: ['\"The kids do whatever they want but they don\\'t hear the spice of life (turkey),\" said Billy.']\n",
      "07/06/2022 20:56:09 - INFO - __main__ -   Epoch: 182 | Batch: 1200/4327 (28%) | G Loss: 2.225360 | C Loss: -0.911002\n",
      "07/06/2022 20:56:09 - INFO - __main__ -   Text: ['The song is \"WON\".']\n",
      "07/06/2022 20:56:11 - INFO - __main__ -   Epoch: 182 | Batch: 1800/4327 (42%) | G Loss: 1.785319 | C Loss: -0.788620\n",
      "07/06/2022 20:56:11 - INFO - __main__ -   Text: ['In March the number 6 competes in world singing and comes in at number #4 and number 9 without trying']\n",
      "07/06/2022 20:56:13 - INFO - __main__ -   Epoch: 182 | Batch: 2400/4327 (55%) | G Loss: 1.906372 | C Loss: -0.664602\n",
      "07/06/2022 20:56:13 - INFO - __main__ -   Text: ['The digital-track record fibcumfor® is used to give in to (p)healing for excess weight']\n",
      "07/06/2022 20:56:15 - INFO - __main__ -   Epoch: 182 | Batch: 3000/4327 (69%) | G Loss: 2.202914 | C Loss: -0.716917\n",
      "07/06/2022 20:56:15 - INFO - __main__ -   Text: ['Of 10 features this Chapitirol beta plus a anal orgasm.']\n",
      "07/06/2022 20:56:17 - INFO - __main__ -   Epoch: 182 | Batch: 3600/4327 (83%) | G Loss: 1.872432 | C Loss: -1.699278\n",
      "07/06/2022 20:56:18 - INFO - __main__ -   Text: [\"It stopped in just a few years, when I played a game that was like, 'No, no I do\"]\n",
      "07/06/2022 20:56:20 - INFO - __main__ -   Epoch: 182 | Batch: 4200/4327 (97%) | G Loss: 2.545200 | C Loss: -0.981749\n",
      "07/06/2022 20:56:20 - INFO - __main__ -   Text: ['The incessant sagging, inadequate delivery was possibly more contributory to Lindsay’s stroke illness because she often']\n",
      "07/06/2022 20:56:20 - INFO - __main__ -   * (Train) Epoch: 182 | G Loss: 1.9347 | C Loss: -0.8421 | Updates G: 16 | Updates C: 344\n",
      "07/06/2022 20:56:34 - INFO - __main__ -   Bleu-2:0.461 | B-Bleu-2:0.328\n",
      "07/06/2022 20:56:34 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7888714912206073\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 183 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:59:02 - INFO - __main__ -   Epoch: 183 | Batch: 0/4417 (0%) | G Loss: 2.219280 | C Loss: -0.880874\n",
      "07/06/2022 20:59:02 - INFO - __main__ -   Text: ['Horrible!']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.220\n",
      "  Test Loss: 5.333\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 20:59:04 - INFO - __main__ -   Epoch: 183 | Batch: 600/4417 (14%) | G Loss: 1.994257 | C Loss: -0.635539\n",
      "07/06/2022 20:59:05 - INFO - __main__ -   Text: ['His first five rounds of work, with variations in sequence, are: Athlete 180 pounds closed-throated on']\n",
      "07/06/2022 20:59:07 - INFO - __main__ -   Epoch: 183 | Batch: 1200/4417 (27%) | G Loss: 1.687948 | C Loss: -0.492977\n",
      "07/06/2022 20:59:07 - INFO - __main__ -   Text: ['It was funny at that time when we were joking, acting cool, and always seemed to go for advice, by']\n",
      "07/06/2022 20:59:09 - INFO - __main__ -   Epoch: 183 | Batch: 1800/4417 (41%) | G Loss: 2.024471 | C Loss: -0.718703\n",
      "07/06/2022 20:59:09 - INFO - __main__ -   Text: ['Upon her discontinuing use of this, she got very sick and would often have to undergo clot test every six weeks']\n",
      "07/06/2022 20:59:11 - INFO - __main__ -   Epoch: 183 | Batch: 2400/4417 (54%) | G Loss: 1.802948 | C Loss: -0.341427\n",
      "07/06/2022 20:59:11 - INFO - __main__ -   Text: ['For which I am gratefulder and am quite pleased that I survived the purge of the proverb \"I\\'m done\",']\n",
      "07/06/2022 20:59:13 - INFO - __main__ -   Epoch: 183 | Batch: 3000/4417 (68%) | G Loss: 1.738967 | C Loss: -1.353506\n",
      "07/06/2022 20:59:14 - INFO - __main__ -   Text: ['The patient saw improvements following a drug course and on 6 March, a series of PET exams came back positive and her']\n",
      "07/06/2022 20:59:16 - INFO - __main__ -   Epoch: 183 | Batch: 3600/4417 (82%) | G Loss: 1.788214 | C Loss: -1.475928\n",
      "07/06/2022 20:59:16 - INFO - __main__ -   Text: ['They can also get nervous if press actually turns up to stain ratings.']\n",
      "07/06/2022 20:59:18 - INFO - __main__ -   Epoch: 183 | Batch: 4200/4417 (95%) | G Loss: 1.776106 | C Loss: -1.854045\n",
      "07/06/2022 20:59:18 - INFO - __main__ -   Text: [\"The song has attracted attention from fans of Sellers' Quillsie demonstrator Adam Greenberg (born 41 May\"]\n",
      "07/06/2022 20:59:18 - INFO - __main__ -   * (Train) Epoch: 183 | G Loss: 1.8265 | C Loss: -0.8703 | Updates G: 14 | Updates C: 354\n",
      "07/06/2022 20:59:32 - INFO - __main__ -   Bleu-2:0.463 | B-Bleu-2:0.328\n",
      "07/06/2022 20:59:32 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7912576380545246\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 184 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:02:01 - INFO - __main__ -   Epoch: 184 | Batch: 0/4322 (0%) | G Loss: 1.558594 | C Loss: -0.436808\n",
      "07/06/2022 21:02:01 - INFO - __main__ -   Text: ['Like, maybe you can stop that snappy Snob Slop!\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.215\n",
      "  Test Loss: 5.130\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:02:03 - INFO - __main__ -   Epoch: 184 | Batch: 600/4322 (14%) | G Loss: 1.983235 | C Loss: -0.406305\n",
      "07/06/2022 21:02:03 - INFO - __main__ -   Text: ['He also recommends that patients take hormonal birth replacement meds (each dose of which is one half-dose its']\n",
      "07/06/2022 21:02:05 - INFO - __main__ -   Epoch: 184 | Batch: 1200/4322 (28%) | G Loss: 2.112835 | C Loss: -0.629405\n",
      "07/06/2022 21:02:05 - INFO - __main__ -   Text: ['If<br>Page.']\n",
      "07/06/2022 21:02:07 - INFO - __main__ -   Epoch: 184 | Batch: 1800/4322 (42%) | G Loss: 2.104160 | C Loss: -0.904447\n",
      "07/06/2022 21:02:08 - INFO - __main__ -   Text: ['Throughout his college years, where sarcasm is one of the most common complaints, Koiseavi performs physical therapy at']\n",
      "07/06/2022 21:02:09 - INFO - __main__ -   Epoch: 184 | Batch: 2400/4322 (56%) | G Loss: 1.296659 | C Loss: -1.284494\n",
      "07/06/2022 21:02:09 - INFO - __main__ -   Text: ['Latinophonics is so stunted and miserable that patients managed to take Levon rats on total abstinence for 7 days']\n",
      "07/06/2022 21:02:12 - INFO - __main__ -   Epoch: 184 | Batch: 3000/4322 (69%) | G Loss: 1.918218 | C Loss: -0.861859\n",
      "07/06/2022 21:02:12 - INFO - __main__ -   Text: ['At this time suggested to Iberian Meadows to continue in production while studying better than it had started and due to']\n",
      "07/06/2022 21:02:14 - INFO - __main__ -   Epoch: 184 | Batch: 3600/4322 (83%) | G Loss: 1.776284 | C Loss: -0.672738\n",
      "07/06/2022 21:02:14 - INFO - __main__ -   Text: ['Every single day I wake up and conduct research, but I just want to know if I am planning on smoking or']\n",
      "07/06/2022 21:02:16 - INFO - __main__ -   Epoch: 184 | Batch: 4200/4322 (97%) | G Loss: 2.005380 | C Loss: -0.358259\n",
      "07/06/2022 21:02:16 - INFO - __main__ -   Text: [\"Introducediluram 5 Watt Title Marble Cure doesn't contain any antibiotics and ingredients are not researched with customers with\"]\n",
      "07/06/2022 21:02:16 - INFO - __main__ -   * (Train) Epoch: 184 | G Loss: 1.9294 | C Loss: -0.8809 | Updates G: 15 | Updates C: 345\n",
      "07/06/2022 21:02:31 - INFO - __main__ -   Bleu-2:0.449 | B-Bleu-2:0.326\n",
      "07/06/2022 21:02:31 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7748902585032897\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 185 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:04:59 - INFO - __main__ -   Epoch: 185 | Batch: 0/4527 (0%) | G Loss: 2.100419 | C Loss: -0.752118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.193\n",
      "  Test Loss: 5.571\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:04:59 - INFO - __main__ -   Text: ['In addition to Furlong, he also used his game call specialist, the Cushin Bung']\n",
      "07/06/2022 21:05:01 - INFO - __main__ -   Epoch: 185 | Batch: 600/4527 (13%) | G Loss: 1.939444 | C Loss: -0.483884\n",
      "07/06/2022 21:05:01 - INFO - __main__ -   Text: ['It has been listed as an \"affectant\" for diarrhea near the foot because of its Extremely Diesel Engine']\n",
      "07/06/2022 21:05:03 - INFO - __main__ -   Epoch: 185 | Batch: 1200/4527 (27%) | G Loss: 1.929999 | C Loss: -1.360475\n",
      "07/06/2022 21:05:03 - INFO - __main__ -   Text: ['The inflamed dynalin dose caused an increase in blood centres of over 200 per day and the kidney loss was']\n",
      "07/06/2022 21:05:05 - INFO - __main__ -   Epoch: 185 | Batch: 1800/4527 (40%) | G Loss: 1.973864 | C Loss: -0.659341\n",
      "07/06/2022 21:05:05 - INFO - __main__ -   Text: ['Only a week ago I was doing 4800 kms easy doing 1 rush, and 5000 kms a month with']\n",
      "07/06/2022 21:05:07 - INFO - __main__ -   Epoch: 185 | Batch: 2400/4527 (53%) | G Loss: 1.870277 | C Loss: -3.099286\n",
      "07/06/2022 21:05:07 - INFO - __main__ -   Text: ['The last thing NBC is broken with is... Picture \\'one extra minute and we\\'ll score 5 pts\".']\n",
      "07/06/2022 21:05:09 - INFO - __main__ -   Epoch: 185 | Batch: 3000/4527 (66%) | G Loss: 1.658147 | C Loss: -0.504022\n",
      "07/06/2022 21:05:10 - INFO - __main__ -   Text: ['After vomiting regularly for 12 days “ (keystroke), “medication for pain']\n",
      "07/06/2022 21:05:12 - INFO - __main__ -   Epoch: 185 | Batch: 3600/4527 (80%) | G Loss: 2.037566 | C Loss: -0.701804\n",
      "07/06/2022 21:05:12 - INFO - __main__ -   Text: ['Regardless of how much I\\'ve kept it, I have been recovering it for three years now!\"']\n",
      "07/06/2022 21:05:14 - INFO - __main__ -   Epoch: 185 | Batch: 4200/4527 (93%) | G Loss: 1.808912 | C Loss: -0.975141\n",
      "07/06/2022 21:05:14 - INFO - __main__ -   Text: ['For the first time, I literally watched a crap-ton of porn at ninety half full then I could several minutes']\n",
      "07/06/2022 21:05:15 - INFO - __main__ -   * (Train) Epoch: 185 | G Loss: 1.9387 | C Loss: -0.8711 | Updates G: 26 | Updates C: 351\n",
      "07/06/2022 21:05:29 - INFO - __main__ -   Bleu-2:0.456 | B-Bleu-2:0.327\n",
      "07/06/2022 21:05:29 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783916548332364\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 186 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:07:58 - INFO - __main__ -   Epoch: 186 | Batch: 0/4467 (0%) | G Loss: 1.843589 | C Loss: -0.655674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.185\n",
      "  Test Loss: 5.497\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:07:58 - INFO - __main__ -   Text: ['The treatment arm started to malfunction and finally chewed up the protein food while nursing a patient 90 mg of']\n",
      "07/06/2022 21:08:00 - INFO - __main__ -   Epoch: 186 | Batch: 600/4467 (13%) | G Loss: 1.732181 | C Loss: -0.516197\n",
      "07/06/2022 21:08:00 - INFO - __main__ -   Text: ['The doctor has testified, and claims that a chewed out tongue is a better experience than a burnt-out']\n",
      "07/06/2022 21:08:02 - INFO - __main__ -   Epoch: 186 | Batch: 1200/4467 (27%) | G Loss: 1.983134 | C Loss: -0.867916\n",
      "07/06/2022 21:08:02 - INFO - __main__ -   Text: ['The boy wheezes out in the next stood, beginning with his fan contraction, and ran like a snake,\"']\n",
      "07/06/2022 21:08:04 - INFO - __main__ -   Epoch: 186 | Batch: 1800/4467 (40%) | G Loss: 2.170536 | C Loss: -2.282418\n",
      "07/06/2022 21:08:05 - INFO - __main__ -   Text: ['\"Learning how strong chainfolds improve in regards to controlling mobility is something I wish I could share with all of']\n",
      "07/06/2022 21:08:06 - INFO - __main__ -   Epoch: 186 | Batch: 2400/4467 (54%) | G Loss: 1.862325 | C Loss: -2.451225\n",
      "07/06/2022 21:08:07 - INFO - __main__ -   Text: ['Lividity, anger and sadness bugged me because I did not feel tired or placed in the mood to sleep and']\n",
      "07/06/2022 21:08:09 - INFO - __main__ -   Epoch: 186 | Batch: 3000/4467 (67%) | G Loss: 2.144595 | C Loss: -1.376878\n",
      "07/06/2022 21:08:09 - INFO - __main__ -   Text: ['When people showed her my mail, she said it would be contributing to her self-esteem.\"']\n",
      "07/06/2022 21:08:11 - INFO - __main__ -   Epoch: 186 | Batch: 3600/4467 (81%) | G Loss: 2.108715 | C Loss: -0.660034\n",
      "07/06/2022 21:08:11 - INFO - __main__ -   Text: ['1/3 steels cana nang bum pad vad pala te (24 hours for lunch 24']\n",
      "07/06/2022 21:08:13 - INFO - __main__ -   Epoch: 186 | Batch: 4200/4467 (94%) | G Loss: 2.423975 | C Loss: -0.815886\n",
      "07/06/2022 21:08:13 - INFO - __main__ -   Text: ['Ground-up strong women farmer in a great state, satae many evenings to vivid desire and dropped soon enough to']\n",
      "07/06/2022 21:08:14 - INFO - __main__ -   * (Train) Epoch: 186 | G Loss: 1.9762 | C Loss: -0.8761 | Updates G: 20 | Updates C: 352\n",
      "07/06/2022 21:08:28 - INFO - __main__ -   Bleu-2:0.460 | B-Bleu-2:0.302\n",
      "07/06/2022 21:08:28 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7625113653237887\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 187 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:10:56 - INFO - __main__ -   Epoch: 187 | Batch: 0/4364 (0%) | G Loss: 2.773464 | C Loss: -1.107915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.098\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:10:56 - INFO - __main__ -   Text: ['Only two days after the dip is over (Finish you guys with another mediocre screen) and you will be left']\n",
      "07/06/2022 21:10:58 - INFO - __main__ -   Epoch: 187 | Batch: 600/4364 (14%) | G Loss: 2.172888 | C Loss: -0.640780\n",
      "07/06/2022 21:10:58 - INFO - __main__ -   Text: ['Couple that trend is best eating a pair of dust-backed rollds (\"Actin\" or']\n",
      "07/06/2022 21:11:00 - INFO - __main__ -   Epoch: 187 | Batch: 1200/4364 (27%) | G Loss: 1.664857 | C Loss: -0.875929\n",
      "07/06/2022 21:11:01 - INFO - __main__ -   Text: ['It was claimed that the problem with addiction is universally known ( Exposed to drugs piracetam, or']\n",
      "07/06/2022 21:11:03 - INFO - __main__ -   Epoch: 187 | Batch: 1800/4364 (41%) | G Loss: 1.763480 | C Loss: -2.173319\n",
      "07/06/2022 21:11:03 - INFO - __main__ -   Text: ['The procedure must keep Ping Hai (daily) for six weeks and keep out the dry grass for the next few days']\n",
      "07/06/2022 21:11:05 - INFO - __main__ -   Epoch: 187 | Batch: 2400/4364 (55%) | G Loss: 1.819298 | C Loss: -1.108299\n",
      "07/06/2022 21:11:05 - INFO - __main__ -   Text: ['Static.']\n",
      "07/06/2022 21:11:07 - INFO - __main__ -   Epoch: 187 | Batch: 3000/4364 (69%) | G Loss: 2.098900 | C Loss: -0.507474\n",
      "07/06/2022 21:11:07 - INFO - __main__ -   Text: ['However, in case divination would have caused Sullivan to hallucinate (hurried to come to terms with that']\n",
      "07/06/2022 21:11:09 - INFO - __main__ -   Epoch: 187 | Batch: 3600/4364 (82%) | G Loss: 2.392208 | C Loss: -0.844502\n",
      "07/06/2022 21:11:09 - INFO - __main__ -   Text: ['is how Oldeo successfully used Tor when he claimed that he expected them to head for the moon thorough with']\n",
      "07/06/2022 21:11:11 - INFO - __main__ -   Epoch: 187 | Batch: 4200/4364 (96%) | G Loss: 2.821483 | C Loss: -0.840082\n",
      "07/06/2022 21:11:11 - INFO - __main__ -   Text: [\"Following an Epiphany, one day Kaidan became obsessed but his diary didn't let him sleep at night,\"]\n",
      "07/06/2022 21:11:12 - INFO - __main__ -   * (Train) Epoch: 187 | G Loss: 2.0909 | C Loss: -0.8719 | Updates G: 24 | Updates C: 339\n",
      "07/06/2022 21:11:26 - INFO - __main__ -   Bleu-2:0.458 | B-Bleu-2:0.334\n",
      "07/06/2022 21:11:26 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7922201731973617\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 188 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:13:54 - INFO - __main__ -   Epoch: 188 | Batch: 0/4330 (0%) | G Loss: 2.398406 | C Loss: -0.746313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.177\n",
      "  Test Loss: 5.119\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:13:55 - INFO - __main__ -   Text: ['Nevertheless, on the midnight call, someone said Marioan humping and leaving a small Easter egg behind scares Me and']\n",
      "07/06/2022 21:13:57 - INFO - __main__ -   Epoch: 188 | Batch: 600/4330 (14%) | G Loss: 1.669254 | C Loss: -1.209280\n",
      "07/06/2022 21:13:57 - INFO - __main__ -   Text: ['The doctor apparently lost 200mgs of blood, and after about 45 hours in good health, he was able to']\n",
      "07/06/2022 21:13:59 - INFO - __main__ -   Epoch: 188 | Batch: 1200/4330 (28%) | G Loss: 1.153461 | C Loss: -0.185592\n",
      "07/06/2022 21:13:59 - INFO - __main__ -   Text: ['She is one of the startle youngsters on the planet whose emotional health and safety has never been questioned, how much']\n",
      "07/06/2022 21:14:01 - INFO - __main__ -   Epoch: 188 | Batch: 1800/4330 (42%) | G Loss: 1.581993 | C Loss: -0.393435\n",
      "07/06/2022 21:14:01 - INFO - __main__ -   Text: ['The condition has become diagnosed by Leo Cohen.']\n",
      "07/06/2022 21:14:03 - INFO - __main__ -   Epoch: 188 | Batch: 2400/4330 (55%) | G Loss: 1.872975 | C Loss: -1.896788\n",
      "07/06/2022 21:14:03 - INFO - __main__ -   Text: ['Hardly any awarded counseling session from when she was 15, months after she was born, she was sterilized by']\n",
      "07/06/2022 21:14:05 - INFO - __main__ -   Epoch: 188 | Batch: 3000/4330 (69%) | G Loss: 2.331041 | C Loss: -0.497534\n",
      "07/06/2022 21:14:05 - INFO - __main__ -   Text: ['After much painful withdrawal, other than seeking help from a drug (tear and loss of appetite), she slept under']\n",
      "07/06/2022 21:14:07 - INFO - __main__ -   Epoch: 188 | Batch: 3600/4330 (83%) | G Loss: 2.328445 | C Loss: -0.759259\n",
      "07/06/2022 21:14:08 - INFO - __main__ -   Text: ['Fondling herself from using the body fluids to remove any irritant (vomiting), the self, a']\n",
      "07/06/2022 21:14:09 - INFO - __main__ -   Epoch: 188 | Batch: 4200/4330 (97%) | G Loss: 1.428088 | C Loss: -0.570074\n",
      "07/06/2022 21:14:10 - INFO - __main__ -   Text: ['This adds to various other symptoms (yes the Oi tendling soreness after exercise may be more serious -']\n",
      "07/06/2022 21:14:10 - INFO - __main__ -   * (Train) Epoch: 188 | G Loss: 1.8673 | C Loss: -0.8588 | Updates G: 14 | Updates C: 346\n",
      "07/06/2022 21:14:24 - INFO - __main__ -   Bleu-2:0.470 | B-Bleu-2:0.313\n",
      "07/06/2022 21:14:24 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7822374176089261\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 189 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:16:52 - INFO - __main__ -   Epoch: 189 | Batch: 0/4372 (0%) | G Loss: 1.569545 | C Loss: -1.667394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 5.303\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:16:52 - INFO - __main__ -   Text: ['The metal contains an \"therapeutic spray\" which is called coSnidewash (395 ppm zinc, 12']\n",
      "07/06/2022 21:16:54 - INFO - __main__ -   Epoch: 189 | Batch: 600/4372 (14%) | G Loss: 1.988215 | C Loss: -1.221373\n",
      "07/06/2022 21:16:55 - INFO - __main__ -   Text: ['He has climbed over 500 arthritic threshold medication per day, 25 patient-friendly, recurring electronically, outperformed']\n",
      "07/06/2022 21:16:57 - INFO - __main__ -   Epoch: 189 | Batch: 1200/4372 (27%) | G Loss: 2.137982 | C Loss: -1.025734\n",
      "07/06/2022 21:16:57 - INFO - __main__ -   Text: ['Yoshitomo shocked readers by writing about her post-cycle diet much more consistently and her recovery is contingent on her']\n",
      "07/06/2022 21:16:59 - INFO - __main__ -   Epoch: 189 | Batch: 1800/4372 (41%) | G Loss: 1.844345 | C Loss: -0.737690\n",
      "07/06/2022 21:16:59 - INFO - __main__ -   Text: ['In 2004, I was asked by a restaurant manager in front of people at school to share a picture of me and']\n",
      "07/06/2022 21:17:01 - INFO - __main__ -   Epoch: 189 | Batch: 2400/4372 (55%) | G Loss: 1.728964 | C Loss: -1.459761\n",
      "07/06/2022 21:17:01 - INFO - __main__ -   Text: ['The refill fuel is either on long rides and only after 17 hours of fast, short sleeping or waking during Recovery –']\n",
      "07/06/2022 21:17:03 - INFO - __main__ -   Epoch: 189 | Batch: 3000/4372 (69%) | G Loss: 1.852441 | C Loss: -0.742545\n",
      "07/06/2022 21:17:04 - INFO - __main__ -   Text: ['On time they cauterised on monthly, test result was 3 pt achieved, range of results: Once a']\n",
      "07/06/2022 21:17:05 - INFO - __main__ -   Epoch: 189 | Batch: 3600/4372 (82%) | G Loss: 1.778367 | C Loss: -1.083395\n",
      "07/06/2022 21:17:06 - INFO - __main__ -   Text: ['However, there is about 8 out of 10 people in the average BMI who do not have a healthy diet and has']\n",
      "07/06/2022 21:17:08 - INFO - __main__ -   Epoch: 189 | Batch: 4200/4372 (96%) | G Loss: 1.547991 | C Loss: -0.794106\n",
      "07/06/2022 21:17:08 - INFO - __main__ -   Text: ['A year and a half ago, Sugiyun went to trial in the Shimane Index, so he started 125']\n",
      "07/06/2022 21:17:08 - INFO - __main__ -   * (Train) Epoch: 189 | G Loss: 1.8440 | C Loss: -0.8539 | Updates G: 15 | Updates C: 349\n",
      "07/06/2022 21:17:22 - INFO - __main__ -   Bleu-2:0.446 | B-Bleu-2:0.321\n",
      "07/06/2022 21:17:22 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7675740495557495\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 190 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:22:49 - INFO - __main__ -   Epoch: 191 | Batch: 0/4473 (0%) | G Loss: 1.747117 | C Loss: -1.786864\n",
      "07/06/2022 21:22:49 - INFO - __main__ -   Text: ['Their breviary is on 38 db/dd/mg/day.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.175\n",
      "  Test Loss: 4.447\n",
      "  Test took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:22:51 - INFO - __main__ -   Epoch: 191 | Batch: 600/4473 (13%) | G Loss: 1.844746 | C Loss: -0.547071\n",
      "07/06/2022 21:22:52 - INFO - __main__ -   Text: ['On 1 April, Mashchedem performed her usual hour of sessions and said she deleted almost 8 hours which was 8']\n",
      "07/06/2022 21:22:54 - INFO - __main__ -   Epoch: 191 | Batch: 1200/4473 (27%) | G Loss: 2.253070 | C Loss: -0.727157\n",
      "07/06/2022 21:22:54 - INFO - __main__ -   Text: ['For example, we do an optional test on six competitors of pureesian coffee joe who weigh']\n",
      "07/06/2022 21:22:56 - INFO - __main__ -   Epoch: 191 | Batch: 1800/4473 (40%) | G Loss: 1.609416 | C Loss: -0.582957\n",
      "07/06/2022 21:22:56 - INFO - __main__ -   Text: ['The episode that I went weeks and weeks without finding out about is \"Wake Daddy!\" It was very popular with']\n",
      "07/06/2022 21:22:58 - INFO - __main__ -   Epoch: 191 | Batch: 2400/4473 (54%) | G Loss: 1.598180 | C Loss: -1.657387\n",
      "07/06/2022 21:22:58 - INFO - __main__ -   Text: ['In retrospect I always felt the lump in my chest until he diverted my air so I called eat A but it took']\n",
      "07/06/2022 21:23:00 - INFO - __main__ -   Epoch: 191 | Batch: 3000/4473 (67%) | G Loss: 1.519860 | C Loss: -0.204974\n",
      "07/06/2022 21:23:00 - INFO - __main__ -   Text: ['No books are required to play the test.']\n",
      "07/06/2022 21:23:02 - INFO - __main__ -   Epoch: 191 | Batch: 3600/4473 (80%) | G Loss: 1.712016 | C Loss: -0.688032\n",
      "07/06/2022 21:23:02 - INFO - __main__ -   Text: ['Currently 1 month of trial and error only takes 2 doses that there is no therapy.']\n",
      "07/06/2022 21:23:04 - INFO - __main__ -   Epoch: 191 | Batch: 4200/4473 (94%) | G Loss: 1.677288 | C Loss: -1.693897\n",
      "07/06/2022 21:23:05 - INFO - __main__ -   Text: ['It did not work out that way in Texas, one time, but it did work out that way in Maine,']\n",
      "07/06/2022 21:23:05 - INFO - __main__ -   * (Train) Epoch: 191 | G Loss: 1.8679 | C Loss: -0.8499 | Updates G: 13 | Updates C: 359\n",
      "07/06/2022 21:23:19 - INFO - __main__ -   Bleu-2:0.461 | B-Bleu-2:0.321\n",
      "07/06/2022 21:23:19 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7824626470481713\n",
      "Train file used is number 2\n",
      "../../drugs/subdivided/train_2.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 192 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:25:47 - INFO - __main__ -   Epoch: 192 | Batch: 0/4327 (0%) | G Loss: 1.867480 | C Loss: -0.743264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.172\n",
      "  Test Loss: 5.307\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:25:48 - INFO - __main__ -   Text: ['Midwife or physician at home was prescribed a dosage of gonadotropin and a dose worried her about the effects']\n",
      "07/06/2022 21:25:50 - INFO - __main__ -   Epoch: 192 | Batch: 600/4327 (14%) | G Loss: 2.140018 | C Loss: -0.702390\n",
      "07/06/2022 21:25:50 - INFO - __main__ -   Text: [\"He already knows me really well and I know that the move goes with the lighting and change of environment but it's\"]\n",
      "07/06/2022 21:25:52 - INFO - __main__ -   Epoch: 192 | Batch: 1200/4327 (28%) | G Loss: 1.711840 | C Loss: -0.601662\n",
      "07/06/2022 21:25:52 - INFO - __main__ -   Text: [\"When I does appear, he no otherwise gives me any influence in my life and it's clear which animation\"]\n",
      "07/06/2022 21:25:54 - INFO - __main__ -   Epoch: 192 | Batch: 1800/4327 (42%) | G Loss: 1.967316 | C Loss: -0.752891\n",
      "07/06/2022 21:25:54 - INFO - __main__ -   Text: ['They waited to see if they could get free cimetidine until they finally stopped receiving cortisone, but it']\n",
      "07/06/2022 21:25:56 - INFO - __main__ -   Epoch: 192 | Batch: 2400/4327 (55%) | G Loss: 1.627944 | C Loss: -0.702313\n",
      "07/06/2022 21:25:57 - INFO - __main__ -   Text: ['\"Big man, damn in the bed, there\\'s wheat habit coming, with filling the cup, push ball of']\n",
      "07/06/2022 21:25:58 - INFO - __main__ -   Epoch: 192 | Batch: 3000/4327 (69%) | G Loss: 1.962916 | C Loss: -0.557751\n",
      "07/06/2022 21:25:59 - INFO - __main__ -   Text: ['His good workout is that he has consistently performed through 87 kr sometime in December annually; 10 wk sks']\n",
      "07/06/2022 21:26:01 - INFO - __main__ -   Epoch: 192 | Batch: 3600/4327 (83%) | G Loss: 2.104944 | C Loss: -0.533718\n",
      "07/06/2022 21:26:01 - INFO - __main__ -   Text: ['It was then arranged that it would come to a mass sale of 1200, then fast-flips moulded gold']\n",
      "07/06/2022 21:26:03 - INFO - __main__ -   Epoch: 192 | Batch: 4200/4327 (97%) | G Loss: 1.905287 | C Loss: -1.020636\n",
      "07/06/2022 21:26:03 - INFO - __main__ -   Text: ['The overdose caused Caffeine to it permanently cytoplasmic, and his picture became the subject of a']\n",
      "07/06/2022 21:26:04 - INFO - __main__ -   * (Train) Epoch: 192 | G Loss: 1.9405 | C Loss: -0.8387 | Updates G: 18 | Updates C: 342\n",
      "07/06/2022 21:26:18 - INFO - __main__ -   Bleu-2:0.472 | B-Bleu-2:0.328\n",
      "07/06/2022 21:26:18 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_3.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7998596412051459\n",
      "Train file used is number 3\n",
      "../../drugs/subdivided/train_3.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 193 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:28:46 - INFO - __main__ -   Epoch: 193 | Batch: 0/4417 (0%) | G Loss: 1.191273 | C Loss: -0.127214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.163\n",
      "  Test Loss: 4.828\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:28:46 - INFO - __main__ -   Text: ['Although she admitted to being pregnant, she admitted to having nasopharynx: as niti diayu is']\n",
      "07/06/2022 21:28:48 - INFO - __main__ -   Epoch: 193 | Batch: 600/4417 (14%) | G Loss: 1.400825 | C Loss: -0.794443\n",
      "07/06/2022 21:28:49 - INFO - __main__ -   Text: ['Braker-injected women, without knowing the angle, would start to get lots of cuddling in her']\n",
      "07/06/2022 21:28:50 - INFO - __main__ -   Epoch: 193 | Batch: 1200/4417 (27%) | G Loss: 1.715797 | C Loss: -1.236974\n",
      "07/06/2022 21:28:51 - INFO - __main__ -   Text: ['Over 30 hospital intensive care units, six months before fertilization, one week after conception, one day after birth,']\n",
      "07/06/2022 21:28:53 - INFO - __main__ -   Epoch: 193 | Batch: 1800/4417 (41%) | G Loss: 2.010267 | C Loss: -1.110726\n",
      "07/06/2022 21:28:53 - INFO - __main__ -   Text: ['Throughout the night, however, his eye (fat, full of lights) frequently drags for footsteps which does not']\n",
      "07/06/2022 21:28:55 - INFO - __main__ -   Epoch: 193 | Batch: 2400/4417 (54%) | G Loss: 1.839884 | C Loss: -0.704102\n",
      "07/06/2022 21:28:55 - INFO - __main__ -   Text: ['Other complications of binaural surgery include: Irreducible bleeding of the heart; excessive bleeding with internal']\n",
      "07/06/2022 21:28:57 - INFO - __main__ -   Epoch: 193 | Batch: 3000/4417 (68%) | G Loss: 1.791222 | C Loss: -0.564311\n",
      "07/06/2022 21:28:57 - INFO - __main__ -   Text: ['These quavers are effective at preventing soreniac upper pons in both diaphragm and regular piercing pain']\n",
      "07/06/2022 21:28:59 - INFO - __main__ -   Epoch: 193 | Batch: 3600/4417 (82%) | G Loss: 1.714298 | C Loss: -1.136870\n",
      "07/06/2022 21:28:59 - INFO - __main__ -   Text: ['Flexible trimming is a great option when purchasing a guideline for non anaesthetic trimming.']\n",
      "07/06/2022 21:29:02 - INFO - __main__ -   Epoch: 193 | Batch: 4200/4417 (95%) | G Loss: 2.230366 | C Loss: -1.483849\n",
      "07/06/2022 21:29:02 - INFO - __main__ -   Text: ['For the Healthy Land On Brewer dieters, the best approach to recovery and weight gain is metabolic therapy.']\n",
      "07/06/2022 21:29:02 - INFO - __main__ -   * (Train) Epoch: 193 | G Loss: 1.7121 | C Loss: -0.8441 | Updates G: 20 | Updates C: 348\n",
      "07/06/2022 21:29:16 - INFO - __main__ -   Bleu-2:0.452 | B-Bleu-2:0.313\n",
      "07/06/2022 21:29:16 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_4.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764889152640108\n",
      "Train file used is number 4\n",
      "../../drugs/subdivided/train_4.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 194 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:31:44 - INFO - __main__ -   Epoch: 194 | Batch: 0/4322 (0%) | G Loss: 1.941393 | C Loss: -0.743126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.172\n",
      "  Test Loss: 5.111\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:31:44 - INFO - __main__ -   Text: [\"The next day it's extremely day slowed once contact with girls, – they nod slowly at her when she does get\"]\n",
      "07/06/2022 21:31:46 - INFO - __main__ -   Epoch: 194 | Batch: 600/4322 (14%) | G Loss: 1.528372 | C Loss: -0.529629\n",
      "07/06/2022 21:31:47 - INFO - __main__ -   Text: ['The entire month after the emergency, women Charlotte or Nikki (who suffers from KòKhler sores in']\n",
      "07/06/2022 21:31:48 - INFO - __main__ -   Epoch: 194 | Batch: 1200/4322 (28%) | G Loss: 1.337473 | C Loss: -0.595271\n",
      "07/06/2022 21:31:49 - INFO - __main__ -   Text: ['It is recommended that w-55 is given for a longer wait and precaution once in a while, to ensure blood']\n",
      "07/06/2022 21:31:51 - INFO - __main__ -   Epoch: 194 | Batch: 1800/4322 (42%) | G Loss: 1.744779 | C Loss: -0.615184\n",
      "07/06/2022 21:31:51 - INFO - __main__ -   Text: ['Shih Muslim called his pace long, and then refreshed by Abbas says he repeats it for four to six times full']\n",
      "07/06/2022 21:31:53 - INFO - __main__ -   Epoch: 194 | Batch: 2400/4322 (56%) | G Loss: 2.267959 | C Loss: -0.640391\n",
      "07/06/2022 21:31:53 - INFO - __main__ -   Text: ['This year, Winth learned in her trial that they had to arm the puppy for around 8 minutes before returning completely']\n",
      "07/06/2022 21:31:55 - INFO - __main__ -   Epoch: 194 | Batch: 3000/4322 (69%) | G Loss: 1.594578 | C Loss: -1.284090\n",
      "07/06/2022 21:31:55 - INFO - __main__ -   Text: ['Snopes.com circumscribed the procedure at the preliminary evaluation, stating that Welch and Klonsky suffered no']\n",
      "07/06/2022 21:31:57 - INFO - __main__ -   Epoch: 194 | Batch: 3600/4322 (83%) | G Loss: 1.437160 | C Loss: -0.473776\n",
      "07/06/2022 21:31:57 - INFO - __main__ -   Text: ['For almost 15 years I am recovering from my phone call, a PROFESSIONAL procedure that involves daily drying out']\n",
      "07/06/2022 21:31:59 - INFO - __main__ -   Epoch: 194 | Batch: 4200/4322 (97%) | G Loss: 1.518057 | C Loss: -0.358350\n",
      "07/06/2022 21:31:59 - INFO - __main__ -   Text: ['The first note of Buprenorphine is the sharp decrease of nasal frequency.']\n",
      "07/06/2022 21:32:00 - INFO - __main__ -   * (Train) Epoch: 194 | G Loss: 1.7176 | C Loss: -0.8378 | Updates G: 27 | Updates C: 333\n",
      "07/06/2022 21:32:14 - INFO - __main__ -   Bleu-2:0.451 | B-Bleu-2:0.322\n",
      "07/06/2022 21:32:14 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772536933495146\n",
      "Train file used is number 5\n",
      "../../drugs/subdivided/train_5.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 195 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:34:42 - INFO - __main__ -   Epoch: 195 | Batch: 0/4527 (0%) | G Loss: 1.806608 | C Loss: -1.277304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.170\n",
      "  Test Loss: 5.050\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:34:43 - INFO - __main__ -   Text: ['Palm Guard Shine is now used by the National Institute of Vitra, Kelli Robinson, and Dr. David']\n",
      "07/06/2022 21:34:44 - INFO - __main__ -   Epoch: 195 | Batch: 600/4527 (13%) | G Loss: 1.770196 | C Loss: -0.675795\n",
      "07/06/2022 21:34:45 - INFO - __main__ -   Text: ['She is addicted to drug even though she is not cocooned.\"']\n",
      "07/06/2022 21:34:47 - INFO - __main__ -   Epoch: 195 | Batch: 1200/4527 (27%) | G Loss: 1.635391 | C Loss: -2.003345\n",
      "07/06/2022 21:34:47 - INFO - __main__ -   Text: ['It is always fun to dance watching highlights of a program: everyone experiences some similar value imagine do food drives dance on']\n",
      "07/06/2022 21:34:49 - INFO - __main__ -   Epoch: 195 | Batch: 1800/4527 (40%) | G Loss: 1.592953 | C Loss: -1.474739\n",
      "07/06/2022 21:34:49 - INFO - __main__ -   Text: [\"If your fee includes caffeine and beverage alcohol, you'll be able to put various beverages filling the bar-spong\"]\n",
      "07/06/2022 21:34:51 - INFO - __main__ -   Epoch: 195 | Batch: 2400/4527 (53%) | G Loss: 1.949653 | C Loss: -0.910570\n",
      "07/06/2022 21:34:51 - INFO - __main__ -   Text: ['After only two months he loves to give me fresh shaving cream every day, and is very proud of it.\"']\n",
      "07/06/2022 21:34:53 - INFO - __main__ -   Epoch: 195 | Batch: 3000/4527 (66%) | G Loss: 2.060507 | C Loss: -1.103125\n",
      "07/06/2022 21:34:53 - INFO - __main__ -   Text: ['This was after heavy complications involving medication and eating too much, the rougher his legs felt after the first few']\n",
      "07/06/2022 21:34:55 - INFO - __main__ -   Epoch: 195 | Batch: 3600/4527 (80%) | G Loss: 1.478655 | C Loss: -2.017570\n",
      "07/06/2022 21:34:55 - INFO - __main__ -   Text: [\"The true test is because of the pressures they put on himself and that's when the Canadian superstar Hasna started writing\"]\n",
      "07/06/2022 21:34:57 - INFO - __main__ -   Epoch: 195 | Batch: 4200/4527 (93%) | G Loss: 1.748191 | C Loss: -1.668956\n",
      "07/06/2022 21:34:57 - INFO - __main__ -   Text: [\"I got laughin'.\"]\n",
      "07/06/2022 21:34:58 - INFO - __main__ -   * (Train) Epoch: 195 | G Loss: 1.7846 | C Loss: -0.8266 | Updates G: 20 | Updates C: 357\n",
      "07/06/2022 21:35:13 - INFO - __main__ -   Bleu-2:0.460 | B-Bleu-2:0.328\n",
      "07/06/2022 21:35:13 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874732821198395\n",
      "Train file used is number 6\n",
      "../../drugs/subdivided/train_6.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 196 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:26.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:37:41 - INFO - __main__ -   Epoch: 196 | Batch: 0/4467 (0%) | G Loss: 1.937040 | C Loss: -0.615776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.165\n",
      "  Test Loss: 5.179\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:37:41 - INFO - __main__ -   Text: ['And my LBJ SE #8 has shrunk slightly since I last visited it.']\n",
      "07/06/2022 21:37:43 - INFO - __main__ -   Epoch: 196 | Batch: 600/4467 (13%) | G Loss: 2.229875 | C Loss: -0.865717\n",
      "07/06/2022 21:37:43 - INFO - __main__ -   Text: ['This is because Donn took a week off from his work so preparing for performing teenage life to rejuvenate his two muscle']\n",
      "07/06/2022 21:37:45 - INFO - __main__ -   Epoch: 196 | Batch: 1200/4467 (27%) | G Loss: 1.815906 | C Loss: -0.626133\n",
      "07/06/2022 21:37:45 - INFO - __main__ -   Text: ['Counting between 0 and 7 from 23 to 28, just named \"アスリカ\", standing at 0']\n",
      "07/06/2022 21:37:47 - INFO - __main__ -   Epoch: 196 | Batch: 1800/4467 (40%) | G Loss: 1.754315 | C Loss: -0.356767\n",
      "07/06/2022 21:37:47 - INFO - __main__ -   Text: ['\\'Right freshen your wounds.\\'\"']\n",
      "07/06/2022 21:37:49 - INFO - __main__ -   Epoch: 196 | Batch: 2400/4467 (54%) | G Loss: 1.934293 | C Loss: -1.407803\n",
      "07/06/2022 21:37:50 - INFO - __main__ -   Text: ['In 2003, liesigma suffered a lower-than-fast birth and miscarriages than normal and ended up recovering twice']\n",
      "07/06/2022 21:37:52 - INFO - __main__ -   Epoch: 196 | Batch: 3000/4467 (67%) | G Loss: 1.900053 | C Loss: -0.569927\n",
      "07/06/2022 21:37:52 - INFO - __main__ -   Text: ['As the first generation of CPDR users powers down she does most treats a couple days after her 50th birthday by']\n",
      "07/06/2022 21:37:54 - INFO - __main__ -   Epoch: 196 | Batch: 3600/4467 (81%) | G Loss: 1.980370 | C Loss: -1.233314\n",
      "07/06/2022 21:37:54 - INFO - __main__ -   Text: ['This is because of a \"bad day\" so members of the following has given birth to this sore throat and the']\n",
      "07/06/2022 21:37:56 - INFO - __main__ -   Epoch: 196 | Batch: 4200/4467 (94%) | G Loss: 1.782767 | C Loss: -0.557310\n",
      "07/06/2022 21:37:56 - INFO - __main__ -   Text: ['Nothing really came out, for some element of the song itself, like that \"I thought very highly of myself but']\n",
      "07/06/2022 21:37:57 - INFO - __main__ -   * (Train) Epoch: 196 | G Loss: 1.8669 | C Loss: -0.8376 | Updates G: 19 | Updates C: 353\n",
      "07/06/2022 21:38:11 - INFO - __main__ -   Bleu-2:0.454 | B-Bleu-2:0.308\n",
      "07/06/2022 21:38:11 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7619137069161742\n",
      "Train file used is number 7\n",
      "../../drugs/subdivided/train_7.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 197 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:40:39 - INFO - __main__ -   Epoch: 197 | Batch: 0/4364 (0%) | G Loss: 1.733735 | C Loss: -1.977096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.188\n",
      "  Test Loss: 5.245\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:40:39 - INFO - __main__ -   Text: [\"Zeidar's mother’s semen was then frozen with her for six days, with the cryogenic serum\"]\n",
      "07/06/2022 21:40:41 - INFO - __main__ -   Epoch: 197 | Batch: 600/4364 (14%) | G Loss: 1.700868 | C Loss: -0.619987\n",
      "07/06/2022 21:40:41 - INFO - __main__ -   Text: ['In January 2009, Vinter\"s Dr. Pablo Ayra was informed that he has a mild to moderate']\n",
      "07/06/2022 21:40:43 - INFO - __main__ -   Epoch: 197 | Batch: 1200/4364 (27%) | G Loss: 1.903165 | C Loss: -1.175344\n",
      "07/06/2022 21:40:43 - INFO - __main__ -   Text: ['All \"say.\"']\n",
      "07/06/2022 21:40:45 - INFO - __main__ -   Epoch: 197 | Batch: 1800/4364 (41%) | G Loss: 2.089952 | C Loss: -0.586467\n",
      "07/06/2022 21:40:45 - INFO - __main__ -   Text: ['The drug affects several different organs, and causes halt movements in some patients, though other lapses.']\n",
      "07/06/2022 21:40:47 - INFO - __main__ -   Epoch: 197 | Batch: 2400/4364 (55%) | G Loss: 2.312756 | C Loss: -0.765856\n",
      "07/06/2022 21:40:48 - INFO - __main__ -   Text: ['He has used cathartic and ideological therapy in recent years, as well as physical therapy in past months before he']\n",
      "07/06/2022 21:40:50 - INFO - __main__ -   Epoch: 197 | Batch: 3000/4364 (69%) | G Loss: 1.708530 | C Loss: -1.275679\n",
      "07/06/2022 21:40:50 - INFO - __main__ -   Text: ['The problem didn\\'t go away; Sami\\'s steady flow of ketamine medication led to \"MRAtopy\"']\n",
      "07/06/2022 21:40:52 - INFO - __main__ -   Epoch: 197 | Batch: 3600/4364 (82%) | G Loss: 1.398320 | C Loss: -0.280550\n",
      "07/06/2022 21:40:52 - INFO - __main__ -   Text: ['In one of his mornings in July 2012, he lost about 10 lbs in the shape of 15 seconds when his']\n",
      "07/06/2022 21:40:54 - INFO - __main__ -   Epoch: 197 | Batch: 4200/4364 (96%) | G Loss: 1.490558 | C Loss: -1.456232\n",
      "07/06/2022 21:40:54 - INFO - __main__ -   Text: [\"He contributed a sauce overall, but it didn't cure any pain or woe and it still retains % of the\"]\n",
      "07/06/2022 21:40:55 - INFO - __main__ -   * (Train) Epoch: 197 | G Loss: 1.8976 | C Loss: -0.8282 | Updates G: 16 | Updates C: 347\n",
      "07/06/2022 21:41:09 - INFO - __main__ -   Bleu-2:0.460 | B-Bleu-2:0.331\n",
      "07/06/2022 21:41:09 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7905206464449989\n",
      "Train file used is number 8\n",
      "../../drugs/subdivided/train_8.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 198 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:43:37 - INFO - __main__ -   Epoch: 198 | Batch: 0/4330 (0%) | G Loss: 1.599380 | C Loss: -1.101965\n",
      "07/06/2022 21:43:37 - INFO - __main__ -   Text: ['The teaspoonps is suppressed 333.\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.185\n",
      "  Test Loss: 5.654\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:43:39 - INFO - __main__ -   Epoch: 198 | Batch: 600/4330 (14%) | G Loss: 1.603431 | C Loss: -0.925343\n",
      "07/06/2022 21:43:39 - INFO - __main__ -   Text: ['\"When using two charges of \\'Ruby on Rails\\' to facilitate fiscal priorities, a seemingly pleasant business experience goes']\n",
      "07/06/2022 21:43:41 - INFO - __main__ -   Epoch: 198 | Batch: 1200/4330 (28%) | G Loss: 1.787859 | C Loss: -0.504909\n",
      "07/06/2022 21:43:41 - INFO - __main__ -   Text: ['One!\"']\n",
      "07/06/2022 21:43:43 - INFO - __main__ -   Epoch: 198 | Batch: 1800/4330 (42%) | G Loss: 1.704304 | C Loss: -0.572921\n",
      "07/06/2022 21:43:44 - INFO - __main__ -   Text: ['If less than 1000 copies remain in print after its release from its first week, it becomes \"demotivated\"']\n",
      "07/06/2022 21:43:45 - INFO - __main__ -   Epoch: 198 | Batch: 2400/4330 (55%) | G Loss: 1.669468 | C Loss: -0.960456\n",
      "07/06/2022 21:43:46 - INFO - __main__ -   Text: ['Gross, raw daily is a nightmare at around 25% and this is mainly due to energy restrictions – because deep inside']\n",
      "07/06/2022 21:43:48 - INFO - __main__ -   Epoch: 198 | Batch: 3000/4330 (69%) | G Loss: 2.135087 | C Loss: -0.687792\n",
      "07/06/2022 21:43:48 - INFO - __main__ -   Text: ['\"Nothing new but bad\" symptoms.']\n",
      "07/06/2022 21:43:50 - INFO - __main__ -   Epoch: 198 | Batch: 3600/4330 (83%) | G Loss: 2.259155 | C Loss: -0.743025\n",
      "07/06/2022 21:43:50 - INFO - __main__ -   Text: [\"The song's sales got serious and many fans have claimed that it has been failing miserably.\"]\n",
      "07/06/2022 21:43:52 - INFO - __main__ -   Epoch: 198 | Batch: 4200/4330 (97%) | G Loss: 1.188187 | C Loss: -0.203219\n",
      "07/06/2022 21:43:52 - INFO - __main__ -   Text: ['A cash reward of one (1) Chrome and Nak 6820, – Monodity Sail Cure) the two']\n",
      "07/06/2022 21:43:52 - INFO - __main__ -   * (Train) Epoch: 198 | G Loss: 1.8193 | C Loss: -0.8481 | Updates G: 25 | Updates C: 335\n",
      "07/06/2022 21:44:06 - INFO - __main__ -   Bleu-2:0.448 | B-Bleu-2:0.305\n",
      "07/06/2022 21:44:06 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7521250488268043\n",
      "Train file used is number 9\n",
      "../../drugs/subdivided/train_9.txt\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 199 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:46:35 - INFO - __main__ -   Epoch: 199 | Batch: 0/4372 (0%) | G Loss: 1.183155 | C Loss: -0.737702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.185\n",
      "  Test Loss: 5.550\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:46:35 - INFO - __main__ -   Text: [\"Although he initially thought he'd never run out on his considerable income, he soon realized there was a barrier to his\"]\n",
      "07/06/2022 21:46:37 - INFO - __main__ -   Epoch: 199 | Batch: 600/4372 (14%) | G Loss: 1.682728 | C Loss: -0.647809\n",
      "07/06/2022 21:46:37 - INFO - __main__ -   Text: ['The future is uncertain but \"I have to keep sleeping for 2 hours per day, but still slept a day to']\n",
      "07/06/2022 21:46:39 - INFO - __main__ -   Epoch: 199 | Batch: 1200/4372 (27%) | G Loss: 1.812751 | C Loss: -0.635206\n",
      "07/06/2022 21:46:39 - INFO - __main__ -   Text: ['However, the sound makes the world stop around the planted speaker motionless and continues until Jai is dead, and']\n",
      "07/06/2022 21:46:42 - INFO - __main__ -   Epoch: 199 | Batch: 1800/4372 (41%) | G Loss: 2.154048 | C Loss: -0.738974\n",
      "07/06/2022 21:46:42 - INFO - __main__ -   Text: [\"They constantly remind themselves I'm not the biggest person, I'm very busy but I am the least interesting person but\"]\n",
      "07/06/2022 21:46:44 - INFO - __main__ -   Epoch: 199 | Batch: 2400/4372 (55%) | G Loss: 1.426423 | C Loss: -1.465155\n",
      "07/06/2022 21:46:44 - INFO - __main__ -   Text: ['On a note, he started my accident fantasy scenario (like refusing to get a new shirt) and I got my']\n",
      "07/06/2022 21:46:46 - INFO - __main__ -   Epoch: 199 | Batch: 3000/4372 (69%) | G Loss: 1.797557 | C Loss: -0.489627\n",
      "07/06/2022 21:46:46 - INFO - __main__ -   Text: ['The symptoms followed after the injection of corticosteroid and corticosteroid, but the next morning, there']\n",
      "07/06/2022 21:46:48 - INFO - __main__ -   Epoch: 199 | Batch: 3600/4372 (82%) | G Loss: 1.765504 | C Loss: -1.531584\n",
      "07/06/2022 21:46:48 - INFO - __main__ -   Text: ['Health problems subsequently progressed and it was reported that Heathery had chronic phobia of calluses during sleep,']\n",
      "07/06/2022 21:46:50 - INFO - __main__ -   Epoch: 199 | Batch: 4200/4372 (96%) | G Loss: 1.892783 | C Loss: -1.455356\n",
      "07/06/2022 21:46:50 - INFO - __main__ -   Text: ['The diet frequently promotes small and fragile female breasts, with awareness of their health.\"']\n",
      "07/06/2022 21:46:51 - INFO - __main__ -   * (Train) Epoch: 199 | G Loss: 1.7079 | C Loss: -0.8072 | Updates G: 27 | Updates C: 337\n",
      "07/06/2022 21:47:05 - INFO - __main__ -   Bleu-2:0.455 | B-Bleu-2:0.300\n",
      "07/06/2022 21:47:05 - INFO - utils -   Loading features from cached file ../../drugs/subdivided/cached_lm_gpt_bert_100_train_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7555281148899132\n",
      "Train file used is number 1\n",
      "Train classification discriminator\n",
      "\n",
      "======== Epoch 200 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     91.    Elapsed: 0:00:16.\n",
      "  Batch    20  of     91.    Elapsed: 0:00:33.\n",
      "  Batch    30  of     91.    Elapsed: 0:00:49.\n",
      "  Batch    40  of     91.    Elapsed: 0:01:05.\n",
      "  Batch    50  of     91.    Elapsed: 0:01:21.\n",
      "  Batch    60  of     91.    Elapsed: 0:01:38.\n",
      "  Batch    70  of     91.    Elapsed: 0:01:54.\n",
      "  Batch    80  of     91.    Elapsed: 0:02:10.\n",
      "  Batch    90  of     91.    Elapsed: 0:02:27.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:49:33 - INFO - __main__ -   Epoch: 200 | Batch: 0/4473 (0%) | G Loss: 2.156794 | C Loss: -0.653070\n",
      "07/06/2022 21:49:33 - INFO - __main__ -   Text: ['We recommend: Name Frequency Tyrwaa Ya 5/10 False!\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.195\n",
      "  Test Loss: 5.557\n",
      "  Test took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 21:49:35 - INFO - __main__ -   Epoch: 200 | Batch: 600/4473 (13%) | G Loss: 1.690808 | C Loss: -0.619488\n",
      "07/06/2022 21:49:35 - INFO - __main__ -   Text: ['Ability to metabolize this drug has been among The actual dosage is unclear, seemingly because it was administered during weight loss']\n",
      "07/06/2022 21:49:37 - INFO - __main__ -   Epoch: 200 | Batch: 1200/4473 (27%) | G Loss: 1.674550 | C Loss: -0.555010\n",
      "07/06/2022 21:49:37 - INFO - __main__ -   Text: ['Nuvixested plants that had not reached puberty during the study period had a significantly softer reaction and had an even']\n",
      "07/06/2022 21:49:39 - INFO - __main__ -   Epoch: 200 | Batch: 1800/4473 (40%) | G Loss: 1.670536 | C Loss: -0.665273\n",
      "07/06/2022 21:49:40 - INFO - __main__ -   Text: ['Joining YouTube another week is a manual, almost all YouTube videos go on fast (with daily disappearing due to severe']\n",
      "07/06/2022 21:49:42 - INFO - __main__ -   Epoch: 200 | Batch: 2400/4473 (54%) | G Loss: 2.039033 | C Loss: -0.792891\n",
      "07/06/2022 21:49:42 - INFO - __main__ -   Text: [\"Somehow, she suddenly stopped hurting herself and experienced a mental capacity that she couldn't easily relinquish, after pouring\"]\n",
      "07/06/2022 21:49:44 - INFO - __main__ -   Epoch: 200 | Batch: 3000/4473 (67%) | G Loss: 1.813323 | C Loss: -0.820641\n",
      "07/06/2022 21:49:44 - INFO - __main__ -   Text: [\"There have been protests put out by the makers for Heavys and wasn't looking for 'Eat carbon copy,\"]\n",
      "07/06/2022 21:49:46 - INFO - __main__ -   Epoch: 200 | Batch: 3600/4473 (80%) | G Loss: 1.530604 | C Loss: -0.144521\n",
      "07/06/2022 21:49:46 - INFO - __main__ -   Text: ['AD .']\n",
      "07/06/2022 21:49:48 - INFO - __main__ -   Epoch: 200 | Batch: 4200/4473 (94%) | G Loss: 1.761663 | C Loss: -1.170133\n",
      "07/06/2022 21:49:48 - INFO - __main__ -   Text: ['Friends who have already told \"Essentially You Will Heal the veal and have eaten it or you will']\n",
      "07/06/2022 21:49:49 - INFO - __main__ -   * (Train) Epoch: 200 | G Loss: 1.7665 | C Loss: -0.8198 | Updates G: 18 | Updates C: 354\n",
      "07/06/2022 21:50:03 - INFO - __main__ -   Bleu-2:0.457 | B-Bleu-2:0.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780260130148276\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', type=int, default=0)\n",
    "    parser.add_argument('--epochs', type=int, default=15)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--gp_lambda', type=int, default=10)\n",
    "    parser.add_argument('--n_layers', type=int, default=20, help=\"Number of layers of generator and critic\")\n",
    "    parser.add_argument('--block_dim', type=int, default=100)\n",
    "    parser.add_argument('--interval', type=int, default=10, help=\"Steps before logging output\")\n",
    "    parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available())\n",
    "    \n",
    "    # Optimus parameters\n",
    "    parser.add_argument(\"--train_data_file\", default=None, type=str, required=True,\n",
    "                        help=\"The input training data file (a text file).\")\n",
    "    parser.add_argument(\"--valid_data_file\", default=None, type=str, required=True,\n",
    "                        help=\"The input validation data file (a text file).\")\n",
    "    parser.add_argument(\"--checkpoint_dir\", default=None, type=str, required=True,\n",
    "                        help=\"The directory where checkpoints are saved.\")\n",
    "    parser.add_argument('--generator_dir', default=None, type=str, help=\"Directory where GAN models are saved\")\n",
    "    parser.add_argument(\"--output_dir\", default=None, type=str, required=True,\n",
    "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "    parser.add_argument(\"--dataset\", default='Snli', type=str, help=\"The dataset.\")    \n",
    "    parser.add_argument(\"--latent_size\", default=32, type=int, help=\"Latent space dimension.\")\n",
    "    ## Encoder options\n",
    "    parser.add_argument(\"--encoder_model_type\", default=\"bert\", type=str,\n",
    "                        help=\"The encoder model architecture to be fine-tuned.\")\n",
    "    parser.add_argument(\"--encoder_model_name_or_path\", default=\"bert-base-cased\", type=str,\n",
    "                        help=\"The encoder model checkpoint for weights initialization.\")\n",
    "    parser.add_argument(\"--encoder_config_name\", default=\"\", type=str,\n",
    "                        help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "    parser.add_argument(\"--encoder_tokenizer_name\", default=\"\", type=str,\n",
    "                        help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "    ## Decoder options\n",
    "    parser.add_argument(\"--decoder_model_type\", default=\"gpt2\", type=str,\n",
    "                        help=\"The decoder model architecture to be fine-tuned.\")\n",
    "    parser.add_argument(\"--decoder_model_name_or_path\", default=\"bert-base-cased\", type=str,\n",
    "                        help=\"The decoder model checkpoint for weights initialization.\")\n",
    "    parser.add_argument(\"--decoder_config_name\", default=\"\", type=str,\n",
    "                        help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "    parser.add_argument(\"--decoder_tokenizer_name\", default=\"\", type=str,\n",
    "                        help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "    parser.add_argument(\"--per_gpu_train_batch_size\", default=1, type=int,\n",
    "                        help=\"Batch size per GPU/CPU for training.\")\n",
    "    parser.add_argument(\"--max_seq_length\", default=512, type=int,\n",
    "                        help=\"Optional input sequence length before tokenization. The sequence will be dropped if it is longer the max_seq_length\")\n",
    "\n",
    "    ## Variational auto-encoder(check this)\n",
    "    parser.add_argument(\"--prompt\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--padding_text\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--length\", type=int, default=20)\n",
    "    parser.add_argument(\"--block_size\", default=-1, type=int,\n",
    "                        help=\"Optional input sequence length after tokenization.\"\n",
    "                             \"The training dataset will be truncated in block of this size for training.\"\n",
    "                             \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n",
    "    parser.add_argument(\"--do_lower_case\", action='store_true',\n",
    "                        help=\"Set this flag if you are using an uncased model.\")\n",
    "    parser.add_argument(\"--use_philly\", action='store_true',\n",
    "                        help=\"Use Philly for computing.\")\n",
    "    parser.add_argument('--gloabl_step_eval', type=int, default=661,\n",
    "                        help=\"Evaluate the results at the given global step\")\n",
    "    # Reinforcement learning parameters\n",
    "    parser.add_argument('--finetune_decoder', type=bool, default=True)\n",
    "    parser.add_argument('--epochs_rl', type=int, default=1000)\n",
    "    parser.add_argument('--batch_size_rl', type=int, default=32)\n",
    "    parser.add_argument('--lr_rl', type=float, default=1e-6)\n",
    "\n",
    "\n",
    "    # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "    args = parser.parse_args(\"--dataset EMNLP \\\n",
    "    --checkpoint_dir=output_dir_768_0_unsure_2 \\\n",
    "    --output_dir=output_dir_768_0_unsure_2 \\\n",
    "    --encoder_model_type=bert \\\n",
    "    --encoder_model_name_or_path=bert-base-cased \\\n",
    "    --decoder_model_type=gpt2 \\\n",
    "    --decoder_model_name_or_path=gpt2 \\\n",
    "    --train_data_file=../../drugs/subdivided/train \\\n",
    "    --valid_data_file=../../drugs/subdivided/test.txt \\\n",
    "    --per_gpu_train_batch_size 12 \\\n",
    "    --block_size 100 \\\n",
    "    --max_seq_length 24 \\\n",
    "    --gloabl_step_eval 508523 \\\n",
    "    --latent_size 768 \\\n",
    "    --block_dim 100 \\\n",
    "    --n_layers 10 \\\n",
    "    --interval 50 \\\n",
    "    --epochs 200 \\\n",
    "    --finetune_decoder False \\\n",
    "    --lr_rl 1e-6 \\\n",
    "    --epochs_rl 100 \\\n",
    "    --batch_size_rl 32\".split())\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    global_step = args.gloabl_step_eval\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    #args.n_gpu = torch.cuda.device_count()\n",
    "    args.device = torch.device(\"cuda:0\")\n",
    "    args.n_gpu=1\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)       \n",
    "    \n",
    "    args.encoder_model_type = args.encoder_model_type.lower()\n",
    "    args.decoder_model_type = args.decoder_model_type.lower()\n",
    "\n",
    "    output_encoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-encoder-{}'.format(global_step))\n",
    "    output_decoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-decoder-{}'.format(global_step)) \n",
    "    checkpoints = [ [output_encoder_dir, output_decoder_dir] ]\n",
    "\n",
    "    # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "    encoder_config_class, encoder_model_class, encoder_tokenizer_class = MODEL_CLASSES[args.encoder_model_type]\n",
    "    model_encoder = encoder_model_class.from_pretrained(output_encoder_dir, latent_size=args.latent_size)\n",
    "    tokenizer_encoder = encoder_tokenizer_class.from_pretrained(args.encoder_tokenizer_name if args.encoder_tokenizer_name else args.encoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "\n",
    "    model_encoder.to(args.device)\n",
    "    if args.block_size <= 0:\n",
    "        args.block_size = tokenizer_encoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "    args.block_size = min(args.block_size, tokenizer_encoder.max_len_single_sentence)\n",
    "\n",
    "    # Load a trained Decoder model and vocabulary that you have fine-tuned\n",
    "    decoder_config_class, decoder_model_class, decoder_tokenizer_class = MODEL_CLASSES[args.decoder_model_type]\n",
    "    model_decoder = decoder_model_class.from_pretrained(output_decoder_dir, latent_size=args.latent_size)\n",
    "    tokenizer_decoder = decoder_tokenizer_class.from_pretrained(args.decoder_tokenizer_name if args.decoder_tokenizer_name else args.decoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "    model_decoder.to(args.device)\n",
    "    if args.block_size <= 0:\n",
    "        args.block_size = tokenizer_decoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "    args.block_size = min(args.block_size, tokenizer_decoder.max_len_single_sentence)\n",
    "\n",
    "    # Chunyuan: Add Padding token to GPT2\n",
    "    special_tokens_dict = {'pad_token': '<PAD>', 'bos_token': '<BOS>', 'eos_token': '<EOS>'}\n",
    "    num_added_toks = tokenizer_decoder.add_special_tokens(special_tokens_dict)\n",
    "    logger.info('We have added {} tokens to GPT2'.format(num_added_toks))\n",
    "    model_decoder.resize_token_embeddings(len(tokenizer_decoder))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n",
    "    assert tokenizer_decoder.pad_token == '<PAD>'\n",
    "\n",
    "    #train_loader, num_txt = build_dataload_and_cache_examples(args, [tokenizer_encoder, tokenizer_decoder], num_txt) \n",
    "    generator = Generator(args.n_layers, args.block_dim,args.latent_size)\n",
    "    critic = Critic(args.n_layers, args.block_dim,args.latent_size)\n",
    "\n",
    "    if args.generator_dir!=None:\n",
    "        logger.info(\"Loading generator and critic\")\n",
    "        generator.load_state_dict(torch.load(args.generator_dir+'/generator_'+str(args.gloabl_step_eval)+'.th'))\n",
    "        critic.load_state_dict(torch.load(args.generator_dir+'/critic_'+str(args.gloabl_step_eval)+'.th'))\n",
    "\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "    c_optimizer = optim.Adam(critic.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    if args.cuda:\n",
    "        generator = generator.cuda()\n",
    "        critic = critic.cuda()\n",
    "    \n",
    "    logger.info('G Parameters:{}'.format(sum([p.numel() for p in generator.parameters() if \\\n",
    "                                p.requires_grad])))\n",
    "    logger.info('C Parameters:{}'.format(sum([p.numel() for p in critic.parameters() if \\\n",
    "                                p.requires_grad])))\n",
    "    \n",
    "    device = args.device\n",
    "    \n",
    "    best_bleu = 0\n",
    "    reference = list()\n",
    "    with(open(args.valid_data_file,\"r\")) as valid:\n",
    "        for sents in valid:\n",
    "            reference.append(sents.replace(\"\\n\", \"\"))\n",
    "            \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        \n",
    "        #Insert GAN-BERT Code Here\n",
    "        \n",
    "        train_loader, num_txt = build_dataload_and_cache_examples(args, [tokenizer_encoder, tokenizer_decoder], num_txt) \n",
    "        \n",
    "        print(\"Train classification discriminator\")\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "        # Perform one full pass over the training set.\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch, args.epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        tr_g_loss = 0\n",
    "        tr_d_loss = 0\n",
    "\n",
    "        # Put the model into training mode.\n",
    "        transformer.train() \n",
    "        #generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Progress update every print_each_n_step batches.\n",
    "            if step % print_each_n_step == 0 and not step == 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                # Report progress.\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            b_label_mask = batch[3].to(device)\n",
    "\n",
    "            real_batch_size = b_input_ids.shape[0]\n",
    "\n",
    "            # Encode real data in the Transformer\n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            hidden_states = model_outputs.last_hidden_state[:,0,:] \n",
    "            #hidden_states = model_outputs[-1]\n",
    "            #print(\"  Number of real sentences (labelled and unlabelled): {}\".format(len(hidden_states)))\n",
    "            \n",
    "            # Generate fake data that should have the same distribution of the ones\n",
    "            # encoded by the transformer. \n",
    "            # First noisy input are used in input to the Generator\n",
    "            fixed_noise = torch.Tensor(np.random.normal(0, 1, (real_batch_size, args.latent_size))).to(args.device)\n",
    "            test_z_gb = generator(fixed_noise).data\n",
    "            fake_sentences = rollout_test(model_decoder, test_z_gb, tokenizer_decoder, args.max_seq_length, real_batch_size, 0, 1)\n",
    "            #print(\"  Number of generated sentences: {}\".format(len(fake_sentences)))\n",
    "\n",
    "            b_input_ids_fake, b_input_mask_fake = generate_data_fake(fake_sentences)\n",
    "            model_outputs_fake = transformer(b_input_ids_fake, attention_mask=b_input_mask_fake)\n",
    "            hidden_states_fake = model_outputs_fake.last_hidden_state[:,0,:] \n",
    "            #hidden_states_fake = model_outputs_fake[-1]\n",
    "\n",
    "            #noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "            # Gnerate Fake data\n",
    "            #gen_rep = generator(noise)\n",
    "            #print(\"Length of generator output {}\".format(len(gen_rep)))\n",
    "            #print(\"Length of single generator output {}\".format(len(gen_rep[0])))\n",
    "\n",
    "            # Generate the output of the Discriminator for real and fake data.\n",
    "            # First, we put together the output of the tranformer and the generator\n",
    "            disciminator_input = torch.cat([hidden_states, hidden_states_fake], dim=0)\n",
    "            # Then, we select the output of the disciminator\n",
    "            features, logits, probs = discriminator(disciminator_input)\n",
    "\n",
    "            # Finally, we separate the discriminator's output for the real and fake\n",
    "            # data\n",
    "            features_list = torch.split(features, real_batch_size)\n",
    "            D_real_features = features_list[0]\n",
    "            D_fake_features = features_list[1]\n",
    "\n",
    "            logits_list = torch.split(logits, real_batch_size)\n",
    "            D_real_logits = logits_list[0]\n",
    "            D_fake_logits = logits_list[1]\n",
    "\n",
    "            probs_list = torch.split(probs, real_batch_size)\n",
    "            D_real_probs = probs_list[0]\n",
    "            D_fake_probs = probs_list[1]\n",
    "\n",
    "            #---------------------------------\n",
    "            #  LOSS evaluation\n",
    "            #---------------------------------\n",
    "            # Generator's LOSS estimation\n",
    "            g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "            g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "            g_loss = g_loss_d + g_feat_reg\n",
    "\n",
    "            # Disciminator's LOSS estimation\n",
    "            logits = D_real_logits[:,0:-1]\n",
    "            log_probs = F.log_softmax(logits, dim=-1)\n",
    "            # The discriminator provides an output for labeled and unlabeled real data\n",
    "            # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "            label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "            per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "            per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "            labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "            # It may be the case that a batch does not contain labeled examples, \n",
    "            # so the \"supervised loss\" in this case is not evaluated\n",
    "            if labeled_example_count == 0:\n",
    "              D_L_Supervised = 0\n",
    "            else:\n",
    "              D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "\n",
    "            D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "            D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "            d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "\n",
    "            #---------------------------------\n",
    "            #  OPTIMIZATION\n",
    "            #---------------------------------\n",
    "            # Avoid gradient accumulation\n",
    "            #gen_optimizer.zero_grad()\n",
    "            dis_optimizer.zero_grad()\n",
    "\n",
    "            # Calculate weigth updates\n",
    "            # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "            g_loss.backward(retain_graph=True)\n",
    "            d_loss.backward() \n",
    "\n",
    "            # Apply modifications\n",
    "            #gen_optimizer.step()\n",
    "            dis_optimizer.step()\n",
    "\n",
    "            # A detail log of the individual losses\n",
    "            #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "            #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "            #             g_loss_d, g_feat_reg))\n",
    "\n",
    "            # Save the losses to print them later\n",
    "            tr_g_loss += g_loss.item()\n",
    "            tr_d_loss += d_loss.item()\n",
    "\n",
    "            # Update the learning rate with the scheduler\n",
    "            if apply_scheduler:\n",
    "              scheduler_d.step()\n",
    "              #scheduler_g.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "        avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "        print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #     TEST ON THE EVALUATION DATASET\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our test set.\n",
    "        print(\"\")\n",
    "        print(\"Running Test...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        transformer.eval() #maybe redundant\n",
    "        discriminator.eval()\n",
    "        #generator.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_test_accuracy = 0\n",
    "\n",
    "        total_test_loss = 0\n",
    "        nb_test_steps = 0\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels_ids = []\n",
    "\n",
    "        #loss\n",
    "        nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in test_dataloader:\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "                model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "                hidden_states = model_outputs.last_hidden_state[:,0,:] \n",
    "                #hidden_states = model_outputs[-1]\n",
    "                _, logits, probs = discriminator(hidden_states)\n",
    "                ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "                filtered_logits = logits[:,0:-1]\n",
    "                # Accumulate the test loss.\n",
    "                total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "\n",
    "            # Accumulate the predictions and the input labels\n",
    "            _, preds = torch.max(filtered_logits, 1)\n",
    "            all_preds += preds.detach().cpu()\n",
    "            all_labels_ids += b_labels.detach().cpu()\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        all_preds = torch.stack(all_preds).numpy()\n",
    "        all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "        test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "        print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "        avg_test_loss = avg_test_loss.item()\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        test_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "        print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch + 1,\n",
    "                'Training Loss generator': avg_train_loss_g,\n",
    "                'Training Loss discriminator': avg_train_loss_d,\n",
    "                'Valid. Loss': avg_test_loss,\n",
    "                'Valid. Accur.': test_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Test Time': test_time\n",
    "            }\n",
    "        )\n",
    "\n",
    "        accuracy_array.append(test_accuracy)\n",
    "        \n",
    "        #OPTAGAN Code\n",
    "        \n",
    "        g_loss, c_loss = train(epoch)\n",
    "\n",
    "        data_test = list()\n",
    "        for i in range(2):\n",
    "            test_noise = torch.Tensor(np.random.normal(0, 1, (250, args.latent_size))).to(args.device)\n",
    "            test_z = generator(test_noise).data\n",
    "            new_sent = rollout_test(model_decoder, test_z, tokenizer_decoder, args.max_seq_length, 250, 0, 1)\n",
    "            data_test.extend(new_sent)\n",
    "\n",
    "        p_reference = random.sample(reference, 500)\n",
    "        bleu = calc_blue_parallel_func(p_reference, data_test, 2, 500)\n",
    "        b_bleu = calc_blue_parallel_func(data_test, p_reference, 2, 500)\n",
    "        logger.info(\"Bleu-2:{:0.3f} | B-Bleu-2:{:0.3f}\".format(bleu, b_bleu))\n",
    "        \n",
    "        print(bleu+b_bleu)\n",
    "        if (bleu+b_bleu) > best_bleu:\n",
    "            best_bleu = bleu + b_bleu\n",
    "            logger.info('* Saving. Best Score:{:0.3f} | Bleu-2:{:0.3f} | B-Bleu-2:{:0.3f}'.format(best_bleu, bleu, b_bleu))\n",
    "            torch.save(generator.state_dict(), args.output_dir+'/generator_'+str(args.gloabl_step_eval)+'.th')\n",
    "            torch.save(critic.state_dict(), args.output_dir+'/critic_'+str(args.gloabl_step_eval)+'.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a70a35fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2275\n"
     ]
    }
   ],
   "source": [
    "print(max(accuracy_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "967334e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.195\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_array[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c07743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(accuracy_array)\n",
    "plt.title('Additional Discriminator OPTAGAN Performance (Medical)', fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.xlim(0,200)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e9ec8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save = pd.DataFrame(accuracy_array)\n",
    "df_to_save.to_csv('accuracy_array_optagan_drugs_cls_last.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18eae8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generating Sentences\n",
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# import argparse\n",
    "\n",
    "# import logging\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "\n",
    "# from modules.gan import Generator\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "# import pickle\n",
    "# import random\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "# from tqdm import tqdm, trange\n",
    "\n",
    "# from func import GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig, BertConfig\n",
    "# from func import GPT2LMHeadModel, GPT2Tokenizer, GPT2ForLatentConnector, GPT2ForLatentConnectorValueHead\n",
    "# from func import OpenAIGPTLMHeadModel, OpenAIGPTTokenizer\n",
    "# from func import XLNetLMHeadModel, XLNetTokenizer\n",
    "# from func import TransfoXLLMHeadModel, TransfoXLTokenizer\n",
    "# from func import BertForLatentConnector, BertTokenizer\n",
    "\n",
    "# from collections import defaultdict\n",
    "# import pdb\n",
    "# from modules.utils import rollout_test\n",
    "\n",
    "# MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "\n",
    "# ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) for conf in (GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig)), ())\n",
    "\n",
    "# logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "#                     datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "#                     level = logging.INFO)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# MODEL_CLASSES = {\n",
    "#     'gpt2': (GPT2Config, GPT2ForLatentConnector, GPT2Tokenizer),\n",
    "#     'bert': (BertConfig, BertForLatentConnector, BertTokenizer),\n",
    "#     'gpt2v': (GPT2Config, GPT2ForLatentConnectorValueHead, GPT2Tokenizer)\n",
    "# }\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--seed', type=int, default=0)\n",
    "#     parser.add_argument('--new_sent', type=int, default=1, help=\"Number of sentences to generate\")\n",
    "#     parser.add_argument('--n_layers', type=int, default=20, help=\"Number of layers of generator\")\n",
    "#     parser.add_argument('--block_dim', type=int, default=100)\n",
    "#     parser.add_argument('--interval', type=int, default=10)\n",
    "#     parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available())\n",
    "#     parser.add_argument('--generator_dir', default=None, type=str, required=True, help=\"Directory of GAN model checkpoint\")\n",
    "#     parser.add_argument(\"--checkpoint_dir\", default=None, type=str, required=True,\n",
    "#                         help=\"The directory where checkpoints are saved.\")\n",
    "#     parser.add_argument(\"--output_dir\", default=None, type=str, required=True,\n",
    "#                         help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "#     parser.add_argument(\"--save\", default=False, type=bool, help=\"Save results to file.\")\n",
    "#     parser.add_argument(\"--latent_size\", default=32, type=int, help=\"Latent space dimension.\")\n",
    "#     parser.add_argument(\"--output_name\", default=\"results\", type=str, help=\"File name of output\")\n",
    "#     parser.add_argument(\"--batch_size\", default=100, type=int, help=\"Batch size to generate outputs\")\n",
    "#     ## Encoder options\n",
    "#     parser.add_argument(\"--encoder_model_type\", default=\"bert\", type=str,\n",
    "#                         help=\"The encoder model architecture to be fine-tuned.\")\n",
    "#     parser.add_argument(\"--encoder_model_name_or_path\", default=\"bert-base-cased\", type=str,\n",
    "#                         help=\"The encoder model checkpoint for weights initialization.\")\n",
    "#     parser.add_argument(\"--encoder_config_name\", default=\"\", type=str,\n",
    "#                         help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "#     parser.add_argument(\"--encoder_tokenizer_name\", default=\"\", type=str,\n",
    "#                         help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "#     ## Decoder options\n",
    "#     parser.add_argument(\"--decoder_model_type\", default=\"gpt2\", type=str,\n",
    "#                         help=\"The decoder model architecture to be fine-tuned.\")\n",
    "#     parser.add_argument(\"--decoder_model_name_or_path\", default=\"gpt2\", type=str,\n",
    "#                         help=\"The decoder model checkpoint for weights initialization.\")\n",
    "#     parser.add_argument(\"--decoder_config_name\", default=\"\", type=str,\n",
    "#                         help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "#     parser.add_argument(\"--decoder_tokenizer_name\", default=\"\", type=str,\n",
    "#                         help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "#     parser.add_argument(\"--max_seq_length\", default=512, type=int,\n",
    "#                         help=\"Optional input sequence length before tokenization. The sequence will be dropped if it is longer the max_seq_length\")\n",
    "#     parser.add_argument(\"--finetune_decoder\", default=False, type=bool,\n",
    "#                         help=\"Uses finetuned decoder in output dir if true.\")\n",
    "\n",
    "#     ## Variational auto-encoder(check this)\n",
    "#     parser.add_argument(\"--top_k\", type=int, default=0)\n",
    "#     parser.add_argument(\"--top_p\", type=float, default=1.0)\n",
    "#     parser.add_argument(\"--prompt\", type=str, default=\"\")\n",
    "#     parser.add_argument(\"--padding_text\", type=str, default=\"\")\n",
    "#     parser.add_argument(\"--length\", type=int, default=20)\n",
    "#     parser.add_argument(\"--block_size\", default=-1, type=int,\n",
    "#                         help=\"Optional input sequence length after tokenization.\"\n",
    "#                              \"The training dataset will be truncated in block of this size for training.\"\n",
    "#                              \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n",
    "#     parser.add_argument(\"--do_lower_case\", action='store_true',\n",
    "#                         help=\"Set this flag if you are using an uncased model.\")\n",
    "#     parser.add_argument(\"--use_philly\", action='store_true',\n",
    "#                         help=\"Use Philly for computing.\")\n",
    "#     parser.add_argument('--gloabl_step_eval', type=int, default=508523,\n",
    "#                         help=\"Evaluate the results at the given global step\")\n",
    "\n",
    "#     # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "#     args = parser.parse_args(\"--checkpoint_dir=output_dir_yahoo_768_0 \\\n",
    "#     --output_dir=output_dir_yahoo_768_0 \\\n",
    "#     --generator_dir=output_dir_yahoo_768_0 \\\n",
    "#     --block_size 100 \\\n",
    "#     --max_seq_length 60 \\\n",
    "#     --gloabl_step_eval 24000 \\\n",
    "#     --latent_size 32 \\\n",
    "#     --block_dim 100 \\\n",
    "#     --new_sent 100 \\\n",
    "#     --n_layers 10 \\\n",
    "#     --top_p 0.9 \\\n",
    "#     --output_name=results \\\n",
    "#     --save True\".split())\n",
    "#     global_step = args.gloabl_step_eval\n",
    "\n",
    "#     np.random.seed(args.seed)\n",
    "#     torch.manual_seed(args.seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "#     args.n_gpu = torch.cuda.device_count()\n",
    "#     if args.n_gpu > 0:\n",
    "#         torch.cuda.manual_seed_all(args.seed)       \n",
    "    \n",
    "#     args.encoder_model_type = args.encoder_model_type.lower()\n",
    "#     args.decoder_model_type = args.decoder_model_type.lower()\n",
    "\n",
    "#     output_encoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-encoder-{}'.format(global_step))\n",
    "#     output_decoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-decoder-{}'.format(global_step))\n",
    "#     if not args.finetune_decoder:\n",
    "#         output_decoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-decoder-{}'.format(global_step))\n",
    "#     else:\n",
    "#          output_decoder_dir = os.path.join(args.output_dir, 'checkpoint-decoder-{}'.format(global_step))\n",
    "#     checkpoints = [ [output_encoder_dir, output_decoder_dir] ]\n",
    "\n",
    "#     # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "#     encoder_config_class, encoder_model_class, encoder_tokenizer_class = MODEL_CLASSES[args.encoder_model_type]\n",
    "#     model_encoder = encoder_model_class.from_pretrained(output_encoder_dir, latent_size=args.latent_size)\n",
    "#     tokenizer_encoder = encoder_tokenizer_class.from_pretrained(args.encoder_tokenizer_name if args.encoder_tokenizer_name else args.encoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "\n",
    "#     model_encoder.to(args.device)\n",
    "#     if args.block_size <= 0:\n",
    "#         args.block_size = tokenizer_encoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "#     args.block_size = min(args.block_size, tokenizer_encoder.max_len_single_sentence)\n",
    "\n",
    "#     # Load a trained Decoder model and vocabulary that you have fine-tuned\n",
    "#     if not args.finetune_decoder:\n",
    "#         decoder_config_class, decoder_model_class, decoder_tokenizer_class = MODEL_CLASSES[args.decoder_model_type]\n",
    "#     else:\n",
    "#         decoder_config_class, decoder_model_class, decoder_tokenizer_class = MODEL_CLASSES[\"gpt2v\"]\n",
    "#     model_decoder = decoder_model_class.from_pretrained(output_decoder_dir, latent_size=args.latent_size)\n",
    "#     tokenizer_decoder = decoder_tokenizer_class.from_pretrained(args.decoder_tokenizer_name if args.decoder_tokenizer_name else args.decoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "#     model_decoder.to(args.device)\n",
    "#     if args.block_size <= 0:\n",
    "#         args.block_size = tokenizer_decoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "#     args.block_size = min(args.block_size, tokenizer_decoder.max_len_single_sentence)\n",
    "\n",
    "#     # Chunyuan: Add Padding token to GPT2\n",
    "#     special_tokens_dict = {'pad_token': '<PAD>', 'bos_token': '<BOS>', 'eos_token': '<EOS>'}\n",
    "#     num_added_toks = tokenizer_decoder.add_special_tokens(special_tokens_dict)\n",
    "#     logger.info('We have added {} tokens to GPT2'.format(num_added_toks))\n",
    "#     model_decoder.resize_token_embeddings(len(tokenizer_decoder))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n",
    "#     assert tokenizer_decoder.pad_token == '<PAD>'\n",
    "    \n",
    "#     generator = Generator(args.n_layers, args.block_dim, args.latent_size)\n",
    "\n",
    "#     if args.cuda:\n",
    "#         generator = generator.cuda()\n",
    "\n",
    "#     generator.load_state_dict(torch.load(args.generator_dir+'/generator_'+str(args.gloabl_step_eval)+'.th'))\n",
    "#     generator.eval()\n",
    "#     model_decoder.eval()\n",
    "#     model_encoder.eval()\n",
    "#     if args.save:\n",
    "#         if not os.path.exists(args.output_dir+\"/{}.txt\".format(args.output_name)):\n",
    "#             with open(args.output_dir+\"/{}.txt\".format(args.output_name), 'w'): \n",
    "#                 pass\n",
    "\n",
    "#     for i in range(int(args.new_sent/args.batch_size)):\n",
    "#         # sample noise\n",
    "#         noise = torch.Tensor(np.random.normal(0, 1, (args.batch_size, args.latent_size))).to(args.device)\n",
    "#         new_z = generator(noise).data\n",
    "\n",
    "#         # create new sent\n",
    "#         sents = rollout_test(model_decoder, new_z, tokenizer_decoder, args.max_seq_length, args.batch_size, args.top_k, args.top_p)\n",
    "\n",
    "#         if args.save:\n",
    "#             with open(args.output_dir+\"/{}.txt\".format(args.output_name), 'a') as file:\n",
    "#                 for i in sents:\n",
    "#                     file.write(i+\"\\n\")\n",
    "#         else:\n",
    "#             for i in sents:\n",
    "#                 logger.info(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab174fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
