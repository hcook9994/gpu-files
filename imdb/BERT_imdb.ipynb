{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ea1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86576f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a0de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = pd.read_csv(\"imdb_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5880a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb=df_imdb.set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93668f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*****Warning: May contain SPOILERS********* My...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He really lost the plot with this one! None of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello everyone, This is my first time posting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love this show as it action packed with adve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text  sentiment\n",
       "Unnamed: 0                                                              \n",
       "0           *****Warning: May contain SPOILERS********* My...          1\n",
       "1           He really lost the plot with this one! None of...          1\n",
       "2           Hello everyone, This is my first time posting ...          0\n",
       "3           On his birthday a small boys tells his mother ...          1\n",
       "4           I love this show as it action packed with adve...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa3ceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    600\n",
       "0    600\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3818ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_imdb.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf8b279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>I normally have no problem walking away from a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>Eye in the Labyrinth is not your average Giall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.5/10. This movie has absolutely nothing good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>I was able to watch this movie in its entirety...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>If you like film, don't miss this one. If you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text  sentiment\n",
       "Unnamed: 0                                                              \n",
       "195         I normally have no problem walking away from a...          1\n",
       "1162        Eye in the Labyrinth is not your average Giall...          0\n",
       "101         0.5/10. This movie has absolutely nothing good...          1\n",
       "792         I was able to watch this movie in its entirety...          0\n",
       "949         If you like film, don't miss this one. If you ...          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c8821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers=list(df['sentiment'].unique())\n",
    "list_zeros = [0]*len(numbers)\n",
    "count_dictionary = dict(zip(numbers, list_zeros))\n",
    "\n",
    "values_array_train=[]\n",
    "values_array_test=[]\n",
    "values_array_unlabelled=[]\n",
    "for index, row in df.iterrows():\n",
    "    if count_dictionary[row['sentiment']]<20:\n",
    "        count_dictionary[row['sentiment']]=count_dictionary[row['sentiment']]+1\n",
    "        values_array_train.append((row['text'],row['sentiment']))\n",
    "    elif count_dictionary[row['sentiment']]<60:\n",
    "        count_dictionary[row['sentiment']]=count_dictionary[row['sentiment']]+1\n",
    "        values_array_test.append((row['text'],row['sentiment']))\n",
    "    elif count_dictionary[row['sentiment']]<600:\n",
    "        count_dictionary[row['sentiment']]=count_dictionary[row['sentiment']]+1\n",
    "        values_array_unlabelled.append((row['text'],'UNK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804df80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15a0c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f64668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_unlabelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faaf4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"I normally have no problem walking away from a bad movie, however this was an unique case. This movie was so bad that I actually sat through the whole thing almost praying it would have one minute of good movie time to justify the hour and a half that was wasted. Needless to say I was brutally disappointed. Set at a beach house where a group of college friends are celebrating vacation, this movie suffers from numerous problems making it not worth seeing. First, there are gaping plot holes. Second, very few of the C-list (i don't even dare call them B) actors can act worth a damn, so any scenes that have potential fail miserably. Third, the rate of the film is very choppy and awkward to watch most of the time making suspense building very difficult, leading to very few surprises for the audience. Fourth and most importantly, the ending is completely anti-climatic partially because of how it ends (setting/who the killer turns out to be) and partially because the dialog is just atrocious. To the films credit, it is the only movie that I will ever say is the worst movie I have ever scene, and i've seen a lot.  So, just like a bad joke you would have been all the happier never hearing, the next time someone asks you if you want to know a secret you will be yelling no, you really don't as you run in the opposite direction.\", 1)\n"
     ]
    }
   ],
   "source": [
    "print(values_array_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c31b5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I read several mixed reviews and several of them downright trashed the movie. I originally became interested in this project because it was being directed by Tony Scott and I have become very interested in his work after Man On Fire had such a profound impact on me. Before I start my review, let me first say this...it\\'s wonderful to see that this movie could have been told in a boring and ordinary manner, yet the writers and Scott chose a different approach.  Plot:  Simply stated, it\\'s not boring. Most Hollywood movies give \\'tried and true\\' plots that they know will connect with people, often ensuring the audiences acceptance of the film and creating a higher probability of profit. This plot was one of the more interesting ones I had seen in a while. Just for reference, I recently watched \\'The Weather Man\\' and \\'Lord of War\\' and while I will say that these movies are excellent, and I enjoyed them both tremendously, both the plots in these movies are boring and they are told exactly how you would expect them to be told. They don\\'t take any chances whatsoever, and they are extremely predictable after you\\'ve watched a fair amount of American films. Domino\\'s plot is both interesting and told in a manner that keeps you thinking, \"oh man, they\\'re screwed now\". And I feel that has been lacking in a lot of recent films. It has a lot of depth to it, in my opinion, and gives you plenty of things to question while watching it. Overall, this is what kept me so interested in the movie.  Characters:  I felt that the characters were accurate. Knightley did a wonderful job of portraying a beautiful woman, who was anything but on the inside and wanted to be viewed as what she was. It was obvious that she wanted to prove herself and she took whatever means she had to accomplish that.  Choco was also very believable, his use of Spanish in inappropriate situations, his reactions to Domino\\'s lack of affection, as well as his jealousy issues within the team...they all rang true to me, which made me feel that his character was that much more realistic.  Rourke\\'s character was the least interesting to me, but it still rang true to me. He seemed like an ordinary guy, trying to make ends meet. I hope that\\'s what the filmmakers were trying to accomplish with him because that\\'s what I got out of it. He did a very good job of showing Ed in an Average Joe kind of way that has made his mistakes, yet is still trying to live.  Claremont/Ladies: I believe that they provided much needed \\'heart\\' to the story. They weren\\'t just people who are out getting money to buy a Bentley, these were real people who had a real problem and they sought others mean to accomplish that goal. You could empathize with them because, to them, this child\\'s illness was a problem with no other solution. These characters were supposed to show real people who are less fortunate who got into this mess because they needed help.  The mobsters: They made the story seem sinister in a way that only the mob can. And I really liked that part. They also padded the story with small intricacies that made the plot that much more interesting.  Christopher Walken/90210 guys:  They provided the comic relief in an otherwise very serious movie. From Walken\\'s awkward statements to the ceaseless references to the 90210 guys being has-beens. Their involvement in the movie only made it that much more enjoyable.  Cinematography....yes....the cinematography. This is where this movie seems to have lost a lot of potential fans. But in my opinion I thought it was genius, the use of the camera to translate the mood of the current situation was extremely effective in my opinion. I considered it a method that was properly realized but could always use improvement, just like anything else. I both applaud and congratulate Scott, the editor, the cinematographer and the director of photography on taking some real chances with this movie. Not only did they go far and above with its presentation, they went that much further. The use of colors, both extremely light and extremely dark provided the \\'look\\' of the film with a sinister and grungy look that accurately depicts the life of the mob, bounty hunters and the less fortunate in a manner that show that their life isn\\'t as peachy or \\'clean\\' as everyone else. If you notice, in times of less stress or conflict, there were very few camera tricks if any at all. This shows that Scott and his crew were trying to achieve something with this look and weren\\'t just doing it for the heck of it. I realize that most people who watched this movie weren\\'t expecting it and it cause many of them to be turned off to this film but I think it was great that Scott took this approach. Hollywood films have grown predictable and bland. Most of them are shot in the same manner with the same twists and turns. And I\\'m glad that Scott tried to make something different.  Granted, this movie isn\\'t for everyone, but to say it\\'s trash and has nothing to offer is completely missing the point. I thoroughly enjoyed this film and I\\'m glad that I spent the money for it. I would recommend this to all, but I\\'m sure it will only hit a chord with few. I must agree with an earlier poster when he said that many of those who refuse to see outside the \\'sphere of MTV\\' won\\'t appreciate this movie, but I think many people will. We should all try to enjoy it for the fact that Scott and co. took some chances and tried to deliver something that was different and unique. And with that in mind, I think he succeeded tremendously.', 0)\n"
     ]
    }
   ],
   "source": [
    "print(values_array_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce423411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"This was far and away the worst movie i've ever seen in my entire life. It was slow, boring, not scary, not funny, not dramatic, not entertaining.  Sarah Michelle Gellar was up to her old playbook of empty expressions of fright and shock. She couldn't sell her character nor could anyone else in the picture.  For those who thought the Grudge was 'kind of alright' then don't go see this unless you get enjoyment out of wasting your time and your life.  I saw this movie for free by the way so I don't want this to come across as a rant from a guy that lost 8 bucks on a terrible movie. It was free, it still sucked, I hated it.  Avoid.\", 'UNK')\n"
     ]
    }
   ],
   "source": [
    "print(values_array_unlabelled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37916145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.3.2\n",
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install sentencepiece\n",
    "\n",
    "##Set random values\n",
    "#seed_val = 42\n",
    "seed_val = 27\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d415d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88a04fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 300\n",
    "batch_size = 20\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "#num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-5\n",
    "#learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 30\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "#model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "#model_name=\"google/electra-large-discriminator\"\n",
    "#model_name=\"google/electra-small-discriminator\"\n",
    "#model_name=\"microsoft/deberta-v2-xxlarge\"\n",
    "#model_name=\"microsoft/deberta-v3-base\"\n",
    "model_name = \"google/electra-base-discriminator\"\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the TREC QC Dataset\n",
    "#--------------------------------\n",
    "#! git clone https://github.com/crux82/ganbert\n",
    "\n",
    "#  NOTE: in this setting 50 classes are involved\n",
    "# labeled_file = \"./ganbert/data/labeled.tsv\"\n",
    "# unlabeled_file = \"./ganbert/data/unlabeled.tsv\"\n",
    "# test_filename = \"./ganbert/data/test.tsv\"\n",
    "\n",
    "label_list = ['UNK',0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c908c079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/electra-base-discriminator/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/electra-base-discriminator/resolve/main/pytorch_model.bin from cache at /home/harry/.cache/huggingface/transformers/aed576b8aec823c870feda40d60bd803ac8e40056ecb7d7f43dd0b2bfd82e373.db390a2059e53ead2bb00e1a2f8cd50b0a47e1969d180cd70339ec3f6f29dce1\n",
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ElectraModel were initialized from the model checkpoint at google/electra-base-discriminator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/google/electra-base-discriminator/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/vocab.txt from cache at /home/harry/.cache/huggingface/transformers/fe616facc71d8e3afc69de3edac76bf1e4a0a741e80d9a99a2cc6a9a8f5f74b5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/tokenizer.json from cache at /home/harry/.cache/huggingface/transformers/81840ac426bf0d690bfb69a4ec7d706e8853d8ab309e7decb6b72ab939d6682e.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/electra-base-discriminator/resolve/main/tokenizer_config.json from cache at /home/harry/.cache/huggingface/transformers/6f8b3f5095b6f44f5c75cee3c56b971b3208b08132ba2f9fb775a4a7b7140942.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9\n",
      "loading configuration file https://huggingface.co/google/electra-base-discriminator/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6383a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the examples\n",
    "labeled_examples = values_array_train\n",
    "#unlabeled_examples = values_array_unlabelled\n",
    "test_examples = values_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d4fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  examples = []\n",
    "\n",
    "  # Count the percentage of labeled examples  \n",
    "  num_labeled_examples = 0\n",
    "  for label_mask in label_masks:\n",
    "    if label_mask: \n",
    "      num_labeled_examples += 1\n",
    "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "  # if required it applies the balance\n",
    "  for index, ex in enumerate(input_examples): \n",
    "    if label_mask_rate == 1 or not balance_label_examples:\n",
    "      examples.append((ex, label_masks[index]))\n",
    "    else:\n",
    "      # IT SIMULATE A LABELED EXAMPLE\n",
    "      if label_masks[index]:\n",
    "        balance = int(1/label_mask_rate)\n",
    "        balance = int(math.log(balance,2))\n",
    "        if balance < 1:\n",
    "          balance = 1\n",
    "        for b in range(0, int(balance)):\n",
    "          examples.append((ex, label_masks[index]))\n",
    "      else:\n",
    "        examples.append((ex, label_masks[index]))\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for (text, label_mask) in examples:\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[text[1]])\n",
    "    label_mask_array.append(label_mask)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "  label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56feab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "# if unlabeled_examples:\n",
    "#   train_examples = train_examples + unlabeled_examples\n",
    "#   #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "#   tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
    "#   train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cce6ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Generator as in \n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
    "        super(Generator, self).__init__()\n",
    "        layers = []\n",
    "        hidden_sizes = [noise_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output_rep = self.layers(noise)\n",
    "        return output_rep\n",
    "\n",
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f27045c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/electra-base-discriminator/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/7d1569a4df2372d67341bda716bce4e3edf3e3ffadb97251bc4b6b35d459f624.57c13443a51769ce892714c93bb3ee3952bad66d7d9662d9de382b808377c3f8\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "#hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "#generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  #generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dcbc408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.379\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.525\n",
      "  Test Loss: 0.951\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.117\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.512\n",
      "  Test Loss: 0.836\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.938\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.500\n",
      "  Test Loss: 0.770\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.838\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.688\n",
      "  Test Loss: 0.724\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 5 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.759\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.738\n",
      "  Test Loss: 0.684\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 6 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.662\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.775\n",
      "  Test Loss: 0.630\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 7 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.581\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.812\n",
      "  Test Loss: 0.563\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 8 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.471\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.787\n",
      "  Test Loss: 0.522\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 9 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.341\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.812\n",
      "  Test Loss: 0.485\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 10 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.266\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.800\n",
      "  Test Loss: 0.495\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 11 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.188\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.775\n",
      "  Test Loss: 0.582\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 12 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.142\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.812\n",
      "  Test Loss: 0.583\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 13 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.109\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.800\n",
      "  Test Loss: 0.610\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 14 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.086\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.800\n",
      "  Test Loss: 0.670\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 15 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.067\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.750\n",
      "  Test Loss: 0.779\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 16 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.055\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.713\n",
      "  Test Loss: 0.948\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 17 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.046\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.713\n",
      "  Test Loss: 1.062\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 18 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.037\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.713\n",
      "  Test Loss: 1.133\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 19 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.035\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.713\n",
      "  Test Loss: 1.163\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 20 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.030\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.713\n",
      "  Test Loss: 1.135\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 21 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.725\n",
      "  Test Loss: 1.084\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 22 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.022\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.750\n",
      "  Test Loss: 1.048\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 23 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.020\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.762\n",
      "  Test Loss: 1.026\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 24 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.787\n",
      "  Test Loss: 1.009\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 25 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.787\n",
      "  Test Loss: 0.997\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 26 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.787\n",
      "  Test Loss: 0.990\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 27 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.014\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.800\n",
      "  Test Loss: 0.991\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 28 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.013\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.787\n",
      "  Test Loss: 0.999\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 29 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.011\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.787\n",
      "  Test Loss: 1.008\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 30 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.011\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.787\n",
      "  Test Loss: 1.020\n",
      "  Test took: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "accuracy_array=[]\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "#g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
    "#gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "#   scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "#                                            num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "    #generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_label_mask = batch[3].to(device)\n",
    "\n",
    "        real_batch_size = b_input_ids.shape[0]\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "        #hidden_states = model_outputs[-1]\n",
    "        #print(hidden_states[0].size())\n",
    "        \n",
    "        # Generate fake data that should have the same distribution of the ones\n",
    "        # encoded by the transformer. \n",
    "        # First noisy input are used in input to the Generator\n",
    "        #noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "        # Gnerate Fake data\n",
    "        #gen_rep = generator(noise)\n",
    "        #print(\"Length of generator output {}\".format(len(gen_rep)))\n",
    "        #print(\"Length of single generator output {}\".format(len(gen_rep[0])))\n",
    "\n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        #disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(hidden_states)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        features_list = torch.split(features, real_batch_size)\n",
    "        D_real_features = features_list[0]\n",
    "        #D_fake_features = features_list[1]\n",
    "      \n",
    "        logits_list = torch.split(logits, real_batch_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "        #D_fake_logits = logits_list[1]\n",
    "        \n",
    "        probs_list = torch.split(probs, real_batch_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        #D_fake_probs = probs_list[1]\n",
    "\n",
    "        #---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        #---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "#         g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "#         g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "#         g_loss = g_loss_d + g_feat_reg\n",
    "  \n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:,0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples, \n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "          D_L_Supervised = 0\n",
    "        else:\n",
    "          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "                 \n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        #D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U #+ D_L_unsupervised2U\n",
    "\n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        #gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        #g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward() \n",
    "        \n",
    "        # Apply modifications\n",
    "        #gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        #tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "          scheduler_d.step()\n",
    "          #scheduler_g.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    #avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    #print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "    discriminator.eval()\n",
    "    #generator.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            #hidden_states = model_outputs[-1]\n",
    "            hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            #'Training Loss generator': avg_train_loss_g,\n",
    "            'Training Loss discriminator': avg_train_loss_d,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    accuracy_array.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fa12c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf10715cf8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68d2ed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e043c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
