{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/crux82/ganbert-pytorch/blob/main/GANBERT_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUpqAwtN8rTA"
   },
   "source": [
    "# GAN-BERT (in Pytorch and compatible with HuggingFace)\n",
    "\n",
    "This is a Pytorch (+ **Huggingface** transformers) implementation of the GAN-BERT model from https://github.com/crux82/ganbert. While the original GAN-BERT was an extension of BERT, this implementation can be adapted to several architectures, ranging from Roberta to Albert!\n",
    "\n",
    "**NOTE**: given that this implementation is different from the original one in Tensorflow, some results can be slighty different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0m5KR34gmRH"
   },
   "source": [
    "Let's GO!\n",
    "\n",
    "Required Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIqpm34x2rms",
    "outputId": "b0205d19-dff1-4967-d003-990c3c5c8164"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers==4.3.2\n",
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install sentencepiece\n",
    "\n",
    "##Set random values\n",
    "seed_val = 4\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeZgRup520II",
    "outputId": "5b8d1039-e1e6-4712-e77b-e1e9f1b9fbcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU3ns8Ic7I-h"
   },
   "source": [
    "### Input Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jw0HC_hU3FUy",
    "outputId": "6ae87fcf-ed0b-4c78-b9aa-7d86d80cb933"
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 64\n",
    "batch_size = 64\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-5\n",
    "learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 50\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the TREC QC Dataset\n",
    "#--------------------------------\n",
    "#! git clone https://github.com/crux82/ganbert\n",
    "\n",
    "#  NOTE: in this setting 50 classes are involved\n",
    "labeled_file = \"../ganbert-master/data/labeled.tsv\"\n",
    "unlabeled_file = \"../ganbert-master/data/unlabeled.tsv\"\n",
    "test_filename = \"../ganbert-master/data/test.tsv\"\n",
    "\n",
    "label_list = [\"UNK_UNK\",\"ABBR_abb\", \"ABBR_exp\", \"DESC_def\", \"DESC_desc\", \n",
    "              \"DESC_manner\", \"DESC_reason\", \"ENTY_animal\", \"ENTY_body\", \n",
    "              \"ENTY_color\", \"ENTY_cremat\", \"ENTY_currency\", \"ENTY_dismed\", \n",
    "              \"ENTY_event\", \"ENTY_food\", \"ENTY_instru\", \"ENTY_lang\", \n",
    "              \"ENTY_letter\", \"ENTY_other\", \"ENTY_plant\", \"ENTY_product\", \n",
    "              \"ENTY_religion\", \"ENTY_sport\", \"ENTY_substance\", \"ENTY_symbol\", \n",
    "              \"ENTY_techmeth\", \"ENTY_termeq\", \"ENTY_veh\", \"ENTY_word\", \"HUM_desc\", \n",
    "              \"HUM_gr\", \"HUM_ind\", \"HUM_title\", \"LOC_city\", \"LOC_country\", \n",
    "              \"LOC_mount\", \"LOC_other\", \"LOC_state\", \"NUM_code\", \"NUM_count\", \n",
    "              \"NUM_date\", \"NUM_dist\", \"NUM_money\", \"NUM_ord\", \"NUM_other\", \n",
    "              \"NUM_perc\", \"NUM_period\", \"NUM_speed\", \"NUM_temp\", \"NUM_volsize\", \n",
    "              \"NUM_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6Q5jzVioTHb"
   },
   "source": [
    "Load the Tranformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "22cde8fbae4e49af993e33f3f2d9a28e",
      "2c671428c4df4355a7a53c71e9bd14ee",
      "44660941ffcc44beae72a1974d458583",
      "afdbd837001c4c74b5ac332ca061ef3a",
      "b489404bf53b4fab9bdb1c0c79a33008",
      "2bfb43b9e8604cbf8ebfd162267f1b8a",
      "4f556917850542da8508f9f839cae9bc",
      "28f045edfa48462fa96a94cffd3b143f",
      "14a6abbb244b41f89626a37640c63118",
      "0dccd0ab28c34880be92b35aa05e6ffb",
      "bf127a02cf6647aba4035c5cbfadc378",
      "098f203f1209452a9d4192af92da7057",
      "ec76cfd2d1da498e9b66885ff1be46b3",
      "b94243bfea7e4441b809b38c7cecd875",
      "0097aa33393342cd99be3dcc30edc5a0",
      "293c4d8660f546f79b43e0dc63250c2f",
      "9fc9479d78e442db91360de7f45b6d7f",
      "14bf2ab82bfc45bd8a3b93f2ab9aa656",
      "a56008dc6c6b41c3850611cc15fb6ea8",
      "504e8c3a107e4e04b51df39e1b3c584e",
      "1f25240f5457445795af70e20e5903f9",
      "5110d1cb9a7547f49244113dc5dd8321",
      "d3a13b7869354881ac7b7887e05d56a7",
      "4d22913664fb4cdbb38e217d4197601d",
      "870fe8f58bb24a47b6a98fa0eed0ebf5",
      "193a5a054d6f4a319842820c4c308322",
      "5a478b81997c4263a60d938447232fd9",
      "5fbebd67d40e470e8a75a4b5b540bbdf",
      "d8b619dff35e4f8cabf586221ad8c962",
      "d7bef2816920414f99a5c9cc676ec254",
      "b465cf9004f549ffa85444bfa16ee4c2",
      "748d5c1fb00e4d91809003527319a9f6",
      "7d501eb3d36e48128a5232879141b281",
      "547d7329b8554b7bb8ae51d61a5e41f8",
      "81b6bafd3fc248afa76cf463f2cb8ab8",
      "bac8f28c84144450b24bbc97fa4860db",
      "30e0829529874db1802f411f72f3d76a",
      "83dd72fbb4204fefb951b3800d73a8d2",
      "f9390d4fc9b147729f1ef5ea85d03774",
      "ddf20490dc874352aa7df35f07a60bcc",
      "c0f0d9a0d4f4440e81e5a6d5a2a3b4ab",
      "f41b83ccf26c40ed88ca6eaf49e09de5",
      "be6339f6256d4b579c53ef8b430ecb25",
      "b79fef6d585843c0a4d885edb2d01ebd"
     ]
    },
    "id": "gxghkkZq3Gbn",
    "outputId": "a4a5afd0-1b6c-4c2d-e3eb-7ced49df4e33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd_ixn5qn_zV"
   },
   "source": [
    "Function required to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W7cP8q7K3BId"
   },
   "outputs": [],
   "source": [
    "def get_qc_examples(input_file):\n",
    "  \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "  examples = []\n",
    "\n",
    "  with open(input_file, 'r') as f:\n",
    "      contents = f.read()\n",
    "      file_as_list = contents.splitlines()\n",
    "      for line in file_as_list[1:]:\n",
    "          split = line.split(\" \")\n",
    "          question = ' '.join(split[1:])\n",
    "\n",
    "          text_a = question\n",
    "          inn_split = split[0].split(\":\")\n",
    "          label = inn_split[0] + \"_\" + inn_split[1]\n",
    "          examples.append((text_a, label))\n",
    "      f.close()\n",
    "\n",
    "  return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K43tOavNqib4"
   },
   "source": [
    "**Load** the input QC dataset (fine-grained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cXCwFyF2qhw7"
   },
   "outputs": [],
   "source": [
    "#Load the examples\n",
    "labeled_examples = get_qc_examples(labeled_file)\n",
    "unlabeled_examples = get_qc_examples(unlabeled_file)\n",
    "test_examples = get_qc_examples(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBhaW5vBfR6B"
   },
   "source": [
    "Functions required to convert examples into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fmKL5AD7I4Zg"
   },
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  examples = []\n",
    "\n",
    "  # Count the percentage of labeled examples  \n",
    "  num_labeled_examples = 0\n",
    "  for label_mask in label_masks:\n",
    "    if label_mask: \n",
    "      num_labeled_examples += 1\n",
    "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "  # if required it applies the balance\n",
    "  for index, ex in enumerate(input_examples): \n",
    "    if label_mask_rate == 1 or not balance_label_examples:\n",
    "      examples.append((ex, label_masks[index]))\n",
    "    else:\n",
    "      # IT SIMULATE A LABELED EXAMPLE\n",
    "      if label_masks[index]:\n",
    "        balance = int(1/label_mask_rate)\n",
    "        balance = int(math.log(balance,2))\n",
    "        if balance < 1:\n",
    "          balance = 1\n",
    "        for b in range(0, int(balance)):\n",
    "          examples.append((ex, label_masks[index]))\n",
    "      else:\n",
    "        examples.append((ex, label_masks[index]))\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for (text, label_mask) in examples:\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[text[1]])\n",
    "    label_mask_array.append(label_mask)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "  label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do3O-VeefT3g"
   },
   "source": [
    "Convert the input examples into DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4c-nsMXlKX-D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10398/1314345009.py:54: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  label_mask_array = torch.tensor(label_mask_array)\n"
     ]
    }
   ],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "if unlabeled_examples:\n",
    "  train_examples = train_examples + unlabeled_examples\n",
    "  #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
    "  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ihcw3vquaQm"
   },
   "source": [
    "We define the Generator and Discriminator as discussed in https://www.aclweb.org/anthology/2020.acl-main.191/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "18kY64-n3I6y"
   },
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Generator as in \n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
    "        super(Generator, self).__init__()\n",
    "        layers = []\n",
    "        hidden_sizes = [noise_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output_rep = self.layers(noise)\n",
    "        return output_rep\n",
    "\n",
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uje9s2zQunFc"
   },
   "source": [
    "We instantiate the Discriminator and Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ylz5rvqE3U2S"
   },
   "outputs": [],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VG3qzp2-usZE"
   },
   "source": [
    "Let's go with the training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NhqylHGK3Va4",
    "outputId": "726efd06-d8de-4a45-a7bb-f186994a6b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:17.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:22.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:27.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:32.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:37.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:42.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:48.\n",
      "\n",
      "  Average training loss generetor: 0.595\n",
      "  Average training loss discriminator: 4.156\n",
      "  Training epcoh took: 0:00:49\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.552\n",
      "  Test Loss: 2.221\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:20.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.751\n",
      "  Average training loss discriminator: 1.669\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.602\n",
      "  Test Loss: 1.837\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:20.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.731\n",
      "  Average training loss discriminator: 1.029\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.600\n",
      "  Test Loss: 1.844\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.721\n",
      "  Average training loss discriminator: 0.854\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.614\n",
      "  Test Loss: 1.940\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 5 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.713\n",
      "  Average training loss discriminator: 0.799\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.616\n",
      "  Test Loss: 2.163\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 6 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.710\n",
      "  Average training loss discriminator: 0.770\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.620\n",
      "  Test Loss: 2.375\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 7 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.710\n",
      "  Average training loss discriminator: 0.754\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.614\n",
      "  Test Loss: 2.623\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 8 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.706\n",
      "  Average training loss discriminator: 0.744\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.614\n",
      "  Test Loss: 2.764\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 9 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 0.736\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.612\n",
      "  Test Loss: 2.996\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 10 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.731\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.606\n",
      "  Test Loss: 3.211\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 11 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.727\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.604\n",
      "  Test Loss: 3.399\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 12 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.722\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 3.524\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 13 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:25.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:34.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    60  of     92.    Elapsed: 0:00:46.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:52.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:57.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.720\n",
      "  Training epcoh took: 0:01:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.594\n",
      "  Test Loss: 3.697\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 14 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:18.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:29.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:53.\n",
      "  Batch    70  of     92.    Elapsed: 0:01:01.\n",
      "  Batch    80  of     92.    Elapsed: 0:01:06.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:11.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.718\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.594\n",
      "  Test Loss: 3.846\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 15 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:51.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.600\n",
      "  Test Loss: 3.744\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 16 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:12.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:23.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:35.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:46.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:58.\n",
      "  Batch    60  of     92.    Elapsed: 0:01:10.\n",
      "  Batch    60  of     92.    Elapsed: 0:01:09.\n",
      "  Batch    70  of     92.    Elapsed: 0:01:21.\n",
      "  Batch    80  of     92.    Elapsed: 0:01:32.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:44.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.714\n",
      "  Training epcoh took: 0:01:46\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.584\n",
      "  Test Loss: 4.035\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 18 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:11.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:23.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:35.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:46.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:58.\n",
      "  Batch    60  of     92.    Elapsed: 0:01:09.\n",
      "  Batch    70  of     92.    Elapsed: 0:01:21.\n",
      "  Batch    80  of     92.    Elapsed: 0:01:32.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:44.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:01:46\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.598\n",
      "  Test Loss: 4.031\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 19 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:11.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:23.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:35.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:46.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:58.\n",
      "  Batch    60  of     92.    Elapsed: 0:01:09.\n",
      "  Batch    70  of     92.    Elapsed: 0:01:21.\n",
      "  Batch    80  of     92.    Elapsed: 0:01:32.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:39.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:01:40\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 4.005\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 20 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.590\n",
      "  Test Loss: 3.598\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 21 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.726\n",
      "  Average training loss discriminator: 0.904\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.588\n",
      "  Test Loss: 2.569\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 22 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.726\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.590\n",
      "  Test Loss: 3.148\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 23 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 3.384\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 24 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:20.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 3.581\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 25 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:16.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:47.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:00:48\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.598\n",
      "  Test Loss: 3.810\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 26 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:36.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:41.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.598\n",
      "  Test Loss: 3.912\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 27 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:34.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:46.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:53.\n",
      "  Batch    90  of     92.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 4.028\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 28 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:05.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:10.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:15.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:21.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:26.\n",
      "  Batch    60  of     92.    Elapsed: 0:00:31.\n",
      "  Batch    70  of     92.    Elapsed: 0:00:42.\n",
      "  Batch    80  of     92.    Elapsed: 0:00:53.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:04.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 3.982\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 29 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:11.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:22.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:33.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:44.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:55.\n",
      "  Batch    60  of     92.    Elapsed: 0:01:07.\n",
      "  Batch    70  of     92.    Elapsed: 0:01:18.\n",
      "  Batch    80  of     92.    Elapsed: 0:01:29.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:40.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:01:42\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 4.070\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 30 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:11.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:22.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:33.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:44.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:56.\n",
      "  Batch    60  of     92.    Elapsed: 0:01:07.\n",
      "  Batch    70  of     92.    Elapsed: 0:01:18.\n",
      "  Batch    80  of     92.    Elapsed: 0:01:29.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:41.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 4.179\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 31 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:11.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:22.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:33.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:44.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:56.\n",
      "  Batch    60  of     92.    Elapsed: 0:01:06.\n",
      "  Batch    70  of     92.    Elapsed: 0:01:18.\n",
      "  Batch    80  of     92.    Elapsed: 0:01:29.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:40.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:01:42\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.596\n",
      "  Test Loss: 4.178\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 32 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:11.\n",
      "  Batch    20  of     92.    Elapsed: 0:00:22.\n",
      "  Batch    30  of     92.    Elapsed: 0:00:33.\n",
      "  Batch    40  of     92.    Elapsed: 0:00:45.\n",
      "  Batch    50  of     92.    Elapsed: 0:00:56.\n",
      "  Batch    60  of     92.    Elapsed: 0:01:07.\n",
      "  Batch    70  of     92.    Elapsed: 0:01:18.\n",
      "  Batch    80  of     92.    Elapsed: 0:01:29.\n",
      "  Batch    90  of     92.    Elapsed: 0:01:40.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.590\n",
      "  Test Loss: 4.245\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 33 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of     92.    Elapsed: 0:00:11.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Apply modifications\u001b[39;00m\n\u001b[1;32m    142\u001b[0m gen_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 143\u001b[0m \u001b[43mdis_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# A detail log of the individual losses\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#             g_loss_d, g_feat_reg))\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Save the losses to print them later\u001b[39;00m\n\u001b[1;32m    151\u001b[0m tr_g_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m g_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adamw.py:145\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 145\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/_functional.py:155\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    151\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    153\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[0;32m--> 155\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "accuracy_array = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
    "gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "  scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_label_mask = batch[3].to(device)\n",
    "\n",
    "        real_batch_size = b_input_ids.shape[0]\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask, output_hidden_states=True)\n",
    "        #hidden_states = model_outputs[-1]\n",
    "        hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "        # Generate fake data that should have the same distribution of the ones\n",
    "        # encoded by the transformer. \n",
    "        # First noisy input are used in input to the Generator\n",
    "        noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "        # Gnerate Fake data\n",
    "        gen_rep = generator(noise)\n",
    "\n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(disciminator_input)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        features_list = torch.split(features, real_batch_size)\n",
    "        D_real_features = features_list[0]\n",
    "        D_fake_features = features_list[1]\n",
    "      \n",
    "        logits_list = torch.split(logits, real_batch_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "        D_fake_logits = logits_list[1]\n",
    "        \n",
    "        probs_list = torch.split(probs, real_batch_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        D_fake_probs = probs_list[1]\n",
    "\n",
    "        #---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        #---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "        g_loss = g_loss_d + g_feat_reg\n",
    "  \n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:,0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples, \n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "          D_L_Supervised = 0\n",
    "        else:\n",
    "          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "                 \n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "\n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward() \n",
    "        \n",
    "        # Apply modifications\n",
    "        gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "          scheduler_d.step()\n",
    "          scheduler_g.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask, output_hidden_states=True)\n",
    "            #hidden_states = model_outputs[-1]\n",
    "            hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss generator': avg_train_loss_g,\n",
    "            'Training Loss discriminator': avg_train_loss_d,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    accuracy_array.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDm9NProRB4c",
    "outputId": "2ffebcf1-6b39-4442-88c6-5f72a58a3722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'Training Loss generator': 0.5946524189785123, 'Training Loss discriminator': 4.15616855673168, 'Valid. Loss': 2.2206952571868896, 'Valid. Accur.': 0.552, 'Training Time': '0:00:49', 'Test Time': '0:00:01'}\n",
      "{'epoch': 2, 'Training Loss generator': 0.7507568209067635, 'Training Loss discriminator': 1.6688151087449945, 'Valid. Loss': 1.8372743129730225, 'Valid. Accur.': 0.602, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 3, 'Training Loss generator': 0.7312210649251938, 'Training Loss discriminator': 1.0288828851088234, 'Valid. Loss': 1.8439531326293945, 'Valid. Accur.': 0.6, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 4, 'Training Loss generator': 0.7207469214563784, 'Training Loss discriminator': 0.854247062102608, 'Valid. Loss': 1.940307378768921, 'Valid. Accur.': 0.614, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 5, 'Training Loss generator': 0.7129359446142031, 'Training Loss discriminator': 0.798881401186404, 'Valid. Loss': 2.1629397869110107, 'Valid. Accur.': 0.616, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 6, 'Training Loss generator': 0.7100250688583954, 'Training Loss discriminator': 0.7703275816596072, 'Valid. Loss': 2.375420093536377, 'Valid. Accur.': 0.62, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 7, 'Training Loss generator': 0.709913889998975, 'Training Loss discriminator': 0.7538508183282354, 'Valid. Loss': 2.6230316162109375, 'Valid. Accur.': 0.614, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 8, 'Training Loss generator': 0.706288782150849, 'Training Loss discriminator': 0.7444531146598898, 'Valid. Loss': 2.7642271518707275, 'Valid. Accur.': 0.614, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 9, 'Training Loss generator': 0.7069703638553619, 'Training Loss discriminator': 0.736092671751976, 'Valid. Loss': 2.9957010746002197, 'Valid. Accur.': 0.612, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 10, 'Training Loss generator': 0.7046745911888455, 'Training Loss discriminator': 0.7305065620204677, 'Valid. Loss': 3.2106521129608154, 'Valid. Accur.': 0.606, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 11, 'Training Loss generator': 0.7051856699197189, 'Training Loss discriminator': 0.726751059293747, 'Valid. Loss': 3.399117946624756, 'Valid. Accur.': 0.604, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 12, 'Training Loss generator': 0.7036813795566559, 'Training Loss discriminator': 0.7221835100132487, 'Valid. Loss': 3.5236902236938477, 'Valid. Accur.': 0.596, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 13, 'Training Loss generator': 0.7040474207504935, 'Training Loss discriminator': 0.7199707549551259, 'Valid. Loss': 3.697058916091919, 'Valid. Accur.': 0.594, 'Training Time': '0:01:03', 'Test Time': '0:00:01'}\n",
      "{'epoch': 14, 'Training Loss generator': 0.7021051638800165, 'Training Loss discriminator': 0.7178892234097356, 'Valid. Loss': 3.8455944061279297, 'Valid. Accur.': 0.594, 'Training Time': '0:01:12', 'Test Time': '0:00:01'}\n",
      "{'epoch': 15, 'Training Loss generator': 0.7034035700818767, 'Training Loss discriminator': 0.7162644409615061, 'Valid. Loss': 3.7438454627990723, 'Valid. Accur.': 0.6, 'Training Time': '0:00:53', 'Test Time': '0:00:02'}\n",
      "{'epoch': 16, 'Training Loss generator': 0.7018142122289409, 'Training Loss discriminator': 0.7142705865528273, 'Valid. Loss': 4.034310340881348, 'Valid. Accur.': 0.588, 'Training Time': '0:01:47', 'Test Time': '0:00:02'}\n",
      "{'epoch': 17, 'Training Loss generator': 0.7009838255851165, 'Training Loss discriminator': 0.7136031959367835, 'Valid. Loss': 4.035366058349609, 'Valid. Accur.': 0.584, 'Training Time': '0:01:46', 'Test Time': '0:00:02'}\n",
      "{'epoch': 18, 'Training Loss generator': 0.7015342738317407, 'Training Loss discriminator': 0.711272710043451, 'Valid. Loss': 4.030584812164307, 'Valid. Accur.': 0.598, 'Training Time': '0:01:46', 'Test Time': '0:00:02'}\n",
      "{'epoch': 19, 'Training Loss generator': 0.7015764693851056, 'Training Loss discriminator': 0.7102161341387293, 'Valid. Loss': 4.005070209503174, 'Valid. Accur.': 0.596, 'Training Time': '0:01:40', 'Test Time': '0:00:01'}\n",
      "{'epoch': 20, 'Training Loss generator': 0.7010235734607863, 'Training Loss discriminator': 0.7164350819328557, 'Valid. Loss': 3.598339080810547, 'Valid. Accur.': 0.59, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 21, 'Training Loss generator': 0.7257910500402036, 'Training Loss discriminator': 0.9044246174719023, 'Valid. Loss': 2.5688681602478027, 'Valid. Accur.': 0.588, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 22, 'Training Loss generator': 0.7052144421183545, 'Training Loss discriminator': 0.726471381990806, 'Valid. Loss': 3.1482200622558594, 'Valid. Accur.': 0.59, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 23, 'Training Loss generator': 0.7017129251490468, 'Training Loss discriminator': 0.7132915031650792, 'Valid. Loss': 3.383596897125244, 'Valid. Accur.': 0.596, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 24, 'Training Loss generator': 0.7016886816076611, 'Training Loss discriminator': 0.7106096822282543, 'Valid. Loss': 3.5813944339752197, 'Valid. Accur.': 0.596, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 25, 'Training Loss generator': 0.701118115497672, 'Training Loss discriminator': 0.7089274085086325, 'Valid. Loss': 3.8103506565093994, 'Valid. Accur.': 0.598, 'Training Time': '0:00:48', 'Test Time': '0:00:01'}\n",
      "{'epoch': 26, 'Training Loss generator': 0.7013860597558643, 'Training Loss discriminator': 0.7071696325488712, 'Valid. Loss': 3.9121499061584473, 'Valid. Accur.': 0.598, 'Training Time': '0:00:47', 'Test Time': '0:00:01'}\n",
      "{'epoch': 27, 'Training Loss generator': 0.7012204547291216, 'Training Loss discriminator': 0.7066055724154348, 'Valid. Loss': 4.028376579284668, 'Valid. Accur.': 0.596, 'Training Time': '0:00:59', 'Test Time': '0:00:01'}\n",
      "{'epoch': 28, 'Training Loss generator': 0.7014352303484211, 'Training Loss discriminator': 0.7063569782868676, 'Valid. Loss': 3.982390880584717, 'Valid. Accur.': 0.596, 'Training Time': '0:01:06', 'Test Time': '0:00:02'}\n",
      "{'epoch': 29, 'Training Loss generator': 0.7011607671561448, 'Training Loss discriminator': 0.70546745930029, 'Valid. Loss': 4.070260047912598, 'Valid. Accur.': 0.596, 'Training Time': '0:01:42', 'Test Time': '0:00:02'}\n",
      "{'epoch': 30, 'Training Loss generator': 0.7003741439269937, 'Training Loss discriminator': 0.7055867333774981, 'Valid. Loss': 4.17913818359375, 'Valid. Accur.': 0.596, 'Training Time': '0:01:43', 'Test Time': '0:00:02'}\n",
      "{'epoch': 31, 'Training Loss generator': 0.7010892292727595, 'Training Loss discriminator': 0.7047296814296556, 'Valid. Loss': 4.177559852600098, 'Valid. Accur.': 0.596, 'Training Time': '0:01:42', 'Test Time': '0:00:02'}\n",
      "{'epoch': 32, 'Training Loss generator': 0.7004509043434392, 'Training Loss discriminator': 0.7043423639691394, 'Valid. Loss': 4.244762897491455, 'Valid. Accur.': 0.59, 'Training Time': '0:01:43', 'Test Time': '0:00:02'}\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:35:10 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "for stat in training_stats:\n",
    "  print(stat)\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff8b032e970>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    "print(max(accuracy_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_array[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "GANBERT_pytorch croce.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0097aa33393342cd99be3dcc30edc5a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_504e8c3a107e4e04b51df39e1b3c584e",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a56008dc6c6b41c3850611cc15fb6ea8",
      "value": 435779157
     }
    },
    "098f203f1209452a9d4192af92da7057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b94243bfea7e4441b809b38c7cecd875",
       "IPY_MODEL_0097aa33393342cd99be3dcc30edc5a0",
       "IPY_MODEL_293c4d8660f546f79b43e0dc63250c2f"
      ],
      "layout": "IPY_MODEL_ec76cfd2d1da498e9b66885ff1be46b3"
     }
    },
    "0dccd0ab28c34880be92b35aa05e6ffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14a6abbb244b41f89626a37640c63118": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14bf2ab82bfc45bd8a3b93f2ab9aa656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "193a5a054d6f4a319842820c4c308322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b465cf9004f549ffa85444bfa16ee4c2",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7bef2816920414f99a5c9cc676ec254",
      "value": 213450
     }
    },
    "1f25240f5457445795af70e20e5903f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22cde8fbae4e49af993e33f3f2d9a28e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44660941ffcc44beae72a1974d458583",
       "IPY_MODEL_afdbd837001c4c74b5ac332ca061ef3a",
       "IPY_MODEL_b489404bf53b4fab9bdb1c0c79a33008"
      ],
      "layout": "IPY_MODEL_2c671428c4df4355a7a53c71e9bd14ee"
     }
    },
    "28f045edfa48462fa96a94cffd3b143f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "293c4d8660f546f79b43e0dc63250c2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5110d1cb9a7547f49244113dc5dd8321",
      "placeholder": "",
      "style": "IPY_MODEL_1f25240f5457445795af70e20e5903f9",
      "value": " 436M/436M [00:29&lt;00:00, 14.8MB/s]"
     }
    },
    "2bfb43b9e8604cbf8ebfd162267f1b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c671428c4df4355a7a53c71e9bd14ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30e0829529874db1802f411f72f3d76a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f41b83ccf26c40ed88ca6eaf49e09de5",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0f0d9a0d4f4440e81e5a6d5a2a3b4ab",
      "value": 435797
     }
    },
    "44660941ffcc44beae72a1974d458583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f556917850542da8508f9f839cae9bc",
      "placeholder": "",
      "style": "IPY_MODEL_2bfb43b9e8604cbf8ebfd162267f1b8a",
      "value": "Downloading: 100%"
     }
    },
    "4d22913664fb4cdbb38e217d4197601d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f556917850542da8508f9f839cae9bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "504e8c3a107e4e04b51df39e1b3c584e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5110d1cb9a7547f49244113dc5dd8321": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "547d7329b8554b7bb8ae51d61a5e41f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bac8f28c84144450b24bbc97fa4860db",
       "IPY_MODEL_30e0829529874db1802f411f72f3d76a",
       "IPY_MODEL_83dd72fbb4204fefb951b3800d73a8d2"
      ],
      "layout": "IPY_MODEL_81b6bafd3fc248afa76cf463f2cb8ab8"
     }
    },
    "5a478b81997c4263a60d938447232fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d501eb3d36e48128a5232879141b281",
      "placeholder": "",
      "style": "IPY_MODEL_748d5c1fb00e4d91809003527319a9f6",
      "value": " 213k/213k [00:00&lt;00:00, 102kB/s]"
     }
    },
    "5fbebd67d40e470e8a75a4b5b540bbdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "748d5c1fb00e4d91809003527319a9f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d501eb3d36e48128a5232879141b281": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81b6bafd3fc248afa76cf463f2cb8ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83dd72fbb4204fefb951b3800d73a8d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b79fef6d585843c0a4d885edb2d01ebd",
      "placeholder": "",
      "style": "IPY_MODEL_be6339f6256d4b579c53ef8b430ecb25",
      "value": " 436k/436k [00:00&lt;00:00, 1.26MB/s]"
     }
    },
    "870fe8f58bb24a47b6a98fa0eed0ebf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8b619dff35e4f8cabf586221ad8c962",
      "placeholder": "",
      "style": "IPY_MODEL_5fbebd67d40e470e8a75a4b5b540bbdf",
      "value": "Downloading: 100%"
     }
    },
    "9fc9479d78e442db91360de7f45b6d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a56008dc6c6b41c3850611cc15fb6ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "afdbd837001c4c74b5ac332ca061ef3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14a6abbb244b41f89626a37640c63118",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_28f045edfa48462fa96a94cffd3b143f",
      "value": 570
     }
    },
    "b465cf9004f549ffa85444bfa16ee4c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b489404bf53b4fab9bdb1c0c79a33008": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf127a02cf6647aba4035c5cbfadc378",
      "placeholder": "",
      "style": "IPY_MODEL_0dccd0ab28c34880be92b35aa05e6ffb",
      "value": " 570/570 [00:00&lt;00:00, 12.0kB/s]"
     }
    },
    "b79fef6d585843c0a4d885edb2d01ebd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b94243bfea7e4441b809b38c7cecd875": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14bf2ab82bfc45bd8a3b93f2ab9aa656",
      "placeholder": "",
      "style": "IPY_MODEL_9fc9479d78e442db91360de7f45b6d7f",
      "value": "Downloading: 100%"
     }
    },
    "bac8f28c84144450b24bbc97fa4860db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddf20490dc874352aa7df35f07a60bcc",
      "placeholder": "",
      "style": "IPY_MODEL_f9390d4fc9b147729f1ef5ea85d03774",
      "value": "Downloading: 100%"
     }
    },
    "be6339f6256d4b579c53ef8b430ecb25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf127a02cf6647aba4035c5cbfadc378": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0f0d9a0d4f4440e81e5a6d5a2a3b4ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3a13b7869354881ac7b7887e05d56a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_870fe8f58bb24a47b6a98fa0eed0ebf5",
       "IPY_MODEL_193a5a054d6f4a319842820c4c308322",
       "IPY_MODEL_5a478b81997c4263a60d938447232fd9"
      ],
      "layout": "IPY_MODEL_4d22913664fb4cdbb38e217d4197601d"
     }
    },
    "d7bef2816920414f99a5c9cc676ec254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d8b619dff35e4f8cabf586221ad8c962": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddf20490dc874352aa7df35f07a60bcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec76cfd2d1da498e9b66885ff1be46b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f41b83ccf26c40ed88ca6eaf49e09de5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9390d4fc9b147729f1ef5ea85d03774": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
