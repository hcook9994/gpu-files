{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ea1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86576f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a0de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_complaints = pd.read_csv(\"data/complaints/complaints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93668f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_complaints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c67662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = ['Product', 'Consumer complaint narrative']\n",
    "# df = df_complaints[col]\n",
    "# df = df[pd.notnull(df['Consumer complaint narrative'])]\n",
    "\n",
    "# df.columns = ['Product', 'Consumer_complaint_narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a40b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98f3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['category_id'] = df['Product'].factorize()[0]\n",
    "# category_id_df = df[['Product', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "# category_to_id = dict(category_id_df.values)\n",
    "# id_to_category = dict(category_id_df[['category_id', 'Product']].values)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "263e568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a1e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8,6))\n",
    "# df.groupby('Product').Consumer_complaint_narrative.count().plot.bar(ylim=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a8079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3818ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf8b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69c8821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers=list(range(0,18))\n",
    "# list_zeros = [0]*18\n",
    "# count_dictionary = dict(zip(numbers, list_zeros))\n",
    "\n",
    "# values_array_train=[]\n",
    "# values_array_test=[]\n",
    "# values_array_unlabelled=[]\n",
    "# for index, row in df.iterrows():\n",
    "#     if count_dictionary[row['category_id']]<10:\n",
    "#         count_dictionary[row['category_id']]=count_dictionary[row['category_id']]+1\n",
    "#         values_array_train.append((row['Consumer_complaint_narrative'],row['category_id']))\n",
    "#     elif count_dictionary[row['category_id']]<50:\n",
    "#         count_dictionary[row['category_id']]=count_dictionary[row['category_id']]+1\n",
    "#         values_array_test.append((row['Consumer_complaint_narrative'],row['category_id']))\n",
    "#     elif count_dictionary[row['category_id']]<500:\n",
    "#         count_dictionary[row['category_id']]=count_dictionary[row['category_id']]+1\n",
    "#         values_array_unlabelled.append((row['Consumer_complaint_narrative'],'UNK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b569f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_l=pd.read_csv(\"assigned/train_l.csv\", index_col=\"Unnamed: 0\")\n",
    "df_test_l=pd.read_csv(\"assigned/test_l.csv\", index_col=\"Unnamed: 0\")\n",
    "df_u=pd.read_csv(\"assigned/u.csv\", index_col=\"Unnamed: 0\")\n",
    "df_train_u=pd.read_csv(\"assigned/train_u.csv\", index_col=\"Unnamed: 0\")\n",
    "df_test_u=pd.read_csv(\"assigned/test_u.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "270b80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_array_train=list(df_train_l.to_records(index=False))\n",
    "values_array_test=list(df_test_l.to_records(index=False))\n",
    "values_array_unlabelled=list(df_u.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "804df80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15a0c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f64668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_unlabelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faaf4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('how has religion affected war?', 4)\n"
     ]
    }
   ],
   "source": [
    "print(values_array_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c31b5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I need Environmental Management Plan for Underground Gas Storage Facility?', 2)\n"
     ]
    }
   ],
   "source": [
    "print(values_array_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce423411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('what is the most abundant cell type in plants?', 'UNK')\n"
     ]
    }
   ],
   "source": [
    "print(values_array_unlabelled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37916145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.3.2\n",
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install sentencepiece\n",
    "\n",
    "##Set random values\n",
    "#seed_val = 42\n",
    "seed_val = 10\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d415d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a04fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 20\n",
    "batch_size = 256\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-5\n",
    "learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 200\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "#model_name=\"google/electra-large-discriminator\"\n",
    "#model_name=\"google/electra-small-discriminator\"\n",
    "#model_name=\"microsoft/deberta-v2-xxlarge\"\n",
    "#model_name=\"microsoft/deberta-v3-base\"\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the TREC QC Dataset\n",
    "#--------------------------------\n",
    "#! git clone https://github.com/crux82/ganbert\n",
    "\n",
    "#  NOTE: in this setting 50 classes are involved\n",
    "# labeled_file = \"./ganbert/data/labeled.tsv\"\n",
    "# unlabeled_file = \"./ganbert/data/unlabeled.tsv\"\n",
    "# test_filename = \"./ganbert/data/test.tsv\"\n",
    "\n",
    "label_list = [\"UNK\",1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c908c079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/harry/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/harry/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/harry/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/harry/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6383a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the examples\n",
    "labeled_examples = values_array_train\n",
    "unlabeled_examples = values_array_unlabelled\n",
    "test_examples = values_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10d4fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  examples = []\n",
    "\n",
    "  # Count the percentage of labeled examples  \n",
    "  num_labeled_examples = 0\n",
    "  for label_mask in label_masks:\n",
    "    if label_mask: \n",
    "      num_labeled_examples += 1\n",
    "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "  # if required it applies the balance\n",
    "  for index, ex in enumerate(input_examples): \n",
    "    if label_mask_rate == 1 or not balance_label_examples:\n",
    "      examples.append((ex, label_masks[index]))\n",
    "    else:\n",
    "      # IT SIMULATE A LABELED EXAMPLE\n",
    "      if label_masks[index]:\n",
    "        balance = int(1/label_mask_rate)\n",
    "        balance = int(math.log(balance,2))\n",
    "        if balance < 1:\n",
    "          balance = 1\n",
    "        for b in range(0, int(balance)):\n",
    "          examples.append((ex, label_masks[index]))\n",
    "      else:\n",
    "        examples.append((ex, label_masks[index]))\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for (text, label_mask) in examples:\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[text[1]])\n",
    "    label_mask_array.append(label_mask)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "  label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56feab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "if unlabeled_examples:\n",
    "  train_examples = train_examples + unlabeled_examples\n",
    "  #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
    "  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cce6ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Generator as in \n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
    "        super(Generator, self).__init__()\n",
    "        layers = []\n",
    "        hidden_sizes = [noise_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output_rep = self.layers(noise)\n",
    "        return output_rep\n",
    "\n",
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f27045c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dcbc408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:18.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.523\n",
      "  Average training loss discriminator: 3.240\n",
      "  Training epcoh took: 0:00:26\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.383\n",
      "  Test Loss: 1.924\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:18.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.731\n",
      "  Average training loss discriminator: 1.081\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.249\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.724\n",
      "  Average training loss discriminator: 0.771\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.425\n",
      "  Test Loss: 2.408\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.714\n",
      "  Average training loss discriminator: 0.747\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.463\n",
      "  Test Loss: 2.560\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 5 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.708\n",
      "  Average training loss discriminator: 0.737\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.458\n",
      "  Test Loss: 2.717\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 6 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.730\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.458\n",
      "  Test Loss: 2.857\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 7 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.726\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.453\n",
      "  Test Loss: 2.997\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 8 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.716\n",
      "  Average training loss discriminator: 0.783\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 2.490\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 9 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.751\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.435\n",
      "  Test Loss: 2.959\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 10 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.722\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 3.227\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 11 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.717\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 3.464\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 12 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.443\n",
      "  Test Loss: 3.613\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 13 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.714\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.450\n",
      "  Test Loss: 3.743\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 14 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 3.887\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 15 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.711\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 4.020\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 16 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.435\n",
      "  Test Loss: 4.151\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 17 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.438\n",
      "  Test Loss: 4.226\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 18 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.438\n",
      "  Test Loss: 4.301\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 19 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 4.400\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 20 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.707\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 4.452\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 21 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.448\n",
      "  Test Loss: 4.423\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 22 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 4.570\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 23 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.706\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 4.624\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 24 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 4.712\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 25 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.705\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.443\n",
      "  Test Loss: 4.762\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 26 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 4.842\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 27 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 4.861\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 28 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 4.969\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 29 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 4.983\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 30 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.438\n",
      "  Test Loss: 5.079\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 31 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.443\n",
      "  Test Loss: 5.130\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 32 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 5.151\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 33 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 5.169\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 34 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.693\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 5.210\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 35 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 5.227\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 36 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.440\n",
      "  Test Loss: 5.231\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 37 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 5.273\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 38 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.448\n",
      "  Test Loss: 5.313\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 39 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.448\n",
      "  Test Loss: 5.365\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 40 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 5.387\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 41 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.443\n",
      "  Test Loss: 5.456\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 42 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 5.529\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 43 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.458\n",
      "  Test Loss: 5.535\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 44 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.438\n",
      "  Test Loss: 5.542\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 45 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.435\n",
      "  Test Loss: 5.714\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 46 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.455\n",
      "  Test Loss: 5.531\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 47 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.458\n",
      "  Test Loss: 5.457\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 48 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.455\n",
      "  Test Loss: 5.573\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 49 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.453\n",
      "  Test Loss: 5.667\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 50 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.455\n",
      "  Test Loss: 5.792\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 51 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.458\n",
      "  Test Loss: 5.863\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 52 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.450\n",
      "  Test Loss: 5.930\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 53 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.450\n",
      "  Test Loss: 5.954\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 54 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.443\n",
      "  Test Loss: 6.013\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 55 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.448\n",
      "  Test Loss: 6.059\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 56 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 6.017\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 57 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.445\n",
      "  Test Loss: 6.076\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 58 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.435\n",
      "  Test Loss: 6.082\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 59 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.432\n",
      "  Test Loss: 6.059\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 60 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.900\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.330\n",
      "  Test Loss: 3.023\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 61 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.713\n",
      "  Average training loss discriminator: 1.020\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.355\n",
      "  Test Loss: 3.737\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 62 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.841\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 3.310\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 63 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.755\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.425\n",
      "  Test Loss: 3.918\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 64 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.723\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 4.115\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 65 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 4.220\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 66 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 4.502\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 67 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.758\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 4.165\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 68 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.702\n",
      "  Average training loss discriminator: 0.763\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 4.769\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 69 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.708\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 4.766\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 70 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.703\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.393\n",
      "  Test Loss: 4.933\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 71 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.395\n",
      "  Test Loss: 5.082\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 72 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 5.227\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 73 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.693\n",
      "  Average training loss discriminator: 0.701\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 5.284\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 74 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 5.361\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 75 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 5.432\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 76 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.693\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 5.487\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 77 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 5.550\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 78 / 200 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 5.578\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 79 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.422\n",
      "  Test Loss: 5.580\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 80 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.425\n",
      "  Test Loss: 5.618\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 81 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.427\n",
      "  Test Loss: 5.709\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 82 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.430\n",
      "  Test Loss: 5.735\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 83 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.427\n",
      "  Test Loss: 5.782\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 84 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.432\n",
      "  Test Loss: 5.812\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 85 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.432\n",
      "  Test Loss: 5.883\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 86 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.425\n",
      "  Test Loss: 6.003\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 87 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 6.077\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 88 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.430\n",
      "  Test Loss: 5.757\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 89 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 0.917\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.430\n",
      "  Test Loss: 5.017\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 90 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.771\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 5.207\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 91 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.760\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 4.258\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 92 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.741\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 4.454\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 93 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.723\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 4.492\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 94 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.759\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 4.655\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 95 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.724\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 4.703\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 96 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 4.722\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 97 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.388\n",
      "  Test Loss: 4.894\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 98 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.393\n",
      "  Test Loss: 5.056\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 99 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.395\n",
      "  Test Loss: 5.201\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 100 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 5.276\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 101 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 5.359\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 102 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 5.438\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 103 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 5.538\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 104 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 5.613\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 105 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 5.648\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 106 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 5.719\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 107 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 5.770\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 108 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 5.809\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 109 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 5.863\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 110 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 5.906\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 111 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 5.946\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 112 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 5.966\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 113 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.004\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 114 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.029\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 115 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.014\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 116 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 6.015\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 117 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 6.049\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 118 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.095\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 119 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.144\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 120 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.115\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 121 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.144\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 122 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.170\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 123 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.223\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 124 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.295\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 125 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.293\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 126 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.261\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 127 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 6.282\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 128 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.322\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 129 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 6.345\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 130 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 6.358\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 131 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.365\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 132 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 6.379\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 133 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.431\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 134 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.433\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 135 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.485\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 136 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.488\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 137 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 6.516\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 138 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.532\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 139 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.551\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 140 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 6.570\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 141 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 6.563\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 142 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.535\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 143 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.533\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 144 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 6.548\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 145 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 6.554\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 146 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 6.557\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 147 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.579\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 148 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.606\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 149 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.638\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 150 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 6.636\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 151 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 6.631\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 152 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:12.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.597\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 153 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 6.593\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 154 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.638\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 155 / 200 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.647\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 156 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.688\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 157 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 6.669\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 158 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 6.638\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 159 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.690\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 160 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 6.670\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 161 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 6.698\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 162 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.749\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 163 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 6.722\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 164 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 6.749\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 165 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 6.769\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 166 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 6.734\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 167 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 6.776\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 168 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 6.778\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 169 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 6.804\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 170 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 6.876\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 171 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 6.858\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 172 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 6.879\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 173 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 6.795\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 174 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 6.954\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 175 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.714\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 6.340\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 176 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.427\n",
      "  Test Loss: 6.346\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 177 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.695\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.425\n",
      "  Test Loss: 6.467\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 178 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.938\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.362\n",
      "  Test Loss: 4.662\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 179 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.800\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.383\n",
      "  Test Loss: 4.580\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 180 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 4.792\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 181 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.749\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.385\n",
      "  Test Loss: 4.229\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 182 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 5.022\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 183 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.729\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 4.792\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 184 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 5.206\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 185 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.760\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 3.990\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 186 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.801\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 3.599\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 187 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.697\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.372\n",
      "  Test Loss: 5.632\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 188 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.698\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.383\n",
      "  Test Loss: 5.832\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 189 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 5.905\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 190 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 6.065\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 191 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.695\n",
      "  Average training loss discriminator: 0.742\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 5.047\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 192 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 5.081\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 193 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.697\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 5.347\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 194 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.741\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.395\n",
      "  Test Loss: 4.837\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 195 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.696\n",
      "  Average training loss discriminator: 0.710\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 5.173\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 196 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.385\n",
      "  Test Loss: 5.378\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 197 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.385\n",
      "  Test Loss: 5.559\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 198 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.385\n",
      "  Test Loss: 5.711\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 199 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.385\n",
      "  Test Loss: 5.839\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 200 / 200 ========\n",
      "Training...\n",
      "  Batch    10  of     43.    Elapsed: 0:00:06.\n",
      "  Batch    20  of     43.    Elapsed: 0:00:13.\n",
      "  Batch    30  of     43.    Elapsed: 0:00:19.\n",
      "  Batch    40  of     43.    Elapsed: 0:00:25.\n",
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 0.696\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.388\n",
      "  Test Loss: 5.929\n",
      "  Test took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "accuracy_array=[]\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
    "gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "  scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_label_mask = batch[3].to(device)\n",
    "\n",
    "        real_batch_size = b_input_ids.shape[0]\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        #hidden_states = model_outputs[-1]\n",
    "        hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "        #print(hidden_states[0].size())\n",
    "        \n",
    "        # Generate fake data that should have the same distribution of the ones\n",
    "        # encoded by the transformer. \n",
    "        # First noisy input are used in input to the Generator\n",
    "        noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "        # Gnerate Fake data\n",
    "        gen_rep = generator(noise)\n",
    "        #print(\"Length of generator output {}\".format(len(gen_rep)))\n",
    "        #print(\"Length of single generator output {}\".format(len(gen_rep[0])))\n",
    "\n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(disciminator_input)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        features_list = torch.split(features, real_batch_size)\n",
    "        D_real_features = features_list[0]\n",
    "        D_fake_features = features_list[1]\n",
    "      \n",
    "        logits_list = torch.split(logits, real_batch_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "        D_fake_logits = logits_list[1]\n",
    "        \n",
    "        probs_list = torch.split(probs, real_batch_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        D_fake_probs = probs_list[1]\n",
    "\n",
    "        #---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        #---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "        g_loss = g_loss_d + g_feat_reg\n",
    "  \n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:,0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples, \n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "          D_L_Supervised = 0\n",
    "        else:\n",
    "          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "                 \n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "\n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward() \n",
    "        \n",
    "        # Apply modifications\n",
    "        gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "          scheduler_d.step()\n",
    "          scheduler_g.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "            #hidden_states = model_outputs[-1]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss generator': avg_train_loss_g,\n",
    "            'Training Loss discriminator': avg_train_loss_d,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    accuracy_array.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fa12c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f876acc16d8>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60603d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4625\n"
     ]
    }
   ],
   "source": [
    "print(max(accuracy_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb4cf2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_array[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed14691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
