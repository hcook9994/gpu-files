{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ea1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86576f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a0de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yahoo = pd.read_csv(\"yahoo_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93668f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yahoo = df_yahoo.set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a40b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yahoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa3ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yahoo['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3818ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_yahoo.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4676c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c8821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers=list(df['label'].unique())\n",
    "# list_zeros = [0]*len(numbers)\n",
    "# count_dictionary = dict(zip(numbers, list_zeros))\n",
    "\n",
    "# values_array_train=[]\n",
    "# values_array_test=[]\n",
    "# values_array_unlabelled=[]\n",
    "# for index, row in df.iterrows():\n",
    "#     if count_dictionary[row['label']]<20:\n",
    "#         count_dictionary[row['label']]=count_dictionary[row['label']]+1\n",
    "#         values_array_train.append((row['question_1'],row['label']))\n",
    "#     elif count_dictionary[row['label']]<60:\n",
    "#         count_dictionary[row['label']]=count_dictionary[row['label']]+1\n",
    "#         values_array_test.append((row['question_1'],row['label']))\n",
    "#     elif count_dictionary[row['label']]<600:\n",
    "#         count_dictionary[row['label']]=count_dictionary[row['label']]+1\n",
    "#         values_array_unlabelled.append((row['question_1'],'UNK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864b66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_l=pd.read_csv(\"assigned/train_l.csv\", index_col=\"Unnamed: 0\")\n",
    "df_test_l=pd.read_csv(\"assigned/test_l.csv\", index_col=\"Unnamed: 0\")\n",
    "df_u=pd.read_csv(\"assigned/u.csv\", index_col=\"Unnamed: 0\")\n",
    "df_train_u=pd.read_csv(\"assigned/train_u.csv\", index_col=\"Unnamed: 0\")\n",
    "df_test_u=pd.read_csv(\"assigned/test_u.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ecdbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_array_train=list(df_train_l.to_records(index=False))\n",
    "values_array_test=list(df_test_l.to_records(index=False))\n",
    "values_array_unlabelled=df_u.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804df80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a0c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f64668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(values_array_unlabelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faaf4b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('how has religion affected war?', 4), ('What is the best talk show on the radio dial?', 8), (\"Any suppositions about somebody's Sun sign?\", 8), ('Poor Peyton?', 6), ('describe the anomalous expansion of water?', 2), ('who likes the cubs?', 6), ('what do you think of beyonce?', 8), ('1-        what is moles?', 3), ('How do you start a non profit charitable organization at work?', 10), ('How do  solve this problem?', 2), ('Need help finding a place.?', 7), ('Does anyone consider professional race car drivers to be \"athletes\"?', 6), ('What nations are currently allied with Mexico?', 10), ('help  me  by  telling me  how  to .....?', 5), ('Ever use Skype?', 7), ('how can i delet my photos?', 5), ('Why Is HIstory Class Soooooo Boring?', 1), ('Ur most embarassing blind date?', 9), ('Marriage seems like a curse. Does anyone else feel that way?', 9), ('How long do the effects of chickenpox last for?', 3), ('What is the worst thing you have done?', 4), ('What is your job? Do you enjoy it?', 1), ('should the sox win the world sieries again?', 6), ('is it bad if you have an email at a young age?', 7), ('how can I run a motor vehicle plate number any good websites?', 7), ('Exercise question?', 3), ('Strong Smell?', 3), ('has Montana signed onto the new 21st Century Banking Laws?', 10), ('what is the exact distance between Earth and the Sun?', 2), ('cOULD DINOSAURS FLY?', 2), ('who to have very cool sex?', 9), ('Which is the best mutual fund in MIP?', 7), ('how can you get clean water form dirty water or lake?', 2), ('how many square metres in a square metre?', 2), ('Why do women think that bad boys are \"confident\"?', 9), ('A Question for American members only.?', 1), ('what is the best brand of protein for post workout?', 3), ('Conflicts about Homosexuality?', 10), ('Why are there too many  Republican in US?', 10), ('why can i not get into messager?', 5), ('Dental care - how do you do it?', 3), ('Song for World Cup 2006? somebody help please?', 6), ('tell me abt urdu adab related site?', 1), ('what is the purpose of being a campus heartthrob?', 7), ('Which Team First Batting in the Quarter Final between India?', 6), ('How do i find the volume of a pointed fifth dome?', 2), ('a gentle mountain awakens here. where am i?', 4), ('What to do with a lot of money?', 7), ('How much are veneers for your teeth?', 3), ('Why do people keep running?', 9), ('Why does everyone think I look like Tony Blair?', 1), ('Any good book review on to kill a mocking bird?', 4), (\"Where can I find someone's criminal history for free?\", 4), ('health quesition?', 3), ('download \"youtube\" videos?', 5), ('link between bookkeeping,accountancy,auditing?', 4), ('Crossword/Science Help!?', 2), ('What movie are you waiting to see?', 8), ('best striker from these choices...?', 6), ('how many square cm per square m?', 2), ('Pictures of Steve Nash?', 6), ('Can u help me out plz!?', 8), ('can u imagine life with out GOOGLE?', 5), ('What is a microburst?', 2), ('Ashley Tisdale vs Hilary Duff?', 8), ('Why should / shouldnt one take up politics?', 10), ('how does eggs get in a uterus?', 3), ('what is crisis?', 2), ('How do you control your nerves?', 3), ('Where can I download free sheet music from?', 8), ('Is it SAFE for me to lose 20 pounds?', 3), ('If you were to add up the wealth of Christians & Muslims?', 1), ('WHAT should i doo?', 9), ('How do I take care of dry skin on face?', 3), ('should school have uniform or not?', 4), ('What is your favorite word? Why?', 4), ('If I reach Level 3 tomorrow what will you send me?', 8), (\"Did Adam & Eve's children engage in incest?\", 1), ('Is Buddah a god?', 1), ('Where can I hear a recording of the three lions football anthem?', 6), ('how do you sanatize the enema tip?', 3), ('What about the Big Bang Theory?', 2), ('Where can I find a map of future geography?', 2), ('smokin weed?', 1), ('What exactly is wrong with Marcus Trescothick ?', 6), ('What do i do with this problem?', 5), ('How much is a googol?', 2), ('Does freelance work affect unemployment benefits?', 7), ('complete free virus remover help?', 5), ('when doess the movie \"keith\" open?', 8), ('Do Cheap home laser hair removal appliances work?', 3), ('Looking for Restless Heart Song Lyrics?', 8), ('what is food poisoning and how does it effect us?', 3), ('What does \"skidrow\" mean?', 4), ('If I were a wolf  would you buy,?', 1), ('Help...What song is this???', 8), ('Can illegals really vote in America?', 10), ('Advice needed?', 9), ('Which album has the song higer ??', 8), ('What is the degree of consideration?', 4), ('mushrooms and drug test?', 2), (\"over-sea's romance?\", 9), ('how much radiation?', 5), ('Any ideas?', 4), ('the best self imployed health insurance?', 7), ('leo and scorpio?', 8), ('what is a curricullum vitae?', 7), ('Best movies with MEL GIBSON?', 8), ('how does metabolism effect  pregnancy?', 3), ('So she likes me...?', 9), ('Am doing the right thing?', 9), ('What do you call someone who is air assault qualified?', 10), ('Should the New York Knicks trade Stephon Marbury?', 6), ('i have no friends?', 7), (\"If i fall a black hole? Where i'll go?\", 2), ('he acts like he dosent like me?', 9), ('Could you take a question seriously if?', 1), ('Will Ohio State Buckeyes lead in 2007 ?', 6), ('is christianity a cult?', 1), ('What is  the difference between Surpac and Minex?', 5), ('Math Problem?', 2), ('who was the political leader forthe south?', 4), ('trees- how do they effect us?', 1), ('Internet Child Predator?', 10), ('Where was your best holiday ever?', 1), ('does this guy like me?', 9), ('for my girl?', 8), ('What is the most reactive family of metals? why?', 2), ('is it wrong to like watersports.  ie pee?', 1), ('where do you go about new tax laws?', 10), ('how to connect vonage to a wireless router?', 5), ('what is computer?', 5), ('my computer beeps when it is turned off,why?', 5), ('What is a zoombox?', 8), ('where is georgia?', 2), ('How many of you like T.I. and 50 cent?', 8), ('Port Saint Lucie - Old Coven Members?', 1), ('please help me to paraphrise these statements! thank you?', 4), ('Why do you think people want to be emo?', 5), ('Help writing power series?', 2), ('my friend is really annoying me!?', 9), ('talking yes, sex no?', 9), ('emo or punk muzic?????', 8), ('how can i create a logo for my company(developer)?', 7), ('what are the iranian people like in your own idea?', 1), ('HEEELLLLPPPP! Boy problem!!?', 9), ('Dose any body know who andre barton is?', 1), ('What is nonwage income?', 7), ('what historical thing happened in 1650 in america?', 4), ('Linux problem?', 5), ('Why would ANYBODY vote Democratic???', 10), ('Why are people impolite to strangers?', 1), ('How can i earn extra cash in the uk only?', 7), ('differences of Sparta and Athens in Ancient Greece?', 4), ('Has Online pharmacy overshadowed brick and mortal pharmacy?', 3), ('Please traslate from Chinese into English?', 1), ('Is America going to go to war with Iran?', 10), ('Moaning Mourinho?', 6), ('if you told him how you feel and...?', 9), ('Where, in Marin County California, is the Vansen Ranch ?', 6), ('how does hair grow?', 7), ('how can I get rid of the ringing in my ears?', 3), ('about the G.E.D test?', 10), ('how can I open any resticted website??', 5), ('Should I do it?', 9), ('average male pants size?', 3), ('which is the best linux??', 5), (\"Who is the youngest ever winner of Wimbledon men's singles?\", 6), ('Which guy?', 9), ('why is austalia called the land of oz?', 4), (\"What's your favorite...?\", 8), ('How to connect to outlook with webmail?', 5), ('How long do burned DVDs last?  Burned CDs?', 5), ('song from forest gump?', 8), ('what is the use of dexamethasone??', 3), ('rooster joke?', 7), ('Unsure about auto insurance law?', 10), ('How can I make a really long day go quicker at work?', 7), ('do the people have the right to die?', 10), ('why didnt UK help US in the Vietnam war?', 10), ('shuffle anyone?', 9), ('Who do Liverpool FC need to buy to win the Premiership?', 6), ('how can i get wireless internet for my laptop.?', 5), ('Where can i find truancy  laws for KS?', 10), ('Need abuse advice?', 10), ('what is 7/16+9/16=?', 7), ('How do you multiply fractions?', 4), ('whos the best QB to ever play in the NFL?', 6), ('Why do certain words suddenly become politically incorrect to say?', 4), ('For people born before 1965.?', 4), ('my age 30 and I cant make relation with girles?', 9), ('What is the name of the Nile goddess?', 4), ('Indian Test Cricket?', 6), ('What is an euro?', 7), ('where can i get a training to get the 220 insurance license?', 7), ('I need several proxy sites to get past school blockers?', 5), ('who loves to play sports?', 6), ('Capital punishment? For or against?', 10), ('has any one heard of alldayairs.com?', 6), ('does capital punishment still happen in the United Kingdom?', 10)]\n"
     ]
    }
   ],
   "source": [
    "print(values_array_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c31b5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I need Environmental Management Plan for Underground Gas Storage Facility?', 2)\n"
     ]
    }
   ],
   "source": [
    "print(values_array_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce423411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('what is the most abundant cell type in plants?', 'UNK')\n"
     ]
    }
   ],
   "source": [
    "print(values_array_unlabelled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37916145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.3.2\n",
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install sentencepiece\n",
    "\n",
    "##Set random values\n",
    "#seed_val = 42\n",
    "seed_val = 4\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d415d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88a04fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 20\n",
    "batch_size = 92\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "#num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-6\n",
    "#learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 400\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "#model_name=\"google/electra-large-discriminator\"\n",
    "#model_name=\"google/electra-small-discriminator\"\n",
    "#model_name=\"microsoft/deberta-v2-xxlarge\"\n",
    "#model_name=\"microsoft/deberta-v3-base\"\n",
    "#model_name = \"google/electra-base-discriminator\"\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the TREC QC Dataset\n",
    "#--------------------------------\n",
    "#! git clone https://github.com/crux82/ganbert\n",
    "\n",
    "#  NOTE: in this setting 50 classes are involved\n",
    "# labeled_file = \"./ganbert/data/labeled.tsv\"\n",
    "# unlabeled_file = \"./ganbert/data/unlabeled.tsv\"\n",
    "# test_filename = \"./ganbert/data/test.tsv\"\n",
    "\n",
    "label_list = ['UNK',1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c908c079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/harry/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/harry/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/harry/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/harry/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6383a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the examples\n",
    "labeled_examples = values_array_train\n",
    "#unlabeled_examples = values_array_unlabelled\n",
    "test_examples = values_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10d4fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  examples = []\n",
    "\n",
    "  # Count the percentage of labeled examples  \n",
    "  num_labeled_examples = 0\n",
    "  for label_mask in label_masks:\n",
    "    if label_mask: \n",
    "      num_labeled_examples += 1\n",
    "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "  # if required it applies the balance\n",
    "  for index, ex in enumerate(input_examples): \n",
    "    if label_mask_rate == 1 or not balance_label_examples:\n",
    "      examples.append((ex, label_masks[index]))\n",
    "    else:\n",
    "      # IT SIMULATE A LABELED EXAMPLE\n",
    "      if label_masks[index]:\n",
    "        balance = int(1/label_mask_rate)\n",
    "        balance = int(math.log(balance,2))\n",
    "        if balance < 1:\n",
    "          balance = 1\n",
    "        for b in range(0, int(balance)):\n",
    "          examples.append((ex, label_masks[index]))\n",
    "      else:\n",
    "        examples.append((ex, label_masks[index]))\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for (text, label_mask) in examples:\n",
    "    print(text[0])\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[text[1]])\n",
    "    label_mask_array.append(label_mask)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "  label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56feab4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how has religion affected war?\n",
      "What is the best talk show on the radio dial?\n",
      "Any suppositions about somebody's Sun sign?\n",
      "Poor Peyton?\n",
      "describe the anomalous expansion of water?\n",
      "who likes the cubs?\n",
      "what do you think of beyonce?\n",
      "1-        what is moles?\n",
      "How do you start a non profit charitable organization at work?\n",
      "How do  solve this problem?\n",
      "Need help finding a place.?\n",
      "Does anyone consider professional race car drivers to be \"athletes\"?\n",
      "What nations are currently allied with Mexico?\n",
      "help  me  by  telling me  how  to .....?\n",
      "Ever use Skype?\n",
      "how can i delet my photos?\n",
      "Why Is HIstory Class Soooooo Boring?\n",
      "Ur most embarassing blind date?\n",
      "Marriage seems like a curse. Does anyone else feel that way?\n",
      "How long do the effects of chickenpox last for?\n",
      "What is the worst thing you have done?\n",
      "What is your job? Do you enjoy it?\n",
      "should the sox win the world sieries again?\n",
      "is it bad if you have an email at a young age?\n",
      "how can I run a motor vehicle plate number any good websites?\n",
      "Exercise question?\n",
      "Strong Smell?\n",
      "has Montana signed onto the new 21st Century Banking Laws?\n",
      "what is the exact distance between Earth and the Sun?\n",
      "cOULD DINOSAURS FLY?\n",
      "who to have very cool sex?\n",
      "Which is the best mutual fund in MIP?\n",
      "how can you get clean water form dirty water or lake?\n",
      "how many square metres in a square metre?\n",
      "Why do women think that bad boys are \"confident\"?\n",
      "A Question for American members only.?\n",
      "what is the best brand of protein for post workout?\n",
      "Conflicts about Homosexuality?\n",
      "Why are there too many  Republican in US?\n",
      "why can i not get into messager?\n",
      "Dental care - how do you do it?\n",
      "Song for World Cup 2006? somebody help please?\n",
      "tell me abt urdu adab related site?\n",
      "what is the purpose of being a campus heartthrob?\n",
      "Which Team First Batting in the Quarter Final between India?\n",
      "How do i find the volume of a pointed fifth dome?\n",
      "a gentle mountain awakens here. where am i?\n",
      "What to do with a lot of money?\n",
      "How much are veneers for your teeth?\n",
      "Why do people keep running?\n",
      "Why does everyone think I look like Tony Blair?\n",
      "Any good book review on to kill a mocking bird?\n",
      "Where can I find someone's criminal history for free?\n",
      "health quesition?\n",
      "download \"youtube\" videos?\n",
      "link between bookkeeping,accountancy,auditing?\n",
      "Crossword/Science Help!?\n",
      "What movie are you waiting to see?\n",
      "best striker from these choices...?\n",
      "how many square cm per square m?\n",
      "Pictures of Steve Nash?\n",
      "Can u help me out plz!?\n",
      "can u imagine life with out GOOGLE?\n",
      "What is a microburst?\n",
      "Ashley Tisdale vs Hilary Duff?\n",
      "Why should / shouldnt one take up politics?\n",
      "how does eggs get in a uterus?\n",
      "what is crisis?\n",
      "How do you control your nerves?\n",
      "Where can I download free sheet music from?\n",
      "Is it SAFE for me to lose 20 pounds?\n",
      "If you were to add up the wealth of Christians & Muslims?\n",
      "WHAT should i doo?\n",
      "How do I take care of dry skin on face?\n",
      "should school have uniform or not?\n",
      "What is your favorite word? Why?\n",
      "If I reach Level 3 tomorrow what will you send me?\n",
      "Did Adam & Eve's children engage in incest?\n",
      "Is Buddah a god?\n",
      "Where can I hear a recording of the three lions football anthem?\n",
      "how do you sanatize the enema tip?\n",
      "What about the Big Bang Theory?\n",
      "Where can I find a map of future geography?\n",
      "smokin weed?\n",
      "What exactly is wrong with Marcus Trescothick ?\n",
      "What do i do with this problem?\n",
      "How much is a googol?\n",
      "Does freelance work affect unemployment benefits?\n",
      "complete free virus remover help?\n",
      "when doess the movie \"keith\" open?\n",
      "Do Cheap home laser hair removal appliances work?\n",
      "Looking for Restless Heart Song Lyrics?\n",
      "what is food poisoning and how does it effect us?\n",
      "What does \"skidrow\" mean?\n",
      "If I were a wolf  would you buy,?\n",
      "Help...What song is this???\n",
      "Can illegals really vote in America?\n",
      "Advice needed?\n",
      "Which album has the song higer ??\n",
      "What is the degree of consideration?\n",
      "mushrooms and drug test?\n",
      "over-sea's romance?\n",
      "how much radiation?\n",
      "Any ideas?\n",
      "the best self imployed health insurance?\n",
      "leo and scorpio?\n",
      "what is a curricullum vitae?\n",
      "Best movies with MEL GIBSON?\n",
      "how does metabolism effect  pregnancy?\n",
      "So she likes me...?\n",
      "Am doing the right thing?\n",
      "What do you call someone who is air assault qualified?\n",
      "Should the New York Knicks trade Stephon Marbury?\n",
      "i have no friends?\n",
      "If i fall a black hole? Where i'll go?\n",
      "he acts like he dosent like me?\n",
      "Could you take a question seriously if?\n",
      "Will Ohio State Buckeyes lead in 2007 ?\n",
      "is christianity a cult?\n",
      "What is  the difference between Surpac and Minex?\n",
      "Math Problem?\n",
      "who was the political leader forthe south?\n",
      "trees- how do they effect us?\n",
      "Internet Child Predator?\n",
      "Where was your best holiday ever?\n",
      "does this guy like me?\n",
      "for my girl?\n",
      "What is the most reactive family of metals? why?\n",
      "is it wrong to like watersports.  ie pee?\n",
      "where do you go about new tax laws?\n",
      "how to connect vonage to a wireless router?\n",
      "what is computer?\n",
      "my computer beeps when it is turned off,why?\n",
      "What is a zoombox?\n",
      "where is georgia?\n",
      "How many of you like T.I. and 50 cent?\n",
      "Port Saint Lucie - Old Coven Members?\n",
      "please help me to paraphrise these statements! thank you?\n",
      "Why do you think people want to be emo?\n",
      "Help writing power series?\n",
      "my friend is really annoying me!?\n",
      "talking yes, sex no?\n",
      "emo or punk muzic?????\n",
      "how can i create a logo for my company(developer)?\n",
      "what are the iranian people like in your own idea?\n",
      "HEEELLLLPPPP! Boy problem!!?\n",
      "Dose any body know who andre barton is?\n",
      "What is nonwage income?\n",
      "what historical thing happened in 1650 in america?\n",
      "Linux problem?\n",
      "Why would ANYBODY vote Democratic???\n",
      "Why are people impolite to strangers?\n",
      "How can i earn extra cash in the uk only?\n",
      "differences of Sparta and Athens in Ancient Greece?\n",
      "Has Online pharmacy overshadowed brick and mortal pharmacy?\n",
      "Please traslate from Chinese into English?\n",
      "Is America going to go to war with Iran?\n",
      "Moaning Mourinho?\n",
      "if you told him how you feel and...?\n",
      "Where, in Marin County California, is the Vansen Ranch ?\n",
      "how does hair grow?\n",
      "how can I get rid of the ringing in my ears?\n",
      "about the G.E.D test?\n",
      "how can I open any resticted website??\n",
      "Should I do it?\n",
      "average male pants size?\n",
      "which is the best linux??\n",
      "Who is the youngest ever winner of Wimbledon men's singles?\n",
      "Which guy?\n",
      "why is austalia called the land of oz?\n",
      "What's your favorite...?\n",
      "How to connect to outlook with webmail?\n",
      "How long do burned DVDs last?  Burned CDs?\n",
      "song from forest gump?\n",
      "what is the use of dexamethasone??\n",
      "rooster joke?\n",
      "Unsure about auto insurance law?\n",
      "How can I make a really long day go quicker at work?\n",
      "do the people have the right to die?\n",
      "why didnt UK help US in the Vietnam war?\n",
      "shuffle anyone?\n",
      "Who do Liverpool FC need to buy to win the Premiership?\n",
      "how can i get wireless internet for my laptop.?\n",
      "Where can i find truancy  laws for KS?\n",
      "Need abuse advice?\n",
      "what is 7/16+9/16=?\n",
      "How do you multiply fractions?\n",
      "whos the best QB to ever play in the NFL?\n",
      "Why do certain words suddenly become politically incorrect to say?\n",
      "For people born before 1965.?\n",
      "my age 30 and I cant make relation with girles?\n",
      "What is the name of the Nile goddess?\n",
      "Indian Test Cricket?\n",
      "What is an euro?\n",
      "where can i get a training to get the 220 insurance license?\n",
      "I need several proxy sites to get past school blockers?\n",
      "who loves to play sports?\n",
      "Capital punishment? For or against?\n",
      "has any one heard of alldayairs.com?\n",
      "does capital punishment still happen in the United Kingdom?\n",
      "I need Environmental Management Plan for Underground Gas Storage Facility?\n",
      "Why, are Penguins always dressed as waiters.?\n",
      "Challenging Challenge Question!!!?\n",
      "how do u no if your school is evil?\n",
      "How do women different from men in communication style?\n",
      "physical and chemical properties of radon?\n",
      "Answer the story of Jack...?\n",
      "the different between si unit and FBC?\n",
      "chemistry help?\n",
      "The decomposition?\n",
      "what is the composition of invisible ink?\n",
      "Who is your favorite political or social activist and why?\n",
      "is it funnier to curse than not?\n",
      "This is interesting....?\n",
      "Do Christians really believe in the horseman Death?\n",
      "What is Kong?\n",
      "how do i reinstall music engine?\n",
      "does anyone here like rammstein?\n",
      "what is love?\n",
      "major contribution about democritus atom theory?\n",
      "math people help please?\n",
      "what is the morphology of plasmodium malariae?\n",
      "Describe to me your god?\n",
      "Can u tell me more about Geishas?\n",
      "what is the 25% of 200.000$?\n",
      "The ups and downs of tarot?\n",
      "how is NH3 affected in homes?\n",
      "Can someone be addicted to Toradol IM?\n",
      "In your heart do you see any truth in this quote?\n",
      "What are some sound wave experiments kids could do in the classroom?\n",
      "Would you date the person above you?\n",
      "I cant understand this?\n",
      "what do u guys think of ???\n",
      "Twice as Cold?\n",
      "who has the answers to the logo and mascot quiz?\n",
      "i love you?\n",
      "Can you put hydrocortizone cream on a cat?\n",
      "How do I start my own ghost hunting club?\n",
      "food poisoning and it's effects?\n",
      "can ne body tell me ne nice movies 2 watch?\n",
      "Which team in the tournament was named after a French explorer?\n",
      "no the you will remember me that just came out?\n",
      "What is Deja Vu??\n",
      "Do monkey eat meat?\n",
      "why do they make coffee sweets?\n",
      "who's the earliest african traditional healer?\n",
      "who like the movie........?\n",
      "Beauty products that contains hazardous chemicals?\n",
      "Are shipping companies the same as clearing and forwarding companies?\n",
      "What would be a good topic for a new blog?\n",
      "Do you like...?\n",
      "what does blood pressure mean?\n",
      "high protien levels?\n",
      "can you say HI?\n",
      "What is the most common blood type?\n",
      "Im looking for lilkc, where r u?\n",
      "Should piracy be illegal?\n",
      "Ampd mobile commercial?\n",
      "how do you get over being shy?\n",
      "health and safety lifting at work?\n",
      "Why do the dallas cowboys always play on Thanksgiving?\n",
      "Why is it called The Angel (islington)?\n",
      "How do I remove objects from an Excel spreadsheet?\n",
      "can sms send from mobile to computer?\n",
      "Could religion be a genetic imperative?\n",
      "what's a single tranche CDO?\n",
      "What causes ring worm?\n",
      "Common sense only, please.!?\n",
      "I am talking about epelepsy.?\n",
      "what is the meaning of the word \"rollercoaster'?\n",
      "What is the definition of pressure?\n",
      "Who will win Lord Stanly??\n",
      "May I thank-you all for giving me a higher education?\n",
      "i want to make more money within the ager of 50?\n",
      "Who had the stupid idea of this questioning/answering?\n",
      "do you know me ?\n",
      "saggitarius and taurus?\n",
      "who is the best overall singer?\n",
      "Since the UK has the least bank holidays....?\n",
      "addition&subtraction are examples of?\n",
      "is there any training center for medicalcode in india?\n",
      "What is a Kubrick?\n",
      "What is the difference between thundering and lightning ?\n",
      "I want to ask for a more specific topic related to electricity?\n",
      "When you enter a chatroom?\n",
      "Can I drive to Paris by car?\n",
      "seed plants have four main structures. They are:?\n",
      "A mathematical experiment?\n",
      "Whats the difference between marrige and common law marriage?\n",
      "what team won in the last baseball world series?\n",
      "how do i tell sum1 i luv him?\n",
      "I'm not getting the right cheatplanet.com?\n",
      "Interview Questions?\n",
      "how did the 100 years war end?\n",
      "anyone know any cheap places to golf in northeast ohio?\n",
      "Is there really such thing as different types of human species?\n",
      "Should I get Facebook?\n",
      "Has anyone ever had their teeth treated for Fluorosis?\n",
      "What was the first planet?\n",
      "Can anybody suggest some brain foods?\n",
      "like an old oak tree?\n",
      "isn't it bizarre ?\n",
      "what is morera,s theorm of complex numbers?\n",
      "Firewall Implementation?\n",
      "y r things easier said than done??\n",
      "what is nepal?\n",
      "What is the best program to clean- up my hardrive?\n",
      "what is corrugation?\n",
      "Clean the gun?\n",
      "Are non-Europeans allowed to buy property in Austria?\n",
      "who will win the snooker world championship?\n",
      "Has anyone here ever been screwed over by Microsoft Tech Support?\n",
      "could jackie chan beat jet lee?\n",
      "so what did u think of the match between Italy and Australia?\n",
      "Where can I find NBA store in Turkey?\n",
      "what causes lightening and thunder?\n",
      "where does the phrase nippy come from?\n",
      "What is the best way to make love with a girl?\n",
      "Am I morbidly Obese?\n",
      "How long is a normal size for a mans penis?\n",
      "what is the best gift?\n",
      "how do identical twins happen?\n",
      "isnt soccer the best sport??\n",
      "what's wrong with me now?\n",
      "Why KOBE BRYANT is the best??\n",
      "An  arrest in                             new York?\n",
      "the ten commandments states there should be no incest?\n",
      "Why should one review one s credit report?\n",
      "what if these?\n",
      "Huge question about LIMEWIRE?\n",
      "how does pleasure and interpersonal communication relate?\n",
      "Who likes any of the CSI Shows?\n",
      "what gets bigger and bigger the more you take from it.?\n",
      "what happened on july 22 1988?\n",
      "how can i ?\n",
      "how to build a website?\n",
      "What would you do if you were lost in a odd country?\n",
      "Are you addicted to the internert?\n",
      "why is the meaning of Legal \"ALIEN\"?\n",
      "Where can I find greetings?\n",
      "who said the quote \"fight evil with love\"?\n",
      "I am just bored!! U get that???\n",
      "How to prepare to be a cheerleading flyer?\n",
      "Do you want to share...?\n",
      "Guys only...??\n",
      "What is the definition of mock iodine?\n",
      "what is a swedish body wrap?\n",
      "Greatest Football Manager?\n",
      "Am I gay, bi, or straight?\n",
      "Why do mormons believe that Jesus and Satan are brothers?\n",
      "Where is fox24?\n",
      "Uknown file format??????\n",
      "what are some good effective leg exercises?\n",
      "Windows Vista?\n",
      "what is full word used for CD?\n",
      "A modest proposal by Jonathan Swift.?\n",
      "Desperate Housewives?\n",
      "Would you go on the show Elimadate,or Next?\n",
      "Why does everyone think that Green Day are posers?\n",
      "Do you know any scholarships that can help my study?\n",
      "are tension headaches a bad sign of something else?\n",
      "what are the variety of research methods?\n",
      "is it wrong to masterbate?\n",
      "Does anyone know any good jokes?\n",
      "Dig it or Diss it?\n",
      "what is an immunological disease?\n",
      "What do you do for a toenail injury?\n",
      "what is gynoclymastia?\n",
      "Why is there a serial number on a dollar bill?\n",
      "gift for someone special?\n",
      "where do i find the department of defense retired personal pay?\n",
      "Where can I find free online resources to learn French?\n",
      "which is the most volcanic body?\n",
      "what do u think?\n",
      "what isthe course for preparing MBA entrances?\n",
      "should i try shrooms?\n",
      "is there any good guys out there?\n",
      "www.fortismeespierson.eu?\n",
      "Solving liner inequalities help?\n",
      "anybody hear about this?\n",
      "pic of schedule world cup 2006?\n",
      "Why do filipinos eat with their bare hands?\n",
      "Should USA avoid war on Iran?\n",
      "what would happen if most people went to hell?\n",
      "What is the best brand of adhesive tape?\n",
      "What do you think would be the worst superhero ability ever?\n",
      "Do you shave yourself.....down there?\n",
      "Who was Russian President, Boris Yektson?\n",
      "why do vegetarians claim to be concerned about the environment?\n",
      "im off the schedule for a week, what should i do?\n",
      "Do you know any Egyptian singers or actors?\n",
      "Homophobic person question?\n",
      "In your opinion what is the best free P2P Software?\n",
      "What do you think about these TNA wrestlers?\n",
      "is their a difference between athletic conditioning and army conditioning?\n",
      "i had endometrosis?\n",
      "What do you think of this?\n",
      "how istall  win xp?\n",
      "How to do cold calls for QA outsourcing company?\n",
      "When your dreams don't even matter anymore?\n",
      "Do eggshells have acids in them?\n",
      "what would america do without inmigrants?\n",
      "i like travelling a lot, cruise ship jobs?\n",
      "trace the growth of the hotel industry as a thriving industry?\n",
      "which girls and dudes what my e-mail address?\n",
      "wat gift u would love to have on your birthday?\n",
      "Should I ask this Girl out?\n",
      "User manual of micrometre srew gauge?\n",
      "English homework help!?\n",
      "has anyone consolidated before? if so did it work for you?\n",
      "Do you smoke marijuana?\n",
      "How come Oprah looks TERRIBLE some days?\n",
      "need to find a job in cabinet making?\n",
      "Are you for dividing or unifying?\n",
      "Have you ever wished upon a falling star?\n",
      "when is semana santa 2006?\n",
      "Anyone use LegalZoom?\n",
      "What can I do to help an ear piercing heal?\n",
      "please answer this serious question.?\n",
      "Where can you get benefits for free?\n",
      "Is beauty a gift or a curse?\n",
      "goverment grants?\n",
      "general infomation on the relevance of quickness in basketball?\n",
      "Will humans develop in the future and how will we develop?\n",
      "do any other girls have problems with there brothers!?\n",
      "Can you tell in what part of the world are you?\n",
      "dating guys?\n",
      "How can I calculate market shares?\n",
      "does anyone know good sites for watching old TV Shows?\n",
      "Where do you buy high quality, but cheap guns?\n",
      "merced calif. zip codes?\n",
      "can back people get sunburn?\n",
      "Good medical school?\n",
      "Physics project?\n",
      "10 points for first. What does Lecherous mean?\n",
      "Can someone tell me how to burn movies?\n",
      "In todays social and political climate?\n",
      "How does Nitrogen help the body? In which way?\n",
      "what is your most favorite thing you own?\n",
      "create a topic for me..?\n",
      "Hey Christians.  Does the bible say anything about this scenario?\n",
      "How much is a ticket for No seatbelt in California??\n",
      "is scalp med good for grow hair?\n",
      "how old are thy ?\n",
      "Do you think Cops dig crazy chicks?\n",
      "What is a good job in the graphic arts?\n",
      "when will the planets align again in the northern hemisphere?\n",
      "is an erection possible without physical contact?\n",
      "Is it wrong to ask out her friend?\n",
      "How do you know if it's true love?\n",
      "who is john cena?\n",
      "How can I get rid of kid urine smell from sneakers?\n",
      "can you get video memory for your laptop?\n",
      "AMD or Intel?\n",
      "What is the average wait time for a computer to turn off?\n",
      "Cheerleading-Back handspring??\n",
      "Christians: Is gossip a sin?\n",
      "What are some good rock songs with palm muted guitar in it?\n",
      "What is the most active volcano?\n",
      "Guitar Question-?\n",
      "How do I get my computer to go faster without restoring it?\n",
      "what is torchwood?\n",
      "Are there female leprechauns?\n",
      "What is the difference between a chemical element and atom?\n",
      "have u ever watched the longest yard?\n",
      "How many lbs. does it take to drop one dress size?\n",
      "can i see BCS bowl games in India?\n",
      "Where did the word cocktail come from?\n",
      "Download Driver of USB VGA Q-Cam?\n",
      "Sore top of foot?\n",
      "Oh no you din't!!?\n",
      "what is download bat.rar?\n",
      "what term is used for \"being afraid of doctors\"?\n",
      "What composition found in the chalk that causes skin diseases?\n",
      "internet people?\n",
      "tips to get high grades???\n",
      "Can you become rich if you dont graduate from high school?\n",
      "Why are the qute girls so shy?\n",
      "How does temperature affect the size of a balloon?\n",
      "What is ur favorite country, and y?\n",
      "how old is george straight?\n",
      "what is the best way to pay off my bills.?\n",
      "factors that promote tourism?\n",
      "does doing your homework even matter?\n",
      "what type of lighting goes in museums?\n",
      "Has anyone had any problems with Mcafee virus scan?\n",
      "What is your favorite Homer Simpson line?\n",
      "What would be a good name for a rap song?\n",
      "can anyone suggest to ger rid of excessive sweating in palms?\n",
      "how can i totally filter my yahoo email?\n",
      "is it possible for peaple to get shorter?\n",
      "Are London based labour MPs insulting the Scots?\n",
      "what vice presidents died in office?\n",
      "where can i see opening ceremony  for world cup 2006 on line?\n",
      "What is thermal energy?\n",
      "why am i here in this existence?\n",
      "Am i overweight!?\n",
      "Is George Bush Pontius Pilate come back from the dead?\n",
      "Has anyone heard of a band called Black Market Radio?\n",
      "Question about Power Point?\n",
      "defination of algae?\n",
      "What does FUBU stand for?\n",
      "java doesnt work right help?\n",
      "selling mobile home, need documents for sale.?\n",
      "How do i know if my boyfriend is gonna dump me?\n",
      "Anybody who think netherlands will win?\n",
      "Is it possible to fall in love over the internet??\n",
      "What is sexy to you?\n",
      "Who is better Usher or Marques Houston?\n",
      "how do you get a boyfriend?\n",
      "What A Good Antivirus That You Have To Buy?\n",
      "How many  or what percentage of goals are scored from corners.?\n",
      "has Saudi Arabia ever won a world cup match ?\n",
      "GIRLS, what if this happened?\n",
      "water comes out from????\n",
      "..Can you help me?\n",
      "Where si the district of columbia and what is it?\n",
      "Please inform top 10 medical colleges/universities in China.?\n",
      "can anyone give me info on cymbalta?\n",
      "What do you make of the following video?\n",
      "when is lost season 3 coming to channel4?\n",
      "who do you think has the best position in choosing a mate?\n",
      "what do most legal documents look like?\n",
      "why don't I get any channels on my dish network?\n",
      "good priceing for selling a computer?\n",
      "how do u tell if he is to controlling?\n",
      "What does \"albino\" mean?\n",
      "do white men really fantasize about black women?\n",
      "i am bored what do i do?\n",
      "Should we be mad at Kerry or Bush?\n",
      "what are the chronology of statins?\n",
      "Most valuable things in life...three things?\n",
      "What's the worst pain you ever been in?\n",
      "What should i do?\n",
      "Anybody knows of a easy to use online Cricket Statistics software?\n",
      "What is wvc.net?\n",
      "Should our Postal System eliminate Saturday delivery?\n",
      "How long would it take America and its allies too conquer Iran?\n",
      "Time Duncan or Kobe Bryant?\n",
      "what are lesbians?\n",
      "what song gets stuck in your head the most?\n",
      "what is an arnold press?\n",
      "which QB should i start this week?\n",
      "WARRIORS have to put 1o characters?\n",
      "Looking for some songs, have you heard of these?\n",
      "how can i handle this boy?\n",
      "Why do i want sex all the time?\n",
      "How does suffering with anxiety and panic attacks effect your relationship?\n",
      "the new windows internet explorer runs so slow why ?\n",
      "how do u know if a boy fancies you?\n",
      "can skateboarding make you fit?\n",
      "what is CatRoot 2?\n",
      "should i be a model?\n",
      "A question for the NBA DRAFT!?\n",
      "What is missing from your life right now?\n",
      "How big is your penis  men?\n",
      "Interested in a pretty girl, how to approach?\n",
      "why money is so important in our live today?\n",
      "How do you bulk up from receiver to tight end?\n",
      "How to hook my computer to my tv?\n",
      "hey how many planets are in space?\n",
      "How You Will Know?\n",
      "What are boils at the top of your butt crack?\n",
      "What is a resin posterior?\n",
      "What are some herbs known to help with cancer treatment?\n",
      "Big mistake??/?\n",
      "how do i stop being nervous?\n",
      "basic training at fort benning?\n",
      "Can all of you accept my apologies?\n",
      "what can i do to get better in basketball?\n",
      "who was napoleon?\n",
      "Who recently won Wimbledon as an outsider (came on invitation)?\n",
      "How do I get more sex from my wife?\n",
      "what happen when you get your physical?\n",
      "World War III?\n",
      "how can I control myself being touch my other woman for marriage ?\n",
      "Do I have this figured out fellow Liberals?\n",
      "Does Japan have a King and a Queen?\n",
      "rules and regulations for a private bus owner?\n",
      "why american people hate arab people ????\n",
      "Where's Nebraska QB Tommie Fraizer?\n",
      "Should we impeach him or make him dictator?\n",
      "Does Luxembourg even have a military? Heh...?\n",
      "Where is Jeffrey Jordan Going to college?\n",
      "how do you save a signature you created with my mail signature?\n",
      "Man vs Woman?\n",
      "How do you feel when you sit around a campfire?\n",
      "Who really lost the war in Iraq?\n",
      "todays messages were accidently deleted can I get them back?\n",
      "Is there a complete online Bible?\n",
      "Why can i not receive emails from my job email?\n",
      "Does anyone want to...?\n",
      "Movie Makers?\n",
      "why did they change from WWF to WWE?\n",
      "what is the most ethnically diverse city on earth?\n",
      "Is the majority of Americans supportive of our Troops?\n",
      "If the USA stop buying and trading with other countries?\n",
      "Does it seem lately that the UK wants their colonies back?\n",
      "we gotta keep stuff under control, right?\n",
      "Did illegal immigrants break a law?\n"
     ]
    }
   ],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "# if unlabeled_examples:\n",
    "#   train_examples = train_examples + unlabeled_examples\n",
    "#   #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "#   tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
    "#   train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cce6ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Generator as in \n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
    "#         super(Generator, self).__init__()\n",
    "#         layers = []\n",
    "#         hidden_sizes = [noise_size] + hidden_sizes\n",
    "#         for i in range(len(hidden_sizes)-1):\n",
    "#             layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "#         layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
    "#         self.layers = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, noise):\n",
    "#         output_rep = self.layers(noise)\n",
    "#         return output_rep\n",
    "\n",
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f27045c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/harry/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "#hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "#generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  #generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dcbc408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.480\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.110\n",
      "  Test Loss: 2.402\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.494\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.113\n",
      "  Test Loss: 2.398\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.467\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.110\n",
      "  Test Loss: 2.394\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.465\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.113\n",
      "  Test Loss: 2.390\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 5 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.467\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.115\n",
      "  Test Loss: 2.385\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 6 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.452\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.117\n",
      "  Test Loss: 2.380\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 7 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.436\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.120\n",
      "  Test Loss: 2.375\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 8 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.433\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.128\n",
      "  Test Loss: 2.370\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 9 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.441\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.140\n",
      "  Test Loss: 2.365\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 10 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.408\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.140\n",
      "  Test Loss: 2.359\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 11 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.374\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.145\n",
      "  Test Loss: 2.355\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 12 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.381\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.142\n",
      "  Test Loss: 2.350\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 13 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.360\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.140\n",
      "  Test Loss: 2.344\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 14 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.346\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.158\n",
      "  Test Loss: 2.339\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 15 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.350\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.152\n",
      "  Test Loss: 2.333\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 16 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.328\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.150\n",
      "  Test Loss: 2.327\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 17 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.319\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.158\n",
      "  Test Loss: 2.320\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 18 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.296\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.163\n",
      "  Test Loss: 2.312\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 19 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.296\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.182\n",
      "  Test Loss: 2.304\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 20 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.264\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.190\n",
      "  Test Loss: 2.294\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 21 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.259\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.210\n",
      "  Test Loss: 2.285\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 22 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.245\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.223\n",
      "  Test Loss: 2.275\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 23 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.220\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.217\n",
      "  Test Loss: 2.264\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 24 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.186\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.240\n",
      "  Test Loss: 2.254\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 25 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.177\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.233\n",
      "  Test Loss: 2.244\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 26 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.130\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.242\n",
      "  Test Loss: 2.233\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 27 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.097\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.255\n",
      "  Test Loss: 2.221\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 28 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.060\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.268\n",
      "  Test Loss: 2.207\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 29 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.079\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.278\n",
      "  Test Loss: 2.193\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 30 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.994\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.278\n",
      "  Test Loss: 2.180\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 31 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 2.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.297\n",
      "  Test Loss: 2.166\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 32 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.955\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.307\n",
      "  Test Loss: 2.153\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 33 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.911\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.312\n",
      "  Test Loss: 2.140\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 34 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.912\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.335\n",
      "  Test Loss: 2.128\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 35 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.924\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.343\n",
      "  Test Loss: 2.120\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 36 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.831\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.338\n",
      "  Test Loss: 2.111\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 37 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.808\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.338\n",
      "  Test Loss: 2.099\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 38 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.787\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.340\n",
      "  Test Loss: 2.086\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 39 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.779\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.343\n",
      "  Test Loss: 2.073\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 40 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.716\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.347\n",
      "  Test Loss: 2.061\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 41 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.699\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.350\n",
      "  Test Loss: 2.050\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 42 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.645\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.340\n",
      "  Test Loss: 2.038\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 43 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.629\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.347\n",
      "  Test Loss: 2.025\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 44 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.616\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.338\n",
      "  Test Loss: 2.013\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 45 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.575\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.352\n",
      "  Test Loss: 2.003\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 46 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.514\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.350\n",
      "  Test Loss: 1.993\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 47 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.464\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.357\n",
      "  Test Loss: 1.983\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 48 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.452\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.357\n",
      "  Test Loss: 1.973\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 49 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.421\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.367\n",
      "  Test Loss: 1.962\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 50 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.377\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.362\n",
      "  Test Loss: 1.950\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 51 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.385\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.365\n",
      "  Test Loss: 1.940\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 52 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.329\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.365\n",
      "  Test Loss: 1.932\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 53 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.262\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.370\n",
      "  Test Loss: 1.924\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 54 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.268\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.378\n",
      "  Test Loss: 1.916\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 55 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.203\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.378\n",
      "  Test Loss: 1.908\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 56 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.210\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.380\n",
      "  Test Loss: 1.901\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 57 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.173\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.372\n",
      "  Test Loss: 1.896\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 58 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.119\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.375\n",
      "  Test Loss: 1.889\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 59 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.073\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.372\n",
      "  Test Loss: 1.881\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 60 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.070\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.380\n",
      "  Test Loss: 1.873\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 61 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.008\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 1.864\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 62 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 1.008\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.383\n",
      "  Test Loss: 1.855\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 63 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.964\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.388\n",
      "  Test Loss: 1.846\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 64 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.913\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 1.840\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 65 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.918\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 1.833\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 66 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.848\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.393\n",
      "  Test Loss: 1.827\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 67 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.844\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.393\n",
      "  Test Loss: 1.821\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 68 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.797\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.395\n",
      "  Test Loss: 1.817\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 69 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.750\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 1.815\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 70 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.769\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 1.811\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 71 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.719\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.390\n",
      "  Test Loss: 1.808\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 72 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.690\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.393\n",
      "  Test Loss: 1.806\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 73 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.674\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 1.803\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 74 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.632\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 1.801\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 75 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.633\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 1.800\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 76 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.625\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 1.800\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 77 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.558\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 1.799\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 78 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.541\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 1.798\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 79 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.536\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.797\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 80 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.512\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.796\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 81 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.519\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 1.798\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 82 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.480\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 1.797\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 83 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.460\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 1.797\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 84 / 400 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss discriminator: 0.463\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 1.798\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 85 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.464\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.802\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 86 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.450\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 1.812\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 87 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.408\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 1.819\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 88 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.412\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 1.816\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 89 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.407\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.807\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 90 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.380\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.805\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 91 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.351\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.806\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 92 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.347\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.808\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 93 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.357\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.812\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 94 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.327\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.817\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 95 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.330\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.821\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 96 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.323\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.823\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 97 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.298\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 1.827\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 98 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.304\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 1.832\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 99 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.295\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.838\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 100 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.278\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 1.842\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 101 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.272\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.846\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 102 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.260\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.849\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 103 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.243\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 1.855\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 104 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.237\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 1.861\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 105 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.246\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.864\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 106 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.242\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.865\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 107 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.218\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.868\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 108 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.225\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.870\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 109 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.206\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 1.871\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 110 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.202\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.874\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 111 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.216\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 1.880\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 112 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.199\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.889\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 113 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.202\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.893\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 114 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.185\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 1.895\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 115 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.187\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.898\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 116 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.163\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.903\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 117 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.174\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.911\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 118 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.167\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 1.918\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 119 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.171\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.921\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 120 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.158\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.922\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 121 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.157\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 1.922\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 122 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.169\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 1.923\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 123 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.154\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.925\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 124 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.149\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 1.927\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 125 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.146\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.405\n",
      "  Test Loss: 1.932\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 126 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.147\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.937\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 127 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.135\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.941\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 128 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.143\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.946\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 129 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.131\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 1.948\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 130 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.138\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.949\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 131 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.129\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 1.950\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 132 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.137\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.950\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 133 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.124\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.420\n",
      "  Test Loss: 1.952\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 134 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.126\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.417\n",
      "  Test Loss: 1.957\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 135 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.121\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.965\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 136 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.119\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.972\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 137 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.118\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.979\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 138 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.115\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.985\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 139 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.112\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.415\n",
      "  Test Loss: 1.989\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 140 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.107\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 1.992\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 141 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.112\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 1.997\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 142 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.114\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.000\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 143 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.105\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.002\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 144 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.108\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.004\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 145 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.103\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.007\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 146 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.099\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.011\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 147 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.107\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.014\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 148 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.107\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.015\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 149 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.097\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.017\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 150 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.098\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.021\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 151 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.096\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.025\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 152 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.091\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.029\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 153 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.092\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.035\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 154 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.093\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.042\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 155 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.090\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.048\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 156 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.087\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.052\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 157 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.086\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.398\n",
      "  Test Loss: 2.054\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 158 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.084\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.055\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 159 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.085\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.055\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 160 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.084\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.054\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 161 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.079\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.053\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 162 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.081\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.054\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 163 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.079\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 2.058\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 164 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.081\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 2.061\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 165 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.078\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.400\n",
      "  Test Loss: 2.065\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 166 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.076\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.070\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 167 / 400 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss discriminator: 0.080\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.073\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 168 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.076\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.076\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 169 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.074\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.080\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 170 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.075\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.085\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 171 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.076\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.090\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 172 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.073\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.094\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 173 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.070\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.098\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 174 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.073\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.102\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 175 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.072\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.105\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 176 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.068\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.107\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 177 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.066\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.111\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 178 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.068\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.115\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 179 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.064\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.119\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 180 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.066\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.123\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 181 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.065\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.126\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 182 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.064\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.129\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 183 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.064\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.132\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 184 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.063\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.135\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 185 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.062\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 2.137\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 186 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.058\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.138\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 187 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.060\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.139\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 188 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.062\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.141\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 189 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.059\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.142\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 190 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.059\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.143\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 191 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.060\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.146\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 192 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.059\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.149\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 193 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.057\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.151\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 194 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.058\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.153\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 195 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.057\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.154\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 196 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.055\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.156\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 197 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.054\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.158\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 198 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.053\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.160\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 199 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.055\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.162\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 200 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.055\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.164\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 201 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.053\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.167\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 202 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.054\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.169\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 203 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.056\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.171\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 204 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.055\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.172\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 205 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.052\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.175\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 206 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.052\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.179\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 207 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.049\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.184\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 208 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.050\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.188\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 209 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.049\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.191\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 210 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.049\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.193\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 211 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.050\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.196\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 212 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.048\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.199\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 213 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.048\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.202\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 214 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.048\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.204\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 215 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.047\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.208\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 216 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.046\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.212\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 217 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.048\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.215\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 218 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.047\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.217\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 219 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.044\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.219\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 220 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.046\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.220\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 221 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.046\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.221\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 222 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.045\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.223\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 223 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.044\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.224\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 224 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.043\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.226\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 225 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.044\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.228\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 226 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.044\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.232\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 227 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.043\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.235\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 228 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.042\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.239\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 229 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.042\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.242\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 230 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.045\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.246\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 231 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.041\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.250\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 232 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.041\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.252\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 233 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.042\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.254\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 234 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.040\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.256\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 235 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.039\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.257\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 236 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.038\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.258\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 237 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.038\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.260\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 238 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.039\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.263\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 239 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.040\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.264\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 240 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.037\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.267\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 241 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.039\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.270\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 242 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.040\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.272\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 243 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.036\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.275\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 244 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.037\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.277\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 245 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.037\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.279\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 246 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.038\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.282\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 247 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.035\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.284\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 248 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.038\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.285\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 249 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.035\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.287\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 250 / 400 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss discriminator: 0.036\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.289\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 251 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.035\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.291\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 252 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.036\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.293\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 253 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.036\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.295\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 254 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.035\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.297\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 255 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.035\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.300\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 256 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.035\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.303\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 257 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.034\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.306\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 258 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.034\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.308\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 259 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.033\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.310\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 260 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.033\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.312\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 261 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.034\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.313\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 262 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.032\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.315\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 263 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.036\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.317\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 264 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.034\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.319\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 265 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.032\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.321\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 266 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.031\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.323\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 267 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.032\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.325\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 268 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.031\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.326\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 269 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.031\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.327\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 270 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.033\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.328\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 271 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.030\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.331\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 272 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.028\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.333\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 273 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.030\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.335\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 274 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.029\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.337\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 275 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.030\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.339\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 276 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.030\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.340\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 277 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.029\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.342\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 278 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.029\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.344\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 279 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.027\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.347\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 280 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.029\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.350\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 281 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.028\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.353\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 282 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.029\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.355\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 283 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.028\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.357\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 284 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.030\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.359\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 285 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.030\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.361\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 286 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.027\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.363\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 287 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.027\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.365\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 288 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.028\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.366\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 289 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.027\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.366\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 290 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.028\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.366\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 291 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.026\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.368\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 292 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.027\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.370\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 293 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.028\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.373\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 294 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.027\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.375\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 295 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.378\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 296 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.026\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.380\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 297 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.383\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 298 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.026\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.386\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 299 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.028\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.391\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 300 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.026\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.403\n",
      "  Test Loss: 2.394\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 301 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.026\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.398\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 302 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.400\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 303 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.026\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.401\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 304 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.027\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.401\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 305 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.024\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.400\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 306 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.024\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.400\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 307 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.024\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.400\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 308 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.400\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 309 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.401\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 310 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.024\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.402\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 311 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.404\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 312 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.406\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 313 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.409\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 314 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.412\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 315 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.025\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.415\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 316 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.417\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 317 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.420\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 318 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.422\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 319 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.424\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 320 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.426\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 321 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.024\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.427\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 322 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.429\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 323 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.022\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.431\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 324 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.433\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 325 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.022\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.435\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 326 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.437\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 327 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.441\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 328 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.445\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 329 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.448\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 330 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.022\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.452\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 331 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.023\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.453\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 332 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.454\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 333 / 400 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss discriminator: 0.024\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.454\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 334 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.454\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 335 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.022\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.455\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 336 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.456\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 337 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.022\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.458\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 338 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.022\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.459\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 339 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.461\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 340 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.462\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 341 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.464\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 342 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.466\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 343 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.469\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 344 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.470\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 345 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.472\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 346 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.022\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.474\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 347 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.476\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 348 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.020\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.477\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 349 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.020\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.478\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 350 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.480\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 351 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.021\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.482\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 352 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.483\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 353 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.485\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 354 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.020\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.486\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 355 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.487\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 356 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.489\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 357 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.490\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 358 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.492\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 359 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.020\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.494\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 360 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.496\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 361 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.497\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 362 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 2.498\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 363 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 2.500\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 364 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 2.501\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 365 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 2.503\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 366 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.504\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 367 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.506\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 368 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 2.508\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 369 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.509\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 370 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.019\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.511\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 371 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.513\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 372 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.514\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 373 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.516\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 374 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.518\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 375 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.519\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 376 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.521\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 377 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.412\n",
      "  Test Loss: 2.523\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 378 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.526\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 379 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.528\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 380 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.530\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 381 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.532\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 382 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.535\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 383 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.536\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 384 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.537\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 385 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.539\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 386 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.405\n",
      "  Test Loss: 2.540\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 387 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.542\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 388 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.543\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 389 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.544\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 390 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.545\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 391 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.546\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 392 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.548\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 393 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.550\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 394 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.550\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 395 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.552\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 396 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.017\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.553\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 397 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.015\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.554\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 398 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.555\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 399 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.407\n",
      "  Test Loss: 2.556\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 400 / 400 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss discriminator: 0.016\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.410\n",
      "  Test Loss: 2.556\n",
      "  Test took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "accuracy_array=[]\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "#g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
    "#gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "#   scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "#                                            num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    #tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "    #generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_label_mask = batch[3].to(device)\n",
    "\n",
    "        real_batch_size = b_input_ids.shape[0]\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        #hidden_states = model_outputs[-1]\n",
    "        hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "        #print(hidden_states[0].size())\n",
    "        \n",
    "        # Generate fake data that should have the same distribution of the ones\n",
    "        # encoded by the transformer. \n",
    "        # First noisy input are used in input to the Generator\n",
    "        #noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "        # Gnerate Fake data\n",
    "        #gen_rep = generator(noise)\n",
    "        #print(\"Length of generator output {}\".format(len(gen_rep)))\n",
    "        #print(\"Length of single generator output {}\".format(len(gen_rep[0])))\n",
    "\n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        #disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(hidden_states)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        features_list = torch.split(features, real_batch_size)\n",
    "        D_real_features = features_list[0]\n",
    "        #D_fake_features = features_list[1]\n",
    "      \n",
    "        logits_list = torch.split(logits, real_batch_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "        #D_fake_logits = logits_list[1]\n",
    "        \n",
    "        probs_list = torch.split(probs, real_batch_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        #D_fake_probs = probs_list[1]\n",
    "\n",
    "        #---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        #---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "#         g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "#         g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "#         g_loss = g_loss_d + g_feat_reg\n",
    "  \n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:,0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples, \n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "          D_L_Supervised = 0\n",
    "        else:\n",
    "          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "                 \n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        #D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U #+ D_L_unsupervised2U\n",
    "\n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        #gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        #g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward() \n",
    "        \n",
    "        # Apply modifications\n",
    "        #gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        #tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "          #scheduler_d.step()\n",
    "          scheduler_g.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    #avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    #print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "    discriminator.eval()\n",
    "    #generator.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            #hidden_states = model_outputs[-1]\n",
    "            hidden_states = model_outputs.last_hidden_state[:,0,:]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            #'Training Loss generator': avg_train_loss_g,\n",
    "            'Training Loss discriminator': avg_train_loss_d,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    accuracy_array.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fa12c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb72c9fd160>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "892efa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cd2901f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_array[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a448ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
